'use strict';(function(){const indexCfg={cache:true};indexCfg.doc={id:'id',field:['title','content'],store:['title','href'],};const index=FlexSearch.create('balance',indexCfg);window.bookSearchIndex=index;index.add({'id':0,'href':'/library/tutorials/docs/articles/data-science/pandas/simple-example-based-guide/','title':"A Simple Example-Based Guide",'content':" NumPy Tutorial: A Simple Example-Based Guide  Introduction Advantages of NumPy NumPy Operations Creating a NumPy Array  The array Method The arange Method The zeros Method The ones Method The linspace Method The eye Method The random Method  Reshaping NumPy Array Finding Max/Min Values Array Indexing in NumPy  Indexing with 1-D Arrays Indexing with 2-D Arrays  Arithmetic Operations with NumPy Arrays  The log Function The exp Function The sqrt Function The sin Function  Linear Algebra Operations with NumPy Arrays  Finding the Vector Dot Product Matrix Multiplication Finding the Inverse of a Matrix Finding the Determinant of a Matrix Finding the Trace of a Matrix  Conclusion  Introduction The NumPy library is a popular Python library used for scientific computing applications, and is an acronym for \u0026ldquo;Numerical Python\u0026rdquo;. NumPy\u0026rsquo;s operations are divided into three main categories: Fourier Transform and Shape Manipulation, Mathematical and Logical Operations, and Linear Algebra and Random Number Generation. To make it as fast as possible, NumPy is written in C and Python.\nIn this article, we will provide a brief introduction to the NumPy stack and we will see how the NumPy library can be used to perform a variety of mathematical tasks.\nAdvantages of NumPy NumPy has several advantages over using core Python mathemtatical functions, a few of which are outlined here:\n NumPy is extremely fast when compared to core Python thanks to its heavy use of C extensions. Many advanced Python libraries, such as Scikit-Learn, Scipy, and Keras, make extensive use of the NumPy library. Therefore, if you plan to pursue a career in data science or machine learning, NumPy is a very good tool to master. NumPy comes with a variety of built-in functionalities, which in core Python would take a fair bit of custom code.  Regarding the last point, take a look at the following script:\nx = [2, 3, 4, 5, 6] y = [a + 2 for a in x]  Here, in order to add 2 to each element in the list x, we have to traverse the entire list and add 2 to each element individually. Now let\u0026rsquo;s see how we can perform the same task with the NumPy library:\nimport numpy as np nums = np.array([2, 3, 4, 5, 6]) nums2 = nums + 2  You can see how easy it is to add a scalar value to each element in the list via NumPy. It is not only readable, but also faster when compared to the previous code.\nThis is just the tip of the iceberg, in reality, the NumPy library is capable of performing far more complex operations in the blink of an eye. Let\u0026rsquo;s explore some of these operations.\nNumPy Operations Before we can perform any NumPy operations, we need to install the NumPy package. To install the NumPy package, you can use the pip installer. Execute the following command to install:\n$ pip install numpy  Otherwise, if you are running Python via the Anaconda distribution, you can execute the following command instead:\n$ conda install numpy  Now that NumPy is installed, let\u0026rsquo;s see some of the most common operations of the library.\nCreating a NumPy Array NumPy arrays are the building blocks of most of the NumPy operations. The NumPy arrays can be divided into two types: One-dimensional arrays and Two-Dimensional arrays.\nThere are several ways to create a NumPy array. In this section, we will discuss a few of them.\nThe array Method To create a one-dimensional NumPy array, we can simply pass a Python list to the array method. Check out the following script for an example:\nimport numpy as np x = [2, 3, 4, 5, 6] nums = np.array([2, 3, 4, 5, 6]) type(nums)  In the script above we first imported the NumPy library as np, and created a list x. We then passed this list to the array function of the NumPy library. Finally, we printed the type of the array, which resulted in the following output:\nnumpy.ndarray  If you were to print the nums array on screen, you would see it displayed like this:\narray([2, 3, 4, 5, 6])  To create a two-dimensional array, you can pass a list of lists to the array method as shown below:\nnums = np.array([[2,4,6], [8,10,12], [14,16,18]])  The above script results in a matrix where every inner list in the outer list becomes a row. The number of columns is equal to the number of elements in each inner list. The output matrix will look like this:\narray([[ 2, 4, 6], [ 8, 10, 12], [14, 16, 18]])  The arange Method Another commonly used method for creating a NumPy array is the arange method. This method takes the start index of the array, the end index, and the step size (which is optional). Take a look at the following example:\nnums = np.arange(2, 7)  Simple enough, right? The above script will return a NumPy array of size 5 with the elements 2, 3, 4, 5, and 6. Remember that the arange method returns an array that starts with the starting index and ends at one index less than the end index. The output of this code looks like this:\narray([2, 3, 4, 5, 6])  Now let\u0026rsquo;s add a step size of 2 to our array and see what happens:\nnums = np.arange(2, 7, 2)  The output now looks like this:\narray([2, 4, 6])  You can see that array starts at 2, followed by a step size of 2 and ends at 6, which is one less than the end index.\nThe zeros Method Apart from generating custom arrays with your pre-filled data, you can also create NumPy arrays with a simpler set of data. For instance, you can use the zeros method to create an array of all zeros as shown below:\nzeros = np.zeros(5)  The above script will return a one-dimensional array of 5 zeros. Print the zeros array and you should see the following:\narray([0., 0., 0., 0., 0.])  Similarly, to create a two-dimensional array, you can pass both the number of rows and columns to the zeros method, as shown below:\nzeros = np.zeros((5, 4))  The above script will return a two-dimensional array of 5 rows and 4 columns:\narray([[0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.]])  The ones Method Similarly, you can create one-dimensional and two-dimensional arrays of all ones using the ones method as follows:\nones = np.ones(5)  array([1., 1., 1., 1., 1.])  And again, for the two-dimensional array, try out the following code:\nones = np.ones((5, 4))  Now if you print the ones array on the screen, you should see the following two-dimensional array:\n[[1. 1. 1. 1.] [1. 1. 1. 1.] [1. 1. 1. 1.] [1. 1. 1. 1.] [1. 1. 1. 1.]]  The linspace Method Another very useful method to create NumPy arrays is the linspace method. This method takes three arguments: a start index, end index, and the number of linearly-spaced numbers that you want between the specified range. For instance, if the first index is 1, the last index is 10 and you need 10 equally spaced elements within this range, you can use the linspace method as follows:\nlin = np.linspace(1, 10, 10)  The output will return integers from 1 to 10:\narray([1., 2., 3., 4., 5., 6., 7., 8., 9., 10.])  Now let\u0026rsquo;s try to create an array with 20 linearly-spaced elements between 1 and 10. Execute the following script:\nlin = np.linspace(1, 10, 20)  This will result in the following array:\narray([ 1. , 1.47368421, 1.94736842, 2.42105263, 2.89473684, 3.36842105, 3.84210526, 4.31578947, 4.78947368, 5.26315789, 5.73684211, 6.21052632, 6.68421053, 7.15789474, 7.63157895, 8.10526316, 8.57894737, 9.05263158, 9.52631579, 10. ])  Notice that the output might look like a matrix, but actually it is a one-dimensional array. Because of the spacing issue, the elements have been displayed in multiple lines.\nThe eye Method The eye method can be used to create an identity matrix, which can be very useful to perform a variety of operations in linear algebra. An identity matrix is a matrix with zeros across rows and columns except the diagonal. The diagonal values are all ones. Let\u0026rsquo;s create a 4x4 identity matrix using the eye method:\nidn = np.eye(4)  The resultant matrix looks like this:\narray([[1., 0., 0., 0.], [0., 1., 0., 0.], [0., 0., 1., 0.], [0., 0., 0., 1.]])  The random Method Often times you will need to create arrays with random numbers. You can use the rand function of NumPy\u0026rsquo;s random module to do so. Here is a simple example of the rand function:\nrandom = np.random.rand(2, 3)  The above script returns a matrix of 2 rows and 3 columns. The matrix contains uniform distribution of numbers between 0 and 1:\narray([[0.26818562, 0.65506793, 0.50035001], [0.527117 , 0.445688 , 0.99661 ]])  Similarly, to create a matrix of random numbers with the Gaussian distribution (or \u0026ldquo;normal\u0026rdquo; distribution), you can instead use the randn method as shown below:\nrandom = np.random.randn(2, 3)  Finally, to create an array of random integers, the randint method exists for such a case. The randint method takes the lower bound, upper bound, and the number of integers to return. For instance, if you want to create an array of 5 random integers between 50 and 100, you can use this method as follows:\nrandom = np.random.randint(50, 100, 5)  In our case, the output looked like this:\narray([54, 59, 84, 62, 74])  It is important to mention that these numbers are generated randomly every time you call the method, so you will see different numbers than in our example.\nWe saw different ways of creating Python arrays. Let\u0026rsquo;s now explore some of the other array functions.\nReshaping NumPy Array Using NumPy you can convert a one-dimensional array into a two-dimensional array using the reshape method.\nLet\u0026rsquo;s first create an array of 16 elements using the arange function. Execute the following code:\nnums = np.arange(1, 17)  The nums array is a one-dimensional array of 16 elements, ranging from 1 to 16:\narray([ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16])  Nos let\u0026rsquo;s convert it into a two-dimensional array of 4 rows and 4 columns:\nnums2 = nums.reshape(4, 4)  The array now looks like this:\narray([[ 1, 2, 3, 4], [ 5, 6, 7, 8], [ 9, 10, 11, 12], [13, 14, 15, 16]])  It is pertinent to mention that you cannot reshape an array if the number of elements in the one-dimensional array is not equal to the product of rows and columns of the reshaped array. For instance, if you have 45 elements in a 1-d array, you cannot reshape it into a matrix of 5 row and 10 columns since a 5x10 matrix has 50 elements and the original one only has 45.\nFinding Max/Min Values You can use min/max functions to easily find the value of the smallest and largest number in your array. For our example, let\u0026rsquo;s first create an array of 5 random integers:\nrandom = np.random.randint(1, 100, 5) print(random)  Our array of random integers looks like this:\n[51 40 84 38 1]  Remember, these numbers are generated randomly, therefore you will most likely have a different set of numbers. Let\u0026rsquo;s use min and max functions to find the minimum and maxim values from the array that we just created. To do so, execute the following code to find minimum value:\nxmin = random.min() print(xmin)  \u0026ldquo;1\u0026rdquo; will be printed in the output.\nSimilarly, for maximum value, execute the following code:\nxmax = random.max() print(xmax)  The above script will return \u0026ldquo;84\u0026rdquo; as the output.\nYou can also find the index of the maximum and minimum values using the argmax() and argmin() functions. Take a look at the following script:\nprint(random.argmax())  The above script will print \u0026ldquo;2\u0026rdquo; since 84 is the largest number in the list and it is located at the second position of the array.\nSimilarly, the argmin() will return \u0026ldquo;4\u0026rdquo; because 1 is the smallest number and is located at the 4th position.\nArray Indexing in NumPy In order to effectively use the NumPy arrays, it is very important to understand the way the arrays are indexed, which I\u0026rsquo;ll discuss in the next few sections.\nIndexing with 1-D Arrays Let\u0026rsquo;s create a simple array of 15 numbers:\nnums = np.arange(1, 16)  You can retrieve any element by passing the index number. Just like Python\u0026rsquo;s lists, NumPy\u0026rsquo;s arrays are zero-indexed. For instance, to find the element at the second index (3rd position) of the array, you can use the following syntax:\nprint(nums[2])  We have the digit 3 at the second index, therefore it will be printed on the screen.\nSubscribe to our Newsletter Get occassional tutorials, guides, and reviews in your inbox. No spam ever. Unsubscribe at any time.\nSubscribe\nYou can also print a range of numbers using indexing. To get the range, you need to pass the start index and one less than the end index, separated by a colon, inside the square brackets that follow the array name. For example, to get the elements from the first to seventh index, you can use the following syntax:\nprint(nums[1:8])  The above script will print the integers from 2 to 8:\n[2 3 4 5 6 7 8]  Here in the nums array, we have 2 at index 1 and 8 at index seven.\nYou can also slice an array and assign the elements of the sliced array to a new array:\nnums2 = nums[0:8] print(nums2)  In the script above we sliced the nums array by extracting its first 8 elements. The resultant elements are assigned to the nums2 array. We then print the nums2 array to the console. The output is a new array of the first 8 numbers:\n[1 2 3 4 5 6 7 8]  Indexing with 2-D Arrays Indexing a two-dimensional NumPy array is very similar to indexing a matrix. Let\u0026rsquo;s first create 3x3 two-dimensional NumPy array. To do so, run the following code:\nnums2d = np.array(([1,2,3],[4,5,6],[7,8,9]))  Now let\u0026rsquo;s print it out:\nprint(nums2d)  [[1 2 3] [4 5 6] [7 8 9]]  Like 1-D arrays, NumPy arrays with two dimensions also follow the zero-based index, that is, in order to access the elements in the first row, you have to specify 0 as the row index. Similarly to access elements in the first column, you need to specify 0 for the column index as well.\nLet\u0026rsquo;s retrieve an element from nums2d array, located in the first row and first column:\nprint(nums2d[0, 0])  You will see \u0026ldquo;1\u0026rdquo; in the output. Similarly, we can retrieve the element at the third row and third column as follows:\nprint(nums2d[2, 2])  You will see \u0026ldquo;9\u0026rdquo; in the output.\nIn addition to extracting a single element, you can extract the whole row by passing only the row index to the square brackets. For instance, the following script returns the first row from the nums2d array:\nprint(nums2d[0])  The output just a one-dimensional array:\n[1 2 3]  Similarly to retrieve the first column only, you can use the following syntax:\nprint(nums2d[:,0])  The output is, again, an array, but it is a combination of the first elements of each array of the two-dimensional array:\n[1 4 7]  Finally, to retrieve the elements from the first two rows and first two columns, the following syntax can be used:\nprint(nums2d[:2,:2])  The above script returns the following output:\n[[1 2] [4 5]]  Arithmetic Operations with NumPy Arrays For the examples in this section, we will use the nums array that we created in the last section.\nLet\u0026rsquo;s first add two arrays together:\nnums3 = nums + nums  You can add two arrays together with the same dimensions. For instance, the nums array contained 15 elements, therefore we can add it to itself. The elements at the corresponding indexes will be added. Now if you print the nums3 array, the output looks like this:\n[ 2 4 6 8 10 12 14 16 18 20 22 24 26 28 30]  As you can see, each position is the sum of the 2 elements at that position in the original arrays.\nIf you add an array with a scalar value, the value will be added to each element in the array. Let\u0026rsquo;s add 10 to the nums array and print the resultant array on the console. Here is how you\u0026rsquo;d do it:\nnums3 = nums + 10 print(nums3)  And the resulting nums3 array becomes:\n[11 12 13 14 15 16 17 18 19 20 21 22 23 24 25]  Subtraction, addition, multiplication, and division can be performed in the same way.\nApart from simple arithmetic, you can execute more complex functions on the Numpy arrays, e.g. log, square root, exponential, etc.\nThe log Function The following code simply returns an array with the log of all elements in the input array:\nnums3 = np.log(nums) print(nums3)  The output looks like this:\n[0. 0.69314718 1.09861229 1.38629436 1.60943791 1.79175947 1.94591015 2.07944154 2.19722458 2.30258509 2.39789527 2.48490665 2.56494936 2.63905733 2.7080502 ]  The exp Function The following script returns an array with exponents of all elements in the input array:\nnums3 = np.exp(nums) print(nums3)  [2.71828183e+00 7.38905610e+00 2.00855369e+01 5.45981500e+01 1.48413159e+02 4.03428793e+02 1.09663316e+03 2.98095799e+03 8.10308393e+03 2.20264658e+04 5.98741417e+04 1.62754791e+05 4.42413392e+05 1.20260428e+06 3.26901737e+06]  The sqrt Function The following script returns an array with the square roots of all the elements in the input array:\nnums3 = np.sqrt(nums) print(nums3)  [1. 1.41421356 1.73205081 2. 2.23606798 2.44948974 2.64575131 2.82842712 3. 3.16227766 3.31662479 3.46410162 3.60555128 3.74165739 3.87298335]  The sin Function The following script returns an array with the sine of all the elements in the input array:\nnums3 = np.sin(nums) print(nums3)  [ 0.84147098 0.90929743 0.14112001 -0.7568025 -0.95892427 -0.2794155 0.6569866 0.98935825 0.41211849 -0.54402111 -0.99999021 -0.53657292 0.42016704 0.99060736 0.65028784]  Linear Algebra Operations with NumPy Arrays One of the biggest advantages of the NumPy arrays is their ability to perform linear algebra operations, such as the vector dot product and the matrix dot product, much faster than you can with the default Python lists.\nFinding the Vector Dot Product Computing the vector dot product for the two vectors can be calculated by multiplying the corresponding elements of the two vectors and then adding the results from the products.\nLet\u0026rsquo;s create two vectors and try to find their dot product manually. A vector in NumPy is basically just a 1-dimensional array. Execute the following script to create our vectors:\nx = np.array([2,4]) y = np.array([1,3])  The dot product of the above two vectors is (2 x 1) + (4 x 3) = 14.\nLet\u0026rsquo;s find the dot product without using the NumPy library. Execute the following script to do so:\ndot_product = 0 for a,b in zip(x,y): dot_product += a * b print(dot_product)  In the script above, we simply looped through corresponding elements in x and y vectors, multiplied them and added them to the previous sum. If you run the script above, you will see \u0026ldquo;14\u0026rdquo; printed to the console.\nNow, let\u0026rsquo;s see how we can find the dot product using the NumPy library. Look at the following script:\na = x * y print(a.sum())  We know that if we multiply the two NumPy arrays, the corresponding elements from both arrays are multiplied based on their index. In the script above, we simply multiplied the x and y vectors. We then call the sum method on the resultant array, which sums all the elements of the array. The above script will also return \u0026ldquo;14\u0026rdquo; in the output.\nThe above method is simple, however, the NumPy library makes it even easier to find the dot product via the dot method, as shown here:\nprint(x.dot(y))  For very large arrays you should also notice a speed improvement over our Python-only version, thanks to NumPy\u0026rsquo;s use of C code to implement many of its core functions and data structures.\nMatrix Multiplication Like the dot product of two vectors, you can also multiply two matrices. In NumPy, a matrix is nothing more than a two-dimensional array. In order to multiply two matrices, the inner dimensions of the matrices must match, which means that the number of columns of the matrix on the left should be equal to the number of rows of the matrix on the right side of the product. For instance, if a matrix X has dimensions [3,4] and another matrix Y has dimensions of [4,2], then the matrices X and Y can be multiplied together. The resultant matrix will have the dimensions [3,2], which is the size of the outer dimensions.\nTo multiply two matrices, the dot function can be used as shown below:\nX = np.array(([1,2,3], [4,5,6])) Y = np.array(([1,2], [4,5], [7,8])) Z = np.dot(X, Y) print(Z)  In the script above we created a 3x2 matrix named X and a 2x3 matrix named Y. We then find the dot product of the two matrices and assigned the resultant matrix to the variable Z. Finally, we print the resultant matrix to the console. In the output you should see a 2x2 matrix as shown below:\n[[30 36] [66 81]]  You can also multiply the two matrices element-wise. To do so, the dimensions of the two matrices must match, just like when we were adding arrays together. The multiply function is used for element-wise multiplication.\nLet\u0026rsquo;s try to multiply the matrices X and Y element-wise:\nZ = np.multiply(X, Y)  The following error will occur when you run the above code:\nValueError: operands could not be broadcast together with shapes (2,3) (3,2)  The error occurs due to the mismatch between the dimensions of the X and Y matrices. Now, let\u0026rsquo;s try multiplying the X matrix with itself using the multiply function:\nZ = np.multiply(X, X)  Now if you print the Z matrix, you should see the following result:\n[[ 1 4 9] [16 25 36]]  The X matrix was successfully able to multiple with itself because the dimensions of the multiplied matrices matched.\nFinding the Inverse of a Matrix Another very useful matrix operation is finding the inverse of a matrix. The NumPy library contains the ìnv function in the linalg module.\nFor our example, let\u0026rsquo;s find the inverse of a 2x2 matrix. Take a look at the following code:\nY = np.array(([1,2], [3,4])) Z = np.linalg.inv(Y) print(Z)  The output of the above code looks like this:\n[[-2. 1. ] [ 1.5 -0.5]]  Now in order to verify if the inverse has been calculated correctly, we can take the dot product of a matrix with its inverse, which should yield an identity matrix.\nW = Y.dot(Z) print(W)  [[1.00000000e+00 1.11022302e-16] [0.00000000e+00 1.00000000e+00]]  And the result was as we expected. Ones in the diagonal and zeros (or very close to zero) elsewhere.\nFinding the Determinant of a Matrix The determinant of a matrix can be calculated using the det method, which is shown here:\nX = np.array(([1,2,3], [4,5,6], [7,8,9])) Z = np.linalg.det(X) print(Z)  In the script above, we created a 3x3 matrix and found its determinant using the det method. In the output, you should see \u0026ldquo;6.66133814775094e-16\u0026rdquo;.\nFinding the Trace of a Matrix The trace of a matrix is the sum of all the elements in the diagonal of a matrix. The NumPy library contains trace function that can be used to find the trace of a matrix. Look at the following example:\nX = np.array(([1,2,3], [4,5,6], [7,8,9])) Z = np.trace(X) print(Z)  In the output, you should see \u0026ldquo;15\u0026rdquo;, since the sum of the diagonal elements of the matrix X is 1 + 5 + 9 = 15.\nConclusion Pythons NumPy library is one of the most popular libraries for numerical computing. In this article, we explored the NumPy library in detail with the help of several examples. We also showed how to perform different linear algebra operations via the NumPy library, which are commonly used in many data science applications.\nWhile we covered quite a bit of NumPy\u0026rsquo;s core functionality, there is still a lot to learn. If you want to learn more, I\u0026rsquo;d suggest you try out a course like Data Science in Python, Pandas, Scikit-learn, Numpy, Matplotlib, which covers NumPy, Pandas, Scikit-learn, and Matplotlib in much more depth than what we were able to cover here.\nI would suggest you practice the examples in this article. If you are planning to start a career as a data scientist, the NumPy library is definitely one of the tools that you must need to learn to be a successful and productive member of the field.\nReference : https://stackabuse.com/numpy-tutorial-a-simple-example-based-guide/\n"});index.add({'id':1,'href':'/library/tutorials/docs/articles/data-science/pandas/','title':"Pandas",'content':" Pandas  Pandas Documentation  "});index.add({'id':2,'href':'/library/tutorials/docs/articles/python/','title':"Python",'content':" Python "});index.add({'id':3,'href':'/library/tutorials/docs/articles/data-science/pandas/10_pandas_tip/','title':"10 Pandas tips",'content':" 10 Python Pandas tips to make data analysis faster Source\n1. Styling Have you ever complained about the table output looks boring when you do .head() in Jupyter notebooks? Is there a way not to display indexes (especially when there is already an ID column)? There’re ways to fix these issues.\nA. Highlight all negative values in a dataframe. (example revised from https://pandas.pydata.org/pandas-docs/stable/user_guide/style.html)\nimport pandas as pd def color_negative_red(val): color = 'red' if val \u0026lt; 0 else 'black' return 'color: %s' % colordf = pd.DataFrame(dict(col_1=[1.53,-2.5,3.53], col_2=[-4.1,5.9,0]) ) df.style.applymap(color_negative_red)  B. Hide the index. Try df.head().style.hide_index()!\nC. Add hovering effects. (example revised from https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.io.formats.style.Styler.set_table_styles.html)\ndf = pd.DataFrame(np.random.randn(5, 3)) df.style.set_table_styles( [{'selector': 'tr:hover', 'props': [('background-color', 'yellow')]}] )  D. More CSS styles. You can use CSS to change the appearance of the table.\ndf = pd.DataFrame( dict(departure=['SFO', 'SFO', 'LAX', 'LAX', 'JFK', 'SFO'], arrival=['ORD', 'DFW', 'DFW', 'ATL', 'ATL', 'ORD'], airlines=['Delta','JetBlue','Delta',’AA','SouthWest', 'Delta']), columns=['airlines', 'departure','arrival']) df.style.set_table_styles( [{'selector': 'tr:nth-of-type(odd)', 'props': [('background', '#eee')]}, {'selector': 'tr:nth-of-type(even)', 'props': [('background', 'white')]}, {'selector': 'th', 'props': [('background', '#606060'), ('color', 'white'), ('font-family', 'verdana')]}, {'selector': 'td', 'props': [('font-family', 'verdana')]}, ] ).hide_index()  2. Pandas options The reader may have experienced the following issues when using .head(n) to check the dataframe:\n(1) There’re too many columns / rows in the dataframe and some columns / rows in the middle are omitted.\n(2) Columns containing long texts get truncated.\n(3) Columns containing floats display too many / too few digits.\nOne can set\nimport pandas as pd pd.options.display.max_columns = 50 # None -\u0026gt; No Restrictions pd.options.display.max_rows = 200 # None -\u0026gt; Be careful with this pd.options.display.max_colwidth = 100 pd.options.display.precision = 3  to solve these issues.\n3. Group by with multiple aggregations In SQL we can do aggregations like\nSELECT A, B, max(A), avg(A), sum(B), min(B), count(*) FROM table GROUP BY A, B  In Pandas it can be done with .groupby() and .agg():\nimport pandas as pd import numpy as np df = pd.DataFrame(dict(A=['coke', 'sprite', 'coke', 'sprite', 'sprite', 'coke', 'coke'], B=['alpha','gamma', 'alpha', 'beta', 'gamma', 'beta', 'beta'], col_1=[1,2,3,4,5,6,7], col_2=[1,6,2,4,7,9,3])) tbl = df.groupby(['A','B']).agg({'col_1': ['max', np.mean], 'col_2': ['sum','min','count']}) # 'count' will always be the count for number of rows in each group.  And the result will look like this:\nBoth the rows and columns are multi-indexed. A quick solution to change it to a dataframe without multi-indices is\ntbl = tbl.reset_index() tbl.columns = ['A', 'B', 'col_1_max', 'col_2_sum', 'col_2_min', 'count']  If you would like to have the column renaming process automated, you can do tbl.columns.get_level_values(0) and tbl.columns.get_level_values(1) to extract the indices in each level and combine them.\n4. Column slicing Some of you might be familiar with this already, but I still find it very useful when handling a dataframe with a ton of columns.\ndf.iloc[:,2:5].head() # select the 2nd to the 4th column df.loc[:,'column_x':].head() # select all columns starting from 'column_x'  5. Add row ID / random row ID to each group To add a row ID / random row ID for each group by A, B, one can first append an ID / random ID to all rows:\nimport numpy as np # df: target dataframe np.random.seed(0) # set random seed df['random_ID_all'] = np.random.permutation(df.shape[0]) df['ID_all'] = [i for i in range(1, df.shape[0]+1)]  To add a random ID to each group (by A, B), one can then do\ndf['ID'] = df.groupby(['A', 'B'])['ID_all'].rank(method='first',ascending=True).astype(int) df['random_ID'] = df.groupby(['A', 'B'])'random_ID_all'].rank(method='first',ascending=True).astype(int)  to get\n6. List all unique values in a group Sometimes after we performed group by, we’d like to aggregate the values in the target column as a list of unique values instead of max, min, …etc. This is how it’s done.\ndf = pd.DataFrame(dict(A=['A','A','A','A','A','B','B','B','B'], B=[1,1,1,2,2,1,1,1,2], C=['CA','NY','CA','FL','FL', 'WA','FL','NY','WA'])) tbl = df[['A', 'B', 'C']].drop_duplicates()\\ .groupby(['A','B'])['C']\\ .apply(list)\\ .reset_index() # list to string (separated by commas) tbl['C'] = tbl.apply(lambda x: (','.join([str(s) for s in x['C']])), axis = 1)  If you’d like to save the result, don’t forget to change the separator to anything other than commas.\n7. Add row total and column total to a numerical dataframe This is another common data manipulation. All you need is .apply().\ndf = pd.DataFrame(dict(A=[2,6,3], B=[2,2,6], C=[3,2,3])) df['col_total'] = df.apply(lambda x: x.sum(), axis=1) df.loc['row_total'] = df.apply(lambda x: x.sum())  8. Check memory usage **.memory_usage(deep=True)** can be used on Pandas dataframes to see the amount of memory used (in bytes) for each column. It’s useful when building machine learning models which may require a lot memory in training.\n9. Cumulative sum From time to time, cumulative sum is required when you generate some statistical outcomes. Simply do `\ndf['cumulative_sum'] = df['target_column'].cumsum()` .  10. Crosstab When you need to count the frequencies for groups formed by 3+ features, pd.crosstab() can make your life easier.\nThanks for reading! Comment below if you find bugs / better solutions.\n"});index.add({'id':4,'href':'/library/tutorials/docs/articles/python/24-trick-python/','title':"24 เคล็ดลับ การใช้งาน Python",'content':" 24 เคล็ดลับ การใช้งาน Python Python เป็นอีกหนึ่งภาษา Programming ที่ได้รับความนิยม ถูกนำไปใช้ในการเขียน Program ได้หลากหลายประเภท โดยไม่ได้จำกัดอยู่ที่งานเฉพาะทางใดทางหนึ่ง ไม่ว่าจะเป็นการพัฒนา Web หรือด้าน Data Science และ Machine Learning เป็นต้น จึงทำให้มีการนำไปใช้กันอย่างแพร่หลาย วันนี้เรามาดู 24 เคล็ดลับ การใช้งาน Python ที่จะช่วยให้คุณประหยัดเวลาและทำงานได้สะดวกขึ้น โดยดูตัวอย่างการใช้งานในแต่ละหัวข้อกันได้เลย\n1. Unpacking Array Items (http://images.techstarthailand.com/images/blog/Article2019/TopPythonTips/01.png)\n2. Swapping Variables 3. Profile And Stats Of Your Code 3. Profile And Stats Of Your Code (http://images.techstarthailand.com/images/blog/Article2019/TopPythonTips/03.png)\n4. Repeat String (http://images.techstarthailand.com/images/blog/Article2019/TopPythonTips/04.png)\n5. Slicing (http://images.techstarthailand.com/images/blog/Article2019/TopPythonTips/05.png)\n6. Reversing \n7. Negative Index ถ้าคุณต้องการที่จะเริ่มต้นจาก Character ตัวสุดท้าย สามารถใช้ Negative Index ได้\n\n8. Intersect Sets กรณีต้องการดึงสมาชิกที่ซ้ำกันของทั้ง 2 Sets\n\n9. Difference In Sets กรณีต้องการดึงสมาชิกของ Set ที่ไม่เป็นสมาชิกของอีก Set หนึ่ง (ในตัวอย่างนี้ ต้องการดึงสมาชิกของ a ที่ไม่ซ้ำกับสมาชิกของ b)\n\n10. Union Of Collections กรณีต้องการดึงสมาชิกทั้งหมดของทั้ง 2 Sets\n\n11. Optional Arguments เราสามารถส่งผ่าน Optional Argument โดยระบุค่า Default ให้กับ Argument ได้:\n\n12. Unknown Arguments Using *arguments หาก Function ของคุณสามารถรับ Argument จำนวนเท่าใดก็ได้ ให้เพิ่ม * ไว้ที่ด้านหน้าของชื่อ Parameter:\n\n13. Dictionary As Arguments Using arguments จะช่วยให้คุณสามารถส่งผ่านจำนวน Keyword Arguments ที่แตกต่างกันไปยัง Function\nนอกจากนี้ คุณยังสามารถส่งผ่านค่า Dictionary เป็น Keyword Arguments ได้:\n\n14. Function With Multiple Outputs ใช้ในกรณีที่ Function ต้องการ Return Outputs หลาย ๆ ค่า:\n](http://images.techstarthailand.com/images/blog/Article2019/TopPythonTips/14.png)\n15. One Liner For Loops \n16. Combining Lists Using Zip  ใช้หลาย ๆ Collection แล้ว Return เป็น Collection ใหม่ Collection ใหม่ จะมี Items ที่แต่ละ Item ประกอบด้วย 1 Element จากแต่ละ Collection ที่ถูก Input เข้ามา ช่วยให้เราสามารถ Transverse ได้หลาย Collection ในเวลาเดียวกัน  \n17. Free up Memory เราสามารถเคลียร์หน่วยความจำ (Garbage Collection) แบบ Manual ได้ตามต้องการ\n\n18. Using Decorators  Decorators สามารถเพิ่ม Function การทำงานให้กับ Code ได้ มันเป็น Function ที่เรียก Object / Function อื่น ๆ ด้วยเหตุนี้ พวกมันจึง Return Object ที่จะถูกเรียกใช้ในภายหลังจากที่ Decorated Function ถูก Invoked Decorates ก็เปรียบเหมือนการใช้แนวคิดของ Aspect-Oriented Programming เราสามารถ Wrap Class/Function จากนั้น Code นั้นจะถูก Executed เมื่อใดก็ตามที่ Function ถูกเรียกใช้  (ตัวอย่างนี้ แสดงถึงวิธีการ Print ชื่อ Function นี่เป็นเพียงตัวอย่าง Code เพื่อแสดงให้เห็นถึงวิธีที่คุณสามารถเรียกใช้ Decorator คุณสามารถใช้ Decorator เพื่อเรียก Loggers ของคุณ, perform security operations เป็นต้น)\n\nและเมื่อเราใช้มันใน Function จะเป็นลักษณะดังนี้:\n\n19. Unzipping \n20. Joining Collection \n21. Memory Footprint Of An Object \n22. Print Current Directory \n23. Print Imported Modules \n24. Get Current Process Id \n ที่มา: https://medium.com/\n "});index.add({'id':5,'href':'/library/tutorials/docs/articles/python/71-python-code-snippet/','title':"71 Python Code Snippets",'content':" 71 Python Code Snippets for Everyday Problems POSTED ON DECEMBER 27, 2019 BY JEREMY GRIFSKI\nLast Updated on February 3, 2020\nIf you’ve been following me for any amount of time, you know that I regularly publish Python code snippets for everyday problems. Well, I figured I’d finally aggregate all those responses in one massive article with links to all those resources.\nAs a heads up, I’m looking to start porting all of the code snippets in this article to Jupyter Notebooks. If you’re interested in that kind of project, head on over to the GitHub repo. I’d appreciate the help!\nTable of Contents  Table of Contents Everyday Problems  Inverting a Dictionary Summing Elements of Two Lists Checking if a File Exists Converting Two Lists Into a Dictionary Checking if a List Is Empty Cloning a List Retrieving the Last Item of a List Making a Python Script Shortcut Sorting a List of Strings Parsing a Spreadsheet Sorting a List of Dictionaries Writing a List Comprehension Merging Two Dictionaries Formatting a String Printing on the Same Line Testing Performance  Share Your Own Problems  Everyday Problems In this section, we’ll take a look at various common scenarios that arise and how to solve them with Python code. Specifically, I’ll share a brief explanation of the problem with a list of Python code solutions. Then, I’ll link all the resources I have.\nInverting a Dictionary Sometimes when we have a dictionary, we want to be able to flip its keys and values. Of course, there are concerns like “how do we deal with duplicate values?” and “what if the values aren’t hashable?” That said, in the simple case, there are a few solutions:\n1. # Use to invert dictionaries that have unique values 2. my_inverted_dict = dict(map(reversed, my_dict.items())) 4. # Use to invert dictionaries that have unique values 5. my_inverted_dict = {value: key for key, value in my_dict.items()} 7. # Use to invert dictionaries that have non-unique values 8. from collections import defaultdict 9. my_inverted_dict = defaultdict(list) 10. {my_inverted_dict[v].append(k) for k, v in my_dict.items()} 12. # Use to invert dictionaries that have non-unique values 13. my_inverted_dict = dict() 14. for key, value in my_dict.items(): 15. my_inverted_dict.setdefault(value, list()).append(key) 17. # Use to invert dictionaries that have lists of values 18. my_dict = {value: key for key in my_inverted_dict for value in my_map[key]}  For more explanation, check out my article titled “How to Invert a Dictionary in Python.” It includes a breakdown of each solution, their performance metrics, and when they’re applicable. Likewise, I have a YouTube video which covers the same topic.\nSumming Elements of Two Lists Let’s say you have two lists, and you want to merge them together into a single list by element. In other words, you want to add the first element of the first list to the first element of the second list and store the result in a new list. Well, there are several ways to do that:\n1. ethernet_devices = [1, [7], [2], [8374163], [84302738]] 2. usb_devices = [1, [7], [1], [2314567], [0]] 4. # The long way 5. all_devices = [ 6. ethernet_devices[0] + usb_devices[0], 7. ethernet_devices[1] + usb_devices[1], 8. ethernet_devices[2] + usb_devices[2], 9. ethernet_devices[3] + usb_devices[3], 10. ethernet_devices[4] + usb_devices[4] 11. ] 13. # Some comprehension magic 14. all_devices = [x + y for x, y in zip(ethernet_devices, usb_devices)] 16. # Let's use maps 17. import operator 18. all_devices = list(map(operator.add, ethernet_devices, usb_devices)) 20. # We can't forget our favorite computation library 21. import numpy as np 22. all_devices = np.add(ethernet_devices, usb_devices)  If you’d like a deeper explanation, check out my article titled “How to Sum Elements of Two Lists in Python” which even includes a fun challenge. Likewise, you might get some value out of my YouTube video on the same topic.\nChecking if a File Exists One of the amazing perks of Python is how easy it is to manage files. Unlike Java, Python has a built-in syntax for file reading and writing. As a result, checking if a file exists is a rather brief task:\n1. # Brute force with a try-except block (Python 3+) 2. try: 3. with open('/path/to/file', 'r') as fh: 4. pass 5. except FileNotFoundError: 6. pass 8. # Leverage the OS package (possible race condition) 9. import os 10. exists = os.path.isfile('/path/to/file') 12. # Wrap the path in an object for enhanced functionality 13. from pathlib import Path 14. config = Path('/path/to/file') 15. if config.is_file(): 16. pass  As always, you can learn more about these solutions in my article titled “How to Check if a File Exists in Python” which features three solutions and performances metrics.\nConverting Two Lists Into a Dictionary Previously, we talked about summing two lists in Python. As it turns out, there’s a lot we can do with two lists. For example, we could try mapping one onto the other to create a dictionary.\nAs with many of these problems, there are a few concerns. For instance, what if the two lists aren’t the same size? Likewise, what if the keys aren’t unique or hashable? That said, in the simple case, there are some straightforward solutions:\n1. column_names = ['id', 'color', 'style'] 2. column_values = [1, 'red', 'bold'] 4. # Convert two lists into a dictionary with zip and the dict constructor 5. name_to_value_dict = dict(zip(column_names, column_values)) 7. # Convert two lists into a dictionary with a dictionary comprehension 8. name_to_value_dict = {key:value for key, value in zip(column_names, column_values)} 10. # Convert two lists into a dictionary with a loop 11. name_value_tuples = zip(column_names, column_values) 12. name_to_value_dict = {} 13. for key, value in name_value_tuples: 14. if key in name_to_value_dict: 15. pass # Insert logic for handling duplicate keys 16. else: 17. name_to_value_dict[key] = value  Once again, you can find an explanation for each of these solutions and more in my article titled “How to Convert Two Lists Into a Dictionary in Python.” If you are a visual person, you might prefer my YouTube video which covers mapping lists to dictionaries as well.\nChecking if a List Is Empty If you come from a statically typed language like Java or C, you might be bothered by the lack of static types in Python. Sure, not knowing the type of a variable can sometimes be frustrating, but there are perks as well. For instance, we can check if a list is empty by its type flexibility—among other methods:\n1. my_list = list() 3. # Check if a list is empty by its length 4. if len(my_list) == 0: 5. pass # the list is empty 7. # Check if a list is empty by direct comparison (only works for lists) 8. if my_list == []: 9. pass # the list is empty 11. # Check if a list is empty by its type flexibility **preferred method** 12. if not my_list: 13. pass # the list is empty  If you’d like to learn more about these three solutions, check out my article titled “How to Check if a List in Empty in Python.” If you’re in a pinch, check out my YouTube video which covers the same topic.\nCloning a List One of my favorite subjects in programming is copying data types. After all, it’s never easy in this reference-based world we live, and that’s true for Python as well. Luckily, if we want to copy a list, there are a few ways to do it:\n1. my_list = [27, 13, -11, 60, 39, 15] 3. # Clone a list by brute force 4. my_duplicate_list = [item for item in my_list] 6. # Clone a list with a slice 7. my_duplicate_list = my_list[:] 9. # Clone a list with the list constructor 10. my_duplicate_list = list(my_list) 12. # Clone a list with the copy function (Python 3.3+) 13. my_duplicate_list = my_list.copy() # preferred method 15. # Clone a list with the copy package 16. import copy 17. my_duplicate_list = copy.copy(my_list) 18. my_deep_duplicate_list = copy.deepcopy(my_list) 20. # Clone a list with multiplication? 21. my_duplicate_list = my_list * 1 # do not do this  When it comes to cloning, it’s important to be aware of the difference between shallow and deep copies. Luckily, I have an article covering that topic.\nFinally, you can find out more about the solutions listed above in my article titled “How to Clone a List in Python.” In addition, you might find value in my related YouTube video titled “7 Ways to Copy a List in Python Featuring The Pittsburgh Penguins.”\nRetrieving the Last Item of a List Since we’re on the topic of lists, lets talk about getting the last item of a list. In most languages, this involves some convoluted mathematical expression involving the length of the list. What if I told you there is are several more interesting solutions in Python?\n1. my_list = ['red', 'blue', 'green'] 3. # Get the last item with brute force using len 4. last_item = my_list[len(my_list) - 1] 6. # Remove the last item from the list using pop 7. last_item = my_list.pop() 9. # Get the last item using negative indices *preferred \u0026amp; quickest method* 10. last_item = my_list[-1] 12. # Get the last item using iterable unpacking 13. *_, last_item = my_list  As always, you can learn more about these solutions from my article titled “How to Get the Last Item of a List in Python” which features a challenge, performance metrics, and a YouTube video.\nMaking a Python Script Shortcut Sometimes when you create a script, you want to be able to run it conveniently at the click of a button. Fortunately, there are several ways to do that.\nFirst, we can create a Windows shortcut with the following settings:\n1. \\path\\to\\trc-image-titler.py -o \\path\\to\\output  Likewise, we can also create a batch file with the following code:\n1. @echo off 2. \\path\\to\\trc-image-titler.py -o \\path\\to\\output  Finally, we can create a bash script with the following code:\n1. #!/bin/sh 2. python /path/to/trc-image-titler.py -o /path/to/output  If you’re looking for more explanation, check out the article titled “How to Make a Python Script Shortcut with Arguments.”\nSorting a List of Strings Sorting is a common task that you’re expected to know how to implement in Computer Science. Despite the intense focus on sorting algorithms in most curriculum, no one really tells you how complicated sorting can actually get. For instance, sorting numbers is straightforward, but what about sorting strings? How do we decide a proper ordering? Fortunately, there are a lot of options in Python:\n1. my_list = [\u0026quot;leaf\u0026quot;, \u0026quot;cherry\u0026quot;, \u0026quot;fish\u0026quot;] 3. # Brute force method using bubble sort 4. my_list = [\u0026quot;leaf\u0026quot;, \u0026quot;cherry\u0026quot;, \u0026quot;fish\u0026quot;] 5. size = len(my_list) 6. for i in range(size): 7. for j in range(size): 8. if my_list[i] \u0026lt; my_list[j]: 9. temp = my_list[i] 10. my_list[i] = my_list[j] 11. my_list[j] = temp 13. # Generic list sort *fastest* 14. my_list.sort() 16. # Casefold list sort 17. my_list.sort(key=str.casefold) 19. # Generic list sorted 20. my_list = sorted(my_list) 22. # Custom list sort using casefold (\u0026gt;= Python 3.3) 23. my_list = sorted(my_list, key=str.casefold) 25. # Custom list sort using current locale 26. import locale 27. from functools import cmp_to_key 28. my_list = sorted(my_list, key=cmp_to_key(locale.strcoll)) 30. # Custom reverse list sort using casefold (\u0026gt;= Python 3.3) 31. my_list = sorted(my_list, key=str.casefold, reverse=True)  If you’re curious about how some of these solutions work, or you just want to know what some of the potential risks are, check out my article titled “How to Sort a List of Strings in Python.”\nParsing a Spreadsheet One of the more interesting use cases for Python is data science. Unfortunately, however, that means handling a lot of raw data in various formats like text files and spreadsheets. Luckily, Python has plenty of built-in utilities for reading different file formats. For example, we can parse a spreadsheet with ease:\n1. # Brute force solution 2. csv_mapping_list = [] 3. with open(\u0026quot;/path/to/data.csv\u0026quot;) as my_data: 4. line_count = 0 5. for line in my_data: 6. row_list = [val.strip() for val in line.split(\u0026quot;,\u0026quot;)] 7. if line_count == 0: 8. header = row_list 9. else: 10. row_dict = {key: value for key, value in zip(header, row_list)} 11. csv_mapping_list.append(row_dict) 12. line_count += 1 14. # CSV reader solution 15. import csv 16. csv_mapping_list = [] 17. with open(\u0026quot;/path/to/data.csv\u0026quot;) as my_data: 18. csv_reader = csv.reader(my_data, delimiter=\u0026quot;,\u0026quot;) 19. line_count = 0 20. for line in csv_reader: 21. if line_count == 0: 22. header = line 23. else: 24. row_dict = {key: value for key, value in zip(header, line)} 25. csv_mapping_list.append(row_dict) 26. line_count += 1 28. # CSV DictReader solution 29. import csv 30. with open(\u0026quot;/path/to/dict.csv\u0026quot;) as my_data: 31. csv_mapping_list = list(csv.DictReader(my_data))  In this case, we try to get our output in a list of dictionaries. If you want to know more about how this works, check out the complete article titled “How to Parse a Spreadsheet in Python.”\nSorting a List of Dictionaries Once you have a list of dictionaries, you might want to organize them in some specific order. For example, if the dictionaries have a key for date, we can try sorting them in chronological order. Luckily, sorting is another relatively painless task:\n1. csv_mapping_list = [ 2. { 3. \u0026quot;Name\u0026quot;: \u0026quot;Jeremy\u0026quot;, 4. \u0026quot;Age\u0026quot;: 25, 5. \u0026quot;Favorite Color\u0026quot;: \u0026quot;Blue\u0026quot; 6. }, 7. { 8. \u0026quot;Name\u0026quot;: \u0026quot;Ally\u0026quot;, 9. \u0026quot;Age\u0026quot;: 41, 10. \u0026quot;Favorite Color\u0026quot;: \u0026quot;Magenta\u0026quot; 11. }, 12. { 13. \u0026quot;Name\u0026quot;: \u0026quot;Jasmine\u0026quot;, 14. \u0026quot;Age\u0026quot;: 29, 15. \u0026quot;Favorite Color\u0026quot;: \u0026quot;Aqua\u0026quot; 16. } 17. ] 19. # Custom sorting 20. size = len(csv_mapping_list) 21. for i in range(size): 22. min_index = i 23. for j in range(i + 1, size): 24. if csv_mapping_list[min_index][\u0026quot;Age\u0026quot;] \u0026gt; csv_mapping_list[j][\u0026quot;Age\u0026quot;]: 25. min_index = j 26. csv_mapping_list[i], csv_mapping_list[min_index] = csv_mapping_list[min_index], csv_mapping_list[i] 28. # List sorting function 29. csv_mapping_list.sort(key=lambda item: item.get(\u0026quot;Age\u0026quot;)) 31. # List sorting using itemgetter 32. from operator import itemgetter 33. f = itemgetter('Name') 34. csv_mapping_list.sort(key=f) 36. # Iterable sorted function 37. csv_mapping_list = sorted(csv_mapping_list, key=lambda item: item.get(\u0026quot;Age\u0026quot;))  All these solutions and more outlined in my article titled “How to Sort a List of Dictionaries in Python.”\nWriting a List Comprehension One of my favorite Python topics to chat about is list comprehensions. As someone who grew up on languages like Java, C/C++, and C#, I had never seen anything quite like a list comprehension until I played with Python. Now, I’m positively obsessed with them. As a result, I put together an entire list of examples:\n1. # Define a generic 1D list of constants 2. my_list = [2, 5, -4, 6] 4. # Duplicate a 1D list of constants 5. [item for item in my_list] 7. # Duplicate and scale a 1D list of constants 8. [2 * item for item in my_list] 10. # Duplicate and filter out non-negatives from 1D list of constants 11. [item for item in my_list if item \u0026lt; 0] 13. # Duplicate, filter, and scale a 1D list of constants 14. [2 * item for item in my_list if item \u0026lt; 0] 16. # Generate all possible pairs from two lists 17. [(a, b) for a in (1, 3, 5) for b in (2, 4, 6)] 19. # Redefine list of contents to be 2D 20. my_list = [[1, 2], [3, 4]] 22. # Duplicate a 2D list 23. [[item for item in sub_list] for sub_list in my_list] 25. # Duplicate an n-dimensional list 26. def deep_copy(to_copy): 27. if type(to_copy) is list: 28. return [deep_copy(item) for item in to_copy] 29. else: 30. return to_copy  As always, you can find a more formal explanation of all this code in my article titled “How to Write a List Comprehension in Python.” As an added bonus, I have a YouTube video which shares several examples of list comprehensions.\nMerging Two Dictionaries In this collection, we talk a lot about handling data structures like lists and dictionaries. Well, this one is no different. In particular, we’re looking at merging two dictionaries. Of course, combining two dictionaries comes with risks. For example, what if there are duplicate keys? Luckily, we have solutions for that:\n1. yusuke_power = {\u0026quot;Yusuke Urameshi\u0026quot;: \u0026quot;Spirit Gun\u0026quot;} 2. hiei_power = {\u0026quot;Hiei\u0026quot;: \u0026quot;Jagan Eye\u0026quot;} 3. powers = dict() 5. # Brute force 6. for dictionary in (yusuke_power, hiei_power): 7. for key, value in dictionary.items(): 8. powers[key] = value 10. # Dictionary Comprehension 11. powers = {key: value for d in (yusuke_power, hiei_power) for key, value in d.items()} 13. # Copy and update 14. powers = yusuke_power.copy() 15. powers.update(hiei_power) 17. # Dictionary unpacking (Python 3.5+) 18. powers = {**yusuke_power, **hiei_power} 20. # Backwards compatible function for any number of dicts 21. def merge_dicts(*dicts: dict): 22. merged_dict = dict() 23. for dictionary in dicts: 24. merge_dict.update(dictionary) 25. return merged_dict  If you’re interested, I have an article which covers this exact topic called “How to Merge Two Dictionaries in Python” which features four solutions as well performance metrics.\nFormatting a String Whether we like to admit it or not, we often find ourselves burying print statements throughout our code for quick debugging purposes. After all, a well placed print statement can save you a lot of time. Unfortunately, it’s not always easy or convenient to actually display what we want. Luckily, Python has a lot of formatting options:\n1. name = \u0026quot;Jeremy\u0026quot; 2. age = 25 4. # String formatting using concatenation 5. print(\u0026quot;My name is \u0026quot; + name + \u0026quot;, and I am \u0026quot; + str(age) + \u0026quot; years old.\u0026quot;) 7. # String formatting using multiple prints 8. print(\u0026quot;My name is \u0026quot;, end=\u0026quot;\u0026quot;) 9. print(name, end=\u0026quot;\u0026quot;) 10. print(\u0026quot;, and I am \u0026quot;, end=\u0026quot;\u0026quot;) 11. print(age, end=\u0026quot;\u0026quot;) 12. print(\u0026quot; years old.\u0026quot;) 14. # String formatting using join 15. print(''.join([\u0026quot;My name is \u0026quot;, name, \u0026quot;, and I am \u0026quot;, str(age), \u0026quot; years old\u0026quot;])) 17. # String formatting using modulus operator 18. print(\u0026quot;My name is %s, and I am %d years old.\u0026quot; % (name, age)) 20. # String formatting using format function with ordered parameters 21. print(\u0026quot;My name is {}, and I am {} years old\u0026quot;.format(name, age)) 23. # String formatting using format function with named parameters 24. print(\u0026quot;My name is {n}, and I am {a} years old\u0026quot;.format(a=age, n=name)) 26. # String formatting using f-Strings (Python 3.6+) 27. print(f\u0026quot;My name is {name}, and I am {age} years old\u0026quot;)  Keep in mind that these solutions don’t have to be used with print statements. In other words, feel free to use solutions like f-strings wherever you need them.\nAs always, you can find an explanation of all these solutions and more in my article titled “How to Format a String in Python.” If you’d rather see these snippets in action, check out my YouTube video titled “6 Ways to Format a String in Python Featuring My Cat.”\nPrinting on the Same Line Along a similar line as formatting strings, sometimes you just need to print on the same line in Python. As the print command is currently designed, it automatically applies a newline to the end of your string. Luckily, there are a few ways around that:\n1. # Python 2 only 2. print \u0026quot;Live PD\u0026quot;, 4. # Backwards compatible (also fastest) 5. import sys 6. sys.stdout.write(\u0026quot;Breaking Bad\u0026quot;) 8. # Python 3 only 9. print(\u0026quot;Mob Psycho 100\u0026quot;, end=\u0026quot;\u0026quot;)  As always, if you plan to use any of these solutions, check out the article titled “How to Print on the Same Line in Python” for additional use cases and caveats.\nTesting Performance Finally, sometimes you just want to compare a couple chunks of code. Luckily, Python has a few straightforward options:\n1. # Brute force solution 2. import datetime 3. start_time = datetime.datetime.now() 4. [(a, b) for a in (1, 3, 5) for b in (2, 4, 6)] # example snippet 5. end_time = datetime.datetime.now() 6. print end_time - start_time 8. # timeit solution 9. import timeit 10. min(timeit.repeat(\u0026quot;[(a, b) for a in (1, 3, 5) for b in (2, 4, 6)]\u0026quot;)) 12. # cProfile solution 13. import cProfile 14. cProfile.run(\u0026quot;[(a, b) for a in (1, 3, 5) for b in (2, 4, 6)]\u0026quot;)  Again, if you want more details, check the article titled “How to Performance Test Python Code.”\nShare Your Own Problems As you can see, this article and its associated series is already quite large. That said, I’d love to continue growing them. As a result, you should consider sharing some of your own problems. After all, there has be something you Google regularly. Why not share it with us?\nIn the meantime, help grow this collection by hopping on my newsletter, visiting the shop, subscribing to my YouTube channel, and/or becoming a patron. In addition, you’re welcome to browse the following related articles:\n The Controversy Behind the Walrus Operator in Python Rock Paper Scissors Using Modular Arithmetic  Otherwise, thanks for stopping by! I appreciate the support.\n Source : .\n "});index.add({'id':6,'href':'/library/tutorials/docs/articles/python/81-pythoncodesnippets/','title':"81 Python Code Snippets",'content':" 81 Python Code Snippets for Everyday Problems POSTED ON DECEMBER 27, 2019 BY JEREMY GRIFSKI\nIf you’ve been following me for any amount of time, you know that I regularly publish Python code snippets for everyday problems. Well, I figured I’d finally aggregate all those responses in one massive article with links to all those resources.\nAs a heads up, I’m looking to start porting all of the code snippets in this article to Jupyter Notebooks. If you’re interested in that kind of project, head on over to the GitHub repo. I’d appreciate the help!\nTable of Contents  Table of Contents Everyday Problems  Inverting a Dictionary Summing Elements of Two Lists Checking if a File Exists Converting Two Lists Into a Dictionary Checking if a List Is Empty Cloning a List Retrieving the Last Item of a List Making a Python Script Shortcut Sorting a List of Strings Parsing a Spreadsheet Sorting a List of Dictionaries Writing a List Comprehension Merging Two Dictionaries Formatting a String Printing on the Same Line Testing Performance Performing a Reverse Dictionary Lookup Checking if a String Contains a Substring  Share Your Own Problems  Everyday Problems In this section, we’ll take a look at various common scenarios that arise and how to solve them with Python code. Specifically, I’ll share a brief explanation of the problem with a list of Python code solutions. Then, I’ll link all the resources I have.\nInverting a Dictionary Sometimes when we have a dictionary, we want to be able to flip its keys and values. Of course, there are concerns like “how do we deal with duplicate values?” and “what if the values aren’t hashable?” That said, in the simple case, there are a few solutions:\n1. # Use to invert dictionaries that have unique values 2. my_inverted_dict = dict(map(reversed, my_dict.items())) 4. # Use to invert dictionaries that have unique values 5. my_inverted_dict = {value: key for key, value in my_dict.items()} 7. # Use to invert dictionaries that have non-unique values 8. from collections import defaultdict 9. my_inverted_dict = defaultdict(list) 10. {my_inverted_dict[v].append(k) for k, v in my_dict.items()} 12. # Use to invert dictionaries that have non-unique values 13. my_inverted_dict = dict() 14. for key, value in my_dict.items(): 15. my_inverted_dict.setdefault(value, list()).append(key) 17. # Use to invert dictionaries that have lists of values 18. my_dict = {value: key for key in my_inverted_dict for value in my_map[key]}  For more explanation, check out my article titled “How to Invert a Dictionary in Python.” It includes a breakdown of each solution, their performance metrics, and when they’re applicable. Likewise, I have a YouTube video which covers the same topic.\nSumming Elements of Two Lists Let’s say you have two lists, and you want to merge them together into a single list by element. In other words, you want to add the first element of the first list to the first element of the second list and store the result in a new list. Well, there are several ways to do that:\n1. ethernet_devices = [1, [7], [2], [8374163], [84302738]] 2. usb_devices = [1, [7], [1], [2314567], [0]] 4. # The long way 5. all_devices = [ 6. ethernet_devices[0] + usb_devices[0], 7. ethernet_devices[1] + usb_devices[1], 8. ethernet_devices[2] + usb_devices[2], 9. ethernet_devices[3] + usb_devices[3], 10. ethernet_devices[4] + usb_devices[4] 11. ] 13. # Some comprehension magic 14. all_devices = [x + y for x, y in zip(ethernet_devices, usb_devices)] 16. # Let's use maps 17. import operator 18. all_devices = list(map(operator.add, ethernet_devices, usb_devices)) 20. # We can't forget our favorite computation library 21. import numpy as np 22. all_devices = np.add(ethernet_devices, usb_devices)  If you’d like a deeper explanation, check out my article titled “How to Sum Elements of Two Lists in Python” which even includes a fun challenge. Likewise, you might get some value out of my YouTube video on the same topic.\nChecking if a File Exists One of the amazing perks of Python is how easy it is to manage files. Unlike Java, Python has a built-in syntax for file reading and writing. As a result, checking if a file exists is a rather brief task:\n1. # Brute force with a try-except block (Python 3+) 2. try: 3. with open('/path/to/file', 'r') as fh: 4. pass 5. except FileNotFoundError: 6. pass 8. # Leverage the OS package (possible race condition) 9. import os 10. exists = os.path.isfile('/path/to/file') 12. # Wrap the path in an object for enhanced functionality 13. from pathlib import Path 14. config = Path('/path/to/file') 15. if config.is_file(): 16. pass  As always, you can learn more about these solutions in my article titled “How to Check if a File Exists in Python” which features three solutions and performances metrics.\nConverting Two Lists Into a Dictionary Previously, we talked about summing two lists in Python. As it turns out, there’s a lot we can do with two lists. For example, we could try mapping one onto the other to create a dictionary.\nAs with many of these problems, there are a few concerns. For instance, what if the two lists aren’t the same size? Likewise, what if the keys aren’t unique or hashable? That said, in the simple case, there are some straightforward solutions:\n1. column_names = ['id', 'color', 'style'] 2. column_values = [1, 'red', 'bold'] 4. # Convert two lists into a dictionary with zip and the dict constructor 5. name_to_value_dict = dict(zip(column_names, column_values)) 7. # Convert two lists into a dictionary with a dictionary comprehension 8. name_to_value_dict = {key:value for key, value in zip(column_names, column_values)} 10. # Convert two lists into a dictionary with a loop 11. name_value_tuples = zip(column_names, column_values) 12. name_to_value_dict = {} 13. for key, value in name_value_tuples: 14. if key in name_to_value_dict: 15. pass # Insert logic for handling duplicate keys 16. else: 17. name_to_value_dict[key] = value  Once again, you can find an explanation for each of these solutions and more in my article titled “How to Convert Two Lists Into a Dictionary in Python.” If you are a visual person, you might prefer my YouTube video which covers mapping lists to dictionaries as well.\nChecking if a List Is Empty If you come from a statically typed language like Java or C, you might be bothered by the lack of static types in Python. Sure, not knowing the type of a variable can sometimes be frustrating, but there are perks as well. For instance, we can check if a list is empty by its type flexibility—among other methods:\n1. my_list = list() 3. # Check if a list is empty by its length 4. if len(my_list) == 0: 5. pass # the list is empty 7. # Check if a list is empty by direct comparison (only works for lists) 8. if my_list == []: 9. pass # the list is empty 11. # Check if a list is empty by its type flexibility **preferred method** 12. if not my_list: 13. pass # the list is empty  If you’d like to learn more about these three solutions, check out my article titled “How to Check if a List in Empty in Python.” If you’re in a pinch, check out my YouTube video which covers the same topic.\nCloning a List One of my favorite subjects in programming is copying data types. After all, it’s never easy in this reference-based world we live, and that’s true for Python as well. Luckily, if we want to copy a list, there are a few ways to do it:\n1. my_list = [27, 13, -11, 60, 39, 15] 3. # Clone a list by brute force 4. my_duplicate_list = [item for item in my_list] 6. # Clone a list with a slice 7. my_duplicate_list = my_list[:] 9. # Clone a list with the list constructor 10. my_duplicate_list = list(my_list) 12. # Clone a list with the copy function (Python 3.3+) 13. my_duplicate_list = my_list.copy() # preferred method 15. # Clone a list with the copy package 16. import copy 17. my_duplicate_list = copy.copy(my_list) 18. my_deep_duplicate_list = copy.deepcopy(my_list) 20. # Clone a list with multiplication? 21. my_duplicate_list = my_list * 1 # do not do this  When it comes to cloning, it’s important to be aware of the difference between shallow and deep copies. Luckily, I have an article covering that topic.\nFinally, you can find out more about the solutions listed above in my article titled “How to Clone a List in Python.” In addition, you might find value in my related YouTube video titled “7 Ways to Copy a List in Python Featuring The Pittsburgh Penguins.”\nRetrieving the Last Item of a List Since we’re on the topic of lists, lets talk about getting the last item of a list. In most languages, this involves some convoluted mathematical expression involving the length of the list. What if I told you there is are several more interesting solutions in Python?\n1. my_list = ['red', 'blue', 'green'] 3. # Get the last item with brute force using len 4. last_item = my_list[len(my_list) - 1] 6. # Remove the last item from the list using pop 7. last_item = my_list.pop() 9. # Get the last item using negative indices *preferred \u0026amp; quickest method* 10. last_item = my_list[-1] 12. # Get the last item using iterable unpacking 13. *_, last_item = my_list  As always, you can learn more about these solutions from my article titled “How to Get the Last Item of a List in Python” which features a challenge, performance metrics, and a YouTube video.\nMaking a Python Script Shortcut Sometimes when you create a script, you want to be able to run it conveniently at the click of a button. Fortunately, there are several ways to do that.\nFirst, we can create a Windows shortcut with the following settings:\n1. \\path\\to\\trc-image-titler.py -o \\path\\to\\output  Likewise, we can also create a batch file with the following code:\n1. @echo off 2. \\path\\to\\trc-image-titler.py -o \\path\\to\\output  Finally, we can create a bash script with the following code:\n1. #!/bin/sh 2. python /path/to/trc-image-titler.py -o /path/to/output  If you’re looking for more explanation, check out the article titled “How to Make a Python Script Shortcut with Arguments.”\nSorting a List of Strings Sorting is a common task that you’re expected to know how to implement in Computer Science. Despite the intense focus on sorting algorithms in most curriculum, no one really tells you how complicated sorting can actually get. For instance, sorting numbers is straightforward, but what about sorting strings? How do we decide a proper ordering? Fortunately, there are a lot of options in Python:\n1. my_list = [\u0026quot;leaf\u0026quot;, \u0026quot;cherry\u0026quot;, \u0026quot;fish\u0026quot;] 3. # Brute force method using bubble sort 4. my_list = [\u0026quot;leaf\u0026quot;, \u0026quot;cherry\u0026quot;, \u0026quot;fish\u0026quot;] 5. size = len(my_list) 6. for i in range(size): 7. for j in range(size): 8. if my_list[i] \u0026lt; my_list[j]: 9. temp = my_list[i] 10. my_list[i] = my_list[j] 11. my_list[j] = temp 13. # Generic list sort *fastest* 14. my_list.sort() 16. # Casefold list sort 17. my_list.sort(key=str.casefold) 19. # Generic list sorted 20. my_list = sorted(my_list) 22. # Custom list sort using casefold (\u0026gt;= Python 3.3) 23. my_list = sorted(my_list, key=str.casefold) 25. # Custom list sort using current locale 26. import locale 27. from functools import cmp_to_key 28. my_list = sorted(my_list, key=cmp_to_key(locale.strcoll)) 30. # Custom reverse list sort using casefold (\u0026gt;= Python 3.3) 31. my_list = sorted(my_list, key=str.casefold, reverse=True)  If you’re curious about how some of these solutions work, or you just want to know what some of the potential risks are, check out my article titled “How to Sort a List of Strings in Python.”\nParsing a Spreadsheet One of the more interesting use cases for Python is data science. Unfortunately, however, that means handling a lot of raw data in various formats like text files and spreadsheets. Luckily, Python has plenty of built-in utilities for reading different file formats. For example, we can parse a spreadsheet with ease:\n1. # Brute force solution 2. csv_mapping_list = [] 3. with open(\u0026quot;/path/to/data.csv\u0026quot;) as my_data: 4. line_count = 0 5. for line in my_data: 6. row_list = [val.strip() for val in line.split(\u0026quot;,\u0026quot;)] 7. if line_count == 0: 8. header = row_list 9. else: 10. row_dict = {key: value for key, value in zip(header, row_list)} 11. csv_mapping_list.append(row_dict) 12. line_count += 1 14. # CSV reader solution 15. import csv 16. csv_mapping_list = [] 17. with open(\u0026quot;/path/to/data.csv\u0026quot;) as my_data: 18. csv_reader = csv.reader(my_data, delimiter=\u0026quot;,\u0026quot;) 19. line_count = 0 20. for line in csv_reader: 21. if line_count == 0: 22. header = line 23. else: 24. row_dict = {key: value for key, value in zip(header, line)} 25. csv_mapping_list.append(row_dict) 26. line_count += 1 28. # CSV DictReader solution 29. import csv 30. with open(\u0026quot;/path/to/dict.csv\u0026quot;) as my_data: 31. csv_mapping_list = list(csv.DictReader(my_data))  In this case, we try to get our output in a list of dictionaries. If you want to know more about how this works, check out the complete article titled “How to Parse a Spreadsheet in Python.”\nSorting a List of Dictionaries Once you have a list of dictionaries, you might want to organize them in some specific order. For example, if the dictionaries have a key for date, we can try sorting them in chronological order. Luckily, sorting is another relatively painless task:\n1. csv_mapping_list = [ 2. { 3. \u0026quot;Name\u0026quot;: \u0026quot;Jeremy\u0026quot;, 4. \u0026quot;Age\u0026quot;: 25, 5. \u0026quot;Favorite Color\u0026quot;: \u0026quot;Blue\u0026quot; 6. }, 7. { 8. \u0026quot;Name\u0026quot;: \u0026quot;Ally\u0026quot;, 9. \u0026quot;Age\u0026quot;: 41, 10. \u0026quot;Favorite Color\u0026quot;: \u0026quot;Magenta\u0026quot; 11. }, 12. { 13. \u0026quot;Name\u0026quot;: \u0026quot;Jasmine\u0026quot;, 14. \u0026quot;Age\u0026quot;: 29, 15. \u0026quot;Favorite Color\u0026quot;: \u0026quot;Aqua\u0026quot; 16. } 17. ] 19. # Custom sorting 20. size = len(csv_mapping_list) 21. for i in range(size): 22. min_index = i 23. for j in range(i + 1, size): 24. if csv_mapping_list[min_index][\u0026quot;Age\u0026quot;] \u0026gt; csv_mapping_list[j][\u0026quot;Age\u0026quot;]: 25. min_index = j 26. csv_mapping_list[i], csv_mapping_list[min_index] = csv_mapping_list[min_index], csv_mapping_list[i] 28. # List sorting function 29. csv_mapping_list.sort(key=lambda item: item.get(\u0026quot;Age\u0026quot;)) 31. # List sorting using itemgetter 32. from operator import itemgetter 33. f = itemgetter('Name') 34. csv_mapping_list.sort(key=f) 36. # Iterable sorted function 37. csv_mapping_list = sorted(csv_mapping_list, key=lambda item: item.get(\u0026quot;Age\u0026quot;))  All these solutions and more outlined in my article titled “How to Sort a List of Dictionaries in Python.”\nWriting a List Comprehension One of my favorite Python topics to chat about is list comprehensions. As someone who grew up on languages like Java, C/C++, and C#, I had never seen anything quite like a list comprehension until I played with Python. Now, I’m positively obsessed with them. As a result, I put together an entire list of examples:\n1. # Define a generic 1D list of constants 2. my_list = [2, 5, -4, 6] 4. # Duplicate a 1D list of constants 5. [item for item in my_list] 7. # Duplicate and scale a 1D list of constants 8. [2 * item for item in my_list] 10. # Duplicate and filter out non-negatives from 1D list of constants 11. [item for item in my_list if item \u0026lt; 0] 13. # Duplicate, filter, and scale a 1D list of constants 14. [2 * item for item in my_list if item \u0026lt; 0] 16. # Generate all possible pairs from two lists 17. [(a, b) for a in (1, 3, 5) for b in (2, 4, 6)] 19. # Redefine list of contents to be 2D 20. my_list = [[1, 2], [3, 4]] 22. # Duplicate a 2D list 23. [[item for item in sub_list] for sub_list in my_list] 25. # Duplicate an n-dimensional list 26. def deep_copy(to_copy): 27. if type(to_copy) is list: 28. return [deep_copy(item) for item in to_copy] 29. else: 30. return to_copy  As always, you can find a more formal explanation of all this code in my article titled “How to Write a List Comprehension in Python.” As an added bonus, I have a YouTube video which shares several examples of list comprehensions.\nMerging Two Dictionaries In this collection, we talk a lot about handling data structures like lists and dictionaries. Well, this one is no different. In particular, we’re looking at merging two dictionaries. Of course, combining two dictionaries comes with risks. For example, what if there are duplicate keys? Luckily, we have solutions for that:\n1. yusuke_power = {\u0026quot;Yusuke Urameshi\u0026quot;: \u0026quot;Spirit Gun\u0026quot;} 2. hiei_power = {\u0026quot;Hiei\u0026quot;: \u0026quot;Jagan Eye\u0026quot;} 3. powers = dict() 5. # Brute force 6. for dictionary in (yusuke_power, hiei_power): 7. for key, value in dictionary.items(): 8. powers[key] = value 10. # Dictionary Comprehension 11. powers = {key: value for d in (yusuke_power, hiei_power) for key, value in d.items()} 13. # Copy and update 14. powers = yusuke_power.copy() 15. powers.update(hiei_power) 17. # Dictionary unpacking (Python 3.5+) 18. powers = {**yusuke_power, **hiei_power} 20. # Backwards compatible function for any number of dicts 21. def merge_dicts(*dicts: dict): 22. merged_dict = dict() 23. for dictionary in dicts: 24. merge_dict.update(dictionary) 25. return merged_dict  If you’re interested, I have an article which covers this exact topic called “How to Merge Two Dictionaries in Python” which features four solutions as well performance metrics.\nFormatting a String Whether we like to admit it or not, we often find ourselves burying print statements throughout our code for quick debugging purposes. After all, a well placed print statement can save you a lot of time. Unfortunately, it’s not always easy or convenient to actually display what we want. Luckily, Python has a lot of formatting options:\n1. name = \u0026quot;Jeremy\u0026quot; 2. age = 25 4. # String formatting using concatenation 5. print(\u0026quot;My name is \u0026quot; + name + \u0026quot;, and I am \u0026quot; + str(age) + \u0026quot; years old.\u0026quot;) 7. # String formatting using multiple prints 8. print(\u0026quot;My name is \u0026quot;, end=\u0026quot;\u0026quot;) 9. print(name, end=\u0026quot;\u0026quot;) 10. print(\u0026quot;, and I am \u0026quot;, end=\u0026quot;\u0026quot;) 11. print(age, end=\u0026quot;\u0026quot;) 12. print(\u0026quot; years old.\u0026quot;) 14. # String formatting using join 15. print(''.join([\u0026quot;My name is \u0026quot;, name, \u0026quot;, and I am \u0026quot;, str(age), \u0026quot; years old\u0026quot;])) 17. # String formatting using modulus operator 18. print(\u0026quot;My name is %s, and I am %d years old.\u0026quot; % (name, age)) 20. # String formatting using format function with ordered parameters 21. print(\u0026quot;My name is {}, and I am {} years old\u0026quot;.format(name, age)) 23. # String formatting using format function with named parameters 24. print(\u0026quot;My name is {n}, and I am {a} years old\u0026quot;.format(a=age, n=name)) 26. # String formatting using f-Strings (Python 3.6+) 27. print(f\u0026quot;My name is {name}, and I am {age} years old\u0026quot;)  Keep in mind that these solutions don’t have to be used with print statements. In other words, feel free to use solutions like f-strings wherever you need them.\nAs always, you can find an explanation of all these solutions and more in my article titled “How to Format a String in Python.” If you’d rather see these snippets in action, check out my YouTube video titled “6 Ways to Format a String in Python Featuring My Cat.”\nPrinting on the Same Line Along a similar line as formatting strings, sometimes you just need to print on the same line in Python. As the print command is currently designed, it automatically applies a newline to the end of your string. Luckily, there are a few ways around that:\n1. # Python 2 only 2. print \u0026quot;Live PD\u0026quot;, 4. # Backwards compatible (also fastest) 5. import sys 6. sys.stdout.write(\u0026quot;Breaking Bad\u0026quot;) 8. # Python 3 only 9. print(\u0026quot;Mob Psycho 100\u0026quot;, end=\u0026quot;\u0026quot;)  As always, if you plan to use any of these solutions, check out the article titled “How to Print on the Same Line in Python” for additional use cases and caveats.\nTesting Performance Finally, sometimes you just want to compare a couple chunks of code. Luckily, Python has a few straightforward options:\n1. # Brute force solution 2. import datetime 3. start_time = datetime.datetime.now() 4. [(a, b) for a in (1, 3, 5) for b in (2, 4, 6)] # example snippet 5. end_time = datetime.datetime.now() 6. print end_time - start_time 8. # timeit solution 9. import timeit 10. min(timeit.repeat(\u0026quot;[(a, b) for a in (1, 3, 5) for b in (2, 4, 6)]\u0026quot;)) 12. # cProfile solution 13. import cProfile 14. cProfile.run(\u0026quot;[(a, b) for a in (1, 3, 5) for b in (2, 4, 6)]\u0026quot;)  Again, if you want more details, check the article titled “How to Performance Test Python Code.”\nPerforming a Reverse Dictionary Lookup Earlier we talked about reversing a dictionary which is fine in some circumstances. Of course, if our dictionary is enormous, it might not make sense to outright flip the dict. Instead, we can lookup a key based on a value:\n1. my_dict = {\u0026quot;color\u0026quot;: \u0026quot;red\u0026quot;, \u0026quot;width\u0026quot;: 17, \u0026quot;height\u0026quot;: 19} 2. value_to_find = \u0026quot;red\u0026quot; 4. # Brute force solution (fastest) -- single key 5. for key, value in my_dict.items(): 6. if value == value_to_find: 7. print(f'{key}: {value}') 8. break 10. # Brute force solution -- multiple keys 11. for key, value in my_dict.items(): 12. if value == value_to_find: 13. print(f'{key}: {value}') 15. # Generator expression -- single key 16. key = next(key for key, value in my_dict.items() if value == value_to_find) 17. print(f'{key}: {value_to_find}') 19. # Generator expression -- multiple keys 20. exp = (key for key, value in my_dict.items() if value == value_to_find) 21. for key in exp: 22. print(f'{key}: {value}') 24. # Inverse dictionary solution -- single key 25. my_inverted_dict = {value: key for key, value in my_dict.items()} 26. print(f'{my_inverted_dict[value_to_find]}: {value_to_find}') 28. # Inverse dictionary solution (slowest) -- multiple keys 29. my_inverted_dict = dict() 30. for key, value in my_dict.items(): 31. my_inverted_dict.setdefault(value, list()).append(key) 32. print(f'{my_inverted_dict[value_to_find]}: {value_to_find}')  If this seems helpful, you can check out the source article titled “How to Perform a Reverse Dictionary Lookup in Python“. One of the things I loved about writing this article was learning about generator expressions. If you’re seeing them for the first time, you might want to check it out.\nChecking if a String Contains a Substring One thing I find myself searching more often than I should is the way to check if a string contains a substring in Python. Unlike most programming languages, Python leverages a nice keyword for this problem. Of course, there are also method-based solutions as well:\n1. addresses = [ 2. \u0026quot;123 Elm Street\u0026quot;, 3. \u0026quot;531 Oak Street\u0026quot;, 4. \u0026quot;678 Maple Street\u0026quot; 5. ] 6. street = \u0026quot;Elm Street\u0026quot; 8. # Brute force (don't do this) 9. for address in addresses: 10. address_length = len(address) 11. street_length = len(street) 12. for index in range(address_length - street_length + 1): 13. substring = address[index:street_length + index] 14. if substring == street: 15. print(address) 17. # The index method 18. for address in addresses: 19. try: 20. address.index(street) 21. print(address) 22. except ValueError: 23. pass 25. # The find method 26. for address in addresses: 27. if address.find(street) \u0026gt; 0: 28. print(address) 30. # The in keyword (fastest/preferred) 31. for address in addresses: 32. if street in address: 33. print(address)  If you’re like me and forget about the in keyword, you might want to bookmark the “How to Check if a String Contains a Substring” article.\nShare Your Own Problems As you can see, this article and its associated series is already quite large. That said, I’d love to continue growing them. As a result, you should consider sharing some of your own problems. After all, there has be something you Google regularly. Why not share it with us?\nIn the meantime, help grow this collection by hopping on my newsletter, visiting the shop, subscribing to my YouTube channel, and/or becoming a patron. In addition, you’re welcome to browse the following related articles:\n The Controversy Behind the Walrus Operator in Python Rock Paper Scissors Using Modular Arithmetic  Otherwise, thanks for stopping by! I appreciate the support.\n Source : .\n "});index.add({'id':7,'href':'/library/tutorials/docs/python/e-book/automate-the-boring/','title':"Automate the Boring Stuff",'content':" Automate the Boring Stuff with Python By Al Sweigart. Free to read under a Creative Commons license.\nTable of Contents  Chapter 0 – Introduction Chapter 1 – Python Basics Chapter 2 – Flow Control Chapter 3 – Functions Chapter 4 – Lists Chapter 5 – Dictionaries and Structuring Data Chapter 6 – Manipulating Strings Chapter 7 – Pattern Matching with Regular Expressions Chapter 8 – Input Validation Chapter 9 – Reading and Writing Files Chapter 10 – Organizing Files Chapter 11 – Debugging Chapter 12 – Web Scraping Chapter 13 – Working with Excel Spreadsheets Chapter 14 – Working with Google Spreadsheets Chapter 15 – Working with PDF and Word Documents Chapter 16 – Working with CSV Files and JSON Data Chapter 17 – Keeping Time, Scheduling Tasks, and Launching Programs Chapter 18 – Sending Email and Text Messages Chapter 19 – Manipulating Images Chapter 20 – Controlling the Keyboard and Mouse with GUI Automation Appendix A – Installing Third-Party Modules Appendix B – Running Programs Appendix C – Answers to the Practice Questions  (Read the 1st edition book.)\n"});index.add({'id':8,'href':'/library/tutorials/docs/python/beginer/','title':"Beginners",'content':" Python For Beginners  Python Documentation  "});index.add({'id':9,'href':'/library/tutorials/docs/front-end/bootstrap/basic-bootstap/ep-1/','title':"Bootstrap 4 แบบพื้นฐาน ตอนที่ 1",'content':" สรุปการใช้งาน Bootstrap 4 แบบพื้นฐาน ตอนที่ 1 บทความนี้เป็นบทความสอนการใช้ Bootstrap เรื่องมีอยู่ว่าที่ทำงานของผมส่งผมไปเรียนคอส Web Design สอนโดย อ.กษิติ พันธุ์ถนอม คอสนี้เกี่ยวกับการใช้งาน Bootstrap4 ซึ่งผมก็พอจะรู้อยู่บ้างแล้ว การเรียนครั้งนี้เลยเหมือนการทบทวนและเพิ่มเติมเทคนิคต่างๆ ผมก็เลยได้โอกาสเขียนเป็นบล็อกนี้ขึ้นครับ\nโดยเป้าหมายคือ การใช้งาน Bootstrap ทำให้เว็บ responsive แล้วก็ใช้งาน component ของ Bootstrap ต่างๆ รวมถึงคลาสที่ใช้งานบ่อยๆ นอกจากนี้ก็มีแนะนำเทค และการใช้เครื่องมือช่วยต่างๆด้วย\nติดตั้ง VS code เครื่องมือสำหรับเขียน แนะนำ VS Code ใครไม่มีก็ติดตั้งเลย\nดาวน์โหลดได้ที่\nhttps://code.visualstudio.com/\nเริ่มต้น เริ่มจากการพิมพ์คำสั่งลัด html:5 เพื่อให้ VS Code generate code ให้อัตโนมัติ\nคำสั่ง meta UTF-8 และ viewport สำคัญสำหรับ Bootstrap ต้องใส่ทุกครั้ง ซึ่งมันก็สร้างมาให้แล้ว\n\u0026lt;meta charset=\u0026quot;UTF-8\u0026quot; /\u0026gt; \u0026lt;meta name=\u0026quot;viewport\u0026quot; content=\u0026quot;width=device-width, initial-scale=1.0\u0026quot; /\u0026gt;  อีกอันคือพิมพ์ว่า lorem มันจะ generate ประโยคที่เรียกว่า lorem ให้ มันคือคำที่ไม่มีความหมาย เอามาวางไว้เฉยๆว่านี่คือตัวอักษรจะเห็นในงานพวก design หรือตัวอย่างโค้ดบ่อยๆ\nDeprecate tag ใน HTML5 มียกเลิก tag บางอย่างไปแล้ว เปลี่ยนมาใช้อันใหม่ เช่น\n\u0026lt;b\u0026gt;เปลี่ยนเป็น \u0026lt;strong\u0026gt; \u0026lt;i\u0026gt; ไม่ใช่ตัวเอียง แต่เป็น icons\u0026lt;/i\u0026gt;\u0026lt;/strong\u0026gt;\u0026lt;/b\u0026gt;  ทบทวน CSS ก่อนอื่นทบทวน css นิดนึง css คือภาษาสำหรับจัดแต่งหน้า HTML ในบทความนี้ การเขียน style ไม่แนะนำให้ใช้แบบ inline Style เพราะไม่ทำงานในบาง device , Framework แนะนำ external style sheet คือ เขียนแยกจาก HTML tag\nเพิ่ม css ใน html เพิ่มให้ html ขอเราใช้ไฟล์ .css ได้\n\u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;css/custom.css\u0026quot; /\u0026gt;  Selector สมมุติเราจะกำหนดให้ h1 เป็นสี #dd1144\nh1 { color: #d14; }  ต้องการให้ h1 ที่อยู่ใน div เป็นสีแดง เขียนแบบนี้ได้\ndiv h1 { color: red; }  การใช้ !important ปกติการทำงานจะทำแบบบนลงล่าง ทำให้คำสั่งมันทับกันได้ แต่ถ้าไม่อยากให้มันอานทับ ให้เพิ่ม important\nh1 { color: #d14 !important; } h1 { color: green; }  การใช้ id กำหนด id ให้ tag\n\u0026lt;div id=\u0026quot;first\u0026quot;\u0026gt;  ใน CSS จะใช้สัญลักษณ์ #\n#first { background: lightblue; }  การใช้ class กำหนด class ให้ tag ได้ ซึ่งใน Bootstrap จะใช้บ่อย\n\u0026lt;div class=\u0026quot;second\u0026quot;\u0026gt; \u0026lt;h1\u0026gt;Outside\u0026lt;/h1\u0026gt; \u0026lt;/div\u0026gt;  ใน CSS จะใช้สัญลักษณ์ .\n.second { background: indianred; }  id vs class id มีได้ element เดียว แต่ class มีได้หลาย element การใช้ id ส่วนใหญ่จะใช้เชื่อมกับ js ส่วน class จะมักเชื่อมกับ css และใน bootstrap จะเน้นใช้ class ส่วน id จะใช้เชื่อมกับของ bootstrap เอง\nรู้จัก Bootstrap Bootstrap คือ UI Framework พูดง่ายๆคือเขาเขียน CSS , JS สวยๆ มาให้แล้ว เรามีหน้าที่เรียกใช้ ซึ่งส่วนใหญ่ Bootstrap จะใช้ การเรียก class เป็นหลัก เรามาลองใช้งานกันนะ ตอนนี้ Bootstrap เวอชัน 4\nดาวน์โหลด Bootstrap ไปที่เว็บ https://getbootstrap.com/\n\nพอโหลด Bootstrap มาให้ copy มาไว้ในโปรเจค จะได้โฟลเดอร์ css กับ js มีไฟล์ด้านในประมาณนี้\nbootstarp grid จะมีเฉาะเรื่อง grid และ layout\nbootstrap reboot จะมีฟังชันก์ใหม่ ตัวที่ยังไม่ใช่ production จริง\nbootstarp.css จะเป็นแบบโค้ดสวยๆ อ่านได้\nbootstarp.min.css จะทำ minify มาแล้ว ตัด space และ ขึ้นบรรทัดใหม่ ทำให้ไฟล์เล็กลง\n[เวลาจะใช้งานจริง เราจะใช้ bootstrap.min.css ในการทำงาน\n\u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;css/bootstrap.min.css\u0026quot; /\u0026gt;  MaxCDN: \u0026lt;!-- Latest compiled and minified CSS --\u0026gt; \u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;https://maxcdn.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css\u0026quot;/\u0026gt; \u0026lt;!-- jQuery library --\u0026gt; \u0026lt;script src=\u0026quot;https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;!-- Popper JS --\u0026gt; \u0026lt;script src=\u0026quot;https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.16.0/umd/popper.min.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;!-- Latest compiled JavaScript --\u0026gt; \u0026lt;script src=\u0026quot;https://maxcdn.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt;  การจัด Layout แบบ GRID ใน bootstrap จะใช้ระบบ GRID ในการวาง layout ต่างๆ\nเริ่มจากใช้ div ที่มี class ชื่อว่า container\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;UTF-8\u0026quot; /\u0026gt; \u0026lt;meta name=\u0026quot;viewport\u0026quot; content=\u0026quot;width=device-width, initial-scale=1.0\u0026quot; /\u0026gt; \u0026lt;meta http-equiv=\u0026quot;X-UA-Compatible\u0026quot; content=\u0026quot;ie=edge\u0026quot; /\u0026gt; \u0026lt;title\u0026gt;Hello\u0026lt;/title\u0026gt; \u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;css/bootstrap.min.css\u0026quot; /\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div class=\u0026quot;container\u0026quot;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  ด้านในจะมี div ย่อย แบ่งเป็น row col คล้ายกับตาราง\nแนะนำเขียน comment เอาไว้ ซึ่งใน HTML จะใช้ \u0026lt;!– –\u0026gt;\n\u0026lt;body\u0026gt; \u0026lt;div class=\u0026quot;container\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col\u0026quot;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;!-- Close col 1.1 --\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;!-- Close row 1 --\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;!-- Close container --\u0026gt; \u0026lt;/body\u0026gt;  class container จะทำให้มีพื้นที่ว่างด้านข้าง และเปลี่ยน Font เป็น Helvetica Neue\n\nเพื่อนของมันอีกตัวคือ container-fluid มันจะขายเต็มจอ\n\u0026lt;div class=\u0026quot;container-fluid\u0026quot;\u0026gt;\u0026lt;/div\u0026gt;  มาลองเล่นเรื่องรูปภาพกันบ้าง\nดาวน์โหลดรูปภาพ\nเพิ่มรูปภาพใน grid col คือใช้ \n\u0026lt;body\u0026gt; \u0026lt;div class=\u0026quot;container\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;h1\u0026gt;Hello World\u0026lt;/h1\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col\u0026gt; \u0026lt;img src=\u0026quot;img/banner/banner2.jpg\u0026quot;\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt;  ลองเลือกรูปภาพใหญ่ๆ เมื่อเปิดดูจะเห็นว่ารูปภาพมีขนาดใหญ่จนล้นจอ ยิ่งเปิดในมือถือก็ยิ่งล้น มันไม่ responsive\nวิธีแก้คือ เพิ่ม class ชื่อว่า img-fluid\n\u0026lt;img src=\u0026quot;img/banner/banner2.jpg\u0026quot; class=\u0026quot;img-fluid\u0026quot; /\u0026gt;  รูปภาพจะปรับ scale อัตโนมัติ\nลองเพิ่ม col 3 อัน มันจะแบ่งหน้าจอให้เท่ากัน เป็น 3 ส่วน\n\u0026lt;body\u0026gt; \u0026lt;div class=\u0026quot;container\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;h1\u0026gt;Hello World\u0026lt;/h1\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;!-- Close Row 1 --\u0026gt; \u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col\u0026quot;\u0026gt; \u0026lt;img src=\u0026quot;img/banner/banner2.jpg\u0026quot; class=\u0026quot;img-fluid\u0026quot; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;!-- Close Row 2 --\u0026gt; \u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col\u0026quot;\u0026gt; \u0026lt;img src=\u0026quot;img/staffs/staff1.jpg\u0026quot; class=\u0026quot;img-fluid\u0026quot; /\u0026gt; \u0026lt;h1\u0026gt;CEO\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt; Lorem ipsum dolor sit amet consectetur adipisicing elit. Optio odit illum autem porro! Quisquam voluptatibus nesciunt impedit, suscipit corporis, minus culpa molestiae necessitatibus blanditiis, repellat mollitia beatae hic voluptatum deleniti. \u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;col\u0026quot;\u0026gt; \u0026lt;img src=\u0026quot;img/staffs/staff2.jpg\u0026quot; class=\u0026quot;img-fluid\u0026quot; /\u0026gt; \u0026lt;h1\u0026gt;CTO\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt; Lorem ipsum dolor sit amet consectetur adipisicing elit. Optio odit illum autem porro! Quisquam voluptatibus nesciunt impedit, suscipit corporis, minus culpa molestiae necessitatibus blanditiis, repellat mollitia beatae hic voluptatum deleniti. \u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;col\u0026quot;\u0026gt; \u0026lt;img src=\u0026quot;img/staffs/staff3.jpg\u0026quot; class=\u0026quot;img-fluid\u0026quot; /\u0026gt; \u0026lt;h1\u0026gt;CFO\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt; Lorem ipsum dolor sit amet consectetur adipisicing elit. Optio odit illum autem porro! Quisquam voluptatibus nesciunt impedit, suscipit corporis, minus culpa molestiae necessitatibus blanditiis, repellat mollitia beatae hic voluptatum deleniti. \u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;!-- Close Row 3 --\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;!-- Close container --\u0026gt; \u0026lt;/body\u0026gt;  ](https://benzneststudios.com/blog/wp-content/uploads/2018/11/8.png \u0026ldquo;8\u0026rdquo;)\n1 แถวของ Bootstrap มี 12 หน่วย ถ้าเกินมันจะล่วงลงมาแถวใหม่ ถ้าใส่ไม่ถึง 12 มันจะมีช่องว่างที่เหลืออยู่\nวิธีการคือ ใช้คลาส col- ตามด้วยหน่วย เช่น ต้องการให้คอลัมภ์แรก 50% ของแถว อีกสองอันก็แบ่งอันละ 25%\n\u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col-6\u0026quot;\u0026gt; \u0026lt;img src=\u0026quot;img/staffs/staff1.jpg\u0026quot; class=\u0026quot;img-fluid\u0026quot; /\u0026gt; \u0026lt;h1\u0026gt;CEO\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt; Lorem ipsum dolor sit amet consectetur adipisicing elit. Optio odit illum autem porro! Quisquam voluptatibus nesciunt impedit, suscipit corporis, minus culpa molestiae necessitatibus blanditiis, repellat mollitia beatae hic voluptatum deleniti. \u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;col-3\u0026quot;\u0026gt; \u0026lt;img src=\u0026quot;img/staffs/staff2.jpg\u0026quot; class=\u0026quot;img-fluid\u0026quot; /\u0026gt; \u0026lt;h1\u0026gt;CTO\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt; Lorem ipsum dolor sit amet consectetur adipisicing elit. Optio odit illum autem porro! Quisquam voluptatibus nesciunt impedit, suscipit corporis, minus culpa molestiae necessitatibus blanditiis, repellat mollitia beatae hic voluptatum deleniti. \u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;col-3\u0026quot;\u0026gt; \u0026lt;img src=\u0026quot;img/staffs/staff3.jpg\u0026quot; class=\u0026quot;img-fluid\u0026quot; /\u0026gt; \u0026lt;h1\u0026gt;CFO\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt; Lorem ipsum dolor sit amet consectetur adipisicing elit. Optio odit illum autem porro! Quisquam voluptatibus nesciunt impedit, suscipit corporis, minus culpa molestiae necessitatibus blanditiis, repellat mollitia beatae hic voluptatum deleniti. \u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt;  ทีนี้ลองมาดูปัญหาเมื่อเปิดในจอของโทรศัพท์ คอลัมภ์สามอันมันดูอึดอัด การดูในมือถือมันควรจะแสดงทีละอัน มันยังไม่ responsive\nวิธีการคือใช้ Grid option เช่น col-md-4 หมายถึง ถ้าหน้าจอมีขนาดมากกว่า Medium มันจะใช้หน่วยขนาด 4 แต่ถ้าไม่ใช่ มันจะใช้ 1 เป็นค่าเดิม ซึ่ง Medium มีหน้าจอขนาด \u0026gt;= 768px ซึ่งคือหน้าจอคอมนั่นเอง ดังนั้น ถ้าหน้าจอเล็กมันก็จะใช้ col-1 แทนนั่นเอง หน้าจอมือถือเลยแสดง col-1 ซึ่งคืออันเดียวเต็มจอ\n\u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col-md-4\u0026quot;\u0026gt; \u0026lt;img src=\u0026quot;img/staffs/staff1.jpg\u0026quot; class=\u0026quot;img-fluid\u0026quot; /\u0026gt; \u0026lt;h1\u0026gt;CEO\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt; Lorem ipsum dolor sit amet consectetur adipisicing elit. Optio odit illum autem porro! Quisquam voluptatibus nesciunt impedit, suscipit corporis, minus culpa molestiae necessitatibus blanditiis, repellat mollitia beatae hic voluptatum deleniti. \u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;col-md-4\u0026quot;\u0026gt; \u0026lt;img src=\u0026quot;img/staffs/staff2.jpg\u0026quot; class=\u0026quot;img-fluid\u0026quot; /\u0026gt; \u0026lt;h1\u0026gt;CTO\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt; Lorem ipsum dolor sit amet consectetur adipisicing elit. Optio odit illum autem porro! Quisquam voluptatibus nesciunt impedit, suscipit corporis, minus culpa molestiae necessitatibus blanditiis, repellat mollitia beatae hic voluptatum deleniti. \u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;col-md-4\u0026quot;\u0026gt; \u0026lt;img src=\u0026quot;img/staffs/staff3.jpg\u0026quot; class=\u0026quot;img-fluid\u0026quot; /\u0026gt; \u0026lt;h1\u0026gt;CFO\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt; Lorem ipsum dolor sit amet consectetur adipisicing elit. Optio odit illum autem porro! Quisquam voluptatibus nesciunt impedit, suscipit corporis, minus culpa molestiae necessitatibus blanditiis, repellat mollitia beatae hic voluptatum deleniti. \u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;!-- Close Row 3 --\u0026gt;  พอเปิดในจอเล็กมันก็แสดงเต็มจอแล้ว\nดูรายละเอียดเรื่อง Grid Option ได้ที่\nhttps://getbootstrap.com/docs/4.0/layout/grid/\nซึ่งนอกจาก md แล้วก็มี sm , lg , xl ด้วย\n[จะได้ประมาณนี้\n[Source code https://gist.github.com/benznest/f365a2de60451b6696c78d5ce642e293\nการจัด Format ตอนนี้ เราจะเริ่มใช้  ซับซ้อนขึ้น โค้ดมันอาจจะไม่เป็นระเบียบ\nวิธีการให้มันจัดระเบียบ คือ คลิกขวาเลือก Format document หรือกด Shift + Alt + F\n[การซ้อน Grid เราสามารถนำ Grid มาซ้อนอีกชั้นได้ โดยมันจะยังใช้หน่วย 12 เหมือนเดิม\n\u0026lt;!-- Start Row 4 --\u0026gt; \u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col-md-6 col-12\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col-4\u0026quot;\u0026gt; \u0026lt;img src=\u0026quot;img/life/life2.jpg\u0026quot; class=\u0026quot;img-fluid\u0026quot; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;col-8\u0026quot;\u0026gt; \u0026lt;h3\u0026gt;Service\u0026lt;/h3\u0026gt; \u0026lt;p\u0026gt; Lorem ipsum dolor sit amet consectetur adipisicing elit. Optio odit illum autem porro! Quisquam voluptatibus nesciunt impedit \u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col-4\u0026quot;\u0026gt; \u0026lt;img src=\u0026quot;img/life/life3.jpg\u0026quot; class=\u0026quot;img-fluid\u0026quot; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;col-8\u0026quot;\u0026gt; \u0026lt;h3\u0026gt;Subscription\u0026lt;/h3\u0026gt; \u0026lt;p\u0026gt; Lorem ipsum dolor sit amet consectetur adipisicing elit. Optio odit illum autem porro! Quisquam voluptatibus nesciunt impedit \u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col-4\u0026quot;\u0026gt; \u0026lt;img src=\u0026quot;img/life/life4.jpg\u0026quot; class=\u0026quot;img-fluid\u0026quot; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;col-8\u0026quot;\u0026gt; \u0026lt;h3\u0026gt;More\u0026lt;/h3\u0026gt; \u0026lt;p\u0026gt; Lorem ipsum dolor sit amet consectetur adipisicing elit. Optio odit illum autem porro! Quisquam voluptatibus nesciunt impedit \u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;col-md-6 col-12\u0026quot;\u0026gt; \u0026lt;img src=\u0026quot;img/content/office12.jpg\u0026quot; class=\u0026quot;img-fluid\u0026quot; /\u0026gt; \u0026lt;h1\u0026gt;About\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt; Lorem ipsum dolor sit amet consectetur adipisicing elit. Optio odit illum autem porro! Quisquam voluptatibus nesciunt impedit, suscipit corporis, minus culpa molestiae necessitatibus blanditiis, repellat mollitia beatae hic voluptatum deleniti. \u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;!-- Close Row 4 --\u0026gt;  Source code https://gist.github.com/benznest/5c13cf8292c68a89183103233f53f7bd\nClass ของรูปภาพ เพิ่มความสวยงามให้กับรูปภาพ ด้วย class ชื่อว่า rounded รุปภาพจะมีขอบมน\n\u0026lt;img src=\u0026quot;img/life/life4.jpg\u0026quot; class=\u0026quot;img-fluid rounded\u0026quot; /\u0026gt;  หรือจะใช้ class ชื่อว่า rounded-circle ทำให้รูปเป็นวงกลม\n\u0026lt;img src=\u0026quot;img/life/life4.jpg\u0026quot; class=\u0026quot;img-fluid rounded-circle\u0026quot; /\u0026gt;  อีกอัน คือ class ชื่อว่า img-thumbnail ทำให้รูปมีขอบเป็นเส้นด้านนอก\n\u0026lt;img src=\u0026quot;img/life/life4.jpg\u0026quot; class=\u0026quot;img-fluid img-thumbnail\u0026quot; /\u0026gt;  Class ของ Width มี class ของ bootstrap ที่ใช้บ่อย เช่น การกำหนด width %\nเช่น w-50 คือกำหนด ให้มีขนาด 50% และการกำหนด mx-auto d-block คือการกำหนดตรงกลาง\n\u0026lt;img src=\u0026quot;img/staffs/staff1.jpg\u0026quot; class=\u0026quot;w-50 mx-auto d-block\u0026quot; /\u0026gt; \u0026lt;h1 class=\u0026quot;text-center\u0026quot;\u0026gt;CEO\u0026lt;/h1\u0026gt;  class เพื่อนๆในแก็งนี้ก็มี w-25 , w-50 , w-75 , w-100\n\u0026lt;img src=\u0026quot;img/staffs/staff1.jpg\u0026quot; class=\u0026quot;w-50\u0026quot; /\u0026gt; \u0026lt;img src=\u0026quot;img/staffs/staff2.jpg\u0026quot; class=\u0026quot;w-75\u0026quot; /\u0026gt; \u0026lt;img src=\u0026quot;img/staffs/staff3.jpg\u0026quot; class=\u0026quot;w-100\u0026quot; /\u0026gt;  การ Custom Bootstrap เวลาเราจะเพิ่ม css ของเราและต้องการทับกับ bootstrap ให้ไปเขียนที่ custom.css\nเช่น ต้องเปลี่ยนสีพื้นหลัง ของ class container ซึ่ง container เป็นของ bootstrap\nbody { background: #dcebfc; } .container { background: #fff; }  แล้วก็เวลาเรียกใน HTML ให้ใส่ทีหลัง bootstrap.css นะ เพราะมันจะได้อ่านทับ bootstrap แล้วนั่นเอง\n\u0026lt;head\u0026gt; \u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;css/bootstrap.min.css\u0026quot; /\u0026gt; \u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;css/custom.css\u0026quot; /\u0026gt; \u0026lt;/head\u0026gt;  หน่วย rem rem คือ root element มันคือการกำหนด font-size ที่ root แล้วเอามาคูณ เช่น ถ้ากำหนด font-size 10 px\n2 rem = 16×2 = 32 px นั่นเอง\nใน Bootstrap จะใช้ font-size = 16 px ดังนั้น 1 rem = 16 px\nลองกำหนด padding ของ container 4.5rem = 16×4.5 = 72px\nbody { background: #dcebfc; } .container { background: #fff; padding: 4.5rem; }  การ custom ค่า font-size ไม่ใช้ของ bootstrap ต้องไปเซ็ตใน html ที่เป็น root element\nhtml { font-size: 8px; }  ค่า rem ก็จะเปลี่ยนมาใช้ font-size ของเราแทน\nbody { background: #dcebfc; } .container { background: #fff; padding: 10rem; } h1, h2, h3 { color: #4f85d7; }  Class สำหรับ Margin – Padding – Border เราสามารถใช้ rem มาใช้กับ class Margin Padding ได้\nmargin คือระยะห่างจาก element นี้กับอันอื่น\npadding คือระยะห่างจากเนื้อหาถึงขอบ\nborder คือ ขนาดขอบ\nวิธีการคือ {boxmodel}{position}-{rem}\nmargin-top 3 rem = mt-3 padding 5 rem = p-5 margin 2 rem = m-2 padding-bottom 3 rem= pd-3  ลองกำหนด padding-top 4 rem ซึ่งมีขนาด 16×4 = 64 px\n\u0026lt;div class=\u0026quot;row pt-4\u0026quot;\u0026gt; ... \u0026lt;/div\u0026gt;  ซึ่ง class margin padding ใช้บ่อยมากๆ\n\u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col-3 mt-2\u0026quot;\u0026gt; \u0026lt;img src=\u0026quot;img/life/life.jpg\u0026quot; class=\u0026quot;img-fluid rounded\u0026quot; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;col-3 mt-2\u0026quot;\u0026gt; \u0026lt;img src=\u0026quot;img/life/life2.jpg\u0026quot; class=\u0026quot;img-fluid rounded\u0026quot; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;col-3 mt-2\u0026quot;\u0026gt; \u0026lt;img src=\u0026quot;img/life/life3.jpg\u0026quot; class=\u0026quot;img-fluid rounded\u0026quot; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;col-3 mt-2\u0026quot;\u0026gt; \u0026lt;img src=\u0026quot;img/life/life4.jpg\u0026quot; class=\u0026quot;img-fluid rounded\u0026quot; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;col-3 mt-2\u0026quot;\u0026gt; \u0026lt;img src=\u0026quot;img/life/life5.jpg\u0026quot; class=\u0026quot;img-fluid rounded\u0026quot; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;col-3 mt-2\u0026quot;\u0026gt; \u0026lt;img src=\u0026quot;img/life/life6.jpg\u0026quot; class=\u0026quot;img-fluid rounded\u0026quot; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;col-3 mt-2\u0026quot;\u0026gt; \u0026lt;img src=\u0026quot;img/life/life7.jpg\u0026quot; class=\u0026quot;img-fluid rounded\u0026quot; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;col-3 mt-2\u0026quot;\u0026gt; \u0026lt;img src=\u0026quot;img/life/life8.jpg\u0026quot; class=\u0026quot;img-fluid rounded\u0026quot; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;!-- Close Row 5 --\u0026gt;  Custom font มาลองเปลี่ยน font ให้กับเว็บกัน\nเข้าไปดาวน์โหลด font ที่ Google Font\nhttps://fonts.google.com/\nเลือกอันที่ชอบ กด +\n[มันจะมีแถบด้านล่าง กดขึ้นมาเลือกแท็บ IMPORT แล้ว copy โค้ด @import\n[เอาไปวางใน custom.css ของเรา\nจากนั้นอยากใช้ font ตรงไหนก็เอา font-family ไปวางไว้ เช่นใส่ทั้งหน้าเลยก็ใส่ที่ body\n@import url(\u0026quot;https://fonts.googleapis.com/css?family=Indie+Flower\u0026quot;); body { background: #dcebfc; font-family: \u0026quot;Indie Flower\u0026quot;, cursive; } .container { background: #fff; padding: 1.5rem; } h1, h2, h3 { color: #4f85d7; }  ทำ Footer ลองเพิ่ม class ของเราเองชื่อ footer\nเนื้อหาใส่เป็นคำคม เพื่อลองใช้ font อีกตัว\n\u0026lt;div class=\u0026quot;row footer p-5\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col-12\u0026quot;\u0026gt; \u0026lt;h2 class=\u0026quot;text-center\u0026quot;\u0026gt; Nothing in life is to be feared, it is only to be understood. Now is the time to understand more, so that we may fear less. \u0026lt;/h2\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt;  ก็ทำเหมือนเดิม คือเพิ่มตรง @import\nแล้วก็ใส่ font-family ที่ footer\n@import url(\u0026quot;https://fonts.googleapis.com/css?family=Dancing+Script|Indie+Flower\u0026quot;); body { background: #dcebfc; font-family: \u0026quot;Indie Flower\u0026quot;, cursive; } .container { background: #fff; padding: 1.5rem; } h1, h2, h3 { color: #4f85d7; } .footer { font-family: \u0026quot;Dancing Script\u0026quot;, cursive; }  Source code https://gist.github.com/benznest/21a5a7f2acbce4815433cd77f91c0b8e\nFontawesome fontawesome คือ ไลบรารี่เกี่ยวกับ icon ซึ่ง Bootstrap 4 ไม่มี fontawesome ติดมาอีกแล้ว เนื่องจาก fontawesome ไม่มีฟรี\nhttps://fontawesome.com/how-to-use/on-the-web/setup/getting-started?using=web-fonts-with-css\ncopy link CDN ของ Fontawesome เข้ามา\n\u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;css/bootstrap.min.css\u0026quot; /\u0026gt; \u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;https://use.fontawesome.com/releases/v5.5.0/css/all.css\u0026quot; integrity=\u0026quot;sha384-B4dIYHKNBt8Bc12p+WXckhzcICo0wtJAoU8YZTY5qE0Id1GSseTk6S+L3BlXeVIU\u0026quot; crossorigin=\u0026quot;anonymous\u0026quot; /\u0026gt; \u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;css/custom.css\u0026quot; /\u0026gt;  ในเว็บ Fontawesome ก็เลือก icon ที่ชอบ พอกดเข้าไปมันจะมีโค้ดอยู่\n[ให้นำโค้ด มาใช้ โดย  คือ icon มันต้องอยู่ภายใต้แท็กอื่นๆ\n\u0026lt;h2 class=\u0026quot;text-center\u0026quot;\u0026gt; \u0026lt;i class=\u0026quot;far fa-kiss-wink-heart\u0026quot;\u0026gt;\u0026lt;/i\u0026gt; Nothing in life is to be feared, it is only to be understood. Now is the time to understand more, so that we may fear less. \u0026lt;/h2\u0026gt;  เราสามารถนำ  มาใช้ได้เพื่อกำหนดขนาดของมัน\nเช่น custom.css กำหนดขนาดของ icon ที่ 10rem\n.front-icon { display: block; } .front-icon i { font-size: 10rem; }  ใน html ก็เอา span มาครอบ\n\u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col-12\u0026quot;\u0026gt; \u0026lt;span class=\u0026quot;front-icon text-center\u0026quot;\u0026gt; \u0026lt;i class=\u0026quot;far fa-kiss-wink-heart\u0026quot;\u0026gt;\u0026lt;/i\u0026gt; \u0026lt;/span\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;!-- Close Row 7 --\u0026gt;  icon จะมีขนาด 10rem แล้ว\n[หรือจะใช้พื้นหลังสีอื่น ไอคอนสีขาว\n.front-icon { display: block; color: #ffffff; padding: 3rem; background: #4f85d7; } .front-icon i { font-size: 10rem; }  Class ของสี class utilities ที่ใช้บ่อยอีกตัวคือ เกี่ยวกับสี\nอ่านได้ที่ https://getbootstrap.com/docs/4.0/utilities/colors/\nหลักๆคือ มีให้เลือกใช้ดังนี้\n_primary **danger **success **info **dark \\_\\_light_  ใช้กับ class พวก bg- , text-\nเช่น\n\u0026lt;h3 class=\u0026quot;bg-primary p-2 text-white\u0026quot;\u0026gt;Service\u0026lt;/h3\u0026gt;  วิธี Custom เช่นอยากเปลี่ยนสีให้ต่างจาก bootstrap ให้ใส่ !important ด้วย\n.bg-primary { background: #4f85d7 !important; }  การใช้ Animate.css เข้าไปดาวน์โหลด css ได้ที่\nhttps://daneden.github.io/animate.css/\nแล้วเพิ่มเข้ามาใน HTML ของเรา\n\u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;css/animate.css\u0026quot; /\u0026gt;  วิธีการเรียกใช้ ก็แค่ใช้ class\nanimated = เรียกใช้ animated\ninfinite = ทำไปเรื่อยๆ\npulse = Animation แบบ pulse\ndelay-1s = delay 1 วินาที\n\u0026lt;h2 class=\u0026quot;text-center animated infinite pulse delay-1s\u0026quot;\u0026gt; \u0026lt;i class=\u0026quot;far fa-kiss-wink-heart\u0026quot;\u0026gt;\u0026lt;/i\u0026gt; Nothing in life is to be feared, it is only to be understood. Now is the time to understand more, so that we may fear less. \u0026lt;/h2\u0026gt;  Source code https://gist.github.com/benznest/ad45fd26b773e1ff47bb9727a4702494\nสรุป บทความนี้ก็สรุปคร่าวๆเกี่ยวกับการใช้ bootstrap ที่เป็นเรื่องสำคัญๆ เช่นการใช้ grid จัดวาง layout การทำให้รองรับ responsive การใช้ utility class เช่น margin padding รวมถึงพวกสี เช่น primary danger ที่เจอบ่อยมาก แล้วก็แนะนำเกี่ยวกับหน่วย rem ด้วย แถมด้วยเปลี่ยน Font กับใส่ Icon\nตอนหน้าจะเป็นเรื่องของการใช้ component อื่นๆที่ใช้งานบ่อยๆ รวมถึงเทคนิคเกี่ยวกับ bootstrap เพิ่มเติมด้วย\n Source : benzneststudios.com.\n "});index.add({'id':10,'href':'/library/tutorials/docs/articles/webapp/falsk/build-a-crud-web-app/','title':"Build a CRUD Web App. 1-3",'content':" Python Flask for Beginners: Build a CRUD Web App with Python and Flask Part 1-3 Content  Part. I Part. II Part. III  "});index.add({'id':11,'href':'/library/tutorials/docs/python/pandas/1_io/csv-and-text-file/','title':"CSV \u0026 Text files",'content':" CSV \u0026amp; Text files The workhorse function for reading text files (a.k.a. flat files) is read_csv(). See the cookbook for some advanced strategies.\nParsing options read_csv() accepts the following common arguments:\nBasic filepath_or_buffervarious\nEither a path to a file (a str\u0026rdquo;), pathlib.Path\u0026rdquo;), or py._path.local.LocalPath), URL (including http, ftp, and S3 locations), or any object with a read() method (such as an open file or StringIO\u0026rdquo;)).\nsepstr, defaults to ',' for read_csv(), \\t for read_table()\nDelimiter to use. If sep is None, the C engine cannot automatically detect the separator, but the Python parsing engine can, meaning the latter will be used and automatically detect the separator by Python’s builtin sniffer tool, csv.Sniffer\u0026rdquo;). In addition, separators longer than 1 character and different from '\\s+' will be interpreted as regular expressions and will also force the use of the Python parsing engine. Note that regex delimiters are prone to ignoring quoted data. Regex example: '\\\\r\\\\t'.\ndelimiterstr, default None Alternative argument name for sep.\ndelim_whitespaceboolean, default False Specifies whether or not whitespace (e.g. ' ' or '\\t') will be used as the delimiter. Equivalent to setting sep='\\s+'. If this option is set to True, nothing should be passed in for the delimiter parameter.\nColumn and index locations and names headerint or list of ints, default 'infer' Row number(s) to use as the column names, and the start of the data. Default behavior is to infer the column names: if no names are passed the behavior is identical to header=0 and column names are inferred from the first line of the file, if column names are passed explicitly then the behavior is identical to header=None. Explicitly pass header=0 to be able to replace existing names.\nThe header can be a list of ints that specify row locations for a MultiIndex on the columns e.g. [0,1,3]. Intervening rows that are not specified will be skipped (e.g. 2 in this example is skipped). Note that this parameter ignores commented lines and empty lines if skip_blank_lines=True, so header=0 denotes the first line of data rather than the first line of the file.\nnamesarray-like, default None List of column names to use. If file contains no header row, then you should explicitly pass header=None. Duplicates in this list are not allowed.\nindex_colint, str, sequence of int / str, or False, default None Column(s) to use as the row labels of the DataFrame, either given as string name or column index. If a sequence of int / str is given, a MultiIndex is used.\nNote: index_col=False can be used to force pandas to not use the first column as the index, e.g. when you have a malformed file with delimiters at the end of each line.\nusecolslist-like or callable, default None\nReturn a subset of the columns. If list-like, all elements must either be positional (i.e. integer indices into the document columns) or strings that correspond to column names provided either by the user in names or inferred from the document header row(s). For example, a valid list-like usecols parameter would be [0, 1, 2] or ['foo', 'bar', 'baz'].\nElement order is ignored, so usecols=[0, 1] is the same as [1, 0]. To instantiate a DataFrame from data with element order preserved use pd.read_csv(data, usecols=['foo', 'bar'])[['foo', 'bar']] for columns in ['foo', 'bar'] order or pd.read_csv(data, usecols=['foo', 'bar'])[['bar', 'foo']] for ['bar', 'foo'] order.\nIf callable, the callable function will be evaluated against the column names, returning names where the callable function evaluates to True:\nIn [1]: import pandas as pd In [2]: from io import StringIO In [3]: data = ('col1,col2,col3\\n' ...: 'a,b,1\\n' ...: 'a,b,2\\n' ...: 'c,d,3') ...: In [4]: pd.read_csv(StringIO(data)) Out[4]: col1 col2 col3 0 a b 1 1 a b 2 2 c d 3 In [5]: pd.read_csv(StringIO(data), usecols=lambda x: x.upper() in ['COL1', 'COL3']) Out[5]: col1 col3 0 a 1 1 a 2 2 c 3  Using this parameter results in much faster parsing time and lower memory usage.\nsqueezeboolean, default False If the parsed data only contains one column then return a Series.\nprefixstr, default None Prefix to add to column numbers when no header, e.g. ‘X’ for X0, X1, …\nmangle_dupe_colsboolean, default True Duplicate columns will be specified as ‘X’, ‘X.1’…’X.N’, rather than ‘X’…’X’. Passing in False will cause data to be overwritten if there are duplicate names in the columns.\nGeneral parsing configuration dtypeType name or dict of column -\u0026gt; type, default None\nData type for data or columns. E.g. {'a': np.float64, 'b': np.int32} (unsupported with engine='python'). Use str or object together with suitable na_values settings to preserve and not interpret dtype.\nengine{'c', 'python'}\nParser engine to use. The C engine is faster while the Python engine is currently more feature-complete.\nconvertersdict, default None\nDict of functions for converting values in certain columns. Keys can either be integers or column labels.\ntrue_valueslist, default None Values to consider as True. false_valueslist, default None Values to consider as False. skipinitialspaceboolean, default False Skip spaces after delimiter. skiprowslist-like or integer, default None\nLine numbers to skip (0-indexed) or number of lines to skip (int) at the start of the file.\nIf callable, the callable function will be evaluated against the row indices, returning True if the row should be skipped and False otherwise:\nIn [6]: data = ('col1,col2,col3\\n' ...: 'a,b,1\\n' ...: 'a,b,2\\n' ...: 'c,d,3') ...: In [7]: pd.read_csv(StringIO(data)) Out[7]: col1 col2 col3 0 a b 1 1 a b 2 2 c d 3 In [8]: pd.read_csv(StringIO(data), skiprows=lambda x: x % 2 != 0) Out[8]: col1 col2 col3 0 a b 2  skipfooterint, default 0 Number of lines at bottom of file to skip (unsupported with engine=’c’).\nnrowsint, default None Number of rows of file to read. Useful for reading pieces of large files.\nlow_memoryboolean, default True Internally process the file in chunks, resulting in lower memory use while parsing, but possibly mixed type inference. To ensure no mixed types either set False, or specify the type with the dtype parameter. Note that the entire file is read into a single DataFrame regardless, use the chunksize or iterator parameter to return the data in chunks. (Only valid with C parser)\nmemory_mapboolean, default False If a filepath is provided for filepath_or_buffer, map the file object directly onto memory and access the data directly from there. Using this option can improve performance because there is no longer any I/O overhead.\nNA and missing data handling na_valuesscalar, str, list-like, or dict, default None Additional strings to recognize as NA/NaN. If dict passed, specific per-column NA values. See na values const below for a list of the values interpreted as NaN by default.\nkeep_default_naboolean, default True Whether or not to include the default NaN values when parsing the data. Depending on whether na_values is passed in, the behavior is as follows:\n If keep_default_na is True, and na_values are specified, na_values is appended to the default NaN values used for parsing.\n If keep_default_na is True, and na_values are not specified, only the default NaN values are used for parsing.\n If keep_default_na is False, and na_values are specified, only the NaN values specified na_values are used for parsing.\n If keep_default_na is False, and na_values are not specified, no strings will be parsed as NaN.\n  Note that if na_filter is passed in as False, the keep_default_na and na_values parameters will be ignored.\nna_filterboolean, default True\nDetect missing value markers (empty strings and the value of na_values). In data without any NAs, passing na_filter=False can improve the performance of reading a large file.\nverboseboolean, default False\nIndicate number of NA values placed in non-numeric columns.\nskip_blank_linesboolean, default True\nIf True, skip over blank lines rather than interpreting as NaN values.\nDatetime handling parse_datesboolean or list of ints or names or list of lists or dict, default False.\n If True -\u0026gt; try parsing the index.\n If [1, 2, 3] -\u0026gt; try parsing columns 1, 2, 3 each as a separate date column.\n If [[1, 3]] -\u0026gt; combine columns 1 and 3 and parse as a single date column.\n If {'foo': [1, 3]} -\u0026gt; parse columns 1, 3 as date and call result ‘foo’. A fast-path exists for iso8601-formatted dates.\n  infer_datetime_formatboolean, default False\nIf True and parse_dates is enabled for a column, attempt to infer the datetime format to speed up the processing.\nkeep_date_colboolean, default False\nIf True and parse_dates specifies combining multiple columns then keep the original columns.\ndate_parserfunction, default None\nFunction to use for converting a sequence of string columns to an array of datetime instances. The default uses dateutil.parser.parser to do the conversion. pandas will try to call date_parser in three different ways, advancing to the next if an exception occurs: 1) Pass one or more arrays (as defined by parse_dates) as arguments; 2) concatenate (row-wise) the string values from the columns defined by parse_dates into a single array and pass that; and 3) call date_parser once for each row using one or more strings (corresponding to the columns defined by parse_dates) as arguments.\ndayfirstboolean, default False\nDD/MM format dates, international and European format.\ncache_datesboolean, default True\nIf True, use a cache of unique, converted dates to apply the datetime conversion. May produce significant speed-up when parsing duplicate date strings, especially ones with timezone offsets.\nNew in version 0.25.0.\nIteration iteratorboolean, default False\nReturn TextFileReader object for iteration or getting chunks with get_chunk().\nchunksizeint, default None\nReturn TextFileReader object for iteration. See iterating and chunking below.\nQuoting, compression, and file format compression{`'infer'`, `'gzip'`, `'bz2'`, `'zip'`, `'xz'`, `None`}, default `'infer'`  For on-the-fly decompression of on-disk data. If ‘infer’, then use gzip, bz2, zip, or xz if filepath_or_buffer is a string ending in ‘.gz’, ‘.bz2’, ‘.zip’, or ‘.xz’, respectively, and no decompression otherwise. If using ‘zip’, the ZIP file must contain only one data file to be read in. Set to None for no decompression.\nChanged in version 0.24.0: ‘infer’ option added and set to default.\nthousandsstr, default None\nThousands separator.\ndecimalstr, default '.'\nCharacter to recognize as decimal point. E.g. use ',' for European data.\nfloat_precisionstring, default None\nSpecifies which converter the C engine should use for floating-point values. The options are None for the ordinary converter, high for the high-precision converter, and round_trip for the round-trip converter.\nlineterminatorstr (length 1), default None Character to break file into lines. Only valid with C parser.\nquotecharstr (length 1) The character used to denote the start and end of a quoted item. Quoted items can include the delimiter and it will be ignored.\nquotingint or csv.QUOTE_* instance, default 0\nControl field quoting behavior per csv.QUOTE_* constants. Use one of QUOTE_MINIMAL (0), QUOTE_ALL (1), QUOTE_NONNUMERIC (2) or QUOTE_NONE (3).\ndoublequoteboolean, default True\nWhen quotechar is specified and quoting is not QUOTE_NONE, indicate whether or not to interpret two consecutive quotechar elements inside a field as a single quotechar element.\nescapecharstr (length 1), default None\nOne-character string used to escape delimiter when quoting is QUOTE_NONE.\ncommentstr, default None\nIndicates remainder of line should not be parsed. If found at the beginning of a line, the line will be ignored altogether. This parameter must be a single character. Like empty lines (as long as skip_blank_lines=True), fully commented lines are ignored by the parameter header but not by skiprows. For example, if comment='#', parsing ‘#empty\\na,b,c\\n1,2,3’ with header=0 will result in ‘a,b,c’ being treated as the header.\nencodingstr, default None\nEncoding to use for UTF when reading/writing (e.g. 'utf-8'). List of Python standard encodings.\ndialectstr or csv.Dialect\u0026rdquo;) instance, default None\nIf provided, this parameter will override values (default or not) for the following parameters: delimiter, doublequote, escapechar, skipinitialspace, quotechar, and quoting. If it is necessary to override values, a ParserWarning will be issued. See csv.Dialect\u0026rdquo;) documentation for more details.\nError handling error_bad_linesboolean, default True\nLines with too many fields (e.g. a csv line with too many commas) will by default cause an exception to be raised, and no DataFrame will be returned. If False, then these “bad lines” will dropped from the DataFrame that is returned. See bad lines below.\nwarn_bad_linesboolean, default True\nIf error_bad_lines is False, and warn_bad_lines is True, a warning for each “bad line” will be output.\nSpecifying column data types You can indicate the data type for the whole DataFrame or individual columns:\nIn [9]: import numpy as np In [10]: data = ('a,b,c,d\\n' ....: '1,2,3,4\\n' ....: '5,6,7,8\\n' ....: '9,10,11') ....: In [11]: print(data) a,b,c,d 1,2,3,4 5,6,7,8 9,10,11 In [12]: df = pd.read_csv(StringIO(data), dtype=object) In [13]: df Out[13]: a b c d 0 1 2 3 4 1 5 6 7 8 2 9 10 11 NaN In [14]: df['a'][0] Out[14]: '1' In [15]: df = pd.read_csv(StringIO(data), ....: dtype={'b': object, 'c': np.float64, 'd': 'Int64'}) ....: In [16]: df.dtypes Out[16]: a int64 b object c float64 d Int64 dtype: object  Fortunately, pandas offers more than one way to ensure that your column(s) contain only one dtype. If you’re unfamiliar with these concepts, you can see here to learn more about dtypes, and here to learn more about object conversion in pandas.\nFor instance, you can use the converters argument of read_csv():\nIn [17]: data = (\u0026quot;col_1\\n\u0026quot; ....: \u0026quot;1\\n\u0026quot; ....: \u0026quot;2\\n\u0026quot; ....: \u0026quot;'A'\\n\u0026quot; ....: \u0026quot;4.22\u0026quot;) ....: In [18]: df = pd.read_csv(StringIO(data), converters={'col_1': str}) In [19]: df Out[19]: col_1 0 1 1 2 2 'A' 3 4.22 In [20]: df['col_1'].apply(type).value_counts() Out[20]: \u0026lt;class 'str'\u0026gt; 4 Name: col_1, dtype: int64  Or you can use the to_numeric() function to coerce the dtypes after reading in the data,\nIn [21]: df2 = pd.read_csv(StringIO(data)) In [22]: df2['col_1'] = pd.to_numeric(df2['col_1'], errors='coerce') In [23]: df2 Out[23]: col_1 0 1.00 1 2.00 2 NaN 3 4.22 In [24]: df2['col_1'].apply(type).value_counts() Out[24]: \u0026lt;class 'float'\u0026gt; 4 Name: col_1, dtype: int64  which will convert all valid parsing to floats, leaving the invalid parsing as NaN.\nUltimately, how you deal with reading in columns containing mixed dtypes depends on your specific needs. In the case above, if you wanted to NaN out the data anomalies, then to_numeric() is probably your best option. However, if you wanted for all the data to be coerced, no matter the type, then using the converters argument of read_csv() would certainly be worth trying.\n Note\nIn some cases, reading in abnormal data with columns containing mixed dtypes will result in an inconsistent dataset. If you rely on pandas to infer the dtypes of your columns, the parsing engine will go and infer the dtypes for different chunks of the data, rather than the whole dataset at once. Consequently, you can end up with column(s) with mixed dtypes. For example,\n In [25]: col_1 = list(range(500000)) + ['a', 'b'] + list(range(500000)) In [26]: df = pd.DataFrame({'col_1': col_1}) In [27]: df.to_csv('foo.csv') In [28]: mixed_df = pd.read_csv('foo.csv') In [29]: mixed_df['col_1'].apply(type).value_counts() Out[29]: \u0026lt;class 'int'\u0026gt; 737858 \u0026lt;class 'str'\u0026gt; 262144 Name: col_1, dtype: int64 In [30]: mixed_df['col_1'].dtype Out[30]: dtype('O')  will result with mixed_df containing an int dtype for certain chunks of the column, and str for others due to the mixed dtypes from the data that was read in. It is important to note that the overall column will be marked with a dtype of object, which is used for columns with mixed dtypes.\nSpecifying categorical dtype Categorical columns can be parsed directly by specifying dtype='category' or dtype=CategoricalDtype(categories, ordered).\nIn [31]: data = ('col1,col2,col3\\n' ....: 'a,b,1\\n' ....: 'a,b,2\\n' ....: 'c,d,3') ....: In [32]: pd.read_csv(StringIO(data)) Out[32]: col1 col2 col3 0 a b 1 1 a b 2 2 c d 3 In [33]: pd.read_csv(StringIO(data)).dtypes Out[33]: col1 object col2 object col3 int64 dtype: object In [34]: pd.read_csv(StringIO(data), dtype='category').dtypes Out[34]: col1 category col2 category col3 category dtype: object Individual columns can be parsed as a `Categorical` using a dict specification: In [35]: pd.read_csv(StringIO(data), dtype={'col1': 'category'}).dtypes Out[35]: col1 category col2 object col3 int64 dtype: object New in version 0.21.0. Specifying `dtype='category'` will result in an unordered `Categorical` whose `categories` are the unique values observed in the data. For more control on the categories and order, create a `CategoricalDtype` ahead of time, and pass that for that column’s `dtype`. In [36]: from pandas.api.types import CategoricalDtype In [37]: dtype = CategoricalDtype(['d', 'c', 'b', 'a'], ordered=True) In [38]: pd.read_csv(StringIO(data), dtype={'col1': dtype}).dtypes Out[38]: col1 category col2 object col3 int64 dtype: object  When using dtype=CategoricalDtype, “unexpected” values outside of dtype.categories are treated as missing values.\nIn [39]: dtype = CategoricalDtype(['a', 'b', 'd']) # No 'c' In [40]: pd.read_csv(StringIO(data), dtype={'col1': dtype}).col1 Out[40]: 0 a 1 a 2 NaN Name: col1, dtype: category Categories (3, object): [a, b, d]  This matches the behavior of Categorical.set_categories().\nNote\nWith dtype='category', the resulting categories will always be parsed as strings (object dtype). If the categories are numeric they can be converted using the to_numeric() function, or as appropriate, another converter such as to_datetime().\nWhen dtype is a CategoricalDtype with homogeneous categories ( all numeric, all datetimes, etc.), the conversion is done automatically.\nIn [41]: df = pd.read_csv(StringIO(data), dtype='category') In [42]: df.dtypes Out[42]: col1 category col2 category col3 category dtype: object In [43]: df['col3'] Out[43]: 0 1 1 2 2 3 Name: col3, dtype: category Categories (3, object): [1, 2, 3] In [44]: df['col3'].cat.categories = pd.to_numeric(df['col3'].cat.categories) In [45]: df['col3'] Out[45]: 0 1 1 2 2 3 Name: col3, dtype: category Categories (3, int64): [1, 2, 3]  Naming and using columns Handling column names A file may or may not have a header row. pandas assumes the first row should be used as the column names:\nIn [46]: data = ('a,b,c\\n' ....: '1,2,3\\n' ....: '4,5,6\\n' ....: '7,8,9') ....: In [47]: print(data) a,b,c 1,2,3 4,5,6 7,8,9 In [48]: pd.read_csv(StringIO(data)) Out[48]: a b c 0 1 2 3 1 4 5 6 2 7 8 9  By specifying the names argument in conjunction with header you can indicate other names to use and whether or not to throw away the header row (if any):\nIn [49]: print(data) a,b,c 1,2,3 4,5,6 7,8,9 In [50]: pd.read_csv(StringIO(data), names=['foo', 'bar', 'baz'], header=0) Out[50]: foo bar baz 0 1 2 3 1 4 5 6 2 7 8 9 In [51]: pd.read_csv(StringIO(data), names=['foo', 'bar', 'baz'], header=None) Out[51]: foo bar baz 0 a b c 1 1 2 3 2 4 5 6 3 7 8 9  If the header is in a row other than the first, pass the row number to header. This will skip the preceding rows:\nIn [52]: data = ('skip this skip it\\n' ....: 'a,b,c\\n' ....: '1,2,3\\n' ....: '4,5,6\\n' ....: '7,8,9') ....: In [53]: pd.read_csv(StringIO(data), header=1) Out[53]: a b c 0 1 2 3 1 4 5 6 2 7 8 9   Note\nDefault behavior is to infer the column names: if no names are passed the behavior is identical to header=0 and column names are inferred from the first non-blank line of the file, if column names are passed explicitly then the behavior is identical to header=None.\n Duplicate names parsing If the file or header contains duplicate names, pandas will by default distinguish between them so as to prevent overwriting data:\nIn [54]: data = ('a,b,a\\n' ....: '0,1,2\\n' ....: '3,4,5') ....: In [55]: pd.read_csv(StringIO(data)) Out[55]: a b a.1 0 0 1 2 1 3 4 5  There is no more duplicate data because mangle_dupe_cols=True by default, which modifies a series of duplicate columns ‘X’, …, ‘X’ to become ‘X’, ‘X.1’, …, ‘X.N’. If mangle_dupe_cols=False, duplicate data can arise:\nIn [2]: data = 'a,b,a\\n0,1,2\\n3,4,5' In [3]: pd.read_csv(StringIO(data), mangle_dupe_cols=False) Out[3]: a b a 0 2 1 2 1 5 4 5  To prevent users from encountering this problem with duplicate data, a ValueError exception is raised if mangle_dupe_cols != True:\nIn [2]: data = 'a,b,a\\n0,1,2\\n3,4,5' In [3]: pd.read_csv(StringIO(data), mangle_dupe_cols=False) ... ValueError: Setting mangle_dupe_cols=False is not supported yet  Filtering columns (usecols) The usecols argument allows you to select any subset of the columns in a file, either using the column names, position numbers or a callable:\nIn [56]: data = 'a,b,c,d\\n1,2,3,foo\\n4,5,6,bar\\n7,8,9,baz' In [57]: pd.read_csv(StringIO(data)) Out[57]: a b c d 0 1 2 3 foo 1 4 5 6 bar 2 7 8 9 baz In [58]: pd.read_csv(StringIO(data), usecols=['b', 'd']) Out[58]: b d 0 2 foo 1 5 bar 2 8 baz In [59]: pd.read_csv(StringIO(data), usecols=[0, 2, 3]) Out[59]: a c d 0 1 3 foo 1 4 6 bar 2 7 9 baz In [60]: pd.read_csv(StringIO(data), usecols=lambda x: x.upper() in ['A', 'C']) Out[60]: a c 0 1 3 1 4 6 2 7 9  The usecols argument can also be used to specify which columns not to use in the final result:\nIn [61]: pd.read_csv(StringIO(data), usecols=lambda x: x not in ['a', 'c']) Out[61]: b d 0 2 foo 1 5 bar 2 8 baz  In this case, the callable is specifying that we exclude the “a” and “c” columns from the output.\nComments and empty lines Ignoring line comments and empty lines If the comment parameter is specified, then completely commented lines will be ignored. By default, completely blank lines will be ignored as well.\nIn [62]: data = ('\\n' ....: 'a,b,c\\n' ....: ' \\n' ....: '# commented line\\n' ....: '1,2,3\\n' ....: '\\n' ....: '4,5,6') ....: In [63]: print(data) a,b,c # commented line 1,2,3 4,5,6 In [64]: pd.read_csv(StringIO(data), comment='#') Out[64]: a b c 0 1 2 3 1 4 5 6  If skip_blank_lines=False, then read_csv will not ignore blank lines:\nIn [65]: data = ('a,b,c\\n' ....: '\\n' ....: '1,2,3\\n' ....: '\\n' ....: '\\n' ....: '4,5,6') ....: In [66]: pd.read_csv(StringIO(data), skip_blank_lines=False) Out[66]: a b c 0 NaN NaN NaN 1 1.0 2.0 3.0 2 NaN NaN NaN 3 NaN NaN NaN 4 4.0 5.0 6.0   Warning\nThe presence of ignored lines might create ambiguities involving line numbers; the parameter header uses row \u0026gt;numbers (ignoring commented/empty lines), while skiprows uses line numbers (including commented/empty lines):\n In [67]: data = ('#comment\\n' ....: 'a,b,c\\n' ....: 'A,B,C\\n' ....: '1,2,3') ....: In [68]: pd.read_csv(StringIO(data), comment='#', header=1) Out[68]: A B C 0 1 2 3 In [69]: data = ('A,B,C\\n' ....: '#comment\\n' ....: 'a,b,c\\n' ....: '1,2,3') ....: In [70]: pd.read_csv(StringIO(data), comment='#', skiprows=2) Out[70]: a b c 0 1 2 3  If both header and skiprows are specified, header will be relative to the end of skiprows. For example:\nIn [71]: data = ('# empty\\n' ....: '# second empty line\\n' ....: '# third emptyline\\n' ....: 'X,Y,Z\\n' ....: '1,2,3\\n' ....: 'A,B,C\\n' ....: '1,2.,4.\\n' ....: '5.,NaN,10.0\\n') ....: In [72]: print(data) # empty # second empty line # third emptyline X,Y,Z 1,2,3 A,B,C 1,2.,4. 5.,NaN,10.0 In [73]: pd.read_csv(StringIO(data), comment='#', skiprows=4, header=1) Out[73]: A B C 0 1.0 2.0 4.0 1 5.0 NaN 10.0  Comments Sometimes comments or meta data may be included in a file:\nIn [74]: print(open('tmp.csv').read()) ID,level,category Patient1,123000,x # really unpleasant Patient2,23000,y # wouldn't take his medicine Patient3,1234018,z # awesome  By default, the parser includes the comments in the output:\nIn [75]: df = pd.read_csv('tmp.csv') In [76]: df Out[76]: ID level category 0 Patient1 123000 x # really unpleasant 1 Patient2 23000 y # wouldn't take his medicine 2 Patient3 1234018 z # awesome  We can suppress the comments using the comment keyword:\nIn [77]: df = pd.read_csv('tmp.csv', comment='#') In [78]: df Out[78]: ID level category 0 Patient1 123000 x 1 Patient2 23000 y 2 Patient3 1234018 z  Dealing with Unicode data The encoding argument should be used for encoded unicode data, which will result in byte strings being decoded to unicode in the result:\nIn [79]: from io import BytesIO In [80]: data = (b'word,length\\n' ....: b'Tr\\xc3\\xa4umen,7\\n' ....: b'Gr\\xc3\\xbc\\xc3\\x9fe,5') ....: In [81]: data = data.decode('utf8').encode('latin-1') In [82]: df = pd.read_csv(BytesIO(data), encoding='latin-1') In [83]: df Out[83]: word length 0 Träumen 7 1 Grüße 5 In [84]: df['word'][1] Out[84]: 'Grüße'  Some formats which encode all characters as multiple bytes, like UTF-16, won’t parse correctly at all without specifying the encoding. Full list of Python standard encodings.\nIndex columns and trailing delimiters If a file has one more column of data than the number of column names, the first column will be used as the DataFrame’s row names:\nIn [85]: data = ('a,b,c\\n' ....: '4,apple,bat,5.7\\n' ....: '8,orange,cow,10') ....: In [86]: pd.read_csv(StringIO(data)) Out[86]: a b c 4 apple bat 5.7 8 orange cow 10.0 In [87]: data = ('index,a,b,c\\n' ....: '4,apple,bat,5.7\\n' ....: '8,orange,cow,10') ....: In [88]: pd.read_csv(StringIO(data), index_col=0) Out[88]: a b c index 4 apple bat 5.7 8 orange cow 10.0  Ordinarily, you can achieve this behavior using the index_col option.\nThere are some exception cases when a file has been prepared with delimiters at the end of each data line, confusing the parser. To explicitly disable the index column inference and discard the last column, pass index_col=False:\nIn [89]: data = ('a,b,c\\n' ....: '4,apple,bat,\\n' ....: '8,orange,cow,') ....: In [90]: print(data) a,b,c 4,apple,bat, 8,orange,cow, In [91]: pd.read_csv(StringIO(data)) Out[91]: a b c 4 apple bat NaN 8 orange cow NaN In [92]: pd.read_csv(StringIO(data), index_col=False) Out[92]: a b c 0 4 apple bat 1 8 orange cow  If a subset of data is being parsed using the usecols option, the index_col specification is based on that subset, not the original data.\nIn [93]: data = ('a,b,c\\n' ....: '4,apple,bat,\\n' ....: '8,orange,cow,') ....: In [94]: print(data) a,b,c 4,apple,bat, 8,orange,cow, In [95]: pd.read_csv(StringIO(data), usecols=['b', 'c']) Out[95]: b c 4 bat NaN 8 cow NaN In [96]: pd.read_csv(StringIO(data), usecols=['b', 'c'], index_col=0) Out[96]: b c 4 bat NaN 8 cow NaN  Date Handling Specifying date columns To better facilitate working with datetime data, read_csv() uses the keyword arguments parse_dates and date_parser to allow users to specify a variety of columns and date/time formats to turn the input text data into datetime objects.\nThe simplest case is to just pass in parse_dates=True:\n# Use a column as an index, and parse it as dates. In [97]: df = pd.read_csv('foo.csv', index_col=0, parse_dates=True) In [98]: df Out[98]: A B C date 2009-01-01 a 1 2 2009-01-02 b 3 4 2009-01-03 c 4 5 # These are Python datetime objects In [99]: df.index Out[99]: DatetimeIndex(['2009-01-01', '2009-01-02', '2009-01-03'], dtype='datetime64[ns]', name='date', freq=None)  It is often the case that we may want to store date and time data separately, or store various date fields separately. the parse_dates keyword can be used to specify a combination of columns to parse the dates and/or times from.\nYou can specify a list of column lists to parse_dates, the resulting date columns will be prepended to the output (so as to not affect the existing column order) and the new column names will be the concatenation of the component column names:\nIn [100]: print(open('tmp.csv').read()) KORD,19990127, 19:00:00, 18:56:00, 0.8100 KORD,19990127, 20:00:00, 19:56:00, 0.0100 KORD,19990127, 21:00:00, 20:56:00, -0.5900 KORD,19990127, 21:00:00, 21:18:00, -0.9900 KORD,19990127, 22:00:00, 21:56:00, -0.5900 KORD,19990127, 23:00:00, 22:56:00, -0.5900 In [101]: df = pd.read_csv('tmp.csv', header=None, parse_dates=[[1, 2], [1, 3]]) In [102]: df Out[102]: 1_2 1_3 0 4 0 1999-01-27 19:00:00 1999-01-27 18:56:00 KORD 0.81 1 1999-01-27 20:00:00 1999-01-27 19:56:00 KORD 0.01 2 1999-01-27 21:00:00 1999-01-27 20:56:00 KORD -0.59 3 1999-01-27 21:00:00 1999-01-27 21:18:00 KORD -0.99 4 1999-01-27 22:00:00 1999-01-27 21:56:00 KORD -0.59 5 1999-01-27 23:00:00 1999-01-27 22:56:00 KORD -0.59  By default the parser removes the component date columns, but you can choose to retain them via the keep_date_col keyword:\nIn [103]: df = pd.read_csv('tmp.csv', header=None, parse_dates=[[1, 2], [1, 3]], .....: keep_date_col=True) .....: In [104]: df Out[104]: 1_2 1_3 0 1 2 3 4 0 1999-01-27 19:00:00 1999-01-27 18:56:00 KORD 19990127 19:00:00 18:56:00 0.81 1 1999-01-27 20:00:00 1999-01-27 19:56:00 KORD 19990127 20:00:00 19:56:00 0.01 2 1999-01-27 21:00:00 1999-01-27 20:56:00 KORD 19990127 21:00:00 20:56:00 -0.59 3 1999-01-27 21:00:00 1999-01-27 21:18:00 KORD 19990127 21:00:00 21:18:00 -0.99 4 1999-01-27 22:00:00 1999-01-27 21:56:00 KORD 19990127 22:00:00 21:56:00 -0.59 5 1999-01-27 23:00:00 1999-01-27 22:56:00 KORD 19990127 23:00:00 22:56:00 -0.59  Note that if you wish to combine multiple columns into a single date column, a nested list must be used. In other words, parse_dates=[1, 2] indicates that the second and third columns should each be parsed as separate date columns while parse_dates=[[1, 2]] means the two columns should be parsed into a single column.\nYou can also use a dict to specify custom name columns:\nIn [105]: date_spec = {'nominal': [1, 2], 'actual': [1, 3]} In [106]: df = pd.read_csv('tmp.csv', header=None, parse_dates=date_spec) In [107]: df Out[107]: nominal actual 0 4 0 1999-01-27 19:00:00 1999-01-27 18:56:00 KORD 0.81 1 1999-01-27 20:00:00 1999-01-27 19:56:00 KORD 0.01 2 1999-01-27 21:00:00 1999-01-27 20:56:00 KORD -0.59 3 1999-01-27 21:00:00 1999-01-27 21:18:00 KORD -0.99 4 1999-01-27 22:00:00 1999-01-27 21:56:00 KORD -0.59 5 1999-01-27 23:00:00 1999-01-27 22:56:00 KORD -0.59  It is important to remember that if multiple text columns are to be parsed into a single date column, then a new column is prepended to the data. The index_col specification is based off of this new set of columns rather than the original data columns:\nIn [108]: date_spec = {'nominal': [1, 2], 'actual': [1, 3]} In [109]: df = pd.read_csv('tmp.csv', header=None, parse_dates=date_spec, .....: index_col=0) # index is the nominal column .....: In [110]: df Out[110]: actual 0 4 nominal 1999-01-27 19:00:00 1999-01-27 18:56:00 KORD 0.81 1999-01-27 20:00:00 1999-01-27 19:56:00 KORD 0.01 1999-01-27 21:00:00 1999-01-27 20:56:00 KORD -0.59 1999-01-27 21:00:00 1999-01-27 21:18:00 KORD -0.99 1999-01-27 22:00:00 1999-01-27 21:56:00 KORD -0.59 1999-01-27 23:00:00 1999-01-27 22:56:00 KORD -0.59   Note\nIf a column or index contains an unparsable date, the entire column or index will be returned unaltered as an object data type. For non-standard datetime parsing, use to_datetime() after pd.read_csv.\n Note\nread_csv has a fast_path for parsing datetime strings in iso8601 format, e.g “2000-01-01T00:01:02+00:00” and similar variations. If you can arrange for your data to store datetimes in this format, load times will be significantly faster, ~20x has been observed.\n\rNote\nWhen passing a dict as the parse_dates argument, the order of the columns prepended is not guaranteed, because dict objects do not impose an ordering on their keys. On Python 2.7+ you may use collections.OrderedDict instead of a regular dict if this matters to you. Because of this, when using a dict for ‘parse_dates’ in conjunction with the index_col argument, it’s best to specify index_col as a column label rather then as an index on the resulting frame.\nDate parsing functions[](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#date-parsing-functions \u0026ldquo;Permalink to this headline\u0026rdquo;) Finally, the parser allows you to specify a custom date_parser function to take full advantage of the flexibility of the date parsing API:\nIn [111]: df = pd.read_csv('tmp.csv', header=None, parse_dates=date_spec, .....: date_parser=pd.io.date_converters.parse_date_time) .....: In [112]: df Out[112]: nominal actual 0 4 0 1999-01-27 19:00:00 1999-01-27 18:56:00 KORD 0.81 1 1999-01-27 20:00:00 1999-01-27 19:56:00 KORD 0.01 2 1999-01-27 21:00:00 1999-01-27 20:56:00 KORD -0.59 3 1999-01-27 21:00:00 1999-01-27 21:18:00 KORD -0.99 4 1999-01-27 22:00:00 1999-01-27 21:56:00 KORD -0.59 5 1999-01-27 23:00:00 1999-01-27 22:56:00 KORD -0.59  Pandas will try to call the date_parser function in three different ways. If an exception is raised, the next one is tried:\n date_parser is first called with one or more arrays as arguments, as defined using parse_dates (e.g., date_parser(['2013', '2013'], ['1', '2'])).\n If #1 fails, date_parser is called with all the columns concatenated row-wise into a single array (e.g., date_parser(['2013 1', '2013 2'])).\n If #2 fails, date_parser is called once for every row with one or more string arguments from the columns indicated with parse_dates (e.g., date_parser('2013', '1') for the first row, date_parser('2013', '2') for the second, etc.).\n  Note that performance-wise, you should try these methods of parsing dates in order:\n Try to infer the format using infer_datetime_format=True (see section below).\n If you know the format, use pd.to_datetime(): date_parser=lambda x: pd.to_datetime(x, format=...).\n If you have a really non-standard format, use a custom date_parser function. For optimal performance, this should be vectorized, i.e., it should accept arrays as arguments.\n  You can explore the date parsing functionality in date_converters.py and add your own. We would love to turn this module into a community supported set of date/time parsers. To get you started, date_converters.py contains functions to parse dual date and time columns, year/month/day columns, and year/month/day/hour/minute/second columns. It also contains a generic_parser function so you can curry it with a function that deals with a single date rather than the entire array.\nParsing a CSV with mixed timezones Pandas cannot natively represent a column or index with mixed timezones. If your CSV file contains columns with a mixture of timezones, the default result will be an object-dtype column with strings, even with parse_dates.\nIn [113]: content = \u0026quot;\u0026quot;\u0026quot;\\ .....: a .....: 2000-01-01T00:00:00+05:00 .....: 2000-01-01T00:00:00+06:00\u0026quot;\u0026quot;\u0026quot; .....: In [114]: df = pd.read_csv(StringIO(content), parse_dates=['a']) In [115]: df['a'] Out[115]: 0 2000-01-01 00:00:00+05:00 1 2000-01-01 00:00:00+06:00 Name: a, dtype: object  To parse the mixed-timezone values as a datetime column, pass a partially-applied to_datetime() with utc=True as the date_parser.\nIn [116]: df = pd.read_csv(StringIO(content), parse_dates=['a'], .....: date_parser=lambda col: pd.to_datetime(col, utc=True)) .....: In [117]: df['a'] Out[117]: 0 1999-12-31 19:00:00+00:00 1 1999-12-31 18:00:00+00:00 Name: a, dtype: datetime64[ns, UTC]  Inferring datetime format If you have parse_dates enabled for some or all of your columns, and your datetime strings are all formatted the same way, you may get a large speed up by setting infer_datetime_format=True. If set, pandas will attempt to guess the format of your datetime strings, and then use a faster means of parsing the strings. 5-10x parsing speeds have been observed. pandas will fallback to the usual parsing if either the format cannot be guessed or the format that was guessed cannot properly parse the entire column of strings. So in general, infer_datetime_format should not have any negative consequences if enabled.\nHere are some examples of datetime strings that can be guessed (All representing December 30th, 2011 at 00:00:00):\n “20111230”\n “2011/12/30”\n “20111230 00:00:00”\n “12/30/2011 00:00:00”\n “30/Dec/2011 00:00:00”\n “30/December/2011 00:00:00”   Note that infer_datetime_format is sensitive to dayfirst. With dayfirst=True, it will guess “01/12/2011” to be December 1st. With dayfirst=False (default) it will guess “01/12/2011” to be January 12th.\n# Try to infer the format for the index column In [118]: df = pd.read_csv('foo.csv', index_col=0, parse_dates=True, .....: infer_datetime_format=True) .....: In [119]: df Out[119]: A B C date 2009-01-01 a 1 2 2009-01-02 b 3 4 2009-01-03 c 4 5  International date formats While US date formats tend to be MM/DD/YYYY, many international formats use DD/MM/YYYY instead. For convenience, a dayfirst keyword is provided:\nIn [120]: print(open('tmp.csv').read()) date,value,cat 1/6/2000,5,a 2/6/2000,10,b 3/6/2000,15,c In [121]: pd.read_csv('tmp.csv', parse_dates=[0]) Out[121]: date value cat 0 2000-01-06 5 a 1 2000-02-06 10 b 2 2000-03-06 15 c In [122]: pd.read_csv('tmp.csv', dayfirst=True, parse_dates=[0]) Out[122]: date value cat 0 2000-06-01 5 a 1 2000-06-02 10 b 2 2000-06-03 15 c  Specifying method for floating-point conversion The parameter float_precision can be specified in order to use a specific floating-point converter during parsing with the C engine. The options are the ordinary converter, the high-precision converter, and the round-trip converter (which is guaranteed to round-trip values after writing to a file). For example:\nIn [123]: val = '0.3066101993807095471566981359501369297504425048828125' In [124]: data = 'a,b,c\\n1,2,{0}'.format(val) In [125]: abs(pd.read_csv(StringIO(data), engine='c', .....: float_precision=None)['c'][0] - float(val)) .....: Out[125]: 1.1102230246251565e-16 In [126]: abs(pd.read_csv(StringIO(data), engine='c', .....: float_precision='high')['c'][0] - float(val)) .....: Out[126]: 5.551115123125783e-17 In [127]: abs(pd.read_csv(StringIO(data), engine='c', .....: float_precision='round_trip')['c'][0] - float(val)) .....: Out[127]: 0.0  Thousand separators For large numbers that have been written with a thousands separator, you can set the thousands keyword to a string of length 1 so that integers will be parsed correctly:\nBy default, numbers with a thousands separator will be parsed as strings:\nIn [128]: print(open('tmp.csv').read()) ID|level|category Patient1|123,000|x Patient2|23,000|y Patient3|1,234,018|z In [129]: df = pd.read_csv('tmp.csv', sep='|') In [130]: df Out[130]: ID level category 0 Patient1 123,000 x 1 Patient2 23,000 y 2 Patient3 1,234,018 z In [131]: df.level.dtype Out[131]: dtype('O') The `thousands` keyword allows integers to be parsed correctly: In [132]: print(open('tmp.csv').read()) ID|level|category Patient1|123,000|x Patient2|23,000|y Patient3|1,234,018|z In [133]: df = pd.read_csv('tmp.csv', sep='|', thousands=',') In [134]: df Out[134]: ID level category 0 Patient1 123000 x 1 Patient2 23000 y 2 Patient3 1234018 z In [135]: df.level.dtype Out[135]: dtype('int64')  NA values To control which values are parsed as missing values (which are signified by NaN), specify a string in na_values. If you specify a list of strings, then all values in it are considered to be missing values. If you specify a number (a float, like 5.0 or an integer like 5), the corresponding equivalent values will also imply a missing value (in this case effectively [5.0, 5] are recognized as NaN).\nTo completely override the default values that are recognized as missing, specify keep_default_na=False.\nThe default NaN recognized values are ['-1.#IND', '1.#QNAN', '1.#IND', '-1.#QNAN', '#N/A N/A', '#N/A', 'N/A', 'n/a', 'NA', '\u0026lt;NA\u0026gt;', '#NA', 'NULL', 'null', 'NaN', '-NaN', 'nan', '-nan', ''].\nLet us consider some examples:\npd.read_csv('path_to_file.csv', na_values=[5])  In the example above 5 and 5.0 will be recognized as NaN, in addition to the defaults. A string will first be interpreted as a numerical 5, then as a NaN.\npd.read_csv('path_to_file.csv', keep_default_na=False, na_values=[\u0026quot;\u0026quot;])  Above, only an empty field will be recognized as NaN.\npd.read_csv('path_to_file.csv', keep_default_na=False, na_values=[\u0026quot;NA\u0026quot;, \u0026quot;0\u0026quot;])  Above, both NA and 0 as strings are NaN.\npd.read_csv('path_to_file.csv', na_values=[\u0026quot;Nope\u0026quot;])  The default values, in addition to the string \u0026quot;Nope\u0026quot; are recognized as NaN.\nInfinity inf like values will be parsed as np.inf (positive infinity), and -inf as -np.inf (negative infinity). These will ignore the case of the value, meaning Inf, will also be parsed as np.inf.\nReturning Series Using the squeeze keyword, the parser will return output with a single column as a Series:\nIn [136]: print(open('tmp.csv').read()) level Patient1,123000 Patient2,23000 Patient3,1234018 In [137]: output = pd.read_csv('tmp.csv', squeeze=True) In [138]: output Out[138]: Patient1 123000 Patient2 23000 Patient3 1234018 Name: level, dtype: int64 In [139]: type(output) Out[139]: pandas.core.series.Series  Boolean values The common values True, False, TRUE, and FALSE are all recognized as boolean. Occasionally you might want to recognize other values as being boolean. To do this, use the true_values and false_values options as follows:\nIn [140]: data = ('a,b,c\\n' .....: '1,Yes,2\\n' .....: '3,No,4') .....: In [141]: print(data) a,b,c 1,Yes,2 3,No,4 In [142]: pd.read_csv(StringIO(data)) Out[142]: a b c 0 1 Yes 2 1 3 No 4 In [143]: pd.read_csv(StringIO(data), true_values=['Yes'], false_values=['No']) Out[143]: a b c 0 1 True 2 1 3 False 4  Handling “bad” lines Some files may have malformed lines with too few fields or too many. Lines with too few fields will have NA values filled in the trailing fields. Lines with too many fields will raise an error by default:\nIn [144]: data = ('a,b,c\\n' .....: '1,2,3\\n' .....: '4,5,6,7\\n' .....: '8,9,10') .....: In [145]: pd.read_csv(StringIO(data)) --------------------------------------------------------------------------- ParserError Traceback (most recent call last) \u0026lt;ipython-input-145-6388c394e6b8\u0026gt; in \u0026lt;module\u0026gt; ----\u0026gt; 1 pd.read_csv(StringIO(data)) /pandas/pandas/io/parsers.py in parser_f(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision) 674 ) 675 --\u0026gt; 676 return _read(filepath_or_buffer, kwds) 677 678 parser_f.__name__ = name /pandas/pandas/io/parsers.py in _read(filepath_or_buffer, kwds) 452 453 try: --\u0026gt; 454 data = parser.read(nrows) 455 finally: 456 parser.close() /pandas/pandas/io/parsers.py in read(self, nrows) 1131 def read(self, nrows=None): 1132 nrows = _validate_integer(\u0026quot;nrows\u0026quot;, nrows) -\u0026gt; 1133 ret = self._engine.read(nrows) 1134 1135 # May alter columns / col_dict /pandas/pandas/io/parsers.py in read(self, nrows) 2035 def read(self, nrows=None): 2036 try: -\u0026gt; 2037 data = self._reader.read(nrows) 2038 except StopIteration: 2039 if self._first_chunk: /pandas/pandas/_libs/parsers.pyx in pandas._libs.parsers.TextReader.read() /pandas/pandas/_libs/parsers.pyx in pandas._libs.parsers.TextReader._read_low_memory() /pandas/pandas/_libs/parsers.pyx in pandas._libs.parsers.TextReader._read_rows() /pandas/pandas/_libs/parsers.pyx in pandas._libs.parsers.TextReader._tokenize_rows() /pandas/pandas/_libs/parsers.pyx in pandas._libs.parsers.raise_parser_error()  ParserError: Error tokenizing data. C error: Expected 3 fields in line 3, saw 4\nYou can elect to skip bad lines:\nIn [29]: pd.read_csv(StringIO(data), error_bad_lines=False) Skipping line 3: expected 3 fields, saw 4  Out[29]: a b c 0 1 2 3 1 8 9 10  You can also use the usecols parameter to eliminate extraneous column data that appear in some lines but not others:\nIn [30]: pd.read_csv(StringIO(data), usecols=[0, 1, 2]) Out[30]: a b c 0 1 2 3 1 4 5 6 2 8 9 10  Dialect The dialect keyword gives greater flexibility in specifying the file format. By default it uses the Excel dialect but you can specify either the dialect name or a csv.Dialect\u0026rdquo;) instance.\nSuppose you had data with unenclosed quotes:\nIn [146]: print(data) label1,label2,label3 index1,\u0026quot;a,c,e index2,b,d,f  By default, read_csv uses the Excel dialect and treats the double quote as the quote character, which causes it to fail when it finds a newline before it finds the closing double quote.\nWe can get around this using dialect:\nIn [147]: import csv In [148]: dia = csv.excel() In [149]: dia.quoting = csv.QUOTE_NONE In [150]: pd.read_csv(StringIO(data), dialect=dia) Out[150]: label1 label2 label3 index1 \u0026quot;a c e index2 b d f  All of the dialect options can be specified separately by keyword arguments:\nIn [151]: data = 'a,b,c~1,2,3~4,5,6' In [152]: pd.read_csv(StringIO(data), lineterminator='~') Out[152]: a b c 0 1 2 3 1 4 5 6  Another common dialect option is skipinitialspace, to skip any whitespace after a delimiter:\nIn [153]: data = 'a, b, c\\n1, 2, 3\\n4, 5, 6' In [154]: print(data) a, b, c 1, 2, 3 4, 5, 6 In [155]: pd.read_csv(StringIO(data), skipinitialspace=True) Out[155]: a b c 0 1 2 3 1 4 5 6  The parsers make every attempt to “do the right thing” and not be fragile. Type inference is a pretty big deal. If a column can be coerced to integer dtype without altering the contents, the parser will do so. Any non-numeric columns will come through as object dtype as with the rest of pandas objects.\nQuoting and Escape Characters Quotes (and other escape characters) in embedded fields can be handled in any number of ways. One way is to use backslashes; to properly parse this data, you should pass the escapechar option:\nIn [156]: data = 'a,b\\n\u0026quot;hello, \\\\\u0026quot;Bob\\\\\u0026quot;, nice to see you\u0026quot;,5' In [157]: print(data) a,b \u0026quot;hello, \\\u0026quot;Bob\\\u0026quot;, nice to see you\u0026quot;,5 In [158]: pd.read_csv(StringIO(data), escapechar='\\\\') Out[158]: a b 0 hello, \u0026quot;Bob\u0026quot;, nice to see you 5  Files with fixed width columns While read_csv() reads delimited data, the read_fwf() function works with data files that have known and fixed column widths. The function parameters to read_fwf are largely the same as read_csv with two extra parameters, and a different usage of the delimiter parameter:\n colspecs: A list of pairs (tuples) giving the extents of the fixed-width fields of each line as half-open intervals (i.e., [from, to[ ). String value ‘infer’ can be used to instruct the parser to try detecting the column specifications from the first 100 rows of the data. Default behavior, if not specified, is to infer.\n widths: A list of field widths which can be used instead of ‘colspecs’ if the intervals are contiguous.\n delimiter: Characters to consider as filler characters in the fixed-width file. Can be used to specify the filler character of the fields if it is not spaces (e.g., ‘~’).\n  Consider a typical fixed-width data file:\nIn [159]: print(open('bar.csv').read()) id8141 360.242940 149.910199 11950.7 id1594 444.953632 166.985655 11788.4 id1849 364.136849 183.628767 11806.2 id1230 413.836124 184.375703 11916.8 id1948 502.953953 173.237159 12468.3  In order to parse this file into a DataFrame, we simply need to supply the column specifications to the read_fwf function along with the file name:\n# Column specifications are a list of half-intervals In [160]: colspecs = [(0, 6), (8, 20), (21, 33), (34, 43)] In [161]: df = pd.read_fwf('bar.csv', colspecs=colspecs, header=None, index_col=0) In [162]: df Out[162]: 1 2 3 0 id8141 360.242940 149.910199 11950.7 id1594 444.953632 166.985655 11788.4 id1849 364.136849 183.628767 11806.2 id1230 413.836124 184.375703 11916.8 id1948 502.953953 173.237159 12468.3  Note how the parser automatically picks column names X.when header=None argument is specified. Alternatively, you can supply just the column widths for contiguous columns:\n# Widths are a list of integers In [163]: widths = [6, 14, 13, 10] In [164]: df = pd.read_fwf('bar.csv', widths=widths, header=None) In [165]: df Out[165]: 0 1 2 3 0 id8141 360.242940 149.910199 11950.7 1 id1594 444.953632 166.985655 11788.4 2 id1849 364.136849 183.628767 11806.2 3 id1230 413.836124 184.375703 11916.8 4 id1948 502.953953 173.237159 12468.3  The parser will take care of extra white spaces around the columns so it’s ok to have extra separation between the columns in the file.\nBy default, read_fwf will try to infer the file’s colspecs by using the first 100 rows of the file. It can do it only in cases when the columns are aligned and correctly separated by the provided delimiter (default delimiter is whitespace).\nIn [166]: df = pd.read_fwf('bar.csv', header=None, index_col=0) In [167]: df Out[167]: 1 2 3 0 id8141 360.242940 149.910199 11950.7 id1594 444.953632 166.985655 11788.4 id1849 364.136849 183.628767 11806.2 id1230 413.836124 184.375703 11916.8 id1948 502.953953 173.237159 12468.3  read_fwf supports the dtype parameter for specifying the types of parsed columns to be different from the inferred type.\nIn [168]: pd.read_fwf('bar.csv', header=None, index_col=0).dtypes Out[168]: 1 float64 2 float64 3 float64 dtype: object In [169]: pd.read_fwf('bar.csv', header=None, dtype={2: 'object'}).dtypes Out[169]: 0 object 1 float64 2 object 3 float64 dtype: object  Indexes Files with an “implicit” index column Consider a file with one less entry in the header than the number of data column:\nIn [170]: print(open('foo.csv').read()) A,B,C 20090101,a,1,2 20090102,b,3,4 20090103,c,4,5  In this special case, read_csv assumes that the first column is to be used as the index of the DataFrame:\nIn [171]: pd.read_csv('foo.csv') Out[171]: A B C 20090101 a 1 2 20090102 b 3 4 20090103 c 4 5  Note that the dates weren’t automatically parsed. In that case you would need to do as before:\nIn [172]: df = pd.read_csv('foo.csv', parse_dates=True) In [173]: df.index Out[173]: DatetimeIndex(['2009-01-01', '2009-01-02', '2009-01-03'], dtype='datetime64[ns]', freq=None)  Reading an index with a MultiIndex Suppose you have data indexed by two columns:\nIn [174]: print(open('data/mindex_ex.csv').read()) year,indiv,zit,xit 1977,\u0026quot;A\u0026quot;,1.2,.6 1977,\u0026quot;B\u0026quot;,1.5,.5 1977,\u0026quot;C\u0026quot;,1.7,.8 1978,\u0026quot;A\u0026quot;,.2,.06 1978,\u0026quot;B\u0026quot;,.7,.2 1978,\u0026quot;C\u0026quot;,.8,.3 1978,\u0026quot;D\u0026quot;,.9,.5 1978,\u0026quot;E\u0026quot;,1.4,.9 1979,\u0026quot;C\u0026quot;,.2,.15 1979,\u0026quot;D\u0026quot;,.14,.05 1979,\u0026quot;E\u0026quot;,.5,.15 1979,\u0026quot;F\u0026quot;,1.2,.5 1979,\u0026quot;G\u0026quot;,3.4,1.9 1979,\u0026quot;H\u0026quot;,5.4,2.7 1979,\u0026quot;I\u0026quot;,6.4,1.2  The index_col argument to read_csv can take a list of column numbers to turn multiple columns into a MultiIndex for the index of the returned object:\nIn [175]: df = pd.read_csv(\u0026quot;data/mindex_ex.csv\u0026quot;, index_col=[0, 1]) In [176]: df Out[176]: zit xit year indiv 1977 A 1.20 0.60 B 1.50 0.50 C 1.70 0.80 1978 A 0.20 0.06 B 0.70 0.20 C 0.80 0.30 D 0.90 0.50 E 1.40 0.90 1979 C 0.20 0.15 D 0.14 0.05 E 0.50 0.15 F 1.20 0.50 G 3.40 1.90 H 5.40 2.70 I 6.40 1.20 In [177]: df.loc[1978] Out[177]: zit xit indiv A 0.2 0.06 B 0.7 0.20 C 0.8 0.30 D 0.9 0.50 E 1.4 0.90  Reading columns with a MultiIndex By specifying list of row locations for the header argument, you can read in a MultiIndex for the columns. Specifying non-consecutive rows will skip the intervening rows.\nIn [178]: from pandas._testing import makeCustomDataframe as mkdf In [179]: df = mkdf(5, 3, r_idx_nlevels=2, c_idx_nlevels=4) In [180]: df.to_csv('mi.csv') In [181]: print(open('mi.csv').read()) C0,,C_l0_g0,C_l0_g1,C_l0_g2 C1,,C_l1_g0,C_l1_g1,C_l1_g2 C2,,C_l2_g0,C_l2_g1,C_l2_g2 C3,,C_l3_g0,C_l3_g1,C_l3_g2 R0,R1,,, R_l0_g0,R_l1_g0,R0C0,R0C1,R0C2 R_l0_g1,R_l1_g1,R1C0,R1C1,R1C2 R_l0_g2,R_l1_g2,R2C0,R2C1,R2C2 R_l0_g3,R_l1_g3,R3C0,R3C1,R3C2 R_l0_g4,R_l1_g4,R4C0,R4C1,R4C2 In [182]: pd.read_csv('mi.csv', header=[0, 1, 2, 3], index_col=[0, 1]) Out[182]: C0 C_l0_g0 C_l0_g1 C_l0_g2 C1 C_l1_g0 C_l1_g1 C_l1_g2 C2 C_l2_g0 C_l2_g1 C_l2_g2 C3 C_l3_g0 C_l3_g1 C_l3_g2 R0 R1 R_l0_g0 R_l1_g0 R0C0 R0C1 R0C2 R_l0_g1 R_l1_g1 R1C0 R1C1 R1C2 R_l0_g2 R_l1_g2 R2C0 R2C1 R2C2 R_l0_g3 R_l1_g3 R3C0 R3C1 R3C2 R_l0_g4 R_l1_g4 R4C0 R4C1 R4C2  read_csv is also able to interpret a more common format of multi-columns indices.\nIn [183]: print(open('mi2.csv').read()) ,a,a,a,b,c,c ,q,r,s,t,u,v one,1,2,3,4,5,6 two,7,8,9,10,11,12 In [184]: pd.read_csv('mi2.csv', header=[0, 1], index_col=0) Out[184]: a b c q r s t u v one 1 2 3 4 5 6 two 7 8 9 10 11 12  Note: If an index_col is not specified (e.g. you don’t have an index, or wrote it with df.to_csv(..., index=False), then any names on the columns index will be lost.\nAutomatically “sniffing” the delimiter read_csv is capable of inferring delimited (not necessarily comma-separated) files, as pandas uses the csv.Sniffer\u0026rdquo;) class of the csv module. For this, you have to specify sep=None.\nIn [185]: print(open('tmp2.sv').read()) :0:1:2:3 0:0.4691122999071863:-0.2828633443286633:-1.5090585031735124:-1.1356323710171934 1:1.2121120250208506:-0.17321464905330858:0.11920871129693428:-1.0442359662799567 2:-0.8618489633477999:-2.1045692188948086:-0.4949292740687813:1.071803807037338 3:0.7215551622443669:-0.7067711336300845:-1.0395749851146963:0.27185988554282986 4:-0.42497232978883753:0.567020349793672:0.27623201927771873:-1.0874006912859915 5:-0.6736897080883706:0.1136484096888855:-1.4784265524372235:0.5249876671147047 6:0.4047052186802365:0.5770459859204836:-1.7150020161146375:-1.0392684835147725 7:-0.3706468582364464:-1.1578922506419993:-1.344311812731667:0.8448851414248841 8:1.0757697837155533:-0.10904997528022223:1.6435630703622064:-1.4693879595399115 9:0.35702056413309086:-0.6746001037299882:-1.776903716971867:-0.9689138124473498 In [186]: pd.read_csv('tmp2.sv', sep=None, engine='python') Out[186]: Unnamed: 0 0 1 2 3 0 0 0.469112 -0.282863 -1.509059 -1.135632 1 1 1.212112 -0.173215 0.119209 -1.044236 2 2 -0.861849 -2.104569 -0.494929 1.071804 3 3 0.721555 -0.706771 -1.039575 0.271860 4 4 -0.424972 0.567020 0.276232 -1.087401 5 5 -0.673690 0.113648 -1.478427 0.524988 6 6 0.404705 0.577046 -1.715002 -1.039268 7 7 -0.370647 -1.157892 -1.344312 0.844885 8 8 1.075770 -0.109050 1.643563 -1.469388 9 9 0.357021 -0.674600 -1.776904 -0.968914  Reading multiple files to create a single DataFrame It’s best to use concat() to combine multiple files. See the cookbook for an example.\nIterating through files chunk by chunk Suppose you wish to iterate through a (potentially very large) file lazily rather than reading the entire file into memory, such as the following:\nIn [187]: print(open('tmp.sv').read()) |0|1|2|3 0|0.4691122999071863|-0.2828633443286633|-1.5090585031735124|-1.1356323710171934 1|1.2121120250208506|-0.17321464905330858|0.11920871129693428|-1.0442359662799567 2|-0.8618489633477999|-2.1045692188948086|-0.4949292740687813|1.071803807037338 3|0.7215551622443669|-0.7067711336300845|-1.0395749851146963|0.27185988554282986 4|-0.42497232978883753|0.567020349793672|0.27623201927771873|-1.0874006912859915 5|-0.6736897080883706|0.1136484096888855|-1.4784265524372235|0.5249876671147047 6|0.4047052186802365|0.5770459859204836|-1.7150020161146375|-1.0392684835147725 7|-0.3706468582364464|-1.1578922506419993|-1.344311812731667|0.8448851414248841 8|1.0757697837155533|-0.10904997528022223|1.6435630703622064|-1.4693879595399115 9|0.35702056413309086|-0.6746001037299882|-1.776903716971867|-0.9689138124473498 In [188]: table = pd.read_csv('tmp.sv', sep='|') In [189]: table Out[189]: Unnamed: 0 0 1 2 3 0 0 0.469112 -0.282863 -1.509059 -1.135632 1 1 1.212112 -0.173215 0.119209 -1.044236 2 2 -0.861849 -2.104569 -0.494929 1.071804 3 3 0.721555 -0.706771 -1.039575 0.271860 4 4 -0.424972 0.567020 0.276232 -1.087401 5 5 -0.673690 0.113648 -1.478427 0.524988 6 6 0.404705 0.577046 -1.715002 -1.039268 7 7 -0.370647 -1.157892 -1.344312 0.844885 8 8 1.075770 -0.109050 1.643563 -1.469388 9 9 0.357021 -0.674600 -1.776904 -0.968914  By specifying a chunksize to read_csv, the return value will be an iterable object of type TextFileReader:\nIn [190]: reader = pd.read_csv('tmp.sv', sep='|', chunksize=4) In [191]: reader Out[191]: \u0026lt;pandas.io.parsers.TextFileReader at 0x7f9184154b50\u0026gt; In [192]: for chunk in reader: .....: print(chunk) .....: Unnamed: 0 0 1 2 3 0 0 0.469112 -0.282863 -1.509059 -1.135632 1 1 1.212112 -0.173215 0.119209 -1.044236 2 2 -0.861849 -2.104569 -0.494929 1.071804 3 3 0.721555 -0.706771 -1.039575 0.271860 Unnamed: 0 0 1 2 3 4 4 -0.424972 0.567020 0.276232 -1.087401 5 5 -0.673690 0.113648 -1.478427 0.524988 6 6 0.404705 0.577046 -1.715002 -1.039268 7 7 -0.370647 -1.157892 -1.344312 0.844885 Unnamed: 0 0 1 2 3 8 8 1.075770 -0.10905 1.643563 -1.469388 9 9 0.357021 -0.67460 -1.776904 -0.968914 Specifying `iterator=True` will also return the `TextFileReader` object: In [193]: reader = pd.read_csv('tmp.sv', sep='|', iterator=True) In [194]: reader.get_chunk(5) Out[194]: Unnamed: 0 0 1 2 3 0 0 0.469112 -0.282863 -1.509059 -1.135632 1 1 1.212112 -0.173215 0.119209 -1.044236 2 2 -0.861849 -2.104569 -0.494929 1.071804 3 3 0.721555 -0.706771 -1.039575 0.271860 4 4 -0.424972 0.567020 0.276232 -1.087401  Specifying the parser engine Under the hood pandas uses a fast and efficient parser implemented in C as well as a Python implementation which is currently more feature-complete. Where possible pandas uses the C parser (specified as engine='c'), but may fall back to Python if C-unsupported options are specified. Currently, C-unsupported options include:\n sep other than a single character (e.g. regex separators)\n skipfooter\n sep=None with delim_whitespace=False\n  Specifying any of the above options will produce a ParserWarning unless the python engine is selected explicitly using engine='python'.\nReading remote files You can pass in a URL to a CSV file:\ndf = pd.read_csv('https://download.bls.gov/pub/time.series/cu/cu.item', sep='\\t')  S3 URLs are handled as well but require installing the S3Fs library:\ndf = pd.read_csv('s3://pandas-test/tips.csv')  If your S3 bucket requires credentials you will need to set them as environment variables or in the ~/.aws/credentials config file, refer to the S3Fs documentation on credentials.\nWriting out data Writing to CSV format The Series and DataFrame objects have an instance method to_csv which allows storing the contents of the object as a comma-separated-values file. The function takes a number of arguments. Only the first is required.\n path_or_buf: A string path to the file to write or a file object. If a file object it must be opened with newline=’’\n sep : Field delimiter for the output file (default “,”)\n na_rep: A string representation of a missing value (default ‘’)\n float_format: Format string for floating point numbers\n columns: Columns to write (default None)\n header: Whether to write out the column names (default True)\n index: whether to write row (index) names (default True)\n index_label: Column label(s) for index column(s) if desired. If None (default), and header and index are True, then the index names are used. (A sequence should be given if the DataFrame uses MultiIndex).\n mode : Python write mode, default ‘w’\n encoding: a string representing the encoding to use if the contents are non-ASCII, for Python versions prior to 3\n line_terminator: Character sequence denoting line end (default os.linesep)\n quoting: Set quoting rules as in csv module (default csv.QUOTE_MINIMAL). Note that if you have set a float_format then floats are converted to strings and csv.QUOTE_NONNUMERIC will treat them as non-numeric\n quotechar: Character used to quote fields (default ‘”’)\n doublequote: Control quoting of quotechar in fields (default True)\n escapechar: Character used to escape sep and quotechar when appropriate (default None)\n chunksize: Number of rows to write at a time\n date_format: Format string for datetime objects\n  Writing a formatted string The DataFrame object has an instance method to_string which allows control over the string representation of the object. All arguments are optional:\n buf default None, for example a StringIO object\n columns default None, which columns to write\n col_space default None, minimum width of each column.\n na_rep default NaN, representation of NA value\n formatters default None, a dictionary (by column) of functions each of which takes a single argument and returns a formatted string\n float_format default None, a function which takes a single (float) argument and returns a formatted string; to be applied to floats in the DataFrame.\n sparsify default True, set to False for a DataFrame with a hierarchical index to print every MultiIndex key at each row.\n index_names default True, will print the names of the indices\n index default True, will print the index (ie, row labels)\n header default True, will print the column labels\n justify default left, will print column headers left- or right-justified\n  The Series object also has a to_string method, but with only the buf, na_rep, float_format arguments. There is also a length argument which, if set to True, will additionally output the length of the Series.\n Source : .\n "});index.add({'id':12,'href':'/library/tutorials/docs/python/flask/learning-flask/ep-1/','title':"Ep.1 Your first Flask app",'content':" Your first Flask app | Learning Flask Ep. 1 In the first part of this series, you\u0026rsquo;ll learn how to create and run your very first Flask web application\nCreating a project directory and virtual environment First of all, we need to create our new project directory. We\u0026rsquo;re going to a new directory called app in our home directory.\n Tip - I advise using the same names for your project so it\u0026rsquo;s easier to follow along\n Go ahead and create the directory with the following:\nmkdir ~/app\nNext, let\u0026rsquo;s move into the app directory:\ncd ~/app\nNow we need create out Python virtual environment. Do so with the following command:\npython -m venv env\nThis will create a new virtual environment called env\nYou\u0026rsquo;ll see a new directory appear inside the app directory called env. Now we need to activate our virtual environment before we install Flask.\nGo ahead and run the following command to activate the environment:\nsource env/bin/activate\nYou should see (env) appear in front of your terminal prompt indicating the virtual environment is activated!\nUpdating pip It\u0026rsquo;s best practice to update pip (Python\u0026rsquo;s package manager) after creating a new virtual environment. We can do so with the following:\npip install --upgrade pip\nYou should see a success message like the following\nCollecting pip Using cached https://files.pythonhosted.org/packages/46/dc/7fd5df840efb3e56c8b4f768793a237ec4ee59891959d6a215d63f727023/pip-19.0.1-py2.py3-none-any.whl Installing collected packages: pip Found existing installation: pip 18.1 Uninstalling pip-18.1: Successfully uninstalled pip-18.1 Successfully installed pip-19.0.1  Now we\u0026rsquo;re ready to install Flask!\nInstalling Flask You install Flask just as you would any other Python package.\npip install flask\nIf we now run pip list, you\u0026rsquo;ll see the following:\nPackage Version ------------ ------- Click 7.0 Flask 1.0.2 itsdangerous 1.1.0 Jinja2 2.10 MarkupSafe 1.1.0 pip 19.0.1 setuptools 40.6.2 Werkzeug 0.14.1   Note - Flask comes with several other packages so don\u0026rsquo;t be alarmed when you see MarkupSafe or itsdangerous!\n Ok so we\u0026rsquo;ve got everything we need to start building our very simple application. Let\u0026rsquo;s get to it.\nCreating a Flask app This guide is just to show you the most basic Flask application possible. You\u0026rsquo;ll learn the correct way to structure a Flask application over the next couple of parts in this series.\nThe most basic Flask app can be just a single file. We\u0026rsquo;re going to call it app.py. Make sure you\u0026rsquo;re in the app directory and run the following to create it:\ntouch app.py\nLet\u0026rsquo;s write some code! Go ahead and open up app.py in your favourite editor and follow along.\nFirst of all, we need to import Flask from flask\nfrom flask import Flask\nNow we need to create our Flask application. We\u0026rsquo;re going to pass __name__ to Flask and assign it to the variable app\nDon\u0026rsquo;t worry about exactly why we\u0026rsquo;re doing this. We\u0026rsquo;ll cover it in a more advanced episode in this series.\nfrom flask import Flask app = Flask(__name__)  Next up, we need to create a route or view (route and view are used interchangeably)\nLet\u0026rsquo;s create a route and explain it line by line after:\nfrom flask import Flask app = Flask(__name__) @app.route(\u0026quot;/\u0026quot;) def index(): return \u0026quot;Hello world!\u0026quot;  Let\u0026rsquo;s talk through the 3 lines we just added:\n@app.route(\u0026quot;/\u0026quot;)\nRoutes in Flask are created using the @app.route decorator and passing in a URL or path.\nIn this example, we\u0026rsquo;ve passed \u0026quot;/\u0026quot; into the @app.route decorator. \u0026quot;/\u0026quot; is the root of the website or application.\nThis route will be triggered when someone goes to the root or index of our website, for example http://example.com.\ndef index(): return \u0026quot;Hello world!\u0026quot;\nUnder the @app.route decorator, we simply write a standard Python function with a return statement.\nFlask will return whatever we pass to the return statement! In this case, just a short \u0026quot;Hello world!\u0026quot; string.\nWe need to add 2 more lines of code before we can run our app. Add the following:\nfrom flask import Flask app = Flask(__name__) @app.route(\u0026quot;/\u0026quot;) def index(): return \u0026quot;Hello world!\u0026quot; if __name__ == \u0026quot;__main__\u0026quot;: app.run()`  Let\u0026rsquo;s take a look at what we added:\nif __name__ == \u0026quot;__main__\u0026quot;: app.run()  Again, I don\u0026rsquo;t want you to worry too much about what\u0026rsquo;s happening here. For now just know that __name__ is a special variable used by the Python interpreter to understand if a file is the main program.\nJust as we passed __name__ into the Flask() class, the special variable __name__ is equal to __main__. You\u0026rsquo;ll learn more about this principle as you advance through the series.\nRunning the Flask app Time to see the app in action! We can run our Flask app in a couple of ways.\nIn your terminal, make sure you\u0026rsquo;re in the same directory as app.py and run the following:\npython app.py\nYou\u0026rsquo;ll see the following message in your terminal to let you know Flask is running:\n* Serving Flask app \u0026quot;app\u0026quot; (lazy loading) * Environment: production WARNING: Do not use the development server in a production environment. Use a production WSGI server instead. * Debug mode: off * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit) 127.0.0.1 - - [03/Feb/2019 14:35:04] \u0026quot;GET / HTTP/1.1\u0026quot; 200 - 127.0.0.1 - - [03/Feb/2019 14:35:04] \u0026quot;GET /favicon.ico HTTP/1.1\u0026quot; 404  Great, our app is running! Ignore any of the warning messages in your terminal and open up a new browser tab and head to the following URL:\nhttp://127.0.0.1:5000/\nYou should see Hello world! in your browser!\nHead back over to your terminal and stop the app by hitting Ctrl + c\nSo you\u0026rsquo;ve seen one way to run your Flask app but it\u0026rsquo;s not recommended. There\u0026rsquo;s a better way.\nFlask environment variables To make running our app even easier, we\u0026rsquo;re going to set a couple of environment variables in our shell. Run the following commands and we\u0026rsquo;ll talk through them after:\nexport FLASK_APP=app.py export FLASK_ENV=development  Running export FLASK_APP=app.py will set the FLASK_APP variable to app.py\nRunning export FLASK_ENV=development tells Flask we want to run our app in development mode\n Warning - Never run a live Flask application in production using development mode\n We\u0026rsquo;re quite a way from deploying our app to the web but I want to drill it home early, just so you know. We\u0026rsquo;ll cover the reasons why later in the series.\nWe can now run our app using the following simple command:\nflask run\nYou\u0026rsquo;ll see:\n* Serving Flask app \u0026quot;app.py\u0026quot; (lazy loading) * Environment: development * Debug mode: on * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit) * Restarting with stat * Debugger is active! * Debugger PIN: 201-167-879  You\u0026rsquo;ll notice we don\u0026rsquo;t get any of the warnings and that Environment is set to development\nHead back to http://127.0.0.1:5000/ and you\u0026rsquo;ll see the same Hello world! message as before.\nUse Ctrl + c in your terminal to stop the app when you\u0026rsquo;re ready.\nTo deactivate your virtual environment, simply enter:\ndeactivate\nWrapping up You now know how to create and run a very basic Flask application, along with some best practices for setting environment variables and using the flask run command.\nNext up, learning how to structure your Flask application properly!\nLast modified · 28 Feb 2019\n Source : pythonise.com\n "});index.add({'id':13,'href':'/library/tutorials/docs/articles/webapp/html/','title':"HTML",'content':" HTML "});index.add({'id':14,'href':'/library/tutorials/docs/python/pandas/1_io/','title':"IO tools (text, CSV, HDF5, …)",'content':" IO tools (text, CSV, HDF5, …) The pandas I/O API is a set of top level reader functions accessed like pandas.read_csv() that generally return a pandas object. The corresponding writer functions are object methods that are accessed like DataFrame.to_csv(). Below is a table containing available readers and writers.\n IO tools (text, CSV, HDF5, …) Indexing and selecting data MultiIndex / advanced indexing Merge, join, and concatenate Reshaping and pivot tables Working with text data Working with missing data Categorical data Nullable integer data type Nullable Boolean Data Type Visualization Computational tools Group By: split-apply-combine Time series / date functionality Time deltas Styling Options and settings Enhancing performance Scaling to large datasets Sparse data structures Frequently Asked Questions (FAQ) Cookbook     Type Data Description Reader Writer     text CSV read_csv to_csv   text Fixed-Width Text File read_fwf -   text JSON read_json to_json   text HTML read_html to_html   text Local clipboard read_clipboard to_clipboard   - MS Excel read_excel to_excel   binary OpenDocument read_excel -   binary HDF5 Format read_hdf to_hdf   binary Feather Format read_feather to_feather   binary Parquet Format read_parquet to_parquet   binary ORC Format read_orc -   binary Msgpack read_msgpack to_msgpack   binary Stata read_stata to_stata   binary SAS read_sas -   binary SPSS read_spss -   binary Python Pickle Format read_pickle to_pickle   SQL SQL read_sql to_sql   SQL Google BigQuery read_gbq to_gbq    Here is an informal performance comparison for some of these IO methods.\n Note\nFor examples that use the StringIO class, make sure you import it according to your Python version, i.e. from StringIO import StringIO for Python 2 and from io import StringIO for Python 3.\nSource : .\n "});index.add({'id':15,'href':'/library/tutorials/docs/front-end/javascript/cheatsheet/','title':"JavaScript Cheat Sheet",'content':" JavaScript Cheat Sheet  Link  If - Else⇵ if ((age \u0026gt;= 14) \u0026amp;\u0026amp; (age \u0026lt; 19)) { // logical condition status = \u0026quot;Eligible.\u0026quot;; // executed if condition is true } else { // else block is optional status = \u0026quot;Not eligible.\u0026quot;; // executed if condition is false } Switch Statement switch (new Date().getDay()) { // input is current day case 6: // if (day == 6) text = \u0026quot;Saturday\u0026quot;; break; case 0: // if (day == 0) text = \u0026quot;Sunday\u0026quot;; break; default: // else... text = \u0026quot;Whatever\u0026quot;; }  Basics➤\nOn page script \u0026lt;script type=\u0026quot;text/javascript\u0026quot;\u0026gt; \u0026lt;/script\u0026gt; Include external JS file \u0026lt;script src=\u0026quot;filename.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt;  Delay - 1 second timeout\nsetTimeout(function () {\t}, 1000); Functions function addNumbers(a, b) { return a + b; ; } x = addNumbers(1, 2); Edit DOM element document.getElementById(\u0026quot;elementID\u0026quot;).innerHTML = \u0026quot;Hello World!\u0026quot;;  Output\nconsole.log(a); // write to the browser console document.write(a); // write to the HTML alert(a); // output in an alert box confirm(\u0026quot;Really?\u0026quot;); // yes/no dialog, returns true/false depending on user click prompt(\u0026quot;Your age?\u0026quot;,\u0026quot;0\u0026quot;); // input dialog. Second argument is the initial value Comments /* Multi line comment */ // One line  "});index.add({'id':16,'href':'/library/tutorials/docs/python/flask/learning-flask/','title':"Learning Flask",'content':" Learning Flask "});index.add({'id':17,'href':'/library/tutorials/docs/python/beginer/list/list/','title':"Lists",'content':" Lists ในบทนี้ คุณจะได้เรียนรู้เกี่ยวกับโครงสร้างข้อมูลแบบ List ในภาษา Python เราจะพูดถึงการสร้างและใช้งาน List ในเบื้องต้น การใช้งานเมธอดและฟังก์ชันเพื่อจัดการข้อมูลภายใน List และการใช้งานคำสั่ง For loop กับ List รวมถึงการ slicing\nList (ลิสต์) คือโครงสร้างข้อมูลชนิดหนึ่งในภาษา Python ที่ใช้เก็บข้อมูลแบบลำดับ (Sequence) โดยมี Index เป็นตัวระบุตำแหน่งในการเข้าถึงข้อมูล เราสามารถใช้ List เพื่อเก็บข้อมูลจำนวนมากและหลากหลายประเภทในเวลาเดียวกัน List เป็นประเภทข้อมูลที่ใช้อย่างหลากหลายในการเขียนโปรแกรม นอกจากนี้ ในภาษา Python ยังมี built-in function ที่สามารถทำงานกับ List และใน List ออบเจ็คเองก็มีเมธอดต่างๆ เป็นจำนวนมากที่ช่วยอำนวยความสะดวกในการเขียนโปรแกรม\nการประกาศและใช้งาน List List นั้นเป็นตัวแปรประเภทหนึ่ง การใช้งานของมันจะเหมือนกันอาเรย์ในภาษาอื่นๆ ในการประกาศ List นั้นข้อมูลของมันจะอยู่ภายในเครื่องหมาย [] และคั่นสมาชิกแต่ละตัวด้วยเครื่องหมายคอมมา , มาดูตัวอย่างการประกาศ List ในภาษา Python\nnumbers = [-1, 2, 5, 8, 10, 13] names = ['Mateo', 'Danny', 'James', 'Thomas', 'Luke'] mixed_type = [-2, 5, 84.2, \u0026quot;Mountain\u0026quot;, \u0026quot;Python\u0026quot;]  ในตัวอย่าง เราได้สร้างตัวแปร List สามตัวแปร numbers เป็นตัวแปร List ที่มีสมาชิกเป็นตัวเลขจำนวนเต็ม 6 ตัว names เป็น List ของ String ที่สำหรับเก็บชื่อและมี 5 รายชื่อ และสุดท้ายตัวแปร mixed_type เป็น List ที่เก็บข้อมูลประเภทต่างๆ แบบรวมกันในตัวแปรเดียวซึ่งมีสมาชิกทั้งหมด 5 ตัว ซึ่งทั้งหมดนี้เป็นการกำหนดสมาชิกให้กับ List พร้อมกับการประกาศตัวแปร ในภาษา Python เราสามารถกำหนดค่าให้กับ List หลังจากประกาศตัวแปรแล้วได้ มาดูตัวอย่าง\nnumbers = [] numbers.append(-1) numbers.append(2) numbers.append(5) numbers.append(8) numbers.append(10) numbers.append(13) names = ['Mateo', 'Danny'] names.append('James') names.append('Thomas') names.append('Luke') print(numbers) print(names) print('numbers count = ', len(numbers)) print('names count = ', len(names))  ในตัวอย่าง เป็นการกำหนดค่าให้กับ List หลังจากที่มันถูกสร้างแล้ว เราใช้เมธอด append() เพื่อเพิ่มข้อมูลใหม่เข้าไปใน List ซึ่งข้อมูลที่เพิ่มเข้าจะอยู่ท้ายสุดและเรียง Index เพิ่มขึ้นไปเรื่อยๆ โดยเริ่มจาก 0 ในตัวแปร numbers เราได้เพิ่ม 5 จำนวนเต็มเข้าไปใน List และในตัวแปร names ในตอนแรกได้ประกาศและกำหนดสองชื่อให้กับตัวแปร และเพิ่มเข้าไปภายหลังอีก 3 ชื่อ และฟังก์ชัน len() ใช้เพื่อนับจำนวนสมาชิกภายใน List\n[-1, 2, 5, 8, 10, 13] ['Mateo', 'Danny', 'James', 'Thomas', 'Luke'] numbers count = 6 names count = 5  การเข้าถึงข้อมูลภายใน List List นั้นใช้ Index สำหรับการเข้าถึงข้อมูล โดย Index ของ List จะเป็นจำนวนเต็มที่เริ่มจาก 0 และเพิ่มขึ้นทีละ 1 ไปเรื่อยๆ ดังนั้น เราจึงสามารถเข้าถึงข้อมูลภายใน List เพื่ออ่านหรืออัพเดทค่าได้โดยตรงผ่าน Index ของมัน นี่เป็นโค้ดการเข้าถึงข้อมูลภายใน List ในภาษา Python\nnames = ['Mateo', 'Danny', 'James', 'Thomas', 'Luke'] print('names[0] = ', names[0]) print('names[3] = ', names[3]) print('names[-1] = ', names[-1]) # update value names[0] = 'Bob' print('names[0] = ', names[0])  ในตัวอย่าง เรามีตัวแปร List ที่ชื่อว่า names ดังนั้น เพือเข้าถึงสมาชิกตัวแรกภายใน List ซึ่งก็คือ \u0026ldquo;Mateo\u0026rdquo; นั้นจะใช้คำสั่ง names[0] และสมาชิกที่มีค่าเป็น \u0026ldquo;Thomas\u0026rdquo; ซึ่งอยู่ตำแหน่งที่ 4 จะใช้คำสั่ง names[3] สังเกตว่า Index จะลดลงหนึ่งเพราะ Index ของ List นั้นเริ่มต้นจาก 0\nprint('names[-1] = ', names[-1])  นอกจากนี้ เราสามารถเข้าถึงข้อมูลภายใน List โดยการใช้ Index เป็นจำนวนลบได้ โดยเริ่มจาก -1 ซึ่งเป็นสมาชิกตัวสุดท้ายของ List และ -2 สมาชิกตัวถัดมาและลดลงไปทีละ 1\nnames[0] = 'Bob' print('names[0] = ', names[0])  นี่เป็นการอัพเดทค่าของสมาชิกภายใน List ในตัวอย่างเราได้เปลี่ยนค่าของสมาชิกในตำแหน่งแรกของ List จากเดิมที่เป็น \u0026ldquo;Mateo\u0026rdquo; ให้เป็น \u0026ldquo;Bob\u0026rdquo;\nnames[0] = Mateo names[3] = Thomas names[-1] = Luke names[0] = Bob  การอ่านค่าใน List ด้วยคำสัง For loop เนื่องจาก List นั้นเก็บข้อมูลเป็นแบบลำดับและใช้ Index ในการเข้าถึงข้อมูล ดังนั้น เราจึงมักจะใช้คำสั่งวนซ้ำสำหรับการเขียนโปรแกรมที่ทำงานกับ List เพราะทำให้การทำงานรวดเร็วและง่ายขึ้น เช่น การใช้คำสั่งวนซ้ำวนอ่านค่าใน List ที่มีข้อมูลเป็นจำนวนมาก เป็นต้น ต่อไปมาดูตัวอย่างการใช้งานคำสั่ง For loop กับ List ในภาษา Python\nnumbers = [10, 20, 30, 40, 50, 60, 70] sum = 0 for n in numbers: print(n, end =' ') sum += n print('sum = ', sum) names = ['Mateo', 'Danny', 'James', 'Thomas', 'Luke'] for i in range(0, len(names)): print(names[i].upper(), end =' ')  ในตัวอย่าง เป็นการวนอ่านค่าภายใน List ด้วยการใช้คำสั่ง For loop โดยเราได้แยกการทำงานออกเป็นสองลูป ในลูปแรกเป็นการใช้งานคำสั่ง For loop เพื่อวนอ่านค่าภายใน List numbers โดยตรง โปรแกรมจะวนอ่านค่าไปทีละค่าและนำค่าในแต่ละรอบที่ได้มาใส่ในตัวแปร n เราได้ทำการแสดงผลตัวเลขภายใน List และหาผลรวมของตัวเลขภายใน List โดยเก็บไว้ในตัวแปร sum\nในลูปที่สอง เป็นการใช้คำสั่ง For loop เช่นกัน แต่ในตอนนี้เราจะสร้าง Index ขึ้นมาโดยการใช้ตัวแปร i เป็นตัวรัน Index จาก 0 ถึงขนาดตัวสุดท้ายของ List ที่สร้างจากฟังก์ชัน range() และเราแสดงผลชื่อในตัวพิมพ์ใหญ่ด้วยเมธอด upper() ของ String\n10 20 30 40 50 60 70 sum = 280 MATEO DANNY JAMES THOMAS LUKE  List slicing ในภาษา Python เราสามารถตัดข้อมูลจาก List หนึ่งแล้วนำไปสร้างเป็น List ใหม่ได้ โดยวิธีดังกล่าวนั้นเรียกกว่า slicing ในการตัดข้อมูลใน List นั้นจะทำในรูปแบบ [a:b] เมื่อ a เป็น Index เริ่มต้นและ b เป็น Index ก่อนสมาชิกตัวสุดท้ายที่ต้องการตัด มาดูตัวอย่างของ list slicing\nch = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'] a = ch[0:4] # a - d b = ch[4:9] # e - h c = ch[:3] # a - c d = ch[3:] # c - h e = ch[:] # copy all list, or equivalent to e = ch f = ch[0:2] + ch[6:8] # a - b and g - h print(a) print(b) print(c) print(d) print(e) print(f)  ในตัวอย่าง เรามีตัวแปร ch ซึ่งมีสมาชิกเป็นตัวอักษรในภาษาอังกฤษจาก a ถึง h หลังจากนั้นเราได้ทำการ slice ข้อมูลจาก List ดังกล่าว ในตัวแปร a นั้นเป็นการตัดเอาข้อมูลจากตำแหน่งที่ 0 ถึง 3 มา ในตัวแปร b นั้นตัดเอาตำแหน่งที่ 4 ถึง 8 ถัดมาเป็นตัวแปร c d และ e เป็นการเว้นว่างตำแหน่งข้างหน้าและข้างหลัง ซึ่งถ้าตำแหน่งข้างหน้าถูกเว้นว่างไว้ เป็นการตัดเอาสมาชิกตั้งแต่ตำแหน่งเริ่มต้นของ List และถ้าตำแหน่งสิ้นสุดถูกเว้นว่างไว้ เป็นการตัดเอาจนถึงสมาชิกตัวสุดท้ายของ List และในตัวแปร f เป็นการตัดเอาสองส่วนของ List มาต่อกัน ในการนำสอง List มาต่อกันนั้นเราจะใช้ตัวดำเนินการ +\n['a', 'b', 'c', 'd'] ['e', 'f', 'g', 'h'] ['a', 'b', 'c'] ['d', 'e', 'f', 'g', 'h'] ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'] ['a', 'b', 'g', 'h']  การใช้งานคำสั่ง del เพื่อลบข้อมูลใน List คำสั่ง del เป็นคำสั่งที่ใช้สำหรับลบตัวแปรใดๆ ออกไปจากหน่วยความจำหรือใช้ยกเลิกตัวแปรที่เคยประกาศไปแล้ว เราสามารถใช้คำสั่ง del เพื่อลบสมาชิกภายใน List ได้เช่นเดียวกัน มาดูตัวอย่างการใช้งานคำสั่ง del ในภาษา Python\nch = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'] del ch[0] # delete a print(ch) del ch[0] # delete b print(ch) del ch[2:4] # delete e, f print(ch) del ch[:] # delete all print(ch)  ในตัวอย่าง เป็นการใช้งานคำสั่ง del สำหรับลบสมาชิกภายใน List ในตอนแรก เราได้ลบอักษร a ออกไปจาก List ซึ่งสมาชิกตัวแรกนั้นจะมี Index เป็น 0 ดังนั้น เมื่อการลบเสร็จสิ้น List จะทำการเลื่อนตัวอักษร b มายัง Index 0 แทน ซึ่งสิ่งนี้เป็นสภาวะการสูญเสียตำแหน่งของ List หรือ Index lose หลังจากนั้น เราได้ลบโดยการใช้วิธีการกำหนด Index แบบ slicing เราได้ทำการลบค่าจาก Index 0 ถึง 3 ซึ่งเป็นการลบตัวอักษรจาก e ถึง f และในคำสั่งสุดท้ายเป็นการลบข้อมูลภายใน List ทั้งหมด\n['b', 'c', 'd', 'e', 'f', 'g', 'h'] ['c', 'd', 'e', 'f', 'g', 'h'] ['c', 'd', 'g', 'h'] []  Warning: จากตัวอย่างข้างต้นนั้น เมื่อคุณต้องการลบข้อมูลทั้งหมดภายใน List เราจะใช้ del ch[:] เพราะว่าเป็นการลบแบบ slicing จากตำแหน่งแรกถึงตำแหน่งสุดท้ายและจะทำให้มันกลายเป็น List ว่างปล่าว เมื่อคุณใช้คำสั่ง del ch จะหมายความว่าลบตัวแปรออกไปจากหน่วยความจำแทน\nในบทนี้ คุณได้เรียนรู้เกี่ยวกับการประกาศและใช้งาน List ในภาษา Python นอกจากนี้เรายังใช้คำสัง For loop เพื่อให้ง่ายในการอ่านข้อมูลภายใน List รวมทั้งการตัดข้อมูลใน List ด้วยการ slicing และการใช้คำสั่ง del เพื่อลบข้อมูลภายใน List ออกไป ในบทต่อไป เราจะเป็นการใช้งานฟังก์ชันและเมธอดของ List\nReference :\n http://marcuscode.com/lang/python/lists  "});index.add({'id':18,'href':'/library/tutorials/docs/python/pandas/','title':"Pandas",'content':" Pandas User Guide The User Guide covers all of pandas by topic area. Each of the subsections introduces a topic (such as “working with missing data”), and discusses how pandas approaches the problem, with many examples throughout.\nUsers brand-new to pandas should start with 10 minutes to pandas.\nFurther information on any specific method can be obtained in the API reference.\n IO tools (text, CSV, HDF5, …)  CSV \u0026amp; text files JSON HTML Excel files OpenDocument Spreadsheets Binary Excel (.xlsb) files Clipboard Pickling msgpack HDF5 (PyTables) Feather Parquet ORC SQL queries Google BigQuery Stata format SAS formats SPSS formats Other file formats Performance considerations  Indexing and selecting data  Different choices for indexing Basics Attribute access Slicing ranges Selection by label Selection by position Selection by callable IX indexer is deprecated Indexing with list with missing labels is deprecated Selecting random samples Setting with enlargement Fast scalar value getting and setting Boolean indexing Indexing with isin The where() Method and Masking The query() Method Duplicate data Dictionary-like get() method The lookup() method Index objects Set / reset index Returning a view versus a copy  MultiIndex / advanced indexing  Hierarchical indexing (MultiIndex) Advanced indexing with hierarchical index Sorting a MultiIndex Take methods Index types Miscellaneous indexing FAQ  Merge, join, and concatenate  Concatenating objects Database-style DataFrame or named Series joining/merging Timeseries friendly merging  Reshaping and pivot tables  Reshaping by pivoting DataFrame objects Reshaping by stacking and unstacking Reshaping by Melt Combining with stats and GroupBy Pivot tables Cross tabulations Tiling Computing indicator / dummy variables Factorizing values Examples Exploding a list-like column  Working with text data  Text Data Types String Methods Splitting and replacing strings Concatenation Indexing with .str Extracting substrings Testing for Strings that match or contain a pattern Creating indicator variables Method summary  Working with missing data  Values considered “missing” Inserting missing data Calculations with missing data Sum/prod of empties/nans NA values in GroupBy Filling missing values: fillna Filling with a PandasObject Dropping axis labels with missing data: dropna Interpolation Replacing generic values String/regular expression replacement Numeric replacement Experimental NA scalar to denote missing values  Categorical data  Object creation CategoricalDtype Description Working with categories Sorting and order Comparisons Operations Data munging Getting data in/out Missing data Differences to R’s factor Gotchas  Nullable integer data type  Construction Operations Scalar NA Value  Nullable Boolean Data Type  Indexing with NA values Kleene Logical Operations  Visualization  Basic plotting: plot Other plots Plotting with missing data Plotting Tools Plot Formatting Plotting directly with matplotlib  Computational tools  Statistical functions Window Functions Aggregation Expanding windows Exponentially weighted windows  Group By: split-apply-combine  Splitting an object into groups Iterating through groups Selecting a group Aggregation Transformation Filtration Dispatching to instance methods Flexible apply Other useful features Examples  Time series / date functionality  Overview Timestamps vs. Time Spans Converting to timestamps Generating ranges of timestamps Timestamp limitations Indexing Time/date components DateOffset objects Time Series-Related Instance Methods Resampling Time span representation Converting between representations Representing out-of-bounds spans Time zone handling  Time deltas  Parsing Operations Reductions Frequency conversion Attributes TimedeltaIndex Resampling  Styling  Building styles Finer control: slicing Finer Control: Display Values Builtin styles Sharing styles Other Options Fun stuff Export to Excel Extensibility  Options and settings  Overview Getting and setting options Setting startup options in Python/IPython environment Frequently Used Options Available options Number formatting Unicode formatting Table schema display  Enhancing performance  Cython (writing C extensions for pandas) Using Numba Expression evaluation via eval()  Scaling to large datasets  Load less data Use efficient datatypes Use chunking Use other libraries  Sparse data structures  SparseArray SparseDtype Sparse accessor Sparse calculation Migrating Interaction with scipy.sparse  Frequently Asked Questions (FAQ)  DataFrame memory usage Using if/truth statements with pandas NaN, Integer NA values and NA type promotions Differences with NumPy Thread-safety Byte-Ordering issues  Cookbook  Idioms Selection MultiIndexing Missing data Grouping Timeseries Merge Plotting Data In/Out Computation Timedeltas Aliasing axis names Creating example data   Pandas Documentation  IO tools (text, CSV, HDF5, …) Indexing and selecting data MultiIndex / advanced indexing Merge, join, and concatenate Reshaping and pivot tables Working with text data Working with missing data Categorical data Nullable integer data type Nullable Boolean Data Type Visualization Computational tools Group By: split-apply-combine Time series / date functionality Time deltas Styling Options and settings Enhancing performance Scaling to large datasets Sparse data structures Frequently Asked Questions (FAQ) Cookbook  "});index.add({'id':19,'href':'/library/tutorials/docs/articles/data-science/pandas/user_guide/','title':"Pandas User Guide",'content':" User Guide  Source : Pandas Document : .\n The User Guide covers all of pandas by topic area. Each of the subsections introduces a topic (such as “working with missing data”), and discusses how pandas approaches the problem, with many examples throughout.\nUsers brand-new to pandas should start with 10 minutes to pandas.\nFurther information on any specific method can be obtained in the API reference.\n IO tools (text, CSV, HDF5, …)  CSV \u0026amp; text files JSON HTML Excel files OpenDocument Spreadsheets Binary Excel (.xlsb) files Clipboard Pickling msgpack HDF5 (PyTables) Feather Parquet ORC SQL queries Google BigQuery Stata format SAS formats SPSS formats Other file formats Performance considerations  Indexing and selecting data  Different choices for indexing Basics Attribute access Slicing ranges Selection by label Selection by position Selection by callable IX indexer is deprecated Indexing with list with missing labels is deprecated Selecting random samples Setting with enlargement Fast scalar value getting and setting Boolean indexing Indexing with isin The where() Method and Masking The query() Method Duplicate data Dictionary-like get() method The lookup() method Index objects Set / reset index Returning a view versus a copy  MultiIndex / advanced indexing  Hierarchical indexing (MultiIndex) Advanced indexing with hierarchical index Sorting a MultiIndex Take methods Index types Miscellaneous indexing FAQ  Merge, join, and concatenate  Concatenating objects Database-style DataFrame or named Series joining/merging Timeseries friendly merging  Reshaping and pivot tables  Reshaping by pivoting DataFrame objects Reshaping by stacking and unstacking Reshaping by Melt Combining with stats and GroupBy Pivot tables Cross tabulations Tiling Computing indicator / dummy variables Factorizing values Examples Exploding a list-like column  Working with text data  Text Data Types String Methods Splitting and replacing strings Concatenation Indexing with .str Extracting substrings Testing for Strings that match or contain a pattern Creating indicator variables Method summary  Working with missing data  Values considered “missing” Inserting missing data Calculations with missing data Sum/prod of empties/nans NA values in GroupBy Filling missing values: fillna Filling with a PandasObject Dropping axis labels with missing data: dropna Interpolation Replacing generic values String/regular expression replacement Numeric replacement Experimental NA scalar to denote missing values  Categorical data  Object creation CategoricalDtype Description Working with categories Sorting and order Comparisons Operations Data munging Getting data in/out Missing data Differences to R’s factor Gotchas  Nullable integer data type  Construction Operations Scalar NA Value  Nullable Boolean Data Type  Indexing with NA values Kleene Logical Operations  Visualization  Basic plotting: plot Other plots Plotting with missing data Plotting Tools Plot Formatting Plotting directly with matplotlib  Computational tools  Statistical functions Window Functions Aggregation Expanding windows Exponentially weighted windows  Group By: split-apply-combine  Splitting an object into groups Iterating through groups Selecting a group Aggregation Transformation Filtration Dispatching to instance methods Flexible apply Other useful features Examples  Time series / date functionality  Overview Timestamps vs. Time Spans Converting to timestamps Generating ranges of timestamps Timestamp limitations Indexing Time/date components DateOffset objects Time Series-Related Instance Methods Resampling Time span representation Converting between representations Representing out-of-bounds spans Time zone handling  Time deltas  Parsing Operations Reductions Frequency conversion Attributes TimedeltaIndex Resampling  Styling  Building styles Finer control: slicing Finer Control: Display Values Builtin styles Sharing styles Other Options Fun stuff Export to Excel Extensibility  Options and settings  Overview Getting and setting options Setting startup options in Python/IPython environment Frequently Used Options Available options Number formatting Unicode formatting Table schema display  Enhancing performance  Cython (writing C extensions for pandas) Using Numba Expression evaluation via eval()  Scaling to large datasets  Load less data Use efficient datatypes Use chunking Use other libraries  Sparse data structures  SparseArray SparseDtype Sparse accessor Sparse calculation Migrating Interaction with scipy.sparse  Frequently Asked Questions (FAQ)  DataFrame memory usage Using if/truth statements with pandas NaN, Integer NA values and NA type promotions Differences with NumPy Thread-safety Byte-Ordering issues  Cookbook  Idioms Selection MultiIndexing Missing data Grouping Timeseries Merge Plotting Data In/Out Computation Timedeltas Aliasing axis names Creating example data   "});index.add({'id':20,'href':'/library/tutorials/docs/articles/webapp/falsk/build-a-crud-web-app/part-1/','title':"Part. I",'content':" Python Flask for Beginners: Build a CRUD Web App with Python and Flask Part. I I’ve named the app Project Dream Team, and it will have the following features:\n Users will be able to register and login as employees The administrator will be able to create, update, and delete departments and roles The administrator will be able to assign employees to a department and assign them roles The administrator will be able to view all employees and their details  Part One will cover:\n Users will be able to register and login as employees The administrator will be able to create, update, and delete departments and roles The administrator will be able to assign employees to a department and assign them roles The administrator will be able to view all employees and their details  Ready? Here we go!\nPrerequisites This tutorial builds on my introductory tutorial, Getting Started With Flask, picking up where it left off. It assumes you have, to begin with, the following dependencies installed:\n Users will be able to register and login as employees The administrator will be able to create, update, and delete departments and roles The administrator will be able to assign employees to a department and assign them roles The administrator will be able to view all employees and their details  You should have a virtual environment set up and activated. You should also have the following file and directory structure:\n\u0026amp;#x251C;\u0026amp;#x2500;\u0026amp;#x2500; dream-team \u0026amp;#xA0;\u0026amp;#xA0; \u0026amp;#x251C;\u0026amp;#x2500;\u0026amp;#x2500; app \u0026amp;#xA0;\u0026amp;#xA0; \u0026amp;#x2502;\u0026amp;#xA0;\u0026amp;#xA0; \u0026amp;#x251C;\u0026amp;#x2500;\u0026amp;#x2500; __init__.py \u0026amp;#xA0;\u0026amp;#xA0; \u0026amp;#x2502;\u0026amp;#xA0;\u0026amp;#xA0; \u0026amp;#x251C;\u0026amp;#x2500;\u0026amp;#x2500; templates \u0026amp;#xA0;\u0026amp;#xA0; \u0026amp;#x2502;\u0026amp;#xA0;\u0026amp;#xA0; \u0026amp;#x251C;\u0026amp;#x2500;\u0026amp;#x2500; models.py \u0026amp;#xA0; \u0026amp;#x2502;\u0026amp;#xA0;\u0026amp;#xA0; \u0026amp;#x2514;\u0026amp;#x2500;\u0026amp;#x2500; views.py \u0026amp;#xA0;\u0026amp;#xA0; \u0026amp;#x251C;\u0026amp;#x2500;\u0026amp;#x2500; config.py \u0026amp;#xA0; \u0026amp;#xA0; \u0026amp;#x251C;\u0026amp;#x2500;\u0026amp;#x2500; requirements.txt \u0026amp;#xA0;\u0026amp;#xA0; \u0026amp;#x2514;\u0026amp;#x2500;\u0026amp;#x2500; run.py  This project structure groups the similar components of the application together. The dream-team directory houses all the project files. The app directory is the application package, and houses different but interlinked modules of the application. All templates are stored in the templates directory, all models are in the models.py file, and all routes are in the views.py file. The run.py file is the application\u0026rsquo;s entry point, the config.py file contains the application configurations, and the requirements.txt file contains the software dependencies for the application.\nIf you don\u0026rsquo;t have these set up, please visit the introductory tutorial and catch up!\nDatabase Setup Flask has support for several relational database management systems, including SQLite, MySQL, and PostgreSQL. For this tutorial, we will be using MySQL. It’s popular and therefore has a lot of support, in addition to being scalable, secure, and rich in features.\nWe will install the following (remember to activate your virtual environment):\n Users will be able to register and login as employees The administrator will be able to create, update, and delete departments and roles The administrator will be able to assign employees to a department and assign them roles The administrator will be able to view all employees and their details\n$ pip install flask-sqlalchemy mysql-python   We\u0026rsquo;ll then create the MySQL database. Ensure you have MySQL installed and running, and then log in as the root user:\n$ mysql -u root mysql\u0026gt; CREATE USER \u0026amp;apos;dt_admin\u0026amp;apos;@\u0026amp;apos;localhost\u0026amp;apos; IDENTIFIED BY \u0026amp;apos;dt2016\u0026amp;apos;; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; CREATE DATABASE dreamteam_db; Query OK, 1 row affected (0.00 sec) mysql\u0026gt; GRANT ALL PRIVILEGES ON dreamteam_db . * TO \u0026amp;apos;dt_admin\u0026amp;apos;@\u0026amp;apos;localhost\u0026amp;apos;; Query OK, 0 rows affected (0.00 sec)  We have now created a new user dt_admin with the password dt2016, created a new database dreamteam_db, and granted the new user all database privileges.\nNext, let\u0026rsquo;s edit the config.py. Remove any exisiting code and add the following:\n# config.py class Config(object): \u0026quot;\u0026quot;\u0026quot; Common configurations \u0026quot;\u0026quot;\u0026quot; # Put any configurations here that are common across all environments class DevelopmentConfig(Config): \u0026quot;\u0026quot;\u0026quot; Development configurations \u0026quot;\u0026quot;\u0026quot; DEBUG = True SQLALCHEMY_ECHO = True class ProductionConfig(Config): \u0026quot;\u0026quot;\u0026quot; Production configurations \u0026quot;\u0026quot;\u0026quot; DEBUG = False app_config = { \u0026amp;apos;development\u0026amp;apos;: DevelopmentConfig, \u0026amp;apos;production\u0026amp;apos;: ProductionConfig }  It is good practice to specify configurations for different environments. In the file above, we have specifed configurations for development, which we will use while building the app and running it locally, as well as production, which we will use when the app is deployed.\nSome useful configuration variables are:\n Users will be able to register and login as employees The administrator will be able to create, update, and delete departments and roles The administrator will be able to assign employees to a department and assign them roles The administrator will be able to view all employees and their details  You can find more Flask configuration variables here and SQLAlchemy configuration variables here.\nNext, create an instance directory in the dream-team directory, and then create a config.py file inside it. We will put configuration variables here that will not be pushed to version control due to their sensitive nature. In this case, we put the secret key as well as the database URI which contains the database user password.\n# instance/config.py SECRET_KEY = \u0026amp;apos;p9Bv\u0026lt;3Eid9%$i01\u0026amp;apos; SQLALCHEMY_DATABASE_URI = \u0026amp;apos;mysql://dt_admin:dt2016@localhost/dreamteam_db\u0026amp;apos;  Now, let\u0026rsquo;s edit the app/__init__.py file. Remove any existing code and add the following:\n# app/__init__.py # third-party imports from flask import Flask from flask_sqlalchemy import SQLAlchemy # local imports from config import app_config # db variable initialization db = SQLAlchemy() def create_app(config_name): app = Flask(__name__, instance_relative_config=True) app.config.from_object(app_config[config_name]) app.config.from_pyfile(\u0026amp;apos;config.py\u0026amp;apos;) db.init_app(app) return app  We\u0026rsquo;ve created a function, create_app that, given a configuration name, loads the correct configuration from the config.py file, as well as the configurations from the instance/config.py file. We have also created a db object which we will use to interact with the database.\nNext, let\u0026rsquo;s edit the run.py file:\n# run.py import os from app import create_app config_name = os.getenv(\u0026amp;apos;FLASK_CONFIG\u0026amp;apos;) app = create_app(config_name) if __name__ == \u0026amp;apos;__main__\u0026amp;apos;: app.run()  We create the app by running the create_app function and passing in the configuration name. We get this from the OS environment variable FLASK_CONFIG. Because we are in development, we should set the environment variable to development.\nLet\u0026rsquo;s run the app to ensure everything is working as expected. First, delete the app/views.py file as well as the app/templates directory as we will not be needing them going forward. Next, add a temporary route to the app/__init__.py file as follows:\n# app/__init__.py # existing code remains def create_app(config_name): # existing code remains # temporary route @app.route(\u0026amp;apos;/\u0026amp;apos;) def hello_world(): return \u0026amp;apos;Hello, World!\u0026amp;apos; return app  Make sure you set the FLASK_CONFIG and FLASK_APP environment variables before running the app:\n$ export FLASK_CONFIG=development $ export FLASK_APP=run.py $ flask run * Serving Flask app \u0026quot;run\u0026quot; * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)  We can see the “Hello, World” string we set in the route. The app is working well so far.\nModels Now to work on the models. Remember that a model is a representation of a database table in code. We\u0026rsquo;ll need three models: Employee, Department, and Role.\nBut first, let’s install Flask-Login, which will help us with user management and handle logging in, logging out, and user sessions. The Employee model will inherit from Flask-Login’s UserMixin class which will make it easier for us to make use of its properties and methods.\n$ pip install flask-login  To use Flask-Login, we need to create a LoginManager object and initialize it in the app/__init__.py file. First, remove the route we added earlier, and then add the following:\n# app/__init__.py # after existing third-party imports from flask_login import LoginManager # after the db variable initialization login_manager = LoginManager() def create_app(config_name): # existing code remains login_manager.init_app(app) login_manager.login_message = \u0026quot;You must be logged in to access this page.\u0026quot; login_manager.login_view = \u0026quot;auth.login\u0026quot; return app  In addition to initializing the LoginManager object, we\u0026rsquo;ve also added a login_view and login_message to it. This way, if a user tries to access a page that they are not authorized to, it will redirect to the specified view and display the specified message. We haven\u0026rsquo;t created the auth.login view yet, but we will when we get to authentication.\nNow add the following code to the app/models.py file:\n# app/models.py from flask_login import UserMixin from werkzeug.security import generate_password_hash, check_password_hash from app import db, login_manager class Employee(UserMixin, db.Model): \u0026quot;\u0026quot;\u0026quot; Create an Employee table \u0026quot;\u0026quot;\u0026quot; # Ensures table will be named in plural and not in singular # as is the name of the model __tablename__ = \u0026amp;apos;employees\u0026amp;apos; id = db.Column(db.Integer, primary_key=True) email = db.Column(db.String(60), index=True, unique=True) username = db.Column(db.String(60), index=True, unique=True) first_name = db.Column(db.String(60), index=True) last_name = db.Column(db.String(60), index=True) password_hash = db.Column(db.String(128)) department_id = db.Column(db.Integer, db.ForeignKey(\u0026amp;apos;departments.id\u0026amp;apos;)) role_id = db.Column(db.Integer, db.ForeignKey(\u0026amp;apos;roles.id\u0026amp;apos;)) is_admin = db.Column(db.Boolean, default=False) @property def password(self): \u0026quot;\u0026quot;\u0026quot; Prevent pasword from being accessed \u0026quot;\u0026quot;\u0026quot; raise AttributeError(\u0026amp;apos;password is not a readable attribute.\u0026amp;apos;) @password.setter def password(self, password): \u0026quot;\u0026quot;\u0026quot; Set password to a hashed password \u0026quot;\u0026quot;\u0026quot; self.password_hash = generate_password_hash(password) def verify_password(self, password): \u0026quot;\u0026quot;\u0026quot; Check if hashed password matches actual password \u0026quot;\u0026quot;\u0026quot; return check_password_hash(self.password_hash, password) def __repr__(self): return \u0026amp;apos;\u0026lt;Employee: {}\u0026gt;\u0026amp;apos;.format(self.username) # Set up user_loader @login_manager.user_loader def load_user(user_id): return Employee.query.get(int(user_id)) class Department(db.Model): \u0026quot;\u0026quot;\u0026quot; Create a Department table \u0026quot;\u0026quot;\u0026quot; __tablename__ = \u0026amp;apos;departments\u0026amp;apos; id = db.Column(db.Integer, primary_key=True) name = db.Column(db.String(60), unique=True) description = db.Column(db.String(200)) employees = db.relationship(\u0026amp;apos;Employee\u0026amp;apos;, backref=\u0026amp;apos;department\u0026amp;apos;, lazy=\u0026amp;apos;dynamic\u0026amp;apos;) def __repr__(self): return \u0026amp;apos;\u0026lt;Department: {}\u0026gt;\u0026amp;apos;.format(self.name) class Role(db.Model): \u0026quot;\u0026quot;\u0026quot; Create a Role table \u0026quot;\u0026quot;\u0026quot; __tablename__ = \u0026amp;apos;roles\u0026amp;apos; id = db.Column(db.Integer, primary_key=True) name = db.Column(db.String(60), unique=True) description = db.Column(db.String(200)) employees = db.relationship(\u0026amp;apos;Employee\u0026amp;apos;, backref=\u0026amp;apos;role\u0026amp;apos;, lazy=\u0026amp;apos;dynamic\u0026amp;apos;) def __repr__(self): return \u0026amp;apos;\u0026lt;Role: {}\u0026gt;\u0026amp;apos;.format(self.name)  In the Employee model, we make use of some of Werkzeug\u0026rsquo;s handy security helper methods, generate_password_hash, which allows us to hash passwords, and check_password_hash, which allows us ensure the hashed password matches the password. To enhance security, we have a password method which ensures that the password can never be accessed; instead an error will be raised. We also have two foreign key fields, department_id and role_id, which refer to the ID\u0026rsquo;s of the department and role assigned to the employee.\nNote that we have an is_admin field which is set to False by default. We will override this when creating the admin user. Just after the Employee model, we have a user_loader callback, which Flask-Login uses to reload the user object from the user ID stored in the session.\nThe Department and Role models are quite similar. Both have name and description fields. Additionally, both have a one-to-many relationship with the Employee model (one department or role can have many employees). We define this in both models using the employees field. backref allows us to create a new property on the Employee model such that we can use employee.department or employee.role to get the department or role assigned to that employee. lazy defines how the data will be loaded from the database; in this case it will be loaded dynamically, which is ideal for managing large collections.\nMigration Migrations allow us to manage changes we make to the models, and propagate these changes in the database. For example, if later on we make a change to a field in one of the models, all we will need to do is create and apply a migration, and the database will reflect the change.\nWe’ll begin by installing Flask-Migrate, which will handle the database migrations using Alembic, a lightweight database migration tool. Alembic emits ALTER statements to a database thus implememting changes made to the models. It also auto-generates minimalistic migration scripts, which may be complex to write.\n$ pip install flask-migrate  We\u0026rsquo;ll need to edit the app/__init__.py file:\n# app/__init__.py # after existing third-party imports from flask_migrate import Migrate # existing code remains def create_app(config_name): # existing code remains migrate = Migrate(app, db) from app import models return app  We have created a migrate object which will allow us to run migrations using Flask-Migrate. We have also imported the models from the app package. Next, we\u0026rsquo;ll run the following command to create a migration repository:\n$ flask db init  This creates a migrations directory in the dream-team directory:\n\u0026amp;#x2514;\u0026amp;#x2500;\u0026amp;#x2500; migrations \u0026amp;#x251C;\u0026amp;#x2500;\u0026amp;#x2500; README \u0026amp;#x251C;\u0026amp;#x2500;\u0026amp;#x2500; alembic.ini \u0026amp;#x251C;\u0026amp;#x2500;\u0026amp;#x2500; env.py \u0026amp;#x251C;\u0026amp;#x2500;\u0026amp;#x2500; script.py.mako \u0026amp;#x2514;\u0026amp;#x2500;\u0026amp;#x2500; versions  Next, we will create the first migration:\n$ flask db migrate  Finally, we\u0026rsquo;ll apply the migration:\n$ flask db upgrade  We\u0026rsquo;ve sucessfully created tables based on the models we wrote! Let\u0026rsquo;s check the MySQL database to confirm this:\n$ mysql -u root mysql\u0026gt; use dreamteam_db; mysql\u0026gt; show tables; +------------------------+ | Tables_in_dreamteam_db | +------------------------+ | alembic_version | | departments | | employees | | roles | +------------------------+ 4 rows in set (0.00 sec)  Blueprints Blueprints are great for organising a flask app into components, each with its own views and forms. I find that blueprints make for a cleaner and more organised project structure because each blueprint is a distinct component that addresses a specific functionality of the app. Each blueprint can even have its own cutsom URL prefix or subdomain. Blueprints are particularly convenient for large applications.\nWe\u0026rsquo;re going to have three blueprints in this app:\n Users will be able to register and login as employees The administrator will be able to create, update, and delete departments and roles The administrator will be able to assign employees to a department and assign them roles The administrator will be able to view all employees and their details  Create the relevant files and directories so that your directory structure resembles this:\n\u0026amp;#x2514;\u0026amp;#x2500;\u0026amp;#x2500; dream-team \u0026amp;#x251C;\u0026amp;#x2500;\u0026amp;#x2500; app \u0026amp;#x2502;\u0026amp;#xA0;\u0026amp;#xA0; \u0026amp;#x251C;\u0026amp;#x2500;\u0026amp;#x2500; __init__.py \u0026amp;#x2502;\u0026amp;#xA0;\u0026amp;#xA0; \u0026amp;#x251C;\u0026amp;#x2500;\u0026amp;#x2500; admin \u0026amp;#x2502;\u0026amp;#xA0;\u0026amp;#xA0; \u0026amp;#x2502;\u0026amp;#xA0;\u0026amp;#xA0; \u0026amp;#x251C;\u0026amp;#x2500;\u0026amp;#x2500; __init__.py \u0026amp;#x2502;\u0026amp;#xA0;\u0026amp;#xA0; \u0026amp;#x2502;\u0026amp;#xA0;\u0026amp;#xA0; \u0026amp;#x251C;\u0026amp;#x2500;\u0026amp;#x2500; forms.py \u0026amp;#x2502;\u0026amp;#xA0;\u0026amp;#xA0; \u0026amp;#x2502;\u0026amp;#xA0;\u0026amp;#xA0; \u0026amp;#x2514;\u0026amp;#x2500;\u0026amp;#x2500; views.py \u0026amp;#x2502;\u0026amp;#xA0;\u0026amp;#xA0; \u0026amp;#x251C;\u0026amp;#x2500;\u0026amp;#x2500; auth \u0026amp;#x2502;\u0026amp;#xA0;\u0026amp;#xA0; \u0026amp;#x2502;\u0026amp;#xA0;\u0026amp;#xA0; \u0026amp;#x251C;\u0026amp;#x2500;\u0026amp;#x2500; __init__.py \u0026amp;#x2502;\u0026amp;#xA0;\u0026amp;#xA0; \u0026amp;#x2502;\u0026amp;#xA0;\u0026amp;#xA0; \u0026amp;#x251C;\u0026amp;#x2500;\u0026amp;#x2500; forms.py \u0026amp;#x2502;\u0026amp;#xA0;\u0026amp;#xA0; \u0026amp;#x2502;\u0026amp;#xA0;\u0026amp;#xA0; \u0026amp;#x2514;\u0026amp;#x2500;\u0026amp;#x2500; views.py \u0026amp;#x2502;\u0026amp;#xA0;\u0026amp;#xA0; \u0026amp;#x251C;\u0026amp;#x2500;\u0026amp;#x2500; home \u0026amp;#x2502;\u0026amp;#xA0;\u0026amp;#xA0; \u0026amp;#x2502;\u0026amp;#xA0;\u0026amp;#xA0; \u0026amp;#x251C;\u0026amp;#x2500;\u0026amp;#x2500; __init__.py \u0026amp;#x2502;\u0026amp;#xA0;\u0026amp;#xA0; \u0026amp;#x2502;\u0026amp;#xA0;\u0026amp;#xA0; \u0026amp;#x2514;\u0026amp;#x2500;\u0026amp;#x2500; views.py \u0026amp;#x2502;\u0026amp;#xA0;\u0026amp;#xA0; \u0026amp;#x251C;\u0026amp;#x2500;\u0026amp;#x2500; models.py \u0026amp;#x2502;\u0026amp;#xA0;\u0026amp;#xA0; \u0026amp;#x251C;\u0026amp;#x2500;\u0026amp;#x2500; static \u0026amp;#x2502;\u0026amp;#xA0;\u0026amp;#xA0; \u0026amp;#x2514;\u0026amp;#x2500;\u0026amp;#x2500; templates \u0026amp;#x251C;\u0026amp;#x2500;\u0026amp;#x2500; config.py \u0026amp;#x251C;\u0026amp;#x2500;\u0026amp;#x2500; instance \u0026amp;#x2502;\u0026amp;#xA0;\u0026amp;#xA0; \u0026amp;#x2514;\u0026amp;#x2500;\u0026amp;#x2500; config.py \u0026amp;#x251C;\u0026amp;#x2500;\u0026amp;#x2500; migrations \u0026amp;#x2502;\u0026amp;#xA0;\u0026amp;#xA0; \u0026amp;#x251C;\u0026amp;#x2500;\u0026amp;#x2500; README \u0026amp;#x2502;\u0026amp;#xA0;\u0026amp;#xA0; \u0026amp;#x251C;\u0026amp;#x2500;\u0026amp;#x2500; alembic.ini \u0026amp;#x2502;\u0026amp;#xA0;\u0026amp;#xA0; \u0026amp;#x251C;\u0026amp;#x2500;\u0026amp;#x2500; env.py \u0026amp;#x2502;\u0026amp;#xA0;\u0026amp;#xA0; \u0026amp;#x251C;\u0026amp;#x2500;\u0026amp;#x2500; script.py.mako \u0026amp;#x2502;\u0026amp;#xA0;\u0026amp;#xA0; \u0026amp;#x2514;\u0026amp;#x2500;\u0026amp;#x2500; versions \u0026amp;#x2502;\u0026amp;#xA0;\u0026amp;#xA0; \u0026amp;#x2514;\u0026amp;#x2500;\u0026amp;#x2500; a1a1d8b30202_.py \u0026amp;#x251C;\u0026amp;#x2500;\u0026amp;#x2500; requirements.txt \u0026amp;#x2514;\u0026amp;#x2500;\u0026amp;#x2500; run.py  I chose not to have static and templates directories for each blueprint, because all the application templates will inherit from the same base template and use the same CSS file. Instead, the templates directory will have sub-directories for each blueprint so that blueprint templates can be grouped together.\nIn each blueprint\u0026rsquo;s __init__.py file, we need to create a Blueprint object and initialize it with a name. We also need to import the views.\n# app/admin/__init__.py from flask import Blueprint admin = Blueprint(\u0026amp;apos;admin\u0026amp;apos;, __name__) from . import views # app/auth/__init__.py from flask import Blueprint auth = Blueprint(\u0026amp;apos;auth\u0026amp;apos;, __name__) from . import views # app/home/__init__.py from flask import Blueprint home = Blueprint(\u0026amp;apos;home\u0026amp;apos;, __name__) from . import views  Then, we can register the blueprints on the app in the app/__init__.py file, like so:\n# app/__init__.py # existing code remains def create_app(config_name): # existing code remains from app import models from .admin import admin as admin_blueprint app.register_blueprint(admin_blueprint, url_prefix=\u0026amp;apos;/admin\u0026amp;apos;) from .auth import auth as auth_blueprint app.register_blueprint(auth_blueprint) from .home import home as home_blueprint app.register_blueprint(home_blueprint) return app  We have imported each blueprint object and registered it. For the admin blueprint, we have added a url prefix, /admin. This means that all the views for this blueprint will be accessed in the browser with the url prefix admin.\nHome Blueprint Time to work on fleshing out the blueprints! We\u0026rsquo;ll start with the home blueprint, which will have the homepage as well as the dashboard.\n# app/home/views.py from flask import render_template from flask_login import login_required from . import home @home.route(\u0026amp;apos;/\u0026amp;apos;) def homepage(): \u0026quot;\u0026quot;\u0026quot; Render the homepage template on the / route \u0026quot;\u0026quot;\u0026quot; return render_template(\u0026amp;apos;home/index.html\u0026amp;apos;, title=\u0026quot;Welcome\u0026quot;) @home.route(\u0026amp;apos;/dashboard\u0026amp;apos;) @login_required def dashboard(): \u0026quot;\u0026quot;\u0026quot; Render the dashboard template on the /dashboard route \u0026quot;\u0026quot;\u0026quot; return render_template(\u0026amp;apos;home/dashboard.html\u0026amp;apos;, title=\u0026quot;Dashboard\u0026quot;)  Each view function has a decorator, home.route, which has a URL route as a parameter (remember that home is the name of the blueprint as specified in the app/home/__init__.py file). Each view handles requests to the specified URL.\nThe homepage view renders the home template, while the dashboard view renders the dashboard template. Note that the dashboard view has a login_required decorator, meaning that users must be logged in to access it.\nNow to work on the base template, which all other templates will inherit from. Create a base.html file in the app/templates directory and add the following code:\n\u0026lt;!-- app/templates/base.html --\u0026gt; \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;{{ title }} | Project Dream Team\u0026lt;/title\u0026gt; \u0026lt;link href=\u0026quot;https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css\u0026quot; rel=\u0026quot;stylesheet\u0026quot;\u0026gt; \u0026lt;link href=\u0026quot;{{ url_for(\u0026amp;apos;static\u0026amp;apos;, filename=\u0026amp;apos;css/style.css\u0026amp;apos;) }}\u0026quot; rel=\u0026quot;stylesheet\u0026quot;\u0026gt; \u0026lt;link rel=\u0026quot;shortcut icon\u0026quot; href=\u0026quot;{{ url_for(\u0026amp;apos;static\u0026amp;apos;, filename=\u0026amp;apos;img/favicon.ico\u0026amp;apos;) }}\u0026quot;\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;nav class=\u0026quot;navbar navbar-default navbar-fixed-top topnav\u0026quot; role=\u0026quot;navigation\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;container topnav\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;navbar-header\u0026quot;\u0026gt; \u0026lt;button type=\u0026quot;button\u0026quot; class=\u0026quot;navbar-toggle\u0026quot; data-toggle=\u0026quot;collapse\u0026quot; data-target=\u0026quot;#bs-example-navbar-collapse-1\u0026quot;\u0026gt; \u0026lt;span class=\u0026quot;sr-only\u0026quot;\u0026gt;Toggle navigation\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;icon-bar\u0026quot;\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;icon-bar\u0026quot;\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;icon-bar\u0026quot;\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;/button\u0026gt; \u0026lt;a class=\u0026quot;navbar-brand topnav\u0026quot; href=\u0026quot;{{ url_for(\u0026amp;apos;home.homepage\u0026amp;apos;) }}\u0026quot;\u0026gt;Project Dream Team\u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;collapse navbar-collapse\u0026quot; id=\u0026quot;bs-example-navbar-collapse-1\u0026quot;\u0026gt; \u0026lt;ul class=\u0026quot;nav navbar-nav navbar-right\u0026quot;\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;{{ url_for(\u0026amp;apos;home.homepage\u0026amp;apos;) }}\u0026quot;\u0026gt;Home\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;#\u0026quot;\u0026gt;Register\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;#\u0026quot;\u0026gt;Login\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/nav\u0026gt; \u0026lt;div class=\u0026quot;wrapper\u0026quot;\u0026gt; {% block body %} {% endblock %} \u0026lt;div class=\u0026quot;push\u0026quot;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;footer\u0026gt; \u0026lt;div class=\u0026quot;container\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col-lg-12\u0026quot;\u0026gt; \u0026lt;ul class=\u0026quot;list-inline\u0026quot;\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;{{ url_for(\u0026amp;apos;home.homepage\u0026amp;apos;) }}\u0026quot;\u0026gt;Home\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;footer-menu-divider\u0026quot;\u0026gt;\u0026amp;#x22C5;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;#\u0026quot;\u0026gt;Register\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;footer-menu-divider\u0026quot;\u0026gt;\u0026amp;#x22C5;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;#\u0026quot;\u0026gt;Login\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;p class=\u0026quot;copyright text-muted small\u0026quot;\u0026gt;Copyright \u0026amp;#xA9; 2016. All Rights Reserved\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/footer\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  Note that we use # for the Register and Login links. We will update this when we are working on the auth blueprint.\nNext, create a home directory inside the app/templates directory. The homepage template, index.html, will go inside it:\n\u0026lt;!-- app/templates/home/index.html --\u0026gt; {% extends \u0026quot;base.html\u0026quot; %} {% block title %}Home{% endblock %} {% block body %} \u0026lt;div class=\u0026quot;intro-header\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;container\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col-lg-12\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;intro-message\u0026quot;\u0026gt; \u0026lt;h1\u0026gt;Project Dream Team\u0026lt;/h1\u0026gt; \u0026lt;h3\u0026gt;The best company in the world!\u0026lt;/h3\u0026gt; \u0026lt;hr class=\u0026quot;intro-divider\u0026quot;\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {% endblock %}  Inside the static directory, add css and img directories. Add the following CSS file, style.css, to your static/css directory (note that you will need a background image, intro-bg.jpg, as well as a favicon in your static/img directory):\n/* app/static/css/style.css */ body, html { width: 100%; height: 100%; } body, h1, h2, h3 { font-family: \u0026quot;Lato\u0026quot;, \u0026quot;Helvetica Neue\u0026quot;, Helvetica, Arial, sans-serif; font-weight: 700; } a, .navbar-default .navbar-brand, .navbar-default .navbar-nav\u0026gt;li\u0026gt;a { color: #aec251; } a:hover, .navbar-default .navbar-brand:hover, .navbar-default .navbar-nav\u0026gt;li\u0026gt;a:hover { color: #687430; } footer { padding: 50px 0; background-color: #f8f8f8; } p.copyright { margin: 15px 0 0; } .alert-info { width: 50%; margin: auto; color: #687430; background-color: #e6ecca; border-color: #aec251; } .btn-default { border-color: #aec251; color: #aec251; } .btn-default:hover { background-color: #aec251; } .center { margin: auto; width: 50%; padding: 10px; } .content-section { padding: 50px 0; border-top: 1px solid #e7e7e7; } .footer, .push { clear: both; height: 4em; } .intro-divider { width: 400px; border-top: 1px solid #f8f8f8; border-bottom: 1px solid rgba(0,0,0,0.2); } .intro-header { padding-top: 50px; padding-bottom: 50px; text-align: center; color: #f8f8f8; background: url(../img/intro-bg.jpg) no-repeat center center; background-size: cover; height: 100%; } .intro-message { position: relative; padding-top: 20%; padding-bottom: 20%; } .intro-message \u0026gt; h1 { margin: 0; text-shadow: 2px 2px 3px rgba(0,0,0,0.6); font-size: 5em; } .intro-message \u0026gt; h3 { text-shadow: 2px 2px 3px rgba(0,0,0,0.6); } .lead { font-size: 18px; font-weight: 400; } .topnav { font-size: 14px; } .wrapper { min-height: 100%; height: auto !important; height: 100%; margin: 0 auto -4em; }  Run the app; you should be able to see the homepage now.\nAuth Blueprint For the auth blueprint, we’ll begin by creating the registration and login forms. We’ll use Flask-WTF, which will allow us to create forms that are secure (thanks to CSRF protection and reCAPTCHA support).\npip install Flask-WTF  Now to write the code for the forms:\n# app/auth/forms.py from flask_wtf import FlaskForm from wtforms import PasswordField, StringField, SubmitField, ValidationError from wtforms.validators import DataRequired, Email, EqualTo from ..models import Employee class RegistrationForm(FlaskForm): \u0026quot;\u0026quot;\u0026quot; Form for users to create new account \u0026quot;\u0026quot;\u0026quot; email = StringField(\u0026amp;apos;Email\u0026amp;apos;, validators=[DataRequired(), Email()]) username = StringField(\u0026amp;apos;Username\u0026amp;apos;, validators=[DataRequired()]) first_name = StringField(\u0026amp;apos;First Name\u0026amp;apos;, validators=[DataRequired()]) last_name = StringField(\u0026amp;apos;Last Name\u0026amp;apos;, validators=[DataRequired()]) password = PasswordField(\u0026amp;apos;Password\u0026amp;apos;, validators=[ DataRequired(), EqualTo(\u0026amp;apos;confirm_password\u0026amp;apos;) ]) confirm_password = PasswordField(\u0026amp;apos;Confirm Password\u0026amp;apos;) submit = SubmitField(\u0026amp;apos;Register\u0026amp;apos;) def validate_email(self, field): if Employee.query.filter_by(email=field.data).first(): raise ValidationError(\u0026amp;apos;Email is already in use.\u0026amp;apos;) def validate_username(self, field): if Employee.query.filter_by(username=field.data).first(): raise ValidationError(\u0026amp;apos;Username is already in use.\u0026amp;apos;) class LoginForm(FlaskForm): \u0026quot;\u0026quot;\u0026quot; Form for users to login \u0026quot;\u0026quot;\u0026quot; email = StringField(\u0026amp;apos;Email\u0026amp;apos;, validators=[DataRequired(), Email()]) password = PasswordField(\u0026amp;apos;Password\u0026amp;apos;, validators=[DataRequired()]) submit = SubmitField(\u0026amp;apos;Login\u0026amp;apos;)  Flask-WTF has a number of validators that make writing forms much easier. All the fields in the models have the DataRequired validator, which means that users will be required to fill all of them in order to register or login.\nFor the registration form, we require users to fill in their email address, username, first name, last name, and their password twice. We use the Email validator to ensure valid email formats are used (e.g some-name@some-domain.com.) We use the EqualTo validator to confirm that the password and confirm_password fields in the RegistrationForm match. We also create methods (validate_email and validate_username) to ensure that the email and username entered have not been used before.\nThe submit field in both forms will be represented as a button that users will be able to click to register and login respectively.\nWith the forms in place, we can write the views:\n# app/auth/views.py from flask import flash, redirect, render_template, url_for from flask_login import login_required, login_user, logout_user from . import auth from forms import LoginForm, RegistrationForm from .. import db from ..models import Employee @auth.route(\u0026amp;apos;/register\u0026amp;apos;, methods=[\u0026amp;apos;GET\u0026amp;apos;, \u0026amp;apos;POST\u0026amp;apos;]) def register(): \u0026quot;\u0026quot;\u0026quot; Handle requests to the /register route Add an employee to the database through the registration form \u0026quot;\u0026quot;\u0026quot; form = RegistrationForm() if form.validate_on_submit(): employee = Employee(email=form.email.data, username=form.username.data, first_name=form.first_name.data, last_name=form.last_name.data, password=form.password.data) # add employee to the database db.session.add(employee) db.session.commit() flash(\u0026amp;apos;You have successfully registered! You may now login.\u0026amp;apos;) # redirect to the login page return redirect(url_for(\u0026amp;apos;auth.login\u0026amp;apos;)) # load registration template return render_template(\u0026amp;apos;auth/register.html\u0026amp;apos;, form=form, title=\u0026amp;apos;Register\u0026amp;apos;) @auth.route(\u0026amp;apos;/login\u0026amp;apos;, methods=[\u0026amp;apos;GET\u0026amp;apos;, \u0026amp;apos;POST\u0026amp;apos;]) def login(): \u0026quot;\u0026quot;\u0026quot; Handle requests to the /login route Log an employee in through the login form \u0026quot;\u0026quot;\u0026quot; form = LoginForm() if form.validate_on_submit(): # check whether employee exists in the database and whether # the password entered matches the password in the database employee = Employee.query.filter_by(email=form.email.data).first() if employee is not None and employee.verify_password( form.password.data): # log employee in login_user(employee) # redirect to the dashboard page after login return redirect(url_for(\u0026amp;apos;home.dashboard\u0026amp;apos;)) # when login details are incorrect else: flash(\u0026amp;apos;Invalid email or password.\u0026amp;apos;) # load login template return render_template(\u0026amp;apos;auth/login.html\u0026amp;apos;, form=form, title=\u0026amp;apos;Login\u0026amp;apos;) @auth.route(\u0026amp;apos;/logout\u0026amp;apos;) @login_required def logout(): \u0026quot;\u0026quot;\u0026quot; Handle requests to the /logout route Log an employee out through the logout link \u0026quot;\u0026quot;\u0026quot; logout_user() flash(\u0026amp;apos;You have successfully been logged out.\u0026amp;apos;) # redirect to the login page return redirect(url_for(\u0026amp;apos;auth.login\u0026amp;apos;))  Just like in the home blueprint, each view here handles requests to the specified URL. The register view creates an instance of the Employee model class using the registration form data to populate the fields, and then adds it to the database. This esentially registers a new employee.\nThe login view queries the database to check whether an employee exists with an email address that matches the email provided in the login form data. It then uses the verify_password method to check that the password in the database for the employee matches the password provided in the login form data. If both of these are true, it proceeds to log the user in using the login_user method provided by Flask-Login.\nThe logout view has the login_required decorator, which means that a user must be logged in to access it. It calles the logout_user method provided by Flask-Login to log the user out.\nNote the use of flash method, which allows us to use Flask’s message flashing feature. This allows us to communicate feedback to the user, such as informing them of successful registration or unsuccessful login.\nFinally, let’s work on the templates. First, we’ll install Flask-Bootstrap so we can use its wtf and utils libraries. The wtf library will allow us to quickly generate forms in the templates based on the forms in the forms.py file. The utils library will allow us to display the flash messages we set earlier to give feedback to the user.\npip install flask-bootstrap  We need to edit the app/__init__.py file to use Flask-Bootstrap:\n# app/__init__.py # after existing third-party imports from flask_bootstrap import Bootstrap # existing code remains def create_app(config_name): # existing code remains Bootstrap(app) from app import models # blueprint registration remains here return app  We\u0026rsquo;ve made quite a number of edits to the app/__init__.py file. This is the final version of the file and how it should look at this point (note that I have re-arranged the imports and variables in alphabetical order):\n# app/__init__.py # third-party imports from flask import Flask from flask_bootstrap import Bootstrap from flask_login import LoginManager from flask_migrate import Migrate from flask_sqlalchemy import SQLAlchemy # local imports from config import app_config db = SQLAlchemy() login_manager = LoginManager() def create_app(config_name): app = Flask(__name__, instance_relative_config=True) app.config.from_object(app_config[config_name]) app.config.from_pyfile(\u0026amp;apos;config.py\u0026amp;apos;) Bootstrap(app) db.init_app(app) login_manager.init_app(app) login_manager.login_message = \u0026quot;You must be logged in to access this page.\u0026quot; login_manager.login_view = \u0026quot;auth.login\u0026quot; migrate = Migrate(app, db) from app import models from .admin import admin as admin_blueprint app.register_blueprint(admin_blueprint, url_prefix=\u0026amp;apos;/admin\u0026amp;apos;) from .auth import auth as auth_blueprint app.register_blueprint(auth_blueprint) from .home import home as home_blueprint app.register_blueprint(home_blueprint) return app  We need two templates for the auth blueprint: register.html and login.html, which we\u0026rsquo;ll create in an auth directory inside the templates directory.\n\u0026lt;!-- app/templates/auth/register.html --\u0026gt; {% import \u0026quot;bootstrap/wtf.html\u0026quot; as wtf %} {% extends \u0026quot;base.html\u0026quot; %} {% block title %}Register{% endblock %} {% block body %} \u0026lt;div class=\u0026quot;content-section\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;center\u0026quot;\u0026gt; \u0026lt;h1\u0026gt;Register for an account\u0026lt;/h1\u0026gt; \u0026lt;br/\u0026gt; {{ wtf.quick_form(form) }} \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {% endblock %} \u0026lt;!-- app/templates/auth/login.html --\u0026gt; {% import \u0026quot;bootstrap/utils.html\u0026quot; as utils %} {% import \u0026quot;bootstrap/wtf.html\u0026quot; as wtf %} {% extends \u0026quot;base.html\u0026quot; %} {% block title %}Login{% endblock %} {% block body %} \u0026lt;div class=\u0026quot;content-section\u0026quot;\u0026gt; \u0026lt;br/\u0026gt; {{ utils.flashed_messages() }} \u0026lt;br/\u0026gt; \u0026lt;div class=\u0026quot;center\u0026quot;\u0026gt; \u0026lt;h1\u0026gt;Login to your account\u0026lt;/h1\u0026gt; \u0026lt;br/\u0026gt; {{ wtf.quick_form(form) }} \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {% endblock %}  The forms are loaded from the app/auth/views.py file, where we specified which template files to display for each view. Remember the Register and Login links in the base template? Let\u0026rsquo;s update them now so we can access the pages from the menus:\n\u0026lt;!-- app/templates/base.html --\u0026gt; \u0026lt;!-- Modify nav bar menu --\u0026gt; \u0026lt;ul class=\u0026quot;nav navbar-nav navbar-right\u0026quot;\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;{{ url_for(\u0026amp;apos;home.homepage\u0026amp;apos;) }}\u0026quot;\u0026gt;Home\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;{{ url_for(\u0026amp;apos;auth.register\u0026amp;apos;) }}\u0026quot;\u0026gt;Register\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;{{ url_for(\u0026amp;apos;auth.login\u0026amp;apos;) }}\u0026quot;\u0026gt;Login\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;!-- Modify footer menu --\u0026gt; \u0026lt;ul class=\u0026quot;list-inline\u0026quot;\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;{{ url_for(\u0026amp;apos;home.homepage\u0026amp;apos;) }}\u0026quot;\u0026gt;Home\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;footer-menu-divider\u0026quot;\u0026gt;\u0026amp;#x22C5;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;{{ url_for(\u0026amp;apos;auth.register\u0026amp;apos;) }}\u0026quot;\u0026gt;Register\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;footer-menu-divider\u0026quot;\u0026gt;\u0026amp;#x22C5;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;{{ url_for(\u0026amp;apos;auth.login\u0026amp;apos;) }}\u0026quot;\u0026gt;Login\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt;  Run the app again and click on the Register and Login menu links. You should see the templates loaded with the appropriate form.\nTry to fill out the registration form; you should be able to register a new employee. After registration, you should be redirected to the login page, where you will see the flash message we configured in the app/auth/views.py file, inviting you to login.\nLogging in should be successful; however you should get a Template Not Found error after logging in, because the dashboard.html template has not been created yet. Let\u0026rsquo;s do that now:\n\u0026lt;!-- app/templates/home/dashboard.html --\u0026gt; {% extends \u0026quot;base.html\u0026quot; %} {% block title %}Dashboard{% endblock %} {% block body %} \u0026lt;div class=\u0026quot;intro-header\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;container\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col-lg-12\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;intro-message\u0026quot;\u0026gt; \u0026lt;h1\u0026gt;The Dashboard\u0026lt;/h1\u0026gt; \u0026lt;h3\u0026gt;We made it here!\u0026lt;/h3\u0026gt; \u0026lt;hr class=\u0026quot;intro-divider\u0026quot;\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {% endblock %}  Refresh the page. You\u0026rsquo;ll notice that the navigation menu still has the register and login links, even though we are already logged in. We\u0026rsquo;ll need to modify it to show a logout link when a user is already authenticated. We will also include a Hi, username! message in the nav bar:\n\u0026lt;!-- app/templates/base.html --\u0026gt; \u0026lt;!-- In the head tag, include link to Font Awesome CSS so we can use icons --\u0026gt; \u0026lt;link href=\u0026quot;https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css\u0026quot; rel=\u0026quot;stylesheet\u0026quot;\u0026gt; \u0026lt;!-- Modify nav bar menu --\u0026gt; \u0026lt;ul class=\u0026quot;nav navbar-nav navbar-right\u0026quot;\u0026gt; {% if current_user.is_authenticated %} \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;{{ url_for(\u0026amp;apos;home.dashboard\u0026amp;apos;) }}\u0026quot;\u0026gt;Dashboard\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;{{ url_for(\u0026amp;apos;auth.logout\u0026amp;apos;) }}\u0026quot;\u0026gt;Logout\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a\u0026gt;\u0026lt;i class=\u0026quot;fa fa-user\u0026quot;\u0026gt;\u0026lt;/i\u0026gt; Hi, {{ current_user.username }}!\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; {% else %} \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;{{ url_for(\u0026amp;apos;home.homepage\u0026amp;apos;) }}\u0026quot;\u0026gt;Home\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;{{ url_for(\u0026amp;apos;auth.register\u0026amp;apos;) }}\u0026quot;\u0026gt;Register\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;{{ url_for(\u0026amp;apos;auth.login\u0026amp;apos;) }}\u0026quot;\u0026gt;Login\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; {% endif %} \u0026lt;/ul\u0026gt; \u0026lt;!-- Modify footer menu --\u0026gt; \u0026lt;ul class=\u0026quot;list-inline\u0026quot;\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;{{ url_for(\u0026amp;apos;home.homepage\u0026amp;apos;) }}\u0026quot;\u0026gt;Home\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;footer-menu-divider\u0026quot;\u0026gt;\u0026amp;#x22C5;\u0026lt;/li\u0026gt; {% if current_user.is_authenticated %} \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;{{ url_for(\u0026amp;apos;auth.logout\u0026amp;apos;) }}\u0026quot;\u0026gt;Logout\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; {% else %} \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;{{ url_for(\u0026amp;apos;auth.register\u0026amp;apos;) }}\u0026quot;\u0026gt;Register\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;footer-menu-divider\u0026quot;\u0026gt;\u0026amp;#x22C5;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;{{ url_for(\u0026amp;apos;auth.login\u0026amp;apos;) }}\u0026quot;\u0026gt;Login\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; {% endif %} \u0026lt;/ul\u0026gt;  Note how we use if-else statements in the templates. Also, take note of the current_user proxy provided by Flask-Login, which allows us to check whether the user is authenticated and to get the user\u0026rsquo;s username.\nLogging out will take you back to the login page:\nAttempting to access the dashboard page without logging in will redirect you to the login page and display the message we set in the app/__init__.py file:\nNotice that the URL is configured such that once you log in, you will be redirected to the page you initially attempted to access, which in this case is the dashboard.\nConclusion That\u0026rsquo;s it for Part One! We\u0026rsquo;ve covered quite a lot: setting up a MySQL database, creating models, migrating the database, and handling registration, login, and logout. Good job for making it this far!\nWatch this space for Part Two, which will cover the CRUD functionality of the app, allowing admin users to add, list, edit, and delete departments and roles, as well as assign them to employees.\n Source : .\n "});index.add({'id':21,'href':'/library/tutorials/docs/python/flask/primer-jinja-templating/','title':"Primer on Jinja Templating",'content':" Primer on Jinja Templating Flask comes packaged with the powerful Jinja templating language.\nFor those who have not been exposed to a templating language before, such languages essentially contain variables as well as some programming logic, which when evaluated (or rendered into HTML) are replaced with actual values.\nThe variables and/or logic are placed between tags or delimiters. For example, Jinja templates use {% ... %} for expressions or logic (like for loops), while {{ ... }} is used for outputting the results of an expression or a variable to the end user. The latter tag, when rendered, is replaced with a value or values, and is seen by the end user.\nNote: Jinja Templates are just .html files. By convention, they live in the /templates directory in a Flask project. If you’re familiar with string formatting or interpolation, templating languages follow a similar type of logic—just on the scale of an entire HTML page.\nFree Bonus: Click here to get access to a free Jinja Templating Resources Guide (PDF) that shows you tips and tricks as well as common pitfalls to avoid when working with the Jinja 2 templating language.\nRemove ads\nQuick Examples Make sure you have Jinja installed before running these examples (pip install jinja2):\nfrom jinja2 import Template t = Template(\u0026quot;Hello {{ something }}!\u0026quot;) t.render(something=\u0026quot;World\u0026quot;)  Hello World!\u0026rsquo;\nt = Template(\u0026quot;My favorite numbers: {% for n in range(1,10) %}{{n}} \u0026quot; \u0026quot;{% endfor %}\u0026quot;) t.render() # My favorite numbers: 1 2 3 4 5 6 7 8 9 '  Notice how the actual output rendered to the user falls within the tags.\nFlask Examples The code can be found here.\nCreate the following project structure:\n├── requirements.txt ├── run.py └── templates  Activate a virtualenv, then install flask:\n$ pip install flask  Add the following code to run.py:\nfrom flask import Flask, render_template app = Flask(__name__) @app.route(\u0026quot;/\u0026quot;) def template_test(): return render_template('template.html', my_string=\u0026quot;Wheeeee!\u0026quot;, my_list=[0,1,2,3,4,5]) if __name__ == '__main__': app.run(debug=True)  Here, we are establishing the route /, which renders the template template.html via the function render_template(). This function must have a template name. Optionally, you can pass in keyword arguments to the template, like in the example with my_string and my_list.\nAdd the template:\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Flask Template Example\u0026lt;/title\u0026gt; \u0026lt;meta name=\u0026quot;viewport\u0026quot; content=\u0026quot;width=device-width, initial-scale=1.0\u0026quot;\u0026gt; \u0026lt;link href=\u0026quot;http://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.min.css\u0026quot; rel=\u0026quot;stylesheet\u0026quot; media=\u0026quot;screen\u0026quot;\u0026gt; \u0026lt;style type=\u0026quot;text/css\u0026quot;\u0026gt; .container { max-width: 500px; padding-top: 100px; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div class=\u0026quot;container\u0026quot;\u0026gt; \u0026lt;p\u0026gt;My string: {{my_string}}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;Value from the list: {{my_list[3]}}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;Loop through the list:\u0026lt;/p\u0026gt; \u0026lt;ul\u0026gt; {% for n in my_list %} \u0026lt;li\u0026gt;{{n}}\u0026lt;/li\u0026gt; {% endfor %} \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;script src=\u0026quot;http://code.jquery.com/jquery-1.10.2.min.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026quot;http://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  Save this as template.html in the templates directory. Notice the template tags. Can you guess the output before you run the app?\nRun the following:\n$ python run.py  You should see the following:\n\nNote: It’s worth noting that Jinja only supports a few control structures: if-statements and for-loops are the two primary structures.\nThe syntax is similar to Python, differing in that no colon is required and that termination of the block is done using an endif or endfor instead of whitespace.\nYou can also complete the logic within your controller or views and then pass each value to the template using the template tags. However, it is much easier to perform such logic within the templates themselves.\nTemplate Inheritance Templates usually take advantage of inheritance, which includes a single base template that defines the basic structure of all subsequent child templates. You use the tags {% extends %} and {% block %} to implement inheritance.\nThe use case for this is simple: as your application grows, and you continue adding new templates, you will need to keep common code (like an HTML navigation bar, Javascript libraries, CSS stylesheets, and so forth) in sync, which can be a lot of work. Using inheritance, we can move those common pieces to a parent/base template so that we can create or edit such code once, and all child templates will inherent that code.\nNote: You should always add as much recurring code as possible to your base template to save yourself time in the future, which will far outweigh the initial time investment.\nLet’s add inheritance to our example.\nCreate the base (or parent) template:\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Flask Template Example\u0026lt;/title\u0026gt; \u0026lt;meta name=\u0026quot;viewport\u0026quot; content=\u0026quot;width=device-width, initial-scale=1.0\u0026quot;\u0026gt; \u0026lt;link href=\u0026quot;http://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.min.css\u0026quot; rel=\u0026quot;stylesheet\u0026quot; media=\u0026quot;screen\u0026quot;\u0026gt; \u0026lt;style type=\u0026quot;text/css\u0026quot;\u0026gt; .container { max-width: 500px; padding-top: 100px; } h2 {color: red;} \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div class=\u0026quot;container\u0026quot;\u0026gt; \u0026lt;h2\u0026gt;This is part of my base template\u0026lt;/h2\u0026gt; \u0026lt;br\u0026gt; {% block content %}{% endblock %} \u0026lt;br\u0026gt; \u0026lt;h2\u0026gt;This is part of my base template\u0026lt;/h2\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;script src=\u0026quot;http://code.jquery.com/jquery-1.10.2.min.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026quot;http://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  Save this as layout.html.\nDid you notice the {% block %} tags? This defines a block (or area) that child templates can fill in. Further, this just informs the templating engine that a child template may override the block of the template.\nNote: Think of these as placeholders to be filled in by code from the child template(s).\nLet’s do that.\nUpdate template.html:\n{% extends \u0026quot;layout.html\u0026quot; %} {% block content %} \u0026lt;h3\u0026gt; This is the start of my child template\u0026lt;/h3\u0026gt; \u0026lt;br\u0026gt; \u0026lt;p\u0026gt;My string: {{my_string}}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;Value from the list: {{my_list[3]}}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;Loop through the list:\u0026lt;/p\u0026gt; \u0026lt;ul\u0026gt; {% for n in my_list %} \u0026lt;li\u0026gt;{{n}}\u0026lt;/li\u0026gt; {% endfor %} \u0026lt;/ul\u0026gt; \u0026lt;h3\u0026gt; This is the end of my child template\u0026lt;/h3\u0026gt; {% endblock %}  So, the {% extends %} informs the templating engine that this template “extends” another template, layout.html. This establishes the link between the templates.\nRun it. You should see this:\n\nOne common use case is to add a navigation bar.\nAdd the following code to the base template, just after the opening \u0026lt;body\u0026gt; tag:\n\u0026lt;nav class=\u0026quot;navbar navbar-inverse\u0026quot; role=\u0026quot;navigation\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;container-fluid\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;navbar-header\u0026quot;\u0026gt; \u0026lt;button type=\u0026quot;button\u0026quot; class=\u0026quot;navbar-toggle\u0026quot; data-toggle=\u0026quot;collapse\u0026quot; data-target=\u0026quot;#bs-example-navbar-collapse-1\u0026quot;\u0026gt; \u0026lt;span class=\u0026quot;sr-only\u0026quot;\u0026gt;Toggle navigation\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;icon-bar\u0026quot;\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;icon-bar\u0026quot;\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;icon-bar\u0026quot;\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;/button\u0026gt; \u0026lt;a class=\u0026quot;navbar-brand\u0026quot; href=\u0026quot;/\u0026quot;\u0026gt;Jinja!\u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;collapse navbar-collapse\u0026quot; id=\u0026quot;bs-example-navbar-collapse-1\u0026quot;\u0026gt; \u0026lt;ul class=\u0026quot;nav navbar-nav\u0026quot;\u0026gt; \u0026lt;li class=\u0026quot;active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;#\u0026quot;\u0026gt;Link\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;#\u0026quot;\u0026gt;Link\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;form class=\u0026quot;navbar-form navbar-left\u0026quot; role=\u0026quot;search\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;form-group\u0026quot;\u0026gt; \u0026lt;input type=\u0026quot;text\u0026quot; class=\u0026quot;form-control\u0026quot; placeholder=\u0026quot;Search\u0026quot;\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;button type=\u0026quot;submit\u0026quot; class=\u0026quot;btn btn-default\u0026quot;\u0026gt;Submit\u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;ul class=\u0026quot;nav navbar-nav navbar-right\u0026quot;\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;#\u0026quot;\u0026gt;Link\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;dropdown\u0026quot;\u0026gt; \u0026lt;a href=\u0026quot;#\u0026quot; class=\u0026quot;dropdown-toggle\u0026quot; data-toggle=\u0026quot;dropdown\u0026quot;\u0026gt;Dropdown \u0026lt;b class=\u0026quot;caret\u0026quot;\u0026gt;\u0026lt;/b\u0026gt;\u0026lt;/a\u0026gt; \u0026lt;ul class=\u0026quot;dropdown-menu\u0026quot;\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;#\u0026quot;\u0026gt;Action\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;#\u0026quot;\u0026gt;Another action\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;#\u0026quot;\u0026gt;Something else here\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;divider\u0026quot;\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;#\u0026quot;\u0026gt;Separated link\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt;\u0026lt;!-- /.navbar-collapse --\u0026gt; \u0026lt;/div\u0026gt;\u0026lt;!-- /.container-fluid --\u0026gt; \u0026lt;/nav\u0026gt;  Now, every single child template that extends from the base will have the same navigation bar. To steal a line from Java philosophy: “Write once, use anywhere.”\n\nSuper Blocks If you need to render a block from the base template, use a super block:\n{{ super() }}  Add a footer to the base template:\n\u0026lt;div class=\u0026quot;footer\u0026quot;\u0026gt; {% block footer %} Watch! This will be added to my base and child templates using the super powerful super block! \u0026lt;br\u0026gt; \u0026lt;br\u0026gt; {% endblock %} \u0026lt;/div\u0026gt;  Here’s the updated code:\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Flask Template Example\u0026lt;/title\u0026gt; \u0026lt;meta name=\u0026quot;viewport\u0026quot; content=\u0026quot;width=device-width, initial-scale=1.0\u0026quot;\u0026gt; \u0026lt;link href=\u0026quot;http://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.min.css\u0026quot; rel=\u0026quot;stylesheet\u0026quot; media=\u0026quot;screen\u0026quot;\u0026gt; \u0026lt;style type=\u0026quot;text/css\u0026quot;\u0026gt; .container { max-width: 500px; padding-top: 100px; } h2 {color: red;} \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div class=\u0026quot;container\u0026quot;\u0026gt; \u0026lt;h2\u0026gt;This is part of my base template\u0026lt;/h2\u0026gt; \u0026lt;br\u0026gt; {% block content %}{% endblock %} \u0026lt;br\u0026gt; \u0026lt;h2\u0026gt;This is part of my base template\u0026lt;/h2\u0026gt; \u0026lt;br\u0026gt; \u0026lt;div class=\u0026quot;footer\u0026quot;\u0026gt; {% block footer %} Watch! This will be added to my base and child templates using the super powerful super block! \u0026lt;br\u0026gt; \u0026lt;br\u0026gt; \u0026lt;br\u0026gt; {% endblock %} \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;script src=\u0026quot;http://code.jquery.com/jquery-1.10.2.min.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026quot;http://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  Run the app. You should see that the footer is just part of the base:\n\nNow, add the super block to template.html:\n{% extends \u0026quot;layout.html\u0026quot; %} {% block content %} \u0026lt;h3\u0026gt; This is the start of my child template\u0026lt;/h3\u0026gt; \u0026lt;br\u0026gt; \u0026lt;p\u0026gt;My string: {{my_string}}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;Value from the list: {{my_list[3]}}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;Loop through the list:\u0026lt;/p\u0026gt; \u0026lt;ul\u0026gt; {% for n in my_list %} \u0026lt;li\u0026gt;{{n}}\u0026lt;/li\u0026gt; {% endfor %} \u0026lt;/ul\u0026gt; \u0026lt;h3\u0026gt; This is the end of my child template\u0026lt;/h3\u0026gt; {% block footer %} {{super()}} {% endblock %} {% endblock %}  Check it out in your browser:\n\nThe super block is used for common code that both the parent and child templates share, such as the \u0026lt;title\u0026gt;, where both templates share part of the title. Then, you would just need to pass in the other part. It could also be used for a heading.\nHere’s an example:\nParent\n{% block heading %} \u0026lt;h1\u0026gt;{% block page %}{% endblock %} - Flask Super Example\u0026lt;/h1\u0026gt; {% endblock %} **Child** {% block page %}Home{% endblock %} {% block heading %} {{ super() }} {% endblock %}  Let’s see that in action:\n\nSee what happens when you remove {% block page %}Home{% endblock %} from the child template.\nChallenge: Try to update the \u0026lt;title\u0026gt; using the same method with the super block. Check out my code if you need help.\nInstead of hard coding the name of the template, let’s make it dynamic.\nUpdate the two code snippets in template.html:\n{% block title %}{{title}}{% endblock %} {% block page %}{{title}}{% endblock %}  Now, we need to pass in a title variable to our template from our controller, run.py:\n@app.route(\u0026quot;/\u0026quot;) def template_test(): return render_template( 'template.html', my_string=\u0026quot;Wheeeee!\u0026quot;, my_list=[0,1,2,3,4,5], title=\u0026quot;Home\u0026quot;)  Macros In Jinja, we can use macros to abstract commonly used code snippets that are used over and over to not repeat ourselves. For example, it’s common to highlight the link of the current page on the navigation bar (active link). Otherwise, we’d have to use if/elif/else statements to determine the active link. Using macros, we can abstract out such code into a separate file.\nAdd a macros.html file to the templates directory:\n{% macro nav_link(endpoint, name) %} {% if request.endpoint.endswith(endpoint) %} \u0026lt;li class=\u0026quot;active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;{{ url_for(endpoint) }}\u0026quot;\u0026gt;{{name}}\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; {% else %} \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;{{ url_for(endpoint) }}\u0026quot;\u0026gt;{{name}}\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; {% endif %} {% endmacro %}  Here, we’re using Flask’s request object, which is part of Jinja by default, to check the requested endpoint, and then assigning the active class to that endpoint.\nUpdate the unordered list with the nav navbar-nav class in the base template:\n\u0026lt;ul class=\u0026quot;nav navbar-nav\u0026quot;\u0026gt; {{ nav_link('home', 'Home') }} {{ nav_link('about', 'About') }} {{ nav_link('contact', 'Contact Us') }} \u0026lt;/ul\u0026gt;  Also, make sure to add the import at the top of the template: {% from \u0026quot;macros.html\u0026quot; import nav_link with context %}.\nNotice how we’re calling the nav-link macro and passing it two arguments: the endpoint (which comes from our controller) and the text we want displayed.\nFinally, let’s add three new endpoints to the controller:\n@app.route(\u0026quot;/home\u0026quot;) def home(): return render_template( 'template.html', my_string=\u0026quot;Wheeeee!\u0026quot;, my_list=[0,1,2,3,4,5], title=\u0026quot;Home\u0026quot;) @app.route(\u0026quot;/about\u0026quot;) def about(): return render_template( 'template.html', my_string=\u0026quot;Wheeeee!\u0026quot;, my_list=[0,1,2,3,4,5], title=\u0026quot;About\u0026quot;) @app.route(\u0026quot;/contact\u0026quot;) def contact(): return render_template( 'template.html', my_string=\u0026quot;Wheeeee!\u0026quot;, my_list=[0,1,2,3,4,5], title=\u0026quot;Contact Us\u0026quot;)  Refresh the page. Test out the links at the top. Does the current page get highlighted? It should.\n\nCustom Filters Jinja uses filters to modify variables, mostly for formatting purposes.\nHere’s an example:\n{{ num | round }}\nThis will round the num variable. So, if we pass the argument num=46.99 into the template, then 47.0 will be outputted.\nAs you can tell, you specify the variable and then a pipe (|), followed by the filter. Check out this link for the list of filters already included within Jinja. In some cases, you can specify optional arguments in parentheses.\nHere’s an example:\n{{ list|join(', ') }} This will join a list by the comma delimiter. Test this out. Add the following line to _template.html_ \u0026lt;p\u0026gt;Same list with a filter: {{ my_list|join(', ') }}\u0026lt;/p\u0026gt;  Now, besides the built-in filters, we can create our own.\nLet’s add one of our own. One common example is a custom datetime filter.\nAdd the following code to our controller after we create the app, app = Flask(__name__):\n@app.template_filter() def datetimefilter(value, format='%Y/%m/%d %H:%M'): \u0026quot;\u0026quot;\u0026quot;Convert a datetime to a different format.\u0026quot;\u0026quot;\u0026quot; return value.strftime(format) app.jinja_env.filters['datetimefilter'] = datetimefilter  Using the @app.template_filter() decorator, we are registering the datetimefilter() function as a filter.\nNote: The default name for the filter is just the name of the function. However, you can customize it by passing in an argument to the function, such as @app.template_filter(formatdate).\nNext, we are adding the filter to the Jinja environment, making it accessible. Now it’s ready for use.\nAdd the following code to our child template:\n\u0026lt;h4\u0026gt;Current date/time: {{ current_time | datetimefilter }}\u0026lt;/h4\u0026gt;  Finally, just pass in the datetime to our template:\ncurrent_time = datetime.datetime.now()\nTest it.\n\nRef : https://realpython.com/primer-on-jinja-templating/\n"});index.add({'id':22,'href':'/library/tutorials/docs/articles/webapp/javascript/create-progressive-web-app/','title':"Progressive Web App คืออะไร",'content':" Progressive Web App คืออะไร และ มาลองกันแบบง่ายๆ วันเดียวเสร็จ ฮัลโหลๆ สวัสดีครับ ช่วงนี้หายไปนาน แอบไปศึกษา Front-end framework อยู่หลายตัว จนไปเจอกับของเล่นใหม่เรียกว่า Progressive Web App หรือเรียกสั้นๆว่า PWA นั่นเอง ซึ่งประจวบเหมาะกับทาง Google ผู้ผลักดันเทคโนโลยีนี้ก็ได้มา Roadshow แสดงความเทพที่กรุงเทพกันไปหยกๆ ก็เลยถือโอกาสใช้พลังความมั่วส่วนตัว ขอมาเขียนเรื่องนี้ ดีไม่ดี ผิดพลาดตรงไหน ติชมได้เน่อ เริ่มกันเลย …\n บทความนี้เกิดจากเนื้อหาหลายๆส่วนจากทั้งในงาน Roadshow เอง รวมถึงการมั่วซั่วของผู้เขียนนะครับ ดู Reference ได้ท้ายบทความ\n หัวข้อในวันนี้  อะไรคือ PWA ทำไมต้อง PWA เบื้องหลังการทำงานของ PWA เป็นอย่างไร มาลองทำ PWA เล่นๆกันดู  อะไรคือ เจ้า Progressive Web App ? Source: http://www.letsnurture.com/blog/progressive-web-app-an-application-in-a-webpage.html\nเจ้านี่คือเทคโนโลยีที่จะทำให้เว็บของเราเนี่ย มีความใกล้เคียงกับ App ในมือถือมากขึ้น ทั้งความลื่นไหลในการใช้งาน, เข้าเมนูต่างๆอย่างง่ายดาย, การใช้งานเมื่ออยู่ใน Mode Offline, การทำ Push Notification ฯลฯ ในขณะเดียวกันก็เก็บข้อดีของเว็บไว้อาทิเช่น ความสดใหม่ของข้อมูล(อัพเดทกันได้ทันที ไม่ต้องไปอัพ App Store), ความเข้าถึงง่ายไม่ต้อง Install ให้ยุ่งยาก\nแหม่ ดีอย่างงี้ จะให้อธิบายก็ไม่สู้ลองเล่นดูเอง ใครใช้ Android ขอให้หยิบมาถือขึ้นมาแล้วเข้าไปที่ aliexpress.com กันเลยครับ\nวิธีลงเจ้า PWA นี่ก็ง่ายๆ แค่อยู่ในหน้าเว็บแล้วกด Add To Home Screen….\nเรียบร้อย! ท่านได้ลง Progressive Web App ลงเครื่องของท่านแล้วครับ\nทีนี้พอเราลองไปที่หน้า Homescreen ก็จะพบว่ามี Icon ของ Aliexpress สีแดงๆอยู่ ให้ท่านผู้อ่านลองกดเข้าไปปุ้ป ก็จะเห็นหน้า Splash Screen เก๋ๆ เป็นรูปโลโก้ App และ Background สีแดงฉาน เต็มจอ เก๋ๆ ตรงนี้เราก็จะเข้า App มาละครับ สังเกตว่าจะเป็น Feeling แบบ App ที่เราใช้กันเลย ไม่มี Address Bar ให้ยุ่งยาก รวมถึงสามารถกด Hamburger เมนูหรือไอ้เจ้าขีดสามขีดตรงซ้ายบน ให้โชว์เมนูออกมาได้อย่างสวยงาม\nAliexpress.com\nถ้าคิดว่าหมดแค่นี้… ให้ทุกท่านลองปิดอินเตอร์เน็ตในมือถือดู แล้วเข้า App อีกทีครับผม… แต่น แต๊นนน สังเกตได้ว่าแอพยังทำงานได้ เมนูต่างๆยังอยู่ครบ เลยใช่ไหมครับ\nนี่แหล่ะครับ PWA ที่เราจะพูดถึงกันในวันนี้ ซึ่งเรียกได้ว่าเป็นความพยายามแก้ปัญหา Post-App Era จากฝั่งค่าย​ Google นั่นเอง\nทำไมต้อง PWA ? (Post-App Era กับความพยายามของ Google) Section นี้ขอสรุปในแบบของผมจาก Keynote ในงานวัน Progressive Web App Roadshow ที่กรุงเทพนะครับ\nSource: Progressive Web App Roadshow 2016\nเรื่องมันมีอยู่ว่า จากการวิจัยของ comScore Mobile Metrix พบว่าในปัจจุบัน ค่าเฉลี่ยของการโหลดแอพใหม่ลงมือถือต่อเดือนมันอยู่ที่ 0 แล้วจริงๆ ลองคิดง่ายๆครับว่าในมือถือที่เราใช้กันอยู่ เดือนๆนึงโหลดอะไรมาเพิ่มบ้าง รวมถึงใช้กันจริงๆ ทุกวันเนี่ยกี่แอพกัน (ในงานวิจัยบอกว่า 80% ของเวลาที่ใช้มือถือ ใช้อยู่แค่ 3 แอพหลักๆ เท่านั้นเอง)\nในขณะที่มาดูข้อมูลการใช้งานเว็บไซต์ พบว่าผู้ใช้มือถือในหนึ่งเดือน เข้าเว็บไซต์ต่างๆกว่า 100 เว็บไซต์ Google เลยบอกว่าปล่อยไว้อย่างงี้ไม่ได้ละ จึงปิ๊งไอเดีย จะมายกเครื่องเว็บไซต์ของเรากัน ภายใต้แนวคิด…\nSource: Progressive Web App Roadshow 2016\n Reliable - ไม่ใช่กดเปิด App ขึ้นมาแล้วเจอ Downasaur (ชื่อเล่นของตัวไดโนเสาร์ ที่เรามักเจอใน Chrome เวลาเน็ตขัดข้อง) ต้องทำงานได้แม้ในโหมด Offline Fast - มีงานวิจัยออกมาว่า Users กว่า 53% ถอดใจที่จะเข้าเว็บ หากเว็บใช้เวลาโหลดเกิน 3 วินาที ดังนั้นต้องทำไงก็ได้ ให้กดปุ้ปติดปั้ป พร้อมใช้งาน Engaging-แบ่งออกเป็น 3 หัวข้อย่อยๆ ได้แก่\n3.1) Homescreen เข้าถึงง่าย สามารถกด Icon App ได้จาก Home screen\n3.2) Immersive นักพัฒนาสามารถควบคุม Experience ของ User กำหนด รูปแบบหน้าตาของ App ว่าจะมี Address Bar ไหม เอาแนวตั้งแนวนอนได้\n3.3) Notification อันนี้หล่อ คือสามารถ Push Notification ให้ User ได้แบบ App เลยนั่นเอง  เบื้องหลังการทำงานของ PWA ในการทำให้เว็บของเราเป็น PWA นั้น ผมขอแบ่งพระเอกออกเป็น 2 คนหลักๆครับคือ ServiceWorker กับ Manifest.json\n ServiceWorker  Source: Progressive Web App Roadshow 2016\nServiceWorker หรือ SW เอาง่ายๆคือไฟล์ Cilent-side proxy ที่เราเขียนขึ้นมาด้วย JavaScript นี่แหล่ะครับ พอ Users เข้ามาเว็บเรา เราก็จะทำการ Install เจ้า SW นี่ลงไปในเครื่องของ User คนนั้นๆ\nหน้าที่ของ SW ก็คือ กำหนดให้ Cache สิ่งต่างๆที่เราจำเป็นในเว็บของเราไว้ ซึ่งเราก็กำหนดได้ว่าจะให้ Cache ส่วนไหน ไม่ Cache ส่วนไหน\nSource: https://developers.google.com/web/fundamentals/getting-started/codelabs/your-first-pwapp/\nง่ายๆ ให้ลองมองเป็น App ครับ เราอาจจะบอกให้ SW แคช Header, ปุ่มต่างๆ ของเราไว้ เพื่อให้ครั้งต่อไปที่เข้าเว็บไม่ต้องเสียเวลามานั่งโหลดเจ้า Element เหล่านั้นใหม่ แต่ในส่วนเนื้อหาเนี่ยให้ไม่ต้องแคช ให้ดึงออกมาใหม่ทุกครั้ง หรือจะบอกให้ใช้ Strategy ต่างๆเช่น Cache Then Network คือ เข้าเว็บมาให้ดึงเนื้อหาจาก Cache ที่เก็บไว้ก่อน พอ Network โหลดเสร็จค่อยเอาเนื้อหาใหม่มา Re render เข้าไปอีกที\nซึ่งเจ้าตัวนี้ก็จะทำให้เว็บไซต์ของเราทำงานเร็วขึ้นปรู๊ดปร๊าด ผิดหูผิดตา รวมถึงสามารถทำงานในโหมด Offline ได้ด้วย เนื่องจากเรา Browser สามารถไปดึง Element บางส่วนที่เรากำหนดไว้จาก Cache มาใช้งานได้เลย (ลองเล่นตัวนี้ดูครับ https://airhorner.com/ ทำงานได้ Offline เต็มรูปแบบเลย)\nSource: Progressive Web App Roadshow 2016\nไม่หมดเพียงแค่นั้นครับ อีกหนึ่งหน้าที่ที่สำคัญมากๆ ของ SW คือการทำ Push Notification นั่นเอง เนื่องจากเจ้า SW เนี่ยแม้เราทำการปิด Browser ของเราไปแล้ว แต่ OS ก็สามารถทำการปลุก SW ออกมาทำงานได้ ซึ่งก็ทำให้เราสามารถเขียน Code เพื่อรับ Message ที่ส่งมาได้\n2. Manifest.json\nSource: https://addyosmani.com/blog/getting-started-with-progressive-web-apps/\nเจ้าตัวนี้เป็นไฟล์ JSON เล็กๆที่เราใส่เข้าไปใน head ของ html ครับ หน้าที่ของมันมีมากมายอาทิเช่น\n ทำให้เว็บของเรามี Icon สวยๆบน หน้า Home screen เมื่อ Users กด Add to homescreen เว็บของเรา สามารถเปิดเว็บแบบ Full screen mode ไม่มี Address bar เมื่อ Users กดเข้ามาจากหน้า Homescreen ควบคุมมุมมองแนวตั้ง แนวนอน ของ Users ได้ ระบุ สี และ Icon ที่จะใช้มาประกอบเป็น Splash screen (หน้าจอ ตอนกดแอพขึ้นมา ลองดูรูปข้างบนครับ อันขวาสุด)  สำคัญอีกเรื่องเกือบลืมคือเว็บไซต์ของคุณจะใช้งานพวก Service Worker ได้จำเป็นต้องมี HTTPS นะครับ เรียกได้ว่าจะให้พลังที่ยิ่งใหญ่ไปเล่นกับเครื่อง Users ได้ขนาดนั้น เราก็ต้องรับผิดชอบชีวิต ทรัพย์สินเขาให้เรียบร้อย ไม่ใช่โดนดักตีหัวระหว่างทางนะครับ (เดี๋ยวนี้มี Cloudflare, Firebase ให้ลองเล่นกันฟรีๆแล้วนะครับ ซึ่งทำให้เราไปลองทำ HTTPS กันแบบฟรีๆแล้วนะครับ)\nมาลองทำ PWA เล่นๆกันดู เอาหล่ะ ถึงเวลามาลองทำเล่นกันดูแล้ว ในส่วนนี้ผมจะขอเรียบเรียงมาจากCodeLab ในวันงาน PWA RoadShow ของทาง Google นะครับ ละก็จะมีเสริมเติมแต่งไปบ้างประปรายตามทาง\n ดาวน์โหลด Source Code, ติดตั้ง Web Server  ตอนนี้ให้ทุกคนไปโหลด Source Code เบื่องต้นมากันก่อนครับที่ https://github.com/googlecodelabs/your-first-pwapp/archive/master.zip ได้เลย เมื่อ Unzip ออกมาจะได้ your-first-pwapp-master ออกมา สำหรับวันนี้เราจะเริ่มกันที่โฟลเดอร์ work นะครับ เป็นไฟล์ตั้งต้นของเรา\nจากนั้นให้ทุกคนไปลง Web Server ให้เรียบร้อยก่อน Google ก็ให้ Tool ง่ายๆมา ลองเล่นได้ทาง https://chrome.google.com/webstore/detail/web-server-for-chrome/ofhbbkphhbklhfoeikjpcbhemlocgigb?hl=en\nSource: Progressive Web App Roadshow 2016\nพอรันขึ้นมาก็กด Choose Folder เลือกโฟลเดอร์ work ของเรา แล้วกด Web Server URL(s) เข้าไปดูกันได้เลยครับ\n2. มาดูโครงสร้าง App ของเรากันหน่อย\nสำหรับ App ตัวนี้ก็เป็น Single Page App ที่แสดงข้อมูลสภาพอากาศจาก API ของ yahoo แบบง่ายๆครับ โดยมีไฟล์ JavaScript หลักคือ app.js นั่นเอง (JavaScript Plainๆจริง document.querySelector ไม่เจอกันตั้งนาน 555) ซึ่งก็จะมีโครงสร้างหลักๆดังนี้\n[Object] app เป็น Object หลักที่เก็บข้อมูลสำคัญของ App นี้ เออเกือบลืม เขาใช้ Pattern JavaScript แบบนึงเรียกว่า IIFE (immediately-invoked function expression) นะครับ ซึ่งมันจะทำให้ตัวแปรหรือ Function ที่เราประกาศข้างในเนี่ยไม่ไปรบกวน Environment Context อื่นๆ (เห็นมีพี่ท่านนึงเขียน รายละเอียดไว้ ที่นี่ ครับ) ตรงนี้น่าศึกษาๆ\nListener สองตัว สำหรับปุ่ม Refresh กับ เพิ่มเมือง\n[Function] updateForecaseCard ฟังก์ชันที่ทำหน้าที่เอาข้อมูลที่ได้จาก API มาแสดงผลบน Card ครับ\n[Function] getForecast ฟังก์ชันที่ทำการดึงข้อมูลจาก API Endpoint ออกมา\n[Function] updateForecast ฟังก์ชันที่ทำการ Loop เช็คการ์ดต่างๆแล้วสั่ง getForecast เพื่ออัพเดทข้อมูลสภาพอากาศ\n[Object] initialWeatherForecast ข้อมูลเบื้องต้นที่เราจะใส่ไปหลอกๆ เป็นตัวตั้งต้นให้โปรแกรมแสดงผลออกมา\nทีนี้ขอให้ทุกท่านเริ่มโดยการ uncomment บรรทัดนี้ ในไฟล์ index.html\n\u0026lt;!--\u0026lt;script src=\u0026quot;scripts/app.js\u0026quot; async\u0026gt;\u0026lt;/script\u0026gt;--\u0026gt;  เพื่อรับพลังจาก app.js เข้ามา และ uncomment บรรทัดข้างล่างนี้ใน app.js ครับ\n// app.updateForecastCard(initialWeatherForecast);  ซึ่งจะเป็นการสั่งให้นำข้อมูลหลอกๆ ของเราเนี่ยไปอัพเดทบนการ์ดสภาพอากาศของเราทำให้การโหลดแอพขึ้นมาครั้งแรก Cilent ไม่ต้องเสียเวลาไปดึงข้อมูล API เอง\nตรงนี้ใน Production อาจจะทำการ Inject จาก Server ซึ่ง Base ตามตำแหน่งของ User ได้ครับ\nตอนนี้แอพเราควรจะมีหน้าตาเป็นแบบนี้แล้วครับ (ตรงลูกศรสีแดง เผื่อบางท่านยังไม่ทราบว่าไอ้ Chrome Dev Tool สามารถจำลองรูปแบบหน้าจอเป็นมือถือรุ่นดังๆ ต่างๆได้นะครับ ลองเล่นดูสนุกดีครับ)\n3. เก็บข้อมูลเมืองที่ Users ต้องการดูสภาพอากาศกัน\nทีนี้ พอ Users ลองเล่น App ของเราเพิ่มเมืองใหม่เข้ามา เราจะทำอย่างไรเพื่อ Save ข้อมูลของ Users คนนั้นไว้ ให้ครั้งต่อไป เมื่อเข้าเว็บมาก็แสดงเมืองที่เขาเลือกออกมาเลย\nให้เพื่อนๆ ลองเปิด Chrome Dev Tools ขึ้นมาแล้วเลือกไปที่ Tab Application ครับ จะพบว่ามีตัวเลือก Storage ให้เราเล่นมากมาย ง่ายสุดก็จะเป็น Local Storage ซึ่งเป็นวิธีการเก็บข้อมูลคล้ายๆ Cookies แต่เก็บได้มากกว่า พร้อมทั้งมี Browser ที่รองรับมากมายตั้งแต่ IE ยัน Opera\nแต่ทว่าปัญหาของ Local Storage คือ\n เก็บข้อมูลได้แค่แบบ String จะใช้ JSON ก็ทำการ parse, stringify เอา ทำงานแบบ Synchronous หรือ Blocking ทีละอันนั่นเอง ซึ่งอาจเป็นปัญหา Performance ได้ ไม่ทำงานแบบ Transactional กล่าวคือ Write ไปสองอันพร้อมกัน อาจจะ Overwrite กันได้ จนเดาไม่ออกเลยว่าข้อมูลมันจะออกอันไหนออกมา  ยุ่งไปถึงนักพัฒนาต้องทำ Storage ยุคใหม่ๆ เช่นIndexedDB,WebSQL ที่ทำงานได้แบบ Asynchronous, Transactional, รวมถึงสามารถเก้บ Data แบบต่างๆเช่น JSON ได้นั่นเอง\nเรื่องเหมือนจะจบดี แต่ปัญหาคือ Browser รุ่นเก่าๆ บางประเภทยังไม่ Support เจ้านี่เต็มรูปแบบ Google ก็เลยเสนอทางแก้มาคือให้เราใช้ localForage อันเป็น Library ที่ทำให้เราใช้งานเจ้า IndexedDB,WebSQL นี้ง่ายขึ้น รวมไปถึง Switch ไปใช้ localStorage ได้หาก Browser ของ User คนนั้นๆ ไม่ Support IndexedDB หรือ WebSQL\nวิธีการใช้ localForage แบบบ้านๆ ง่ายๆ เพื่อความรวดเร็ว ก็ไปโหลด localforage.min.js มาเก็บไว้เลยละกันครับ\nจากนั้นก็วาง เจ้านี่ในไฟล์ index.html เหนือบรรทัด script tag -\u0026gt; app.js เราได้เลยครับ\n\u0026lt;script type=\u0026quot;text/javascript\u0026quot; src=\u0026quot;scripts/localforage.min.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt;  กลับมาที่ app.js ขั้นตอนของเราจะเป็นงี้คือ ทุกครั้งที่ Users เพิ่มเมืองเข้ามา เราจะ Push Object เมืองของเราเนี่ยเข้าไปที่ Array ที่ชื่อว่า app.selectedCities จากนั้นเราจะเรียก Function ใหม่ที่เราสร้างขึ้น ขอเรียกมันว่า app.saveForage() ซึ่งจะเป็นฟังก์ชันจับเจ้า Array app.selectedCities เนี่ยยัดเข้าไปใน localForage ของเราอีกที\nมาสร้าง Function app.saveForage() กันก่อน ให้ทุกท่านหาบรรทัดที่ 199 จะเจออันนี้ครับ\n// TODO add saveSelectedCities function here  แล้วทำการใส่ Code ส่วนนี้เข้าไปข้างล่าง\napp.saveForage=function(){ localforage.setItem('selectedCities',app.selectedCities) .then(function(value){ console.log('Save data: '+value); }) .catch(function(error){ console.log('Saving data failed: '+error); }) }  จากนั้นให้ไปที่บรรทัดที่ 53 เราจะเจอ\n// TODO init the app.selectedCities array here // TODO push the selected city to the array and save here  ตรงนี้เราจะเช็ค app.selectedCities ก่อนว่ามีไหม ถ้าไม่มีก็สร้างเป็น Array มาซะ\nจากนั้นทำการ Push Object เมืองเข้าไปใน Array แล้วเซฟลง IndexedDB ซะ โดยการใส่ Code ชุดนี้ลงไปครับ\n// TODO init the app.selectedCities array here if (!app.selectedCities) { app.selectedCities = []; }  และ\n// TODO push the selected city to the array and save here app.selectedCities.push({key: key, label: label}); app.saveForage();  ต่อมาเราก็ต้องมีฟังก์ชันที่ Check ว่า Users คนนี้เคยเข้าเล่น App เราและเพิ่มเมืองเล่นไว้หรือยัง\nเลื่อนไปข้างล่าง ตรงที่เราทำการ Inject Data ไว้ในขั้นตอนที่สองครับ แถวๆนี้\n// TODO uncomment line below to test app with fake data app.updateForecastCard(initialWeatherForecast);// TODO add startup code here  ผมจะขออนุญาตเปลี่ยนเป็นฟังก์ชัน app.getForage เลยละกันครับตามนี้ (ลบเจ้า app.updateForecastCard(initialWeatherForecast) ออกไปเลย)\napp.getForage=function(){ localforage.getItem('selectedCities') .then(function(value){ console.log(value); if(value){ app.selectedCities=value; app.selectedCities.forEach(function(city){ app.getForecast(city.key,city.label); }) }else{ app.selectedCities = [{key: initialWeatherForecast.key, label: initialWeatherForecast.label}]; app.updateForecastCard(initialWeatherForecast); app.saveForage() } }) .catch(function(error){ console.log('Getting data failed: '+error); }) }app.getForage();  เจ้านี้ทำหน้าที่ไปดึงข้อมูลใน localForage ออกมาถ้าเจอ Item ที่มี key ว่า selectedCities ก็เอาข้อมูลออกมา getForecast แสดงผลบนแอพ ถ้าไม่เจอก็ทำการใช้ข้อมูล Inject ไปก่อนซะ\nมาถึงตรง แอพเราก็น่าจะเก็บข้อมูลของ Users ได้แล้วครับ ลองปิด Browser แล้วเปิดใหม่ ข้อมูลก็ควรจะยังอยู่ครบนะครับ\n4. ติดตั้ง Service Worker\nทีนี้มาถึงตาพระเอกคนแรกของเราละครับ เราจะทำการบอก app.js ของเราให้ทำการติดตั้ง Service Worker ลงบนเครื่องของ Users ให้เลื่อนลงไปล่างสุดจะเจอ\n// TODO add service worker code here\nให้เราทำการใส่ Code ส่วนนี้ลงไปครับ\nif ('serviceWorker' in navigator) { navigator.serviceWorker .register('./service-worker.js') .then(function() { console.log('Service Worker Registered'); }); }  เจ้านี่จะเป็นการบอกว่าถ้า Browser ของเรามี Support Service Worker ให้ทำการ Register service-worker.js ของเราซะ\nพอใส่เสร็จแล้วก็ให้เราทำการสร้างไฟล์ service-worker.js ขึ้นมาใหม่อันนึงใน Root Directory ที่เดียวกับ index.html ของเราครับ แล้วก็ใส่ code นี้เข้าไป\nvar cacheName = 'weatherPWA-step-6-1'; var filesToCache = [ '/', '/index.html', '/scripts/app.js', '/scripts/localforage.min.js', '/styles/inline.css', '/images/clear.png', '/images/cloudy-scattered-showers.png', '/images/cloudy.png', '/images/fog.png', '/images/ic_add_white_24px.svg', '/images/ic_refresh_white_24px.svg', '/images/partly-cloudy.png', '/images/rain.png', '/images/scattered-showers.png', '/images/sleet.png', '/images/snow.png', '/images/thunderstorm.png', '/images/wind.png' ];self.addEventListener('install', function(e) { console.log('[ServiceWorker] Install'); e.waitUntil( caches.open(cacheName).then(function(cache) { console.log('[ServiceWorker] Caching app shell'); return cache.addAll(filesToCache); }) ); });  ตรงนี้คือเราจะทำการ Install SW ลงไปเครื่องของ Users ครับ จากนั้นทำการเซฟไฟล์ Static ต่างๆที่เรากำหนดไว้ใน Array filesToCache เก็บลงไว้ใน Cache ของเครื่อง User\nเราจะทำการเปิด Cache ด้วย caches.open ซึ่งในส่วนของ cacheName จะต้องกำหนดไว้เพื่อให้เราสามารถอัพเดทเวอร์ชั่นของของไฟล์ต่างๆได้ เดี๋ยวจะไปดูต่อกันครับว่าทำงานอย่างไร\nจากนั้นจะทำการ Add ไฟล์ทั้งหมดลงใน Cache ด้วย cache.addAll นั่นเอง\ne.waitUntil เป็นตัวที่สั่งให้ Browser อย่าพึ่ง Terminate Service Worker ก่อนที่มันจะทำงานเสร็จ อ่านเพิ่มเติมเกี่ยวกับ Service Worker ได้ ที่นี่ ครับ\nหลังจากติดตั้งแล้ว เราจะทำบอกให้ Service Worker เช็ค Version ของ App เรากรณีที่มีการเปลี่ยนแปลงไฟล์ที่เรา Cache ไปนะครับ โดยเราใส่ Code นี้เพิ่มเข้าไปซึ่งจะทำงานทุกครั้งที่มีการเปิดใช้ App\nself.addEventListener('activate', function(e) { console.log('[ServiceWorker] Activate'); e.waitUntil( caches.keys().then(function(keyList) { return Promise.all(keyList.map(function(key) { if (key !== cacheName) { console.log('[ServiceWorker] Removing old cache', key); return caches.delete(key); } })); }) ); return self.clients.claim(); });  หลักการคือจะ Iterate key ของ cache แต่ละตัว ถ้ามันไม่ตรงกับ cacheName ที่เราตั้งไว้บนหัวไฟล์ก็จะทำการลบ cache เก่านั้นทิ้งไปครับผม ฉะนั้นเวลาเราอัพเดทเวอร์ชัน App ของเรา ก็อย่าลืมไปเปลี่ยน cacheName ด้วยนะครับ\nมาถึงตรงนี้ ตรวจงานกันหน่อย น่าจะเจอหน้าตา Cache Storage เป็นแบบนี้แล้วนะครับ\nต่อจากนี้เราจะทำการบอก Service Worker ว่า ในการ fetch data เพื่อดึงข้อมูลเนี่ย ถ้า fetch ไปที่ url ที่มีการ cache ไว้แล้ว ให้ดึงข้อมูลจาก cache ได้เลย ซึ่งจะทำให้เราไม่ต้องมาโหลดเจ้าตัว app shell นี้ใหม่กันทุกรอบครับ ใส่ code ด้านล่างต่อได้เลย\nself.addEventListener('fetch', function(e) { console.log('[ServiceWorker] Fetch', e.request.url); e.respondWith( caches.match(e.request).then(function(response) { return response || fetch(e.request); }) ); });  ทีนี้ใน Chrome Dev Tool ลองกดเป็น Offline mode แล้ว refresh ดูได้เลยครับ :)\nหมายเหตุ เวลาเราแก้ service-worker.js เพื่อให้ Browser ของเราอัพเดทเป็น SW Worker ใหม่ ลบ Cache ลบ IndexedDB ให้หมด ให้กดเข้าไปที่ Clear storage ใน Tab Application ของ Chrome Dev Tool ด้วยนะครับ เดี๋ยวจะงงกันหมด\n5.แคชข้อมูลสภาพอากาศ\nทีนี้เพื่อให้แอพของเราสามารถทำงานในโหมด Offline ได้เต็มรูปแบบ รวมถึงทำตัวให้เหมือน App มือถือที่เราใช้กัน ที่เปิดขึ้นมาแล้ว โชว์ Data เก่าๆจาก Cache ก่อนระหว่างรอโหลด Data ใหม่ขึ้นมา\nมาลุยกันเลยครับ ที่ service-worker.js เหมือนเดิม สร้างตัวแปรใหม่ขึ้นมา\nvar dataCacheName = 'weatherData-v1';  แล้วให้ทำการแก้ไขตัว Listener ‘activate’ ของเรา ตรง if ให้กลายเป็นอย่างนี้แทนครับ เพื่อไม่ให้มันไปลบ Cache นี้ทิ้งไปซะได้\nif (key !== cacheName \u0026amp;\u0026amp; key !== dataCacheName) {  จากนั้นก็ Update Listener ‘fetch’ ของเราใหม่เป็น\nself.addEventListener('fetch', function(e) { console.log('[Service Worker] Fetch', e.request.url); var dataUrl = 'https://query.yahooapis.com/v1/public/yql'; if (e.request.url.indexOf(dataUrl) \u0026gt; -1) { e.respondWith( caches.open(dataCacheName).then(function(cache) { return fetch(e.request).then(function(response){ cache.put(e.request.url, response.clone()); return response; }); }) ); } else { e.respondWith( caches.match(e.request).then(function(response) { return response || fetch(e.request); }) ); } });  ตรงนี้ใน CodeLab จะมีอธิบายไว้ดีครับ คือ ถ้าไอ้ url ที่ไป fetch มาเนี่ยดันไปมีส่วนที่ตรงกับ query.yahoo บลาๆนั่น ให้ทำการดึงข้อมูลจาก Network มา แล้วมาเก็บไว้ที่ Cache ก่อน จากนั้น Return ข้อมูลที่ได้มากลับไป\nส่วนถ้าไม่ตรงกับ query.yahoo เนี่ย ก็คือไอ้พวก App Shell ก็ไปดึงจาก Cache มาเลยนะดู้ด ถ้าไม่เจอค่อยไป fetch โหลดมา\nเดี๋ยวๆ ยังไม่จบ ขอให้กลับไปที่ app.js ก่อนครับ บรรทัดที่ 170 เราจะเจอ\nให้ทำการใส่ Code นี้เข้าไป\nif ('caches' in window) { caches.match(url).then(function(response) { if (response) { response.json().then(function updateFromCache(json) { var results = json.query.results; results.key = key; results.label = label; results.created = json.query.created; app.updateForecastCard(results); }); } }); }  ตรงนี้มีความเท่คือ ถ้า SW เรามีการ cache เจ้าข้อมูลสภาพอากาศไว้แล้วเนี่ย ให้ดึงมาแสดงผลก่อนเลย ระหว่างที่รออัพเดทจากการ fetch network จริงเข้ามาครับ\nตรงนี้มีการ Handle Extreme case ไว้จุดนึงคือ เราไม่รู้ว่าข้อมูลอันไหนมันสด ใหม่กว่ากัน (แต่ปกติ Network มามันก็ต้องใหม่กว่าแหล่ะ) อันนี้เป็น Case Study ไว้ ใน App.js เขามีการเขียนป้องกันให้เราตามนี้ไว้ครับ (ไม่ต้องใส่เพิ่มใดๆ แล้วครับ)\nvar cardLastUpdatedElem = card.querySelector('.card-last-updated'); var cardLastUpdated = cardLastUpdatedElem.textContent; if (cardLastUpdated) { cardLastUpdated = new Date(cardLastUpdated); _// Bail if the card has more recent data then the data_ if (dataLastUpdated.getTime() \u0026lt; cardLastUpdated.getTime()) { return; } }  ตรงนี้เราก็จะได้ PWA ที่สามารถทำงานรวดเร็วและใช้งานได้แม้ Offline อยู่แล้วหล่ะครับ อีกนิดเดียวจบแล้ว อึดใจเดียวครับ\n5. แต่งหน้าทาปาก App ด้วย Manifest.json\nพระเอกคนที่สองของเราที่จะทำหน้าที่บ่งบอกว่า App ของเราหน้าตาเป็นอย่างไรเมื่อ Users ทำการ Add to homescreen เราแก้ได้หมดเลยว่าจะเอา Logo แบบไหน full-screen โหมดไม่มี Address Bar หรือเปล่า\nลองกันไม่ยากครับ สร้างไฟล์ manifest.json ใน Root Directory ของเราแล้วแปะไปตามนี้ได้เลย\n{ \u0026quot;name\u0026quot;: \u0026quot;Weather\u0026quot;, \u0026quot;short_name\u0026quot;: \u0026quot;Weather\u0026quot;, \u0026quot;icons\u0026quot;: [{ \u0026quot;src\u0026quot;: \u0026quot;images/icons/icon-128x128.png\u0026quot;, \u0026quot;sizes\u0026quot;: \u0026quot;128x128\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;image/png\u0026quot; }, { \u0026quot;src\u0026quot;: \u0026quot;images/icons/icon-144x144.png\u0026quot;, \u0026quot;sizes\u0026quot;: \u0026quot;144x144\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;image/png\u0026quot; }, { \u0026quot;src\u0026quot;: \u0026quot;images/icons/icon-152x152.png\u0026quot;, \u0026quot;sizes\u0026quot;: \u0026quot;152x152\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;image/png\u0026quot; }, { \u0026quot;src\u0026quot;: \u0026quot;images/icons/icon-192x192.png\u0026quot;, \u0026quot;sizes\u0026quot;: \u0026quot;192x192\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;image/png\u0026quot; }, { \u0026quot;src\u0026quot;: \u0026quot;images/icons/icon-256x256.png\u0026quot;, \u0026quot;sizes\u0026quot;: \u0026quot;256x256\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;image/png\u0026quot; }], \u0026quot;start_url\u0026quot;: \u0026quot;/index.html\u0026quot;, \u0026quot;display\u0026quot;: \u0026quot;standalone\u0026quot;, \u0026quot;background_color\u0026quot;: \u0026quot;#3E4EB8\u0026quot;, \u0026quot;theme_color\u0026quot;: \u0026quot;#2F3BA2\u0026quot; }  จากนั้นก็ให้ไปที่ไฟล์ html ใน Section header ก็ใส่ตามนี้เข้าไปครับ\n\u0026lt;link rel=\u0026quot;manifest\u0026quot; href=\u0026quot;/manifest.json\u0026quot;\u0026gt;  ยังไม่หมด Codelab ของ Google ใจดีให้ Meta Tag สำหรับ iOS และ Window มาด้วยครับ ตามนี้\n\u0026lt;meta name=\u0026quot;apple-mobile-web-app-capable\u0026quot; content=\u0026quot;yes\u0026quot;\u0026gt; \u0026lt;meta name=\u0026quot;apple-mobile-web-app-status-bar-style\u0026quot; content=\u0026quot;black\u0026quot;\u0026gt; \u0026lt;meta name=\u0026quot;apple-mobile-web-app-title\u0026quot; content=\u0026quot;Weather PWA\u0026quot;\u0026gt; \u0026lt;link rel=\u0026quot;apple-touch-icon\u0026quot; href=\u0026quot;images/icons/icon-152x152.png\u0026quot;\u0026gt;\u0026lt;meta name=\u0026quot;msapplication-TileImage\u0026quot; content=\u0026quot;images/icons/icon-144x144.png\u0026quot;\u0026gt; \u0026lt;meta name=\u0026quot;msapplication-TileColor\u0026quot; content=\u0026quot;#2F3BA2\u0026quot;\u0026gt;  เสร็จแล้วไปลอง Test กันใน Chrome Dev Tools ได้เลยหน้าตาแบบนี้\nฮู่ววว … จบแล้ววววว\nสรุปกันหน่อย เป็นอย่างไรบ้างครับกับ PWA เอาจริงๆ ก็ถ้าเราทำเว็บ SPA ใช้พวก Angular, React, VueJS อยู่แล้ว เพิ่มอีกนิดหน่อยสบายๆเลย ไม่แน่ 1–2 ปีถัดไป มันอาจเป็น Technology ที่ Front-end ทุกคนต้องติดตัวไปกันหมด เหมือนสมัยก่อนที่เป็นกับ Responsive Design ก็ได้ครับ\nเรื่องนึงที่สำคัญคือ Apple ยังไม่เอาด้วย ก็แน่หล่ะ รายได้ของ Apple มาจาก App Store ตั้งเยอะ จะให้มา Bypass ไปลง App กันตามหน้าเว็บเองก็กระไรอยู่ ก็ได้แต่ภาวนาครับ เอา Service Worker มาใส่ไว้หน่อยก็ยังดี\nยังมีส่วนอื่นๆที่น่าสนใจเกี่ยวกับ PWA อีกครับ ไม่ว่าจะเป็น Push Notification ที่ใครสนใจ Google ก็มีทำ CodeLab ไว้แล้ว กดไปลุยได้เลย ที่ https://developers.google.com/web/fundamentals/getting-started/codelabs/push-notifications/\nอีกเรื่องที่น่าศึกษาไม่แพ้กันคือ Caching Strategy ต่างๆ ว่าส่วนไหนของ App ดึง Cache ส่วนไหน ดึง Network ดู Keynote วันงานได้ตรงนี้ครับ https://docs.google.com/presentation/d/1TJSaBfxiwm2pIsyQpd9PSbCuwqeKyqbKx4YGQFZRTfU/edit#slide=id.p103\nวันนี้ก็ขอขอบคุณทุกท่านมากครับ ที่สละเวลามาอ่าน รู้สึกว่าได้ทบทวนตัวเองดี เวลาต้องเขียนบทความออกมา อาจจะมีข้อผิดพลาดบ้าง ก็ขอให้ติชมกันมาได้เลยครับ\nแถมๆ Google มีทำ Library จัดการสร้าง Service Worker ให้เราแบบง่ายๆครับ ใช้ร่วมกับ Gulp ได้เลยเรียกว่า sw-precache https://github.com/GoogleChrome/sw-precache ลองไปเล่นมาแล้วรู้สึกชีวิตดีขึ้นเยอะครับ\nvar gulp = require('gulp'); var sw = require('sw-precache')gulp.task('service', function() { sw.write('service-worker.js', { staticFileGlobs: [ 'scripts/**.js', 'styles/**.css', 'images/**.*', '**.{html,ico}' ], stripPrefix:'.', runtimeCaching:[{ urlPattern: /^https:\\/\\/publicdata-weather\\.firebaseio\\.com/, handler:'networkFirst', options:{ cache:{ name:'weatherData' } } }] }, function(){ console.log('Done Dude'); }); });  ใส่ประมาณนี้ไป อยากใช้ Caching Strategy ไหน ใส่ใน handler แล้วให้มัน Build ให้แปปเดียวเสร็จ ตัวนี้แนะนำเลยครับ\nSource อ้างอิง PWA RoadShow Full day Slide: https://drive.google.com/drive/folders/0B55wxScz_BJtV1lGbTBOYlhLTVk\nYour First Progressive Web App (Code Lab):\nhttps://codelabs.developers.google.com/codelabs/your-first-pwapp/index.html#0\nClient-Side Storage: https://www.html5rocks.com/en/tutorials/offline/storage/\nWeb Storage API:\nhttps://developer.mozilla.org/en-US/docs/Web/API/Web_Storage_API\nUdacity: Intro to Progressive Web Apps:\nhttps://www.udacity.com/course/intro-to-progressive-web-apps\u0026ndash;ud811\nSource:\n"});index.add({'id':23,'href':'/library/tutorials/docs/python/','title':"Python",'content':" Python Python Learning Resources Tutorials and online courses can\u0026rsquo;t cover everything, and whether you\u0026rsquo;re still in the early stages of learning or already an advanced Python programmer, you\u0026rsquo;re going to have to refer to the documentation every now and then. Here are some helpful links for finding quick answers to your questions.\n Official Python Documentation Matplotlib Documentation StackOverflow\n Pandas Documentation\n Seaborn Introduction\n Data Science Courses\n  ไพธอน (Python) ไพธอน หรือ Python เป็นภาษาเขียนโปรแกรมระดับสูง (high-level language) ที่ใช้กันอย่างกว้างขวางในการเขียนโปรแกรมเพื่อวัตถุประสงค์ทั่วไป ภาษาไพธอนนั้นเป็นภาษาแบบการตีความ (interprete) ที่ถูกออกแบบโดยมีปรัญชาที่จะทำให้โค๊ดหรือรหัสทางภาษานั้นอ่านได้ง่ายขึ้น และทำให้โปรแกรมเมอร์สามารถเข้าใจโครงสร้างของภาษาและแนวคิดการเขียนโค๊ดโดยใช้บรรทัดที่น้อยลงกว่าภาษาอื่น เช่น C, C++ และ Java\nไพธอนนั้นมีคุณสมบัติเป็นภาษาเขียนโปรแกรมแบบไดนามิกส์และมีระบบการจัดการหน่วยความจำอัตโนมัติและสนับสนุนการเขียนโปรแกรมหลายรูปแบบ ที่ประกอบไปด้วย การเขียนโปรแกรมเชิงวัตถุ imperative การเขียนโปรแกรมแบบฟังก์ชัน และการเขียนโปรแกรมแบบขั้นตอน ภาษาไพธอนมีไลบรารี่ที่ครอบคลุมการทำงานอย่างหลากหลาย ตัวแปรในภาษาไพธอนนั้นมีให้ใช้ในหลายระบบปฏิบัติการ ทำให้โค๊ดของภาษาไพธอน สามารถทำงานในระบบต่าง ๆ ได้อย่างกว้างขวาง ซึ่งแรกเริ่มนั้นไพธอนถูกพัฒนามาจาก CPython ซึ่งเป็นโปรแกรมแบบเปิด (open source) และมีชุมชนสำหรับเป็นต้นแบบในการพัฒนา เนื่องจากมันได้มีการนำไปพัฒนากระจายไปอย่างหลากหลาย CPython นั้นจึงถูกจัดการโดยองค์กรไม่แสวงหาผลกำไรซึ่งในเวลาต่อมาได้มีชื่ออย่างเป็นทางการว่า Python Software Foundation (PSF)\nภาษาไพธอนนั้นถูกสร้างขึ้นโดยโปรแกรมเมอร์ที่ชื่อว่า Guido van Rossum ที่ Centrum Wiskunde \u0026amp; Informatica (CWI) ในประเทศเนเธอร์แลนด์ เนื่องในผู้ประสบความสำเร็จในการสร้างภาษา ABC ที่มีความสามารถสำหรับการรับมือกับข้อยกเว้น (exception handling) และการติดต่อผสานกับระบบปฏิบัติการ Amoeba ซึ่ง Van Rossum นั้นเป็นผู้เขียนหลักการของภาษาไพธอน และเขาทำหน้าเป็นกลางในการตัดสินใจสำหรับทิศทางการพัฒนาของภาษาไพธอน\nGuido van Rossum - ศาสดาของไพธอน\nปรัชญาของไพธอน หลักปรัชญาของไพธอนสามารถอธิบายได้ด้วย The Zen of Python ซึ่งบัญญัติโดย\nหากรันคำสั่งไปต่อนี้ใน Python interactive\nimport this  ซึ่งจะแสดงผล The Zen of Python ให้เราได้แบบนี้\nThe Zen of Python, by Tim Peters Beautiful is better than ugly. Explicit is better than implicit. Simple is better than complex. Complex is better than complicated. Flat is better than nested. Sparse is better than dense. Readability counts. Special cases aren't special enough to break the rules. Although practicality beats purity. Errors should never pass silently. Unless explicitly silenced. In the face of ambiguity, refuse the temptation to guess. There should be one-- and preferably only one --obvious way to do it. Although that way may not be obvious at first unless you're Dutch. Now is better than never. Although never is often better than *right* now. If the implementation is hard to explain, it's a bad idea. If the implementation is easy to explain, it may be a good idea. Namespaces are one honking great idea -- let's do more of those!  แท้จริงแล้วหลักปรัชญาของไพธอนก็คือไพธอนเป็นภาษาที่สามารถสร้างงานได้หลากหลายกระบวนทัศน์ (Multi-paradigm language) โดยจะมองอะไรที่มากกว่าการเขียนโปรแกรมเพื่อนำมาใช้งานตามรูปแบบเดิม ๆ แต่จะเป็นการนำเอาหลักการของกระบวนทัศน์ (Paradigm) แบบเชิงวัตถุ (Object-oriented programming), แบบเชิงโครงสร้าง (Structured programming), แบบฟังก์ชันแนล (Functional programming) และแบบเชิงมุม (Aspect-oriented programming) นำเอามาใช้ทั้งแบบแยกและนำมาใช้ร่วมกัน ซึ่งไพธอนนั้นเป็นภาษาที่มีการตรวจสอบชนิดตัวแปรแบบยืดหยุ่น (dynamically type-checked) และใช้ Garbage collection ในการจัดการหน่วยความจำ\nทำไมต้องไพธอน 1. ง่ายต่อการเรียนรู้\nไพธอนเป็นภาษาโปรแกรมระดับสูง (High-level programming) มีโครงสร้างที่ไม่ซับซ้อน ทำให้ง่ายต่อการเรียนรู้เมื่อเปรียบเทียบกับภาษาโปรแกรมอื่นๆ ไม่ว่าจะเป็นเด็กวัยประถมหรือผู้ใหญ่วัยทำงานก็สามารถที่จะเรียนรู้ได้ ข้อดีดังกล่าวทำให้เราเน้นความสนใจไปกับการแก้ปัญหาจริงๆ มากขึ้น และช่วยลดเวลาสำหรับการตรวจสอบโครงสร้างและสัญลักษณต่างๆ ของภาษาให้น้อยลง ดังนั้นการเลือกภาษาไพธอนเป็นภาษาแรก จะทำให้ผู้ที่เริ่มต้นศึกษาการเขียนโปรแกรมสามารถใช้เวลาตั้งแต่การเรียนรู้ไปจนถึงการเขียนโปรแกรมเพื่อใช้งานจริงในระยะเวลาที่เร็วขึ้นได้\n2. นำไปใช้งานจริงได้\nนอกจากไพธอนจะเป็นภาษาโปรแกรมที่นำมาใช้เพื่อศึกษาการเขียนโปรแกรมแล้ว แต่เราก็สามารถนำไปใช้งานได้จริงและมีประสิทธิภาพได้ ทำให้บริษัทและองค์กรใหญ่ระดับโลก เช่น Google, Facebook, YouTube, Netflix, Dropbox, Agoda และ NASA เลือกที่จะนำภาษาไพธอนมาใช้ในการพัฒนาเพื่อสร้างผลิตภัณฑ์ซอฟต์แวร์ โดยมีผู้ใช้งานจริงหลายล้านคนทั่วโลก\n3. มีไลบรารีครอบคลุมการใช้งานต่าง ๆ\nเนื่องจากภาษาโปรแกรมไพธอนสามารถนำไปพัฒนาซอฟต์แวร์เพื่อตอบสนองความต้องการในงานทางด้านต่างๆ ได้ ทำให้มีนักพัฒนาจำนวนมากต้องการแบ่งปันผลงานร่วมกับนักพัฒนาคนอื่นๆ เพื่อให้ภาษาไพธอนมีความสามารถมากขึ้น โดยมี Python Package Index (PyPI) ซึ่งเป็นแหล่งรวบรวมโมดูลและไลบรารีครอบคลุมการใช้งานทางด้านต่างๆ เช่น วิทยาศาสตร์ วิทยาศาสตร์ข้อมูล พัฒนาเว็บไซต์ ระบบคอมพิวเตอร์ฝังตัว ระบบเครือข่าย และอื่นๆ อีกมากมาย โดยสามารถเข้าไปค้นหาและดาวน์โหลดโมดูลที่ต้องการได้ที่ https://pypi.org/ หลังจากนั้นก็สามารถนำมาใช้งานในโปรแกรมของเราได้ทันที ภาษาไพธอนมีไลบรารีสำหรับงานทางด้านวิทยาศาสตร์ข้อมูล\n4. งานทางด้านวิทยาศาสตร์ข้อมูล\nในปัจจุบันงานทางด้านวิทยาศาสตร์ข้อมูล (Data Science) ได้รับความสนใจเป็นอย่างมาก เนื่องจากบนอินเทอร์เน็ตมีข้อมูลใหม่เกิดขึ้นตลอดเวลา และมีปริมาณข้อมูลระดับมหาศาล (Big Data) ดังนั้นหากเรานำข้อมูลเหล่านี้มาทำวิเคราะห์ในรูปแบบต่างๆ เพื่อเป็นประโยชน์ทางด้านธุรกิจหรือด้านอื่นๆ จะทำให้องค์กรสามารถสร้างความได้เปรียบเหนือคู่แข่งได้ สำหรับภาษาโปรแกรมไพธอนมีไลบรารีที่ครอบคลุมการทำงานทางด้านวิทยาศาสตร์ข้อมูลที่มีคุณภาพ เป็นที่นิยม และพร้อมใช้งานอยู่จำนวนมาก โดยสามารถแสดงข้อมูลดังตารางด้านล่างนี้\n5. เขียนโปรแกรมได้หลายกระบวนทัศน์ (Multi-paradigms programming)\nกระบวนทัศน์การเขียนโปรแกรม (Programming Paradigm) คือแนวคิดหรือสไตล์ในการเขียนโปรแกรม โดยภาษาไพธอนสนับสนุนการเขียนโปรแกรมได้หลายกระบวนทัศน์ เช่น 1) Imperative programming 2) Event driving programming 3) Object Oriented Programming (OOP) และ 4) Functional programming เป็นต้น ทำให้นักพัฒนาซอฟต์แวร์สามารถเขียนโปรแกรมในรูปแบบที่เหมาะสมกับงานประเภทต่างๆ ได้\n6. มีชุมชนนักพัฒนาที่แข็งแกร่ง\nในปัจจุบันภาษาไพธอนได้รับความนิยมสูงอย่างต่อนื่อง ไพธอนมีชุมชนนักพัฒนาจำนวนมาก นอกจากนั้นการเขียนโปรแกรมไม่ได้จำกัดอยู่เฉพาะในแวดวงของวิทยาศาสตร์คอมพิวเตอร์ (Computer Science) เท่านั้น แต่ผู้ที่ทำงานสาขาอื่นก็อาจมีความต้องการจะนำไปใช้ประโยชน์ในงานทางด้านอื่นๆ ด้วย ทำให้มีชุมชนนักพัฒนาที่ใช้งานภาษาไพธอนเกิดขึ้นบนอินเทอร์เน็ตจำนวนมาก หากต้องการศึกษาหาความรู้เพิ่มเติม ก็มีเนื้อหาที่มีคุณภาพในรูปแบบต่างๆ เช่น วิดีโอ หนังสือ บทความ และเอกสารบนอินเทอร์เน็ตให้ค้นคว้าเพิ่มเติมได้ ถ้าหากติดปัญหาใดๆ ก็สามารถค้นหาวิธีการแก้ปัญหาของคนที่เคยพบปัญหามาก่อน หรืออาจจะขอความช่วยเหลือจากสังคมนักพัฒนาที่ชอบแบ่งปันข้อมูลความรู้ระหว่างกันและกันบนอินเทอร์เน็ต เช่น Stack Overflow และ Quora\n7. ทำงานได้หลายแพลตฟอร์ม\nแม้ว่าในช่วงแรกภาษาไพธอนได้ถูกออกแบบมาให้ทำงานบนระบบปฏิบัติการ Unix เพียงอย่างเดียว อย่างไรก็ตามได้มีการพัฒนาให้สามารถนำไปใช้งานได้หลายระบบปฏิบัติการอื่นๆ ได้ด้วย เช่น Windows Mac และ Linux ดังนั้นนักพัฒนาสามารถเขียนโปรแกรมเพียงครั้งเดียว แต่สามารถนำไปใช้งานบนคอมพิวเตอร์เครื่องใดก็ได้ ทำให้ช่วยลดระยะเวลาและค่าใช้จ่ายในการพัฒนา ทดสอบ และบำรุงรักษาซอฟต์แวร์ให้สามารถใช้งานเป็นปกติได้ทุกระบบปฏิบัติการ นักพัฒนาภาษาไพธอนมีรายได้ดีและเป็นที่ต้องการขององค์กรต่างๆ 8.รายได้ดีและเป็นที่ต้องการขององค์กรต่างๆ นักพัฒนาโปรแกรมด้วยภาษาไพธอนเป็นที่ต้องการในสายงานทางด้านพัฒนาซอฟต์แวร์อย่างมาก โดยข้อมูลล่าสุดของเว็บไซต์ https://indeed.com (ข้อมูลเดือนตุลาคม ปี 2018) ในประเทศสหรัฐอเมริกา มีอัตราการจ้างงานนักพัฒนาด้วยภาษาไพธอนจำนวนมาก โดยมีรายได้เฉลี่ยสูงถึงประมาณ $120,432 เหรียญ/ปี ดังนั้นผู้ที่เขียนโปรแกรมด้วยภาษาไพธอนได้ ก็จะสามารถสร้างรายได้ให้กับตัวเอง และมีโอกาสในการทำงานกับองค์กรทุกระดับได้\n8. สามารถนำไปใช้งานได้ฟรี\nภาษาไพธอนยังเป็นซอฟต์แวร์ประเภทโอเพนซอร์ส (Opensource) หมายความว่าเราสามารถนำซอร์สโค้ด (Source code) มาดัดแปลง แก้ไขได้ทั้งหมด โดยไม่จำเป็นต้องขออนุญาต และที่สำคัญเราสามารถนำไปใช้งานได้ฟรี โดยไม่มีค่าใช้จ่ายเรื่องค่าลิขสิทธิ์ใดๆ\nที่มาของชื่อ \u0026ldquo;ไพธอน\u0026rdquo; คำว่าไพธอน (python) เป็นชื่องูสกุลหนึ่ง ซึ่งในภาษาไทยเรียกว่า \u0026ldquo;งูเหลือม\u0026rdquo; หรือ \u0026ldquo;งูหลาม\u0026rdquo; เป็นงูไม่มีพิษ มีชื่อทางวิทยาศาสตร์ว่าสกุล Pythonidae รากศัพท์เดิมมาจากภาษากรีกคำว่า πύθων อ่านแบบกรีกโบราณว่า \u0026ldquo;ปือทอน\u0026rdquo; อ่านแบบกรีกสมัยใหม่ว่า \u0026ldquo;พีโธน\u0026rdquo; แต่พอมาใช้ในภาษาอังกฤษก็แผลงเป็น \u0026ldquo;ไพธอน\u0026rdquo;\n\u0026ldquo;ปือทอน\u0026rdquo; เป็นชื่อของงูยักษ์รูปร่างคล้ายมังกร ซึ่งปรากฏตัวในเทพปกรณัมกรีก แต่ตอนหลังถูกนำมาใช้เป็นชื่อเรียกงูที่มีอยู่จริง อนึ่ง อักษร \u0026ldquo;ธ\u0026rdquo; ในการเขียนทับศัพท์คำว่า \u0026ldquo;ไพธอน\u0026rdquo; ในที่นี้ไม่ได้แทนเสียง \u0026ldquo;ท\u0026rdquo; แต่แทนเสียง th ในภาษาอังกฤษ ซึ่งไม่เหมือน th ในภาษาไทย แต่เป็นเสียงที่ไม่มีอยู่ในภาษาไทย เสียงนี้จริงๆแล้วใกล้เคียง \u0026ldquo;ซ\u0026rdquo; มากกว่า \u0026ldquo;ท\u0026rdquo; เสียอีก ในภาษากรีกใช้อักษร θ \u0026ldquo;เธตา\u0026rdquo; อย่างไรก็ตามกรีกโบราณไม่มีเสียงนี้ แต่ออกเสียง θ เป็นเสียง \u0026ldquo;ท\u0026rdquo; แทน\nสัญลักษณ์ของภาษาไพธอนใช้เป็นรูปงูสองตัวพันกัน ตัวหนึ่งสีเหลือง อีกตัวหนึ่งสีน้ำเงิน\nเวอร์ชันของไพธอน หลังจากที่เริ่มถูกปล่อยออกมาให้ใช้ ภาษาไพธอนก็พัฒนาขึ้นมาเรื่อยๆ มีการปรับปรุงเวอร์ชันใหม่อยู่บ่อยๆ ปัจจุบันออกมาถึงเวอร์ชัน 3. กว่า ๆ อย่างไรก็ตามเวอร์ชัน 2. กว่าๆก็ยังคงเป็นที่นิยมมากกว่า ดังนั้นจึงควรจะทำความรู้จักไว้ทั้งสองแบบ\nไพธอน 2 นั้นเริ่มถูกปล่อยออกมาในปี 2000 ส่วนไพธอน 3 เริ่มถูกปล่อยออกมาในปี 2008 เวอร์ชัน 3 มีการปรับปรุงอะไรต่างๆให้ดีขึ้นจาก 2 ไปพอสมควร แต่เนื่องจากสูญเสียความเข้ากันได้กับเวอร์ชัน 2 หมายความว่าคนที่เคยเขียนไพธอน 2 มาพอจะเปลี่ยนมาไพธอน 3 จำเป็นจะต้องแก้ไขโค้ด ไม่เช่นนั้นจะไม่สามารถอ่านได้ หรือแสดงผลผิดพลาด นั่นทำให้ยังมีผู้ที่ใช้ไพธอน 2 มานานและไม่อยากจะเปลี่ยนอีกเป็นจำนวนมาก แม้จะผ่านมาหลายปีแล้วแนวโน้มก็ยังคงเป็นเช่นนี้อยู่ ภายหลังจากที่มีการออกเวอร์ชัน 3. ไปแล้ว เวอร์ชัน 2. ก็ยังคงมีการปรับปรุงพัฒนาต่อเนื่องมา โดยมีเวอร์ชัน 2.7 ออกมาในปี 2010 โดยนำเอาความสามารถบางส่วนจากไพธอน 3 มาใช้ และถูกวางให้เป็นรุ่นสุดท้ายที่ขึ้นต้นด้วย 2.\nปัจจุบันไพธอน 2.7 ได้รับความนิยมอย่างมาก เพราะในปัจจุบันโปรแกรมต่าง ๆ ที่ใช้ภาษาไพธอนยังสนับสนุนเวอร์ชัน 2.x เป็นหลักอยู่ อย่างไรก็ตาม แนวโน้มในอนาคตเวอร์ชัน 3.x จะได้รับการสนับสนุนมากขึ้นเรื่อยๆ ผู้ฝึกใช้ใหม่ๆมักถูกแนะนำให้ใช้ 3.x มากกว่า ดังนั้นบทความนี้จะเน้นเวอร์ชัน 3.x เป็นหลัก แต่เพื่อให้คนที่ต้องการใช้ไพธอน 2 สามารถอ่านแล้วอ้างอิงตามได้ด้วย จึงได้เขียนสรุปเรื่องความแตกต่างตรงนี้แยกเอาไว้ สามารถอ่านได้ที่ https://phyblas.hinaboshi.com/20151217\nไพธอนถูกใช้เพื่อสร้างอะไรมาแล้วบ้าง  โปรแกรมฟรี เช่น BitTorrent, Dropbox, Blender ส่วนประกอบของเว็บไซต์ต่างๆเช่น Google, Yahoo!, YouTube โปรแกรมที่ใช้ในหน่วยงานวิจัย เช่น NASA, องค์กรวิจัยเครื่องเร่งพลังงานสูงของญี่ปุ่น (高エネルギー加速器研究機構) ฯลฯ  การใช้งานภาษาไพธอน ไม่ว่าจะเป็นภาษาอะไรก็ตาม การที่จะทำงานได้นั้นต้องประกอบไปด้วยโปรแกรมที่ใช้ในการอ่านตีความหมายของ สิ่งที่เราเขียนลงไปให้กลายเป็นภาษาเครื่องเพื่อให้มันทำงานตามที่เราต้องการ หากให้เปรียบเทียบก็เหมือนกับการแปลงภาษามนุษย์นั่นเอง สมมุติว่ามีนายทุนคนหนึ่งไปเปิดโรงงานในต่างประเทศ โรงงานจะทำงานได้ต้องใช้คนงาน แต่พวกคนงานที่นั่นเขาไม่รู้ภาษาไทย และนายทุนก็ไม่รู้ภาษาอังกฤษ นายทุนจะสั่งงานพวกคนงานให้ทำงานอย่างที่ตัวเองต้องการก็ต้องทำผ่านล่ามให้ ช่วยแปลเป็นภาษาอังกฤษเพื่อจะได้สั่งคนงานได้\nในกรณีนี้ภาษาไพธอนก็เทียบได้กับภาษาไทย คือเป็นภาษาง่ายๆที่เราเข้าใจดีอยู่แล้ว แต่ว่าไม่สามารถนำไปสั่งงานได้โดยตรง ส่วนภาษาอังกฤษก็เทียบได้กับภาษาเครื่อง คือเป็นภาษาที่สามารถนำไปใช้งานได้จริงแต่เราไม่เข้าใจ โดยคนงานก็เทียบได้กับคอมพิวเตอร์ นายทุนเปรียบได้กับผู้เขียนโปรแกรม ส่วนล่ามก็เปรียบได้กับตัวแปรภาษาในคอมพิวเตอร์ ตัวที่ทำหน้าที่ตีความภาษาจะเรียกว่าคอมไพเลอร์ (compiler)\nนอกจากคอมไพเลอร์แล้ว ส่วนประกอบที่สำคัญอีกอย่างรองลงมาก็คือส่วนที่เอาไว้ใช้สำหรับเขียนข้อความลงไป ซึ่งเรียกว่าอีดิเตอร์ (editor) เหมือนกับเราเขียนข้อความในกระดาษบอกล่ามไปทีเดียวเลยว่าต้องการให้ทำอะไรบ้าง แล้วล่ามก็เอาไปบอกคนงานทีเดียว ไม่ต้องคอยสั่งทีละประโยค อีดิเตอร์กับคอมไพเลอร์อาจไม่จำเป็นต้องอยู่ภายในโปรแกรมเดียวกัน เราอาจเขียนโค้ดผ่านโปรแกรมง่ายๆเช่น notepad จากนั้นค่อยนำไปรันก็ได้ ดังนั้น ดังนั้นอีดิเตอร์จึงไม่มีความสำคัญเท่าคอมไพเลอร์\nอย่างไรก็ตาม โปรแกรมที่ใช้ทำงานกับภาษาไพธอนนั้นมักจะประกอบไปด้วยอีดิเตอร์ที่ช่วยอำนวยความสะดวกให้การเขียนง่ายขึ้น เช่นมีการใส่สีให้ข้อความสำคัญ และมีตัวตรวจไวยากรณ์ทำให้มีการฟ้องเวลาเจอข้อผิดพลาดทางวากยสัมพันธ์ (syntax error) ในขณะที่หากเขียนใน notepad จะไม่มีทางรู้ได้เลยว่าผิดตรงไหน นอกจากนี้ยังมีตัวตรวจบั๊ก (debugger) ซึ่งมีไว้ค้นหาข้อผิดพลาดในการทำงานของโปรแกรม\nนอกจากการเขียนโปรแกรมและให้คอมไพเลอร์อ่านแล้ว ในบางภาษาซึ่งรวมถึงภาษาไพธอนด้วยนั้นยังมีอีกวิธีหนึ่งในการใช้งาน นั่นคือการสั่งให้ทำงานแบบคำต่อคำ ซึ่งก็เทียบได้กับการที่นายทุน สั่งล่ามแล้วล่ามก็ไปสั่งคนงานทันทีโดยตรง แล้วคนงานก็เริ่มทำงาน พอทำเสร็จนายทุนก็สั่งงานต่อไปอีกทันที ส่วนที่ใช้สั่งงานโปรแกรมแบบคำต่อคำนั้นเรียกว่า เชลโต้ตอบ (interactive shell) และในกรณีนี้ตัวประมวลผลจะถูกเรียกว่าอินเทอร์พรีเตอร์ (interpreter) ข้อดีคือเห็นผลทันทีอย่างรวดเร็ว ไม่จำเป็นต้องเซฟแล้วค่อยสั่งรัน แต่ข้อเสียคือใส่คำสั่งได้ทีละนิดและต้องสั่งไปเรื่อยๆ ไม่สามารถสั่งงานทิ้งไว้แล้วให้ทำงานยาวๆได้\nสรุปโดยรวม สิ่งที่ต้องมีเพื่อจะทำงานกับภาษาไพธอนก็คือ\n คอมไพเลอร์ ไว้ตีความโค้ดที่เราเขียนเพื่อสั่งให้คอมทำงาน อีดิเตอร์ เอาไว้เขียนโค้ดยาวๆเพื่อให้คอมไพเลอร์อ่านแล้วสั่งคอมอีกที เชลโต้ตอบ เอาไว้ป้อนโค้ดเพื่อสั่งการคอมทันที  ควรจะเริ่มต้นยังไงดี ก่อนอื่นต้องตั้งเป้าว่าจะเรียนไปเพื่ออะไร ถ้าเรียนรู้แล้วไปได้ไกลจริงๆก็สามารถเขียนโปรแกรมอะไรต่างๆได้แทบทุกอย่าง เช่นสร้างโปรแกรมออกมาใช้เองหรือแจกคนอื่น หรือจะสร้างเกมก็สร้างได้ และถ้าทำได้ดีอาจทำขายได้ แล้วก็ดัง\u0026hellip;! อาจดูเพ้อฝันไปสักหน่อย แต่มองเป้าหมายไกลๆไว้ก่อนก็ไม่มีอะไรเสียหาย เพียงแต่ต้องรู้ว่ากว่าจะถึงตอนนั้นต้องผ่านขั้นตอนอะไรมาบ้าง ไม่ว่าอะไรก็ตามต้องเริ่มต้นจากศูนย์กันหมด หากมีพื้นฐานมาแล้วก็ไปได้เร็วขึ้น\n โอกาส ที่วิเศษนั้นอาจซ่อนแฝงอยู่ภายในปรากฏการณ์ที่ดูเหมือนกับว่าไม่มีอะไร แต่มันจะปรากฏให้เห็นได้เฉพาะคนที่มีเป้าหมายในใจอย่างแรงกล้าเท่านั้น\n แหล่งศึกษาสำหรับผู้เริ่มต้น  Official Document\n MascusCode\n เว็บไซต์ MarcusCode มีบทเรียนในการเขียนโปรแกรมในภาษา Python ในพื้นฐานจนถึงระดับสูงแยกตามบท ซึ่งเนื้อหาที่เว็บไซต์นี้สอนนั้นจะกระชับและตรงประเด็น ทำให้ผู้ที่ศึกษาตามสามารถเข้าใจถึงหลักการของภาษาไพธอนได้อย่างรวดเร็ว ตัวอย่างของเนื้อหาที่สอน เช่น โครงสร้างของภาษาไพธอน ตัวแปรและประเภทข้อมูล ตัวดำเนินการ อาเรย์และฟังก์ชัน Link: http://marcuscode.com/lang/python  Google for Education\n เรียนไพธอนที่กูเกิลสำหรับการศึกษา (Google for Education) ก็เป็นอีกช่องทางหนึ่งที่น่าสนใจ ศึกษาไพธอนกับองค์กรระดับโลกอย่างกูเกิล มีทั้งตัวอย่างของโค๊ดและวิดีโอสอน นอกจากนี้ยังช่วยให้เราฝึกภาษาอังกฤษอีกด้วย Link: https://developers.google.com/edu/python/  เว็บไซต์ Dot Python\n เว็บไซต์สอนภาษาไพธอนที่แบ่งเนื้อหาออกเป็นหมวดหมู่ สามารถอ่านและศึกษาตามได้อย่างง่าย ๆ สอนโดยคุณทวีรัตน์ นวลช่วย คณะวิทยาศาสตร์และเทคโนโลยี มหาวิทยาลัยราชภัฏสงขลา Link: https://sites.google.com/site/dotpython/    เว็บบล็อก PhyBlas\n เว็บไซต์ที่สอนเนื้อหาไพธอนที่อธิบายและยกตัวอย่างได้เห็นภาพ เหมาะกับผู้เริ่มต้นเป็นอย่างยิ่ง Link: https://phyblas.hinaboshi.com/saraban/python   บล็อก python3.wannaphong\n สอนพื้นฐานภาษาไพธอน โดย วรรณพงษ์ ภัททิยไพบูลย์ Link: https://python3.wannaphong.com/p/blog-page_7.html  Free Code Camp ได้เผยแพร่ไว้ในบทความ \u0026ldquo;# The Best Python Tutorials\u0026rdquo; ดังนี้\n Python Practice Book: http://anandology.com/python-practice-book/index.html\n Think Python: http://greenteapress.com/thinkpython/html/index.html\n Practical Business Python: http://pbpython.com/\n Another course: https://realpython.com/?utmsource=fsp\u0026amp;utmmedium=promo\u0026amp;utm_campaign=bestresources\n General: https://www.fullstackpython.com/\n Learn the Basics: https://www.codecademy.com/learn/learn-python\n Computer science using Python: https://www.edx.org/course/introduction-computer-science-mitx-6-00-1x-11?ref=hackernoon#!\n List of more resources for learning python: https://github.com/vinta/awesome-python\n Interactive Python: http://interactivepython.org/runestone/static/thinkcspy/index.html\n Developer’s Guide to Python: https://devguide.python.org/\n  Reference :\n https://phyblas.hinaboshi.com/tsuchinoko01 Python Thailand - แหล่งเรียนรู้ภาษาไพธอนสำหรับคนไทย  แหล่งความรู้เพิ่มเติม  Python Tips  "});index.add({'id':24,'href':'/library/tutorials/docs/articles/python/python-101/','title':"Python 101",'content':" Python 101 ฉบับรวบลัด การแสดงผล และรับข้อมูล เริ่มแรกลอง print “hello world” กันก่อน\nprint(\u0026quot;hello_world\u0026quot;)  Data type (ประเภทข้อมูล) 1. String String ก็เป็นตัวแปรที่เก็ยตัวอักษร หรือข้อความ คราวนี้เรามาลองรับ input เป็นชื่อเก็บใส่ตัวแปรที่ชื่อว่า name แล้ว print ออกมากันครับ\nในที่นี้ตัวแปร name ก็จะมี data type คือ string นั้นเอง\nname = input(\u0026quot;What is your name? \u0026quot;) print(\u0026quot;Hello \u0026quot;,name)  2. Numeric    Type Description     Integer จำนวนเต็ม เช่น 10, 20   Float ทศนิยม เช่น 10.0, 20.5    ต่อมาลองรับ input เป็น integer 1 ตัว และ float 1 ตัว แล้วเอามาบวกกันแสดงผลรับเป็น integer\nnum1 = input() # Cast string to integer num1 = int(num1) num2 = input() # Cast string to float num2 = float(num2) total = num1 + num2 # Cast to integer total = int(total) print(\u0026quot;total:\u0026quot;,total)  3. List List ก็คือตัวแปรที่คล้ายๆกับ array ใน C/C++ หรือภาษาอื่นๆนั้นเอง สำหรับใครที่เขียน python เป็นภาษาแรก ให้นึกถึง ตารางที่เก็บข้อมูล\nสมมติ เรามีข้อมูลคะแนนนักเรียนอยู่ 5 คน ดังนี้ 20, 40, 30, 50, 35 เราก็จะสร้างตัวแปรชื่อ score ขึ้นมา\nโดยที่ List จะเก็บค่าไว้ใน [] แต่ละข้อมูลคั่นด้วย comma (,)\nscore = [20, 40, 30, 50, 35]  แล้วถ้าเรา อยากเก็บว่าเพื่อนในห้องเรียนนั่งตรงไหนกันบ้าง ให้เรามีเพื่อน 12 คน\nมีเก้าอี้อยู่ 4 แถว แถวละ 3 ตัว เราก็วาดตารางขึ้นมาก่อน\n    คอลัมน์ 1 คอลัมน์ 2 คอลัมน์ 3     0 แถว1 A J   1 แถว2 F B   2 แถว3 D C   3 แถว4 G E    เราก็จะสร้าง List แบบนี้\ntable = [ ['A','J','L'], # row 1 ['F','B','I'], # row 2 ['D','C','H'], # row 3 ['G','E','K'], # row 4 ] print(table)  แต่ในการเขียน Program เราจะเริ่มนับแถว กับคอลัมน์ ตั้งแต่ 0 ใช้คำว่า Index ในการบอกตำแน่ง\n่เช่น อยากรู้ว่า K นั่งอยู่ตรงไหน ก็คือ แถว 4 คอลัมน์ 3 พอเป็นในทาง programming เราก็จะบอกว่า K อยู่ที่ Index 3,2\nและถ้าทุกคนสังเกต 2 ตัวอย่างผ่านมาจะรู้ว่า List สามารถเก็บตัวแปรประเภทใดก็ได้ สามารถเก็บตัวแปรคนละชนิด ไว้ใน List เดียวกันก็ได้ เช่น\nperson = [\u0026quot;sk\u0026quot;, \u0026quot;conan\u0026quot;, \u0026quot;20\u0026quot;] print(\u0026quot;Name:\u0026quot;, person[0], \u0026quot; Lastname:\u0026quot;, person[1], \u0026quot; Age:\u0026quot;, person[2])  4. Numpy array อันนี้ผมอยากให้ทุกคนได้รู้จักเพราะว่า blog ของผมก็เป็น blog เกี่ยวกับ image processing กับ Computer vision เนอะ แล้วมันเกี่ยวกันยังไงใช่มั้ยครับ\nเพราะว่า Library OpenCV ที่เราใช้ในการทำ Image processing กันเนี่ยมันจะเก็บข้อมูลรูปภาพไว้ใน Numpy array\nNumpy array คือ ตารางหรือ array ที่เก็บค่าข้อมูลที่มี Data type เหมือนกัน ถ้าเป็นรูป ก็จะต้องมี Data type เป็น uint8 มาลองใช้งานกันเลยดีกว่าครับ\nimport numpy as np # Covert list to numpy array that have a datatype is uint8 a = np.array([1,2,3,4], np.uint8) print(a) # Show type of variable a print(type(a)) # Show Data type in variable a print(a.dtype)  Operators (ตัวดำเนินการ) มันก็จะถูกแบ่งแยกย่อยไปอีก เราจะดูเฉพาะตัวที่สำคัญๆนะครับ\n1. Arithmetic Operators จะเป็นตัวดำเนินเกี่ยวกับ Math โดยจะสรุปไว้ตามตารางข้างล่างนะครับ กำหนดให้ a = 10, b = 7\n    Operator Description Example Result     0 + การบวก a + b 17.0   1 - การลบ a - b 3.0   2 * การคูณ a * b 70.0   3 / การหาร a / b 1.4285714   4 % การหาเศษ จากการหาร a % b 3.0   5 ** การยกกำลัง a**b 10000000.0   6 // การหารแบบไม่เอาเศษ a//b 1.0    2. Assignment Operators จะเป็นการให้ค่าตัวแปร กำหนดให้ a = 10\n   Operator Example Result of a     += a += 3 13.0   -= a -= 3 7.0   *= a *= 3 30.0   / a / b 1.4285714   % a %= 3 1.0   ** = a** = 3 1000.0   //= a//=3 1.0    3. Comparison Operators จะเป็นการเปรียบเทียบ กำหนดให้ a = 10, b = 10 | |Operator|Description|Example|Result| |:\u0026mdash;\u0026ndash;:|:\u0026mdash;\u0026mdash;-:|:\u0026mdash;\u0026mdash;\u0026mdash;:|:\u0026mdash;\u0026mdash;\u0026mdash;:|:\u0026mdash;\u0026mdash;\u0026mdash;:| |0|==|ความเท่ากัน|a == b|True| |1|!=|ความไม่เท่ากัน|a != b|False| |2|\u0026gt;|มากกว่า|a \u0026gt; b|False| |3|\u0026lt;|น้อยกว่า|a \u0026lt; b|False| |4|\u0026gt;=|มากกว่าเท่ากับ|a \u0026gt;= b|True| |5|\u0026lt;=|น้อยกว่าเท่ากับ|a \u0026lt;= b|True|\n4. Logical Operators เป็นการเปรียบเทียบทางตรรกศาสตร์ กำหนดให้ a = True, b = False\n   Operator Description Example Result     and ต้องจริงทั้ง 2 ค่า ถึงจะเป็นจริง นอกนั้นเป็นเท็จ a and b False   or ต้องเท็จ 2 ค่า ถึงจะเป็นเท็จ นอกนั้นเป็นจริง a or b True   not ให้ค่าตรงข้าม not (a and a) False    If-Else Condition เป็นการเขียนเพื่อควบคุมการทำงานของโปรแกรมให้เป็นไปตาม ทางเลือก ที่เราตั้งไว้ เช่น ตัวอย่างที่ฮิตก็เป็นการตัดเกรด 80 มากกว่าเท่ากับได้ A, 70 -\u0026gt; B, 60 -\u0026gt; C, 40 -\u0026gt; D และต่ำกว่า 40 ได้ F\nโดยรูปแบบการเขียนก็มี 3 แบบ\n1. if condition ถ้า if เป็นจริงก็ทำ statement1\nif condition: statement 1  2. if-else condition ในส่วนของ if else ก็แปลตรงตัวเลยครับ ถ้า if เป็นจริงก็ทำ statement1 ถ้าไม่จริงก็ทำ statement2 ใน else\nif condition: statement 1 else: statement 2  3. if-elif-else condition ในส่วนนี้ก็ถ้า if เป็นจริงก็ทำ statement1 ถ้าไม่จริงก็ไล่ check ทีละ elif ถ้า codition ไหนเป็นจริงก็เข้าไปทำ statement นั้น โดย elif จะมีมากกว่า 2 อันก็ได้ สุดท้ายถ้าไม่มี condition ไหนที่เป็นจริงเลยก็ทำ else\nif condition 1: statement 1 elif condition 2: statement 2 elif condition 3: statement 3 else: statement 4  มาดูโค้ดตัดเกรดกันครับ\nscore = int(input()) if score \u0026gt;= 80: print(\u0026quot;You got A\u0026quot;) elif score \u0026gt;= 70: print(\u0026quot;You got B\u0026quot;) elif score \u0026gt;= 60: print(\u0026quot;You got C\u0026quot;) elif score \u0026gt;= 40: print(\u0026quot;You got D\u0026quot;) else: print(\u0026quot;You got F\u0026quot;)  While Loop เป็นการทำอะไรที่ต้องวนหลายๆรอบจน กระทั่ง เงื่อนไขที่ตั้งไว้เป็น False เช่น ให้แสดงเลข 1 ถึง n\nn = int(input()) i = 1 while i \u0026lt;= n: print(i) i += 1  จากโค้ดข้างบนเราจะเห็นว่ามีการตั้ง Condition ไว้ว่า ถ้า i \u0026lt;= n ก็ยังให้ loop ทำงานอยู่ ซึ่งในการทำงานแต่ละรอบ ค่า i ก็จะถูกเพิ่มค่าทีละ 1 เราจะเห็นว่าเมื่อค่า i เพิ่มค่าเป็น n+1 Loop ก็จะไม่ทำงาน\nFor Loops การทำงานคล้ายๆ กับ while loop ต่างกันที่ for มีการกำหนดตัวแปร และเพิ่มค่าตรงส่วนของ Condition เลย โดยการเขียน for มีลักษณะ ดังนี้\n# Loop 1 for i in range(start, stop, step): statement # Loop 2 for i in range(start, stop) statement  อันนี้เป็นการสรุปคร่าวๆนะครับ เนื่องจากว่าช่วงนี้ต้องสอน Python ในรุ่นน้องด้วยเวลาที่จำกัดก็เลยลองเขียนบทความนี้ขึ้นมา เดี๋ยวจะมาอัพเดทเรื่อยๆครับ\nที่มาบทความ : skconan.com.  "});index.add({'id':25,'href':'/library/tutorials/docs/python/pythonthailand/','title':"Python Thailand",'content':" Python Thailand Python Thailand - แหล่งเรียนรู้ภาษาไพธอนสำหรับคนไทย print(\u0026quot;Hello Thai Pythonista!\u0026quot;)  ยินดีต้อนรับเข้าสู่ Python Thailand เว็บไซต์ที่เปรียบเสมือนเป็นประตูบานแรกสำหรับคนที่ต้องการก้าวเข้ามาสู่จักรวาลของภาษาไพธอน เว็บไซต์นี้ได้รวบรวมแหล่งข้อมูลที่เกี่ยวข้องกับภาษาไพธอนที่ถูกเขียนขึ้นในภาษาไทย ไม่ว่าจะเป็นทั้งการสอนไพธอน เว็บบล็อกไพธอน รวมถึงวิดีโอที่เกี่ยวกับไพธอนต่าง ๆ ไพธอนนั้นมีประโยชน์มากมาย ไพธอนเปรียบเสมือนไม้กายสิทธิ์ที่สามารถช่วยให้เราสร้างสรรค์นวัตกรรมหรือสิ่งใหม่ ๆ ให้กับมวลมนุษยชาติได้\nด้วยเนื้อหาที่รวบรวมในเว็บไซต์นี้ คุณจะสามารถเขียนโปรแกรมด้วยภาษาไพธอนได้ เริ่มตั้งแต่การสร้างแอพพลิเคชันอย่างง่ายไปจนถึงโปรแกรมการคำนวณที่ซับซ้อน คุณจะเข้าใจหลักการสำคัญในการเขียนโปรแกรมทั้งในพื้นฐานทั้งหมดและในขั้นสูงที่เป็นการเขียนโปรแกรมแบบเชิงวัตถุ คุณจะได้รู้จักกับเครื่องมือที่ใช้ในการพัฒนาโปรแกรมหลากหลายรูปแบบ ซึ่งเนื้อหาเหล่านี้เป็นพื้นฐานที่สำคัญที่จะทำให้คุณสามารถนำไปพัฒนาทักษะการเขียนโปรแกรมภาษาไพธอน ของคุณในขั้นสูงต่อไป เช่น การพัฒนาเว็บไซต์ การสร้างเกม ฐานข้อมูล เน็ตเวิร์ค การจัดการกราฟฟิค\nภาษาไพธอน  ประวัติและต้นกำเนิด ตราสัญลักษณ์ของภาษาไพธอน ปรัชญาของไพธอน เกร็ดความรู้เกี่ยวกับไพธอน ทำไมต้องไพธอน ความสำเร็จของไพธอน   ดาวน์โหลดไพธอนและเครื่องมืออื่น ๆ  เริ่มต้นใช้งานไพธอน ระบบปฏิบัติการที่รองรับ ดาวน์โหลดไพธอน การติดตั้งไพธอน โปรแกรมแก้ไขข้อความสำหรับเขียนภาษาไพธอน ไลบรารี่และแพคเกจ   เนื้อหาไพธอน เลือกระดับความยากของเนื้อหา\n เริ่มต้น (Beginner) ปานกลาง (Intermediate) ขั้นสูง (Advanced)   โจทย์และการแก้ปัญหา  ระดับพื้นฐาน ระดับปานกลาง ระดับยาก โจทย์แข่งขัน คำถามสอบสัมภาษณ์งาน   หนังสือแนะนำ  Python ๑๐๑ คณะวิศวกรรมศาสตร์ จุฬา ฯ เชี่ยวชาญการเขียนโปรแกรมด้วยไพธอน ผศ.ดร. สุชาติ คุ้มมะณี Text books ต่างประเทศอื่น ๆ ที่แนะนำ   แชนแนลยูทูปแนะนำ  SIPA programming prasertcbs Kong Ruksiam Piyanop Nuchanat AI บ้านบ้าน Rangsiman Uncle Engineer   ทอล์คและพอดแคสต์น่าสนใจ  PyCon Thailand 2019 PyCon Thailand 2018 ทำไมเราต้องเรียน Python (ไพธอน) by CodeKids อื่น ๆ   บทความ แบ่งตามหมวดหมู่\n ทั่วไป การพัฒนาเว็บไซต์และอินเทอร์เน็ต การพัฒนาซอฟต์แวร์ การพัฒนาแอพพลิเคชันแบบ Desktop GUI การประยุกต์ใช้ทางคณิตศาสตร์และวิทยาศาสตร์ การประยุกต์ใช้ทางการศึกษา การประยุกต์ใช้ทางศิลปะ การประยุกต์ใช้ทางภาษา การประยุกต์ใช้ทางธุรกิจ เกมส์และ 3D กราฟฟิก ปัญญาประดิษฐ์ (AI) การเรียนรู้แบบลึก (DL) การเรียนรู้ของเครื่องจักร (ML) การจัดการและการเข้าถึงฐานข้อมูล การวิเคราะห์ข้อมูล การประมวลผมภาพ การประยุกต์ใช้ทางมัลติมีเดีย   ผลงานของคนไทยที่สร้างสรรค์ด้วยไพธอน  PyThaiNLP   ชุมชนและสื่อออนไลน์  Python-Thailand สมาคม Python Dev แห่งประเทศไทย ThaiPy Bangkok Thailand Machine Learning \u0026amp; Artificial Intelligence Data Science BKK Colab Thailand เขียนงูให้วัวกลัว   งานประชุมและสัมมนา  PyCon Thailand ThaiPy Bangkok Meetup Code Mania TECHJAM PySomTum   แหล่งเรียนรู้ต่างประเทศ  คอร์สเรียนฟรีไพธอนของต่างประเทศที่น่าสนใจ   ฟอรั่ม  Python Wiki Python Forum r/learnpython/   เบ็ดเตล็ด  เอกสารรวบรวมคำสั่ง   ร่วมเป็นหนึ่งในทีมพัฒนา ใครที่สนใจพัฒนาเว็บไซต์ไม่ว่าจะเป็นการอัพเดทเนื้อหาใหม่หรือการแก้ไขปรับปรุงเนื้อหาเดิมให้มีความถูกต้องมากขึ้น สามารถดูรายละเอียดเพิ่มเติมได้ที่นี่ หรือติดต่อมาทางผู้พัฒนาได้ตามช่องทางต่อไปนี้\n เพจ สมาคม Python Dev แห่งประเทศไทย กลุ่ม Python-Thailand GitHub https://github.com/python-thailand  "});index.add({'id':26,'href':'/library/tutorials/docs/python/snippets/','title':"Snippets",'content':" Python Snippets Table of Content  all_equal all_unique average average_by bifurcate bifurcate_by byte_size camel capitalize capitalize_every_word cast_list chunk clamp_number compact compose compose_right count_by count_occurences curry decapitalize deep_flatten degrees_to_rads delay difference difference_by digitize every every_nth factorial fibonacci filter_non_unique filter_unique find_parity_outliers flatten function_name gcd group_by has_duplicates head in_range initial initialize_2d_list initialize_list_with_range initialize_list_with_values intersection intersection_by is_anagram is_divisible is_even is_odd kebab keys_only last lcm longest_item map_values max_by max_element_index max_n median min_by min_n most_frequent n_times_string none offset palindrome rads_to_degrees reverse_string sample shuffle similarity snake some split_lines spread sum_by symmetric_difference symmetric_difference_by tail transpose unfold union union_by unique_elements values_only when zip  "});index.add({'id':27,'href':'/library/tutorials/docs/articles/webapp/django/start-django-framework/','title':"Start Web Application",'content':" เริ่มพัฒนา Web Application กับภาษา Python ด้วย Django Framework ภาษา Python เริ่มถูกใช้งานอย่างแพร่หลายมากขึ้นเรื่อยๆ ในช่วงนี้เนื่องจากความง่ายในการเรียนรู้ และความสะดวกในการทดสอบโปรแกรม เนื่องจาก Python เป็นภาษาประเภท Script ซึ่งจะแตกต่างกับภาษาประเภท Java หรือ C ที่ต้อง compile code ให้ออกมาเป็น binary ก่อนนำไปรันได้จริง เช่น หากต้องการทดสอบ function substring ว่าจะสามารถตัดคำให้เราถูกต้องหรือไม่ กรณีใช้ภาษา Java หรือ C ก็ต้องเขียน class, main function หรืออื่นๆ อีกมากมายกว่าจะเริ่มทดสอบ function เล็กๆ นี้ได้ แต่ใน Python นั้น เพียงแค่เข้า Python console ก็สามารถทดสอบ function เหล่านี้ได้ทันที\nDjango (อ่านว่าจังโก้ หรือแจงโก้ โดยไม่ออกเสียงตัว D) เป็น framework ที่ใช้ในการสร้าง Web Application ในฝั่งของ Back End ที่พัฒนาด้วยภาษา Python โดยในตัว framework จะมีส่วนประกอบทุกอย่างที่จำเป็นตั้งแต่การเชื่อมต่อฐานข้อมูล ไปจนถึงการ render ข้อมูลออกมาให้ฝั่ง Front End แสดงผลข้อมูลเหล่านั้นได้ ซึ่ง framework ในรูปแบบนี้ในภาษาอื่นๆ เช่น Ruby on rails สำหรับภาษา Ruby, Play Framework สำหรับภาษา Java หรือ Scala, Groovy on Grails สำหรับภาษา Groovy, Laravel สำหรับภาษา PHP, หรือ Express สำหรับภาษา Javascript ของ Node.js เป็นต้น ซึ่งข้อมูลที่อ้างอิงมาจาก www.hotframeworks.com จะเห็นว่า Django มีการใช้งานอย่างแพร่หลายมาก\nWeb Frameworks Popularity Ranking อ้างอิงจาก www.hotframeworks.com\nบทความนี้จะเป็นการสอนพัฒนา Web Application ด้วย Django Framework โดยโปรแกรมตัวอย่างในที่นี้คือ โปรแกรมห้องสมุด ซึ่งโปรแกรมเราจะทำหน้าที่บันทึกหนังสือเข้าในห้องสมุดที่สร้างขึ้น ซึ่งเราจะใช้ Python version 3 และ Django version 1.11.5 ซึ่งเป็น version ล่าสุดขณะเขียนบทความนี้\nสารบัญ การติดตั้ง Python และ Django\nสร้าง Django Project\nสร้าง Django Application\nDjango Template\nการเชื่อมต่อฐานข้อมูล\nDjango Shell\nDjango admin site\nการติดตั้ง Python และ Django  ติดตั้ง Python\n สำหรับ Windows สามารถ Download ได้จาก ที่นี่ ** สำคัญมากต้องติ๊กช่อง “Add python 3.X to PATH” ด้วย\n สำหรับ Linux version ใหม่ๆ จะมี python3 ติดตั้งมาให้ โดย default อยู่แล้ว\n สำหรับ Mac สามารถทำตาม Tutorial นี้ เพื่อติดตั้งได้\nหลังจากติดตั้งแล้วบน Windows พิมพ์คำสั่ง $ py\nบน Linux, Mac พิมพ์คำสั่ง $ python3\nจะต้องได้หน้า python console ออกมาเหมือนในรูปด้านล่างนี้   ตัวอย่าง Python3 console\n ติดตั้ง pip3\npip3 คือ package manager ที่ใช้สำหรับติดตั้ง package เสริมให้กับ Python3 (คล้ายๆ คำสั่ง apt-get บน linux) โดยเราจะใช้ pip ในการติดตั้ง Django ต่อไป\n สำหรับ Windows คำสั่ง pip จะถูกติดตั้งมาอยู่แล้วบน python version 3.5 ขึ้นไป\n สำหรับ Linux ติดตั้งด้วยคำสั่ง $ sudo apt-get install python3-pip\n สำหรับ Mac ทำตาม Link ด้านบนเพื่อติดตั้ง pip3\nเมื่อติดตั้งเสร็จสิ้นทดสอบด้วยการพิมพ์คำสั่ง $ pip3 ใน console\n ติดตั้ง Django\nพิมพ์คำสั่ง $ pip3 install django==1.11.5\nแล้ว pip3 จะ download django เข้ามาติดตั้งในเครื่องให้โดยอัตโนมัติ\n  ตัวอย่างการติดตั้ง Django\n ตรวจสอบการติดตั้ง โดยพิมพ์คำสั่ง $ django-admin ตามรูปด้านล่าง  ตัวอย่างการเรียกคำสั่ง django-admin เพื่อแสดง Django version ที่ติดตั้ง\nNOTE: สำหรับ Linux user อาจเจอ Error\n The program ‘django-admin’ is currently not installed. You can install it by typing:\nsudo apt install python-django-common\n ซึ่งหมายความว่าคำสั่ง django-admin ยังไม่ได้อยู่ใน PATH environment variable ให้ค้นหา Path ของ django-admin ด้วยคำสั่ง $ find / -name django-admin.py\nซึ่งโดยปกติแล้ว path จะอยู่ที่ /home//.local/bin/django-admin.py เช่น\nตัวอย่างการเรียกคำสั่ง django-admin บน Linux\nสร้าง Django Project Browse ไปยัง Folder ที่ต้องการเก็บ project จากนั้น เริ่มสร้าง project ชื่อ “my_library” (ห้องสมุดของฉัน) ด้วยคำสั่ง\n$ django-admin startproject my_library  จะทำให้ได้โฟลเดอร์ my_library ซึ่งด้านในจะเก็บไฟล์ project ของ Django ดังนี้\nโครงสร้างโฟลเดอร์ของ Django Project\n manage.py คือไฟล์ script สำหรับรันคำสั่งต่างๆ ที่เกี่ยวข้องกับ Django โดยปกติไฟล์นี้จะไม่ถูกแก้ไขใด ๆ ทั้งสิ้น init.py คือไฟล์ว่างๆ (ลองเปิดด้วย text editor ดูได้นะครับ) ไฟล์นี้มีไว้เพื่อให้ภาษา Python รู้ว่าโฟลเดอร์ที่อยู่นี้เป็นโฟลเดอร์ที่ใช้เก็บ Python Package โดยปกติไฟล์นี้จะถูกปล่อยเป็นไฟล์ว่าง ๆ ไว้แต่เราสามารถใส่ Python script เข้าไปได้เช่นกันแต่จะไม่ขอพูดถึงรายละเอียดในส่วนนี้ในบทความนี้ โดยรายละเอียดเพิ่มเติมของไฟล์นี้สามารถศึกษาได้จาก ที่นี่ settings.py คือไฟล์ที่ใช้เก็บ configuration ทั้งหมดของ project เอาไว้ เช่น การตั้งค่า Database, Timezone, Logging เป็นต้น ซึ่งค่าที่เก็บในนี้จะอยู่ในรูปแบบ key — value ซึ่งไฟล์นี้จะเป็นไฟล์แรกที่ Django เข้ามาอ่านเมื่อเริ่มการทำงานของ web server urls.py คือไฟล์ที่ใช้เก็บการ routing ของ HTTP request ซึ่งจะกล่าวถึงในหัวข้อถัดไป wsgi.py คือไฟล์ที่ใช้เก็บข้อมูลของ Django project ของเรา ใช้สำหรับการ deploy project เมื่อต้องการเชื่อมต่อกับ Web Server สำหรับรายละเอียดการ deploy สามารถอ่านเพิ่มเติมได้ ที่นี่ หรือ ที่นี่  ทดลองรัน Django Project ที่ port 8000 ด้วยคำส่ัง\n$ py manage.py runserver 0.0.0.0:8000  หรือ สำหรับ Linux ให้รันคำสั่ง\n$ python3 manage.py runserver 0.0.0.0:8000  ตัวอย่างการรัน Django project ครั้งแรก\nซึ่งคำสั่งที่ใช้จะแบ่งเป็น\nคำสั่งที่ใช้สั่งรัน Django Project\n py manage.py คือการสั่งรัน Python script ในไฟล์ manage.py ซึ่งเป็นคำสั่งเริ่มต้นในการรัน Django command ทุกคำสั่ง runserver คือ parameter เพื่อบอกว่าต้องการ start web server ขึ้นมา 0.0.0.0:8000 คือ parameter ของ web server ที่เราจะสร้างขึ้นมา โดย 0.0.0.0 หมายถึงให้ web server ของเรา bind กับทุก ๆ IP ในเครื่องของเรา และ 8000 คือ port ที่ต้องการรัน  หลังจากรัน Django project สำเร็จ สามารถทดลองใช้ web browser เปิดเข้าหน้าเวปของเราได้ที่ http://localhost:8000 จะได้ผลลัพธ์ตามภาพด้านล่าง\nหน้า web ที่เห็นหลังจากสร้าง Django project และรันสำเร็จ\nการรันคำสั่ง runserver จะส่งผลให้ Django ไปอ่าน configuration ในไฟล์ settings.py แล้วเริ่ม start web server ด้วย configuration เหล่านั้น โดยค่า config ที่อยู่ในไฟล์ settings.py มีรายละเอียดดังต่อไปนี้\n BASE_DIR คือตัวแปรที่เก็บ absolute path ไปหา Django project ของเรา ซึ่งโดยปกติข้อมูลส่วนนี้จะถูกเขียนอยู่ในรูปแบบของ Python script ที่ใช้อ้าง path มาถึงไฟล์ settings.py ตัวนี้ (สามารถทดลองโดยการ copy code ดังกล่าวมา save ไว้ในไฟล์ python ที่สร้างมาใหม่แล้วลองรันดูผลลัพธ์ได้) SECRET_KEY คือตัวแปรที่ใช้เก็บ hash text ใช้สำหรับการเข้ารหัสสิ่งต่าง ๆ ใน Django project เช่น session, cookies, password เป็นต้น ดังนั้นจึงไม่ควรเปลี่ยนค่านี้ และเก็บไว้เป็นความลับไม่ copy ไปแสดงในที่อื่น (โดยปกติค่านี้จะไม่ถูกแก้ไขหรือใช้งานอยู่แล้ว จะถูกใช้งานโดยอัตโนมัติเอง) DEBUG คือตัวแปรที่ใช้บอก Django ว่ารันใน mode debug หรือไม่ ซึ่งใน mode debug นี้ Django จะแสดง Error stack traceทั้งหมดออกมาในหน้าจอ web browser เพื่อให้ developer เห็นบรรทัดที่ code error แล้วเข้าแก้ไขได้ทันที ALLOWED_HOSTS คือตัวแปรที่ใช้เก็บชื่อ domain name ของ web site เรา โดยจะเก็บในรูปแบบ list ของ string เช่น [‘www.mylibrary.com’, ‘128.199.148.2XX’] เหตุผลที่ต้องระบุชื่อของ host อย่างเจาะจงเพื่อนำไปสร้าง host header ใน HTTP request เพื่อใช้ป้องกัน Cross Site Scripting attack ที่มีการส่ง host ปลอมมาหลอก server เราได้ INSTALLED_APPS คือตัวแปรที่ใช้เก็บ Django Application ทั้งหมดที่ project นี้จะรู้จัก ซึ่งโดย default Django จะ add default Django Application บางตัวเข้ามาอยู่แล้ว MIDDLEWARE คือ plugin ที่ถูกใช้งานโดย Django เพื่อใช้ในงานด้านต่าง ๆ เช่น django.contrib.auth.middleware.AuthenticationMiddleware ถูกใช้สำหรับการจัดการ user ที่ authenticated กับระบบเข้ากับ HTTP request โดยผ่านทาง session ที่ user นั้น ๆ login อยู่เป็นต้น ซึ่งโดยปกติ Django จะมีการ add middleware ที่จำเป็นมาให้อยู่แล้ว ROOT_URLCONF คือตัวแปรที่ใช้เก็บ path ไปหาไฟล์ urls.py ซึ่งเป็นไฟล์แรกที่ Django เริ่มทำงานเมื่อได้รับ HTTP request TEMPLATES คือตัวแปรที่เก็บ configuration ของ Template โดย Template คือสิ่งที่รับผิดชอบในการ render หน้าเวป HTML + javascript ออกมาแล้วส่งกลับไปให้ web browser ซึ่งจะกล่าวถึงในหัวข้อถัดไป WSGI_APPLICATION คือตัวแปรที่ใช้เก็บ path ไปหาตัวแปร wsgi application ซึ่งถูกใช้ในการ deploy ระบบใน environment จริง เมื่อต้องการเชื่อมต่อ Django เข้ากับ web server ต่าง ๆ DATABASES คือตัวแปรที่เก็บ configuration ต่าง ๆ ของ ฐานข้อมูล เช่น ชนิดของฐานข้อมูล, username, password, ชื่อ database เป็นต้น โดย default Django จะใช้ sqlite3 ซึ่งเป็นฐานข้อมูลชนิดไฟล์ในการทำงาน LANGUAGE_CODE คือตัวแปรที่ใช้เก็บภาษา default ที่ระบบจะแสดงผล TIME_ZONE ใช้เก็บ timezone ตามปกติ USE_I18N คือตัวแปรที่ใช้บอกว่าระบบรองรับ I18N (Internationalization)หรือไม่ ซึ่ง I18N คือระบบการแปลภาษาในหน้าเวปไซด์ให้รองรับหลาย ๆ ภาษา หลักการทำงานคือ Django จะสร้างไฟล์ขึ้นมาเป็น list ของ text ทั้งหมดในหน้าเวปเรา แล้วให้เราแปล text เหล่านี้ให้อยู่ในภาษาอื่น ๆ เท่าที่เราต้องการจะ support แล้ว Django จะนำ text ที่แปลแล้วมาแสดงแก่ผู้ใช้งานอีกทีหนึ่ง USE_L10N คือตัวแปรที่บอกว่า web server ของเรา support L10N (Localization) หรือไม่ ซึ่ง L10N จะแตกต่างกับ I18N คือ I18N จะครอบคลุมถึงการแปลภาษาบนหน้าจอเท่านั้น ส่วน L10N จะมีส่วนไปถึงการแสดงผลต่าง ๆ เช่น รูปแบบการแสดงวันที่, การแสดงหน่วยของเงิน เป็นต้น USE_TZ คือตัวแปรที่ใช้เก็บว่า web server รองรับ Time zone หรือไม่ หากตั้งค่าเป็น false ระบบจะไม่สนใจค่า time zone และใช้เวลาตามเครื่อง server เป็นหลักโดยไม่มีการทดเวลา เหมาะสำหรับการพัฒนาเวปไซด์ที่มีผู้ใช้งานเป็นคนไทย และไม่จำเป็นต้องใช้กับต่างประเทศ STATIC_URL คือตัวแปรที่ใช้เก็บ web url ไปยัง folder ที่ใช้เก็บ static ไฟล์ต่าง ๆ เช่น http://www.mylibrary.com/static/ เป็นต้น STATIC_ROOT ตัวแปรนี้ไม่ได้ถูกสร้างมาโดย default เป็นตัวแปรที่ใช้สำหรับเก็บ path ที่เราไว้เก็บไฟล์ static ต่าง ๆ เช่น ไฟล์ javascript หรือ css  สร้าง Django Application Django framework แนะนำให้แบ่งการพัฒนา web application ของเราออกเป็น module ย่อย ๆ แทนที่จะเก็บใน folder project ใหญ่ ๆ เพียงตัวเดียว โดย module ย่อย ๆ เหล่านี้เรียกว่า Django Application ซึ่งข้อกำหนดในการแบ่ง Django Application นั้น ไม่มีแบบแผนที่ตายตัว ขึ้นอยู่กับความเหมาะสมของแต่ละ project เช่น project my_library (ห้องสมุดของฉัน) อาจสามารถแบ่ง Django Application ออกเป็น\n book_management ใช้สำหรับจัดการหนังสือในห้องสมุด เช่น การลงทะเบียนหนังสือ, การค้นหาหนังสือ, การจัดการยืมคืน เป็นต้น human_resource ใช้สำหรับจัดการพนักงานที่ทำงานในห้องสมุดแห่งนี้ เช่น การลงทะเบียนพนักงาน, การจัดกะการทำงาน, การลงเวลาเข้าออกพนักงาน account ใช้สำหรับเก็บบัญชีรายรับ, รายจ่ายของห้องสมุดแห่งนี้ เป็นต้น  สำหรับคำสั่งที่ใช้ในการสร้าง Django Application ที่ชื่อ book_management คือ\n$ py manage.py startapp book_management  โครงสร้างโฟลเดอร์ของ Django Application\nโดยแต่ละไฟล์จะค่อย ๆ อธิบายผ่านบทความนี้ไปเรื่อย ๆ ครับ\nความต้องการขั้นต่ำที่สุดของ Django คือไฟล์ urls.py และ views.py\nเริ่มจากไฟล์ views.py เป็นไฟล์ที่ใช้เก็บ logic ของ web application คอยควบคุมสิ่งที่รับมาจาก client web browser (HTTP parameters ต่าง ๆ) และควบคุมสิ่งที่จะตอบกลับไปยัง client web browser\nทดลองเปิดไฟล์ views.py ด้วย text editor แล้วเพิ่ม function ลงไปครับ\nตัวอย่างไฟล์ views.py\nจากนั้นแก้ไขไฟล์ urls.py ให้เป็นดังรูป\nตัวอย่างไฟล์ urls.py\nจากนั้นรัน Django อีกครั้ง แล้วเปิด web browser แล้วเข้าหน้าเวป http://localhost:8000/my_index/ จะเห็นว่าหน้าจอที่แสดงผลเปลี่ยนเป็นดังรูปด้านล่างนี้\nตัวอย่างหน้า Web Page แรก\nสิ่งที่เกิดขึ้นภายในการทำงานของ Django สามารถอธิบายได้ด้วยภาพดังต่อไปนี้\nการทำงานของ Django เมื่อได้รับ HTTP Request จาก Web Browser\nเมื่อได้รับ HTTP Request จาก Web Browser มาแล้ว Django จะเริ่มทำงานโดยเริ่มจากไฟล์ urls.py ซึ่งหน้าที่หลักของไฟล์นี้คือการทำ URL Pattern Matching เพื่อดูว่า user request มาที่ URL อะไร จากนั้นจึงค่อยเรียก Python Script ที่ถูก match เพื่อขึ้นมาทำงาน\nอธิบายการทำงานของ urls.py\nจากรูปจะเห็นว่าข้อมูลใน urls.py ถูกแบ่งออกเป็นสองส่วนนั่นคือ\n r’^my_index/$’ ส่วนนี้เป็น String ที่ใช้ระบุถึง Regular Expression ที่จะใช้ match กับ URL ที่ผู้ใช้กรอกมาใน Web Browser\nNOTE: ตัว r ด้านหน้า String ใน Python หมายถึง “Raw String Literal” คือให้มอง String ทั้งหมดโดย ignore สัญลักษณ์พิเศษ นั่นคือ backslash () ทำให้ Python มอง backslash ว่าเป็นตัวอักษรธรรมดาตัวหนึ่งไม่ใช่ escape character ดังนั้น r’\\n’ จะไม่มีผลให้ขึ้นบรรทัดใหม่แต่จะหมายถึงตัวอักษรว่า \\n จริง ๆ views.index คือ Python Script ที่อ้างไปถึงไฟล์ views.py ในโฟลเดอร์ book_management และไปยัง function ที่ชื่อ index ซึ่งจะเห็นว่าในไฟล์ views.py จะมีการเรียก function HttpResponse() เพื่อ return HTML text กลับไปแสดงผลบนหน้าจอ  อธิบายการทำงานไฟล์ views.py\n เป็นส่วนที่ใช้ import function ชื่อ render และ HttpResponse เข้ามาใช้งานใน Script ของเรา การประกาศ function ของ Python เป็น function ชื่อ index โดยรับ parameter เป็น request ซึ่ง parameter นี้มีชนิดตัวแปรเป็น HttpRequest Object ซึ่งภายในตัวแปรนี้จะเก็บข้อมูลต่าง ๆ ของ HTTP เอาไว้ เช่น HTTP parameter, method, content type, body, หรือ path เป็นต้น ประกาศตัวแปรชนิด HttpResponse ซึ่งจากตัวอย่างเราจะส่ง body ของ response เป็น HTML ง่าย ๆ กลับไปแสดงผลยัง Web Browser  Django Template จากตัวอย่างในหัวข้อก่อนหน้าจะเห็นว่าเราสามารถส่ง HTML กลับไปยัง Web Browser ได้โดยผ่านทาง views.py แต่หากเราต้องการส่งหน้า HTML ที่มีความซับซ้อนมากกว่านี้ เช่น มีการแนบไฟล์ Javascript, CSS, หรือภาพ หรือแม้แต่หน้า web site แบบ AngularJS หรือ React กลับไปแสดงผลบน Web Browser จะมีความยุ่งยากมากหากใช้วิธีนี้่ที่ต้องเปลี่ยน library เหล่านั้นเป็น text เพื่อกลับไปแสดงผล ซึ่ง Django มีวิธีที่ใช้ในการส่งหน้า Web Page ที่มีความซับซ้อนโดยผ่านทาง Template Engine\nตัวอย่างอธิบายการทำงานของ Django Template\nจากรูปจะเห็นว่าในการทำงานของ Template นั้นเริ่มจากทางผู้พัฒนาต้องสร้างไฟล์ HTML Template ขึ้นมา ซึ่งสิ่งทีทำให้ไฟล์ HTML นี้ต่างจากไฟล์ HTML ทั่วไปคือจะมีการฝัง Django Tag เข้าไปด้วย โดยในตัวอย่างคือการใช้ {{var1}} หมายถึงการสร้างตัวแปรของ Django ขึ้น จากนั้นเมื่อ Django โหลดไฟล์ Template นี้ขึ้นมาสามารถ pass ค่า ของตัวแปรเข้าไปสู่ไฟล์นี้ได้ หลังจากนั้นจึงได้ไฟล์ HTML ที่สมบูรณ์พร้อมส่งกลับไปแสดงผลยัง Web Browser ต่อไป\nDjango Tag ที่สามารถใช้งานได้มีหลากหลาย เช่น การส่งผ่านตัวแปรธรรมดาดังตัวอย่างด้านบน, การใช้ if/else, การใช้ for loop ซึ่งรายละเอียดของ Django Tag ทั้งหมดสามารถ อ่านเพิ่มเติมได้ที่นี่\nเริ่มการทดลองนี้โดยการสร้าง Folder Template และสร้างไฟล์ index.html\nสร้างโฟลเดอร์ชื่อ templates และสร้างไฟล์ index.html ในนั้น\ncode ในไฟล์ index.html\nจากนั้นแก้ไขไฟล์ settings.py โดยการเพิ่ม ค่าให้กับตัวแปร DIRS ที่อยู่ภายใต้ TEMPLATES configuration ซึ่ง DIRS จะเป็นตัวบอกว่าไฟล์ HTML template ของเราถูกเก็บไว้ที่ไหนบ้าง\nไฟล์ settings.py ที่ถูกแก้ไขเพื่อให้ Django รู้จัก Folder Template\nจากนั้นแก้ไขไฟล์ views.py โดยเพิ่มเติม code ดังต่อไปนี้\nไฟล์ views.py ที่ใช้ในการโหลด HTML Template ชื่อ index.html แล้วผ่านค่าตัวแปร var1 ลงไป\n เพิ่ม import ตัวแปร loader ประกาศตัวแปรชื่อ header_str ให้เป็นชนิด String และมีข้อความดังปรากฎในรูป โหลด template ไฟล์ชื่อ index.html โดย Django จะพยายามไปหาจาก path ที่เรากรอกไว้ใน DIRS ประกาศตัวแปร context เป็นชนิด dictionary (dictionary คือ datatype ที่ใช้เก็บตัวแปรในรูปแบบของ key, value) โดยมีค่า key เป็น var1 ซึ่งเป็นชื่อตัวแปรที่ประกาศใน index.html และ value คือตัวแปร _headerstr เรียกฟังก์ชั่น render เพื่อ generate HTML ไฟล์ออกมาเพื่อส่งให้กับ Client  เปิด Web Browser แล้ว Browse ไปยัง http://localhost:8000/my_index/\nตัวอย่างผลลัพธ์ของหน้าจอ HTML\nเราสามารถย่อ code ที่ใช้ในการ load template ด้วยฟังก์ชั่น render ได้ดังรูปต่อไปนี้\nการเรียกใช้ฟังก์ชั่น render เพื่อย่อ code ที่ใช้ในการ load Django Template\nการโหลด Javascript, CSS, หรือรูปภาพมาใช้งานบนหน้า web page\nกรณีที่เราต้องการใส่ Javascript, CSS หรือรูปเข้าไปเพื่อแสดงผลในหน้าเวป สามารถทำได้โดยผ่าน static (ที่เรียกว่า static เพราะไฟล์ JS, CSS, images เป็นไฟล์ Library ที่คงที่ ไม่มีการเปลี่ยนแปลง) โดยการใช้งาน static feature ใน Django นั้นต้องเริ่มจากไฟล์ settings.py ตรวจสอบว่ามี 2 บรรทัดนี้อยู่ในไฟล์\nConfiguration ที่ทำให้เกิด Feature Static\nจากนั้นเพิ่ม Folder ชื่อ static ภายใต้ Folder book_management และสร้างไฟล์ style.css ขึ้นมา ซึ่ง Django จะไปหาไฟล์ static ตาม path static ที่อยู่ภายใต้ Django Application folder โดยอัตโนมัติ\nสร้างโฟลเดอร์ static และ style.css\nแก้ไขไฟล์ style.css โดยเพิ่มข้อความดังต่อไปนี้ (เป็นการเปลี่ยนพื้นหลังให้เป็นสีเหลือง)\nจากนั้นแก้ไขไฟล์ index.html โดยเพิ่มบรรทัดดังต่อไปนี้เข้าไป\n หมายถึงการ load library static ของ Django เข้าไปใน web browser การเรียกใช้ CSS ภายในหน้าเวป โดยให้สังเกตุ tag href จะมีการเรียกใช้ Django syntax ชื่อ static  จากนั้น browse ไปที่ http://localhost:8000/my_index/ จะได้ผลลัพธ์ดังต่อไปนี้\nภาพผลลัพธ์การ load static ไฟล์จาก Django\nจากตัวอย่างข้างต้นสามารถใช้วิธีเดียวกันนี้ไปประยุกต์ใช้กับการโหลด Javascript และรูปภาพได้ เช่น\n\u0026lt;img src=“{% static ‘background.png’ %}”/\u0026gt; เพื่อ โหลดรูปขึ้นมาแสดงผล \u0026lt;script src=“{% static ‘myscript.js’ %}”/\u0026gt; เพื่อโหลด Javascript Library เข้ามาใช้งาน  การเชื่อมต่อฐานข้อมูล การเข้าถึงฐานข้อมูลของ Django นั้นโดยทั่วไปจะไม่ใช้ SQL statement ตรง ๆ แต่จะถูกกระทำผ่านสิ่งที่เรียกว่า Object Relational Mappings (ORM) ซึ่ง ORM จะเป็นซ่อนคำสั่งของ SQL statement ทั้งหมดออกจากการพัฒนา แต่จะให้ผู้พัฒนาเข้าถึงฐานข้อมูลผ่านทาง class — object แทน (class/object เหมือนใน OOP ทั่วไป)โดย class จะเป็นตัวแทนของ Table ในฐานข้อมูล และ object จะเป็นตัวแทนของข้อมูลในฐานข้อมูล (Record)\nข้อดีของการใช้ ORM คือ syntax สามารถอ่านได้ง่ายกว่า SQL statement, และเราสามารถเปลี่ยนฐานข้อมูลได้โดยง่าย เช่น จากเดิมใช้ SQLite3 ต้องการเปลี่ยนเป็น MySQL หรือ Postgres ก็สามารถทำได้ทันที (อาจมีบางคำสั่งไม่ compatible กันซะทีเดียว ต้องมีการทดสอบให้ดีหลังเปลี่ยนฐานข้อมูลแล้วนะครับ)\nฐานข้อมูลที่จะใช้ในการทดสอบในครั้งนี้คือ SQLite3 ซึ่งเป็นฐานข้อมูลชนิดไฟล์ ซึ่งถูกตั้งค่าไว้เป็น default สำหรับ Django เราสามารถเปลี่ยนแปลงค่านี้ได้ทีหลังในไฟล์ settings.py\nไฟล์ settings.py แสดงการตั้งค่าฐานข้อมูล SQLite3 ซึ่งติดตั้งมาเป็นค่า default\nในหัวข้อนี้เราจะทดลองสร้างฐานข้อมูลที่เก็บข้อมูลของหนังสือ (Book) โดยหนังสือแต่ละเล่มจะถูกจัดอยู่ในหมวดหมู่ (Category) ต่างๆ ดังตัวอย่างต่อไปนี้\nตัวอย่างฐานข้อมูลที่ต้องการสร้าง\nซึ่งสามารถทำได้โดยการแก้ไขไฟล์ models.py ในโฟลเดอร์ book_management ดังต่อไปนี้\nตัวอย่างไฟล์ models.py สำหรับสร้างฐานข้อมูลที่มี table ชื่อ Book และ Category\n Import models object ซึ่งตัว models นี้เป็นพื้นฐานสำหรับการทำให้ class ของเรามีรูปแบบที่ ORM สามารถรู้จักได้ ประกาศ class ชื่อ Category ซึ่งสืบทอด (inherit) มาจาก class models.Model ส่วนนี้จะเป็นการบอกว่าให้สร้าง table ชื่อ Category ขึ้นในฐานข้อมูล ประกาศตัวแปรชื่อ name เป็นชนิด CharField มีความยาวสูงสุด 255 ตัวอักษร ส่วนนี้จะเหมือนกับการประกาศ Database Field ชื่อ name มีชนิดเป็น varchar 255 นั่นเอง ประกาศ class ชื่อ Book เป็นการสร้าง table ชื่อ Book ขึ้นมา ประกาศตัวแปร title เป็นชนิด CharField ประกาศตัวแปร publish_date เป็นชนิด date time ใช้เก็บวันที่ตีพิมพ์ ประกาศตัวแปร category เป็นตัวแปรที่มีความสัมพันธ์ Foreign Key ไปหา table Category โดย parameter ที่ชื่อ on_delete=models.CASCADE หมายถึงการบอกว่าหาก Category Object ถูกลบไป Django จะตามไปลบ Book ทุกตัวที่มี Reference ถึง Category นี้ด้วย  สำหรับรายละเอียดชนิดของตัวแปร (Database Field) ทั้งหมดที่ Django support สามารถอ่านเพิ่มเติมได้ ที่นี่\nแก้ไขไฟล์ settings.py เพื่อให้ Django project รู้ว่ามี Django Application ที่มีฐานข้อมูลได้โดยเพิ่ม ‘book_management’ เข้าไปในส่วนของ INSTALLED_APPS ดังแสดงในรูปด้านล่าง (อย่าลืมใส่ลูกน้ำ (,) ไว้หลังบรรทัด ‘django.contrib.staticfiles’ ด้วยนะครับ) โดยการเขียนอย่างนี้หมายถึงตัวแปร INSTALLED_APPS จะเป็นตัวแปรที่เก็บ list ของ string เอาไว้\nเพิ่ม Django Application ให้กับ Django Project รู้จัก\nในการสร้างฐานข้อมูลจริง ๆ นั้น Django จำเป็นต้อง generate script ออกมาชุดหนึ่ง เรียกว่า Migration File ไว้ใช้สำหรับการสร้างฐานข้อมูลจริง ประโยชน์ของ Migration File ทีสร้างขึ้นมานี้เพื่อให้ Django Application สามารถ track การเปลี่ยนแปลงของฐานข้อมูลได้ตลอดเวลาที่มีการเปลี่ยนแปลง models.py ซึ่ง Django สามารถเปลี่ยน schema ของฐานข้อมูลไปมาได้ หรือจะย้อนกลับไปใช้ schema เก่าได้อย่างง่ายดาย (ในความเป็นจริงหากฐานข้อมูลมีความซับซ้อนมาก ๆ กระบวนการย้อน schema กลับไปก็เป็นสิ่งที่ยากเหมือนกันครับ)\nการทำงานของ Django ORM เพื่อใช้สร้าง Database Schema\nโดยคำสั่งที่ใช้ในการสร้าง Migration File คือ\n\u0026gt; $ py manage.py makemigrations  ตัวอย่างการรันคำสั่ง makemigrations\nหลังจากรันคำสั่งนี้จะส่งผลให้เกิดไฟล์ใหม่ขึ้นมาภายใต้โฟลเดอร์ book_management/migrations คือไฟล์ 0001_initial.py\nสำหรับ Migration File ที่สร้างขึ้นมานี้หากลองเปิดดูจะเห็นว่าเป็นชุดคำสั่งของ Python ที่ใช้สำหรับเปลี่ยนแปลง Schema ในฐานข้อมูล โดยปกติแล้วผู้พัฒนาไม่จำเป็นต้องแก้ไขไฟล์นี้ แต่มีบางกรณีเช่นกันที่ต้องเข้ามาแก้ไข เช่น ต้องการลบ table A พร้อมกับย้ายข้อมูลบางส่วนไปยัง table B เป็นต้น\nจากนั้นสั่งให้ Django สร้างฐานข้อมูลด้วยคำสั่ง\n $ py manage.py migrate\n ตัวอย่างการรันคำสั่ง migrate เพื่อสร้างฐานข้อมูล\nหลังจากรันไฟล์นี้แล้วเราจะได้ไฟล์ใหม่ชื่อ db.sqlite3 ซึ่งเป็นไฟล์ฐานข้อมูลที่มี table ของ Book และ Category อยู่ภายใน และ Django จะทำการสร้าง Table Default อื่นๆ ขึ้นมาด้วย เช่น Table User, role สำหรับการทำ Authentication เป็นต้น\nโครงสร้างฐานข้อมูลที่ถูกสร้างขึ้นโดย Django\nDjango Shell Django Shell คือ python shell แบบหนึ่งซึ่งสามารถเข้าใช้งานฐานข้อมูลได้ ซึ่งเป็น feature ที่สะดวกมากในการเข้าตรวจสอบ debug ฐานข้อมูล หรือทดสอบใส่ข้อมูลเข้าไปในฐานข้อมูลโดยตรง โดยเราสามารถเข้าถึง Django Shell ด้วยคำสั่ง\n$ py manage.py shell  ตัวอย่าง Django Shell\nขั้นตอนต่อไปเป็นการ import table ของฐานข้อมูลให้กับ shell รู้จัก เพื่อเตรียมตัวทำงานกับ table เหล่านี้ต่อไป\nfrom book_management.models import Category, Book  จากนั้นทดลองสร้าง Category ของหนังสือ ชื่อ “Horror” ด้วยคำสั่ง\nhorror_category = Category(name=’Horror’) horror_category.save()  แสดงขั้นตอนการสร้าง Category Horror ในฐานข้อมูล\nจะเห็นว่าการสร้าง Record ใน Database Table นั้นสามารถทำได้อย่างง่าย คล้ายกับการสร้าง object ของ class ตามปกติ โดยในบรรทัดแรกจะเป็นคำสั่งที่ใช้ในการสร้าง object ชื่อ horror_category จาก class Category โดยมี parameter name เป็น Horror และบรรทัดที่สองคำสั่ง save() เป็นฟังก์ชั่นที่ให้ Django เปิดการเชื่อมต่อกับฐานข้อมูลและ save Record ลงฐานข้อมูลจริง\nทดสอบ Browse ฐานข้อมูลจริงเพื่อดูข้อมูลในฐานข้อมูล\nจากรูปจะเห็นว่าในฐานข้อมูลจริงนั้น Django ได้ใส่ Record ที่ชื่อ Horror เข้าไปในฐานข้อมูล และสังเกตุ Field ชื่อ id เป็น Field Default ที่ถูกสร้างขึ้นโดย Django เพื่อใช้เป็น internal key สำหรับเป็น primary key ของ table นี้ เนื่องจากในทุก ๆ table ในฐานข้อมูล Django จะบังคับให้มี primary key อย่างน้อย 1 ตัว ดังนั้นหากเรากำหนด primary key ตอนประกาศ class จะทำให้ Field id นี้หายไป\nทดลองดึงข้อมูลออกจากฐานข้อมูลด้วยคำสั่ง\n\u0026gt; c_list = Category.objects.filter(name=’Horror’) \u0026gt; c_list[0].name  ผลลัพธ์การดึง Category ออกจากฐานข้อมูล\n ประกาศตัวแปรชื่อ c_list ไว้รอรับค่าจากการเรียกฟังก์ชั่น Category.objects จะ return object ชนิด Manager ออกมา ซึ่งเป็น object ที่ใช้เริ่มต้นในการทำ Database operation ต่าง ๆ ต่อไป ฟังก์ชั่น filter คือฟังก์ชั่นที่ใช้ในการค้นหาข้อมูลในฐานข้อมูล เทียบเท่ากับคำสั่ง SELECT ในภาษา SQL ธรรมดา ซึ่งจากในตัวอย่างเราสามารถแปลงเป็น SQL statement ได้ว่า SELECT * FROM Category WHERE name=’horror’ นั่นเอง สิ่งที่ return กลับมาจากฟังก์ชั่น filter คือ QuerySet object ซึ่งเป็น list ของ object (Record ในฐานข้อมูล) ที่ได้จากคำสั่งต่างๆ นั่นเอง สำหรับรายละเอียดคำสั่ง Query อื่น ๆ เช่น order_by, like สามารถอ่านเพิ่มเติมได้จาก ที่นี่  เราสามารถนำความรู้ที่ได้จากส่วนนี้มาใช้ร่วมกับไฟล์ template และ views.py เพื่อส่งผลลัพธ์ที่ได้จากฐานข้อมูลกลับไปให้ผู้ใช้งานได้เห็นได้ เริ่มจากทดลองแก้ไขไฟล์ templates/index.html ดังต่อไปนี้\nแก้ไขไฟล์ index.html เพื่อแสดงผลการนับ Category object และ Book object จากฐานข้อมูล\nจากนั้นแก้ไขไฟล์ views.py ดังต่อไปนี้\nไฟล์ views.py ที่แก้ไขเพื่อแสดงค่าการนับ Category และ Book ในฐานข้อมูล\n len() เป็น function build-in ของ Python โดยรับค่าตัวแปรเป็น list แล้วจะ return มาเป็นจำนวน element ทั้งหมดที่อยู่ใน list โดยจากตัวอย่างเราได้ส่งผลลัพธ์ของการ Query หรือ QuerySet เข้าไป ทำให้ len return ค่าของจำนวน Record ทั้งหมดใน QuerySet นี้ออกมา all() เป็น Manager Function ที่ใช้สำหรับ Select ทุกอย่างออกมาจาก Table ซึ่งจากคำสั่งด้านบนสามารถแปลงเป็น SQL Statement ได้ว่า SELECT * FROM Category นั่นเอง  จากนั้นทดลอง Browse หน้าเวปไปที่ http://localhost:8000/my_index/ จะได้ผลลัพธ์ดังรูปต่อไปนี้\nDjango admin site อีกหนึ่ง Feature เด่นสำหรับ Django คือหน้า Web Page ซึ่งเป็นหน้าสำหรับใช้ในการทำ Database CRUD operation (Create, Read, Update, Delete) เหมาะสำหรับใช้เป็นหลังบ้านสำหรับ Web Admin ใช้บริหารงานต่าง ๆ โดยไม่ต้องเข้าถึงฐานข้อมูลโดยตรง หรือสามารถใช้ในการ debug ข้อมูลได้อย่างรวดเร็วอีกด้วย และยิ่งไปกว่านั้น Django Admin ยังสามารถปรับแต่งแก้ไขให้แสดงรายละเอียดตามที่ต้องการได้หลากหลาย เช่น ต้องการใส่ search box, ใส่ filter เปลี่ยนการแสดงผล เช่น Object Book ต้องการแสดงแค่ชื่อของหนังสือเพียงอย่างเดียว เป็นต้น\nการใช้งาน Django Admin นั้นขอให้ตรวจสอบไฟล์ settings.py และแก้ไขไฟล์ urls.py ให้มีค่าตามที่แสดงในรูปด้านล่างนี้\nไฟล์ settings.py โดยปกติค่าเหล่านี้จะใส่มาให้โดย default อยู่แล้ว\nไฟล์ urls.py แก้ไขโดยเพิ่มบรรทัดที่ highlight ด้วยกรอบสีแดงทั้งสองบรรทัด\nจากนั้นลองใช้ web browser เข้าไปที่ URL : http://localhost:8000/admin/ จะได้ผลลัพธ์ดังรูปต่อไปนี้\nจะเห็นว่าเรายังไม่สามารถเข้าใช้งานหน้า Admin ได้เนื่องจากติด Authentication ให้ทำการเพิ่ม user ด้วยคำสั่งดังรูปต่อไปนี้\nการสร้าง Super User เพื่อเข้าถึงหน้า Django admin site\nจากนั้นกลับไป Login เพื่อเข้าสู่หน้าจอ Django admin site\nจากรูปจะเห็นว่าเราสามารถแก้ไขได้เพียงแค่ Table ที่เกี่ยวกับ user และ group แต่จะไม่เห็น Table Book หรือ Category เนื่องจาก Django admin ยังไม่รู้จัก Table ทั้งสองของเรา ซึ่งเราสามารถทำให้ Django รู้จัก Table ของเราได้โดยผ่านทางไฟล์ admin.py\nแก้ไขไฟล์ admin.py โดยเพิ่ม สองบรรทัดนี้เข้าไป\nจากนั้นเปิดหน้า web admin ใหม่อีกครั้งจะเห็น Book และ Category ขึ้นมา\nจะเห็นว่าการแสดงผลของ Category จะพิมพ์คำว่า Category Object ออกมา เนื่องจาก Django ไม่ทราบว่าเมื่อ object ของ class Category ถูกแปลงเป็น String แล้วจะแสดงผลอย่างไร สามารถแก้ไขตรงนี้ได้โดยการ override function โดยการแก้ไขไฟล์ models.py ดังต่อไปนี้\nการประกาศฟังก์ชั่นภายใน class ของ python จะถูกบังคับให้ใส่ตัวแปรชื่อ self มาเสมอ ซึ่งตัวแปร self จะหมายถึง object ของตัวเอง (เหมือนกับ keyword “this” ใน java หรือ C#) ส่วนฟังก์ชั่นที่ประกาศเพิ่มคือ str จะเหมือนกับฟังก์ชั่น toString() ใน Java นั่นเอง\n Source :.\n "});index.add({'id':28,'href':'/library/tutorials/docs/backup/example/table-of-contents/with-toc/','title':"With ToC",'content':" Caput vino delphine in tamen vias Cognita laeva illo fracta Lorem markdownum pavent auras, surgit nunc cingentibus libet Laomedonque que est. Pastor An arbor filia foedat, ne fugit aliter, per. Helicona illas et callida neptem est Oresitrophos caput, dentibus est venit. Tenet reddite famuli praesentem fortibus, quaeque vis foret si frondes gelidos gravidae circumtulit inpulit armenta nativum.\n Te at cruciabere vides rubentis manebo Maturuit in praetemptat ruborem ignara postquam habitasse Subitarum supplevit quoque fontesque venabula spretis modo Montis tot est mali quasque gravis Quinquennem domus arsit ipse Pellem turis pugnabant locavit  Natus quaerere Pectora et sine mulcere, coniuge dum tincta incurvae. Quis iam; est dextra Peneosque, metuis a verba, primo. Illa sed colloque suis: magno: gramen, aera excutiunt concipit.\n Phrygiae petendo suisque extimuit, super, pars quod audet! Turba negarem. Fuerat attonitus; et dextra retinet sidera ulnas undas instimulat vacuae generis? Agnus dabat et ignotis dextera, sic tibi pacis feriente at mora euhoeque comites hostem vestras Phineus. Vultuque sanguine dominoque metuit risi fama vergit summaque meus clarissimus artesque tinguebat successor nominis cervice caelicolae.\n Limitibus misere sit Aurea non fata repertis praerupit feruntur simul, meae hosti lentaque citius levibus, cum sede dixit, Phaethon texta. Albentibus summos multifidasque iungitur loquendi an pectore, mihi ursaque omnia adfata, aeno parvumque in animi perlucentes. Epytus agis ait vixque clamat ornum adversam spondet, quid sceptra ipsum est. Reseret nec; saeva suo passu debentia linguam terga et aures et cervix de ubera. Coercet gelidumque manus, doluit volvitur induta?\nEnim sua Iuvenilior filia inlustre templa quidem herbis permittat trahens huic. In cruribus proceres sole crescitque fata, quos quos; merui maris se non tamen in, mea.\nGermana aves pignus tecta Mortalia rudibusque caelum cognosceret tantum aquis redito felicior texit, nec, aris parvo acre. Me parum contulerant multi tenentem, gratissime suis; vultum tu occupat deficeret corpora, sonum. E Actaea inplevit Phinea concepit nomenque potest sanguine captam nulla et, in duxisses campis non; mercede. Dicere cur Leucothoen obitum?\nPostibus mittam est nubibus principium pluma, exsecratur facta et. Iunge Mnemonidas pallamque pars; vere restitit alis flumina quae quoque, est ignara infestus Pyrrha. Di ducis terris maculatum At sede praemia manes nullaque!\n"});index.add({'id':29,'href':'/library/tutorials/docs/python/beginer/variable/','title':"ตัวแปรและประเภทข้อมูล",'content':" Variable \u0026amp; Data Types (ตัวแปรและประเภทข้อมูล) ตัวแปรและประข้อมูลในภาษา Python เราจะพูดถึงการประกาศตัวแปรและการนำตัวแปรไปใช้งานในโปรแกรม และเราจะอธิบายถึงข้อมูลประเภทต่างๆ ที่เป็น Primitive datatype ในภาษา Python และรวมทั้งฟังก์ชันสำหรับการใช้งานกับตัวแปร\nตัวแปร ตัวแปร (variable) คือชื่อหรือเครื่องหมายที่กำหนดขึ้นสำหรับใช้เก็บค่าในหน่วยความจำ ตัวแปรจะมีชื่อ (identifier) สำหรับใช้ในการอ้างถึงข้อมูลของมัน ในการเขียนโปรแกรม ค่าของตัวแปรสามารถที่จะกำหนดได้ใน run-time หรือเปลี่ยนแปลงอยู่ตลอดเวลาในขณะที่โปรแกรมทำงาน (executing)\nในการเขียนโปรแกรมคอมพิวเตอร์นั้น ตัวแปรจะแตกต่างจากตัวแปรในทางคณิตศาสตร์ ค่าของตัวแปรนั้นไม่จำเป็นต้องประกอบไปด้วยสูตรหรือสมการที่สมบูรณ์เหมือนกับในคณิตศาสตร์ ในคอมพิวเตอร์ ตัวแปรนั้นอาจจะมีการทำงานซ้ำๆ เช่น การกำหนดค่าในที่หนึ่ง และนำไปใช้อีกที่หนึ่งในโปรแกรม และนอกจากนี้ยังสามารถกำหนดค่าใหม่ให้กับตัวแปรได้ตลอดเวลา ต่อไปเป็นตัวอย่างของการประกาศตัวแปรในภาษา Python\na = 3 b = 4.92 c = \u0026quot;marcuscode.com\u0026quot; c = 10.5  ในตัวอย่าง เราได้ทำการประกาศ 3 ตัวแปร ในการประกาศตัวแปรในภาษา Python คุณไม่จำเป็นต้องระบุประเภทของตัวแปรในตอนที่ประกาศเหมือนในภาษา C ในตัวแปร a มีค่าเป็น 3 และเป็นประเภทเป็น Integer ตัวแปร b มีค่าเป็น 4.92 และเป็นประเภทเป็น Float และตัวแปร c มีค่าเป็น \u0026ldquo;marcuscode.com\u0026rdquo; และเป็นประเภท String ภายหลังเราได้เปลี่ยนค่าของตัวแปร c เป็น 10.5 ตัวแปรกลายเป็นประเภท Float\na, b = 1, 2 x = y = z = 10 print(\u0026quot;a = \u0026quot; , a) print(\u0026quot;b = \u0026quot; , b) print(\u0026quot;x = \u0026quot; , x) print(\u0026quot;y = \u0026quot; , y) print(\u0026quot;z = \u0026quot; , z)  ในภาษา Python นั้นสนับสนุนการกำหนดค่าให้กับตัวแปรหลายค่าในคำสั่งเดียว ในตัวอย่าง เป็นการกำหนดค่า 1 และ 2 กับตัวแปร a และ b ตามลำดับ และในคำสั่งต่อมาเป็นการกำหนดค่า 10 ให้กับตัวแปร x y และ z ซึ่งทำให้การเขียนโปรแกรมสะดวกและรวดเร็วมากขึ้น\na = 1 b = 2 x = 10 y = 10 z = 10  นี่เป็นผลลัพธ์การทำงานของโปรแกรม\nต่อไปจะเป็นการพูดถึงประเภทข้อมูลชนิดต่างๆ ที่ภาษา Python สนับสนุน ซึ่งจะมีอยู่สามประเภทใหญ่ๆ คือ ข้อมูลแบบตัวเลข นั้นจะแบ่งย่อยออกเป็น Integer และ Float ข้อมูลประเภท String และข้อมูลแบบลำดับ เช่น List และ Tuple ประเภทข้อมูลทั้งหมดนี้เป็น Built-in type ในภาษา Python\nNumbers ในภาษา Python นั้นสนับสนุนข้อมูลแบบตัวเลข ซึ่งข้อมูลประเภทนี้จะแบ่งออกเป็น Integer Float Decimal และ Complex อย่างไรก็ตามเราจะเน้นย้ำใน Integer ซึ่งเป็นการเก็บข้อมูลแบบจำนวนเต็ม และ Float เป็นข้อมูลแบบจำนวนจริง สำหรับประเภทแบบ Decimal นั้นแตกต่างไปจาก Float คือสามารถเก็บความละเอียดของจุดทศนิยมได้มากกว่า นอกจากนี้ Python ยังสนุนตัวเลขในรูปแบบ Complex ที่แสดงในแบบ a +bj ต่อไปเป็นตวอย่างในการประกาศและใช้งานตัวแปรแบบตัวเลขในภาษา Python\n# Integer a = 7 b = 3 c = a + b d = a / b print ('a = %d' % a) print ('b = %d' % b) print ('c = %d' % c) print ('d = ', d)  ในตัวอย่าง เป็นการประกาศและใช้งานตัวแปรประเภท Integer เราได้ทำการประกาศตัวแปรและกำหนดค่าให้กับ a และ b ในการแสดงผลในรูปแบบของ String format กับฟังก์ชัน print() นั้นจะใช้ specifier เป็น %d เราสามารถกำหนดค่าให้กับตัวแปรได้โดย Literal หรือ Expression และการหารตัวเลขในภาษา Python นั้นจะได้ค่าเป็น Float เสมอ ถึงแม้ตัวเลขทั้งสองจะเป็น Integer ก็ตาม เช่นในตัวแปร d\na = 7 b = 3 c = 10 d = 2.3333333333333335  นี่เป็นผลลัพธ์การทำงานของโปรแกรม\n# Floating point number speed = 34.12 pi = 22 / 7 height = 2.31E5 length = 1.3E-3 print ('speed = %f' % speed) print ('pi = %f' % pi) print ('height = %f' % height) print ('length = %f' % length) print (pi)  ต่อไปเป็นการประกาศและใช้งานตัวแปรประเภท Float หรือตัวเลขที่มีจุดทศนิยม ในการกำหนดค่าใก้กับตัวแปรนั้นเมื่อคุณกำหนดค่าที่มีจุดนั้นตัวเลขจะเป็นประเภท Float อัตโนมัติ เราสามารถกำหนดค่าโดยตรงหรือในรูปแบบของ Expression ได้ และนอกจากนี้ในภาษา Python ยังสามารถกำหนดในรูปแบบสัญกรณ์วิทยาศาสตร์ได้เหมือนในตัวแปร height ซึ่งหมายถึง 2.31 x 10 ^ 5 และในตัวแปร length ซึ่งหมายถึง 1.3 x 10 ^ -3\nspeed = 34.120000 pi = 3.142857 height = 231000.000000 length = 0.001300 3.142857142857143  นี่เป็นผลลัพธ์การทำงานของโปรแกรม ซึ่งในการแสดงผลของข้อมูลประเภท Float กับการจัดรูปแบบของตัวเลขนั้นจะใช้ %f สำหรับการดูค่าเต็มของตัวเลขจริงๆ นั้นเราจะแสดงค่าของตัวเลขโดยเหมือนในคำสั่งแสดงผลค่าของ pi ในคำสั่งบรรทัดสุดท้าย\nStrings Strings นั้นเป็นประเภทข้อมูลที่สำคัญและใช้งานทั่วไปในการเขียนโปรแกรม ในภาษาเขียนโปรแกรมส่วนมากแล้วจะมีประเภทข้อมูลแบบ String และในภาษา Python เช่นกัน String เป็นลำดับของตัวอักษรหลายตัวเรียงต่อกัน ซึ่งในภาษา Python นั้น String จะอยู่ในเครื่องหมาย Double quote หรือ Single quote เท่านั้น นอกจากนี้ในภาษา Python ยังมีฟังก์ชันในการจัดการกับ String มากมายซึ่งเราจะพูดอีกครั้งในบทของ String ในบทนี้มาทำความรู้จักกับ String เบื้องต้นกันก่อน\nname = \u0026quot;Mateo\u0026quot; country = \u0026quot;Ukrain\u0026quot; language = 'Python' interest = 'Mountain Everest'  ในตัวอย่าง เป็นการประกาศตัวแปรประเภท String สองตัวแปรแรกเป็นการประโดยการใช้ Double quote และสองตัวแปรต่อม่เป็นการใช้ Single quote ซึ่งคุณสามารถใช้แบบไหนก็ได้ แต่มีสิ่งที่แตกต่างกันเล็กน้อยคือเกี่ยวกับการกำหนดตัวอักพิเศษหรือเรียกว่า Escape character\nsentent1 = \u0026quot;What's your name?\u0026quot; sentent2 = 'I\\'m Mateo.' sentent3 = \u0026quot;He said \\\u0026quot;I would learn Python first\\\u0026quot;.\u0026quot; sentent4 = 'His teach replied \u0026quot;Oh well!\u0026quot;' print (sentent1) print (sentent2) print (sentent3) print (sentent4)  ในตัวอย่าง เป็นสิ่งที่แตกต่างของการประกาศ String ทั้งสองแบบกับ Escape character ตัวอักษร \u0026lsquo; และ \u0026ldquo; นั้นเป็น Escape character ดังนั้นในการใช้งานตัวอักษรเหล่านี้ เราจะต้องทำการใส่เครื่องหมาย \\ ลงไปข้างหน้าเสมอ แต่ในภาษา Python เมื่อคุณใช้ Double quote ในการประกาศ String คุณไม่ต้องทำการ Escape character สำหรับ Single quote และในทางกลับกัน อย่างไรก็ตามเราจะพูดอีกครั้งในบทของ String\nWhat's your name? I'm Mateo. He said \u0026quot;I would learn Python first\u0026quot;. His teach replied \u0026quot;Oh well!\u0026quot;  นี่เป็นผลลัพธ์การทำงานของโปรแกรมในการใช้งาน Escape character ในภาษา Python\nsite = 'marcuscode' + '.com' tutorial = 'Python' ' Language' print(site) print(tutorial)  การทำงานอย่างหนึ่งที่สำคัญเกี่ยวกับ String ก็คือการเชื่อมต่อ String ซึ่งเป็นการนำ String ตั้งต่อสองอันขึ้นไปมาต่อกัน ในภาษา Python คุณสามารถต่อ String ได้โดยการใช้เครื่องหมาย + หรือคั่นด้วยช่องว่างหรือบรรทัดใหม่เหมือนในตัวอย่างข้างบน\nmarcuscode.com Python Language  นี่เป็นผลลัพธ์การทำงานของโปรแกรม\nอย่างไรก็ตาม นี่เป็นการแนะนำเกี่ยวกับ String ในเบื้องต้นเท่านั้น เพราะว่า String นั้นมีเนื้อหาเป็นจำนวนมาก คุณจะได้เรียนรู้เกี่ยวกับ String อย่างละเอียด อีกครั้งในบทของ String\nLists Lists เป็นประเภทข้อมูลที่เก็บข้อมูลแบบเป็นชุดและลำดับ กล่าวคือมันสามารถเก็บข้อมูลได้หลายค่าในตัวแปรเดียว และมี Index สำหรับเข้าถึงข้อมูล ในภาษา Python นั้น List จะเป็นเหมือนอาเรย์ในภาษา C มันสามารถเก็บข้อมูลได้หลายตัวและยังสามารถเป็นประเภทข้อมูลที่แตกต่างกันได้อีกด้วย มาดูการประกาศและใช้งาน List ในเบื้องต้น\n# Declare lists numbers = [1, 2, 4, 6, 8, 19] names = [\u0026quot;Mateo\u0026quot;, \u0026quot;Danny\u0026quot;, \u0026quot;James\u0026quot;, \u0026quot;Thomas\u0026quot;, \u0026quot;Luke\u0026quot;] mixed = [-2, 5, 84.2, \u0026quot;Mountain\u0026quot;, \u0026quot;Python\u0026quot;] # Display lists print(numbers) print(names) print(mixed) # Display lists using the for loops for n in numbers: print(n, end=\u0026quot; \u0026quot;) print() for n in names: print(n, end=\u0026quot; \u0026quot;) print() for n in mixed: print(n, end=\u0026quot; \u0026quot;) print()  ในตัวอย่าง เราได้ทำการประกาศ 3 Lists โดยตัวแปรแรกนั้นเป็น List ของตัวเลข และตัวแปรที่สองเป็น List ของ String และตัวแปรสุดท้ายเป็น List แบบรวมกันของประเภทข้อมูล เราใช้ฟังก์ชัน print() ในการแสดงผลข้อมูลใน List และใช้คำสั่ง For loop ในการอ่านค่าในลิสต์และนำมาแสดงผลเช่นกัน\n[1, 2, 4, 6, 8, 19] ['Mateo', 'Danny', 'James', 'Thomas', 'Luke'] [-2, 5, 84.2, 'Mountain', 'Python'] 1 2 4 6 8 19 Mateo Danny James Thomas Luke -2 5 84.2 Mountain Python  นี่เป็นผลการทำงานของโปรแกรม\nlanguages = [\u0026quot;C\u0026quot;, \u0026quot;C++\u0026quot;, \u0026quot;Java\u0026quot;, \u0026quot;Python\u0026quot;, \u0026quot;PHP\u0026quot;] print(\u0026quot;Index at 0 = \u0026quot;, languages[0]) print(\u0026quot;Index at 3 = \u0026quot;, languages[3]) languages[0] = \u0026quot;Scalar\u0026quot; print(\u0026quot;Index at 0 = \u0026quot;, languages[0])  Lists นั้นทำงานกับ Index ดังนั้นเราสามารถเข้าถึงข้อมูลของ List โดยการใช้ Index ของมันได้ ในตัวอย่างเป็นการเข้าถึงข้อมูบภายใน Index ซึ่ง Index ของ List นั้นจะเริ่มจาก 0 ไปจนถึงจำนวนทั้งหมดของมันลบด้วย 1 ในตัวอย่างเราได้แสดงผลข้อมูลของสอง List ในตำแหน่งแรกและในตำแหน่งที่ 4 ด้วย Index 0 และ 3 ตามลำดับ หลังจากนั้นเราเปลี่ยนค่าของ List ที่ตำแหน่งแรกเป็น \u0026ldquo;Scalar\u0026rdquo;\nIndex 0 = C Index 3 = Python Index 0 = Scalar  นี่เป็นผลลัพธ์การทำงานของโปรแกรม ซึ่งคุณได้ทำความรู้จักกับ List ในเบื้องต้น คุณจะได้เรียนรู้เกี่ยวกับ List ในภาษา Python อย่างละเอียดอีกครั้งในบทของ List ซึ่งเราจะพูดเกี่ยวกับการดำเนินการและการใช้ฟังก์ชันของ List นอกจากนี้ Python ยังมีประเภทข้อมูลแบบ Tuple และ Dictionary ซึ่งมีรูปแบบการเก็บข้อมูลคล้ายกับ List จึงคุณจะได้เรียนในบทต่อไป\nฟังก์ชันที่ใช้กับตัวแปร ในภาษา Python นั้นมีฟังก์ชันที่สร้างมาเพื่อให้ใช้งานกับตัวแปร เช่น ฟังก์ชันสำหรับหาขนาดของตัวแปร ฟังก์ชันในการหาประเภทของตัวแปร ฟังก์ชันลบตัวแปรออกไปในหน่วยความจำ และฟังก์ชันในการตรวจสอบว่าตัวแปรมีอยู่หรือไม่ ซึ่งในบางครั้งการเขียนโปรแกรมก็จำเป็นที่คุณอาจจะต้องมีการตรวจสอบสิ่งเหล่านี้ในขณะที่โปรแกรมทำงาน นี่เป็นตัวอย่างการใช้งาน\nimport sys a = 8 b = 13.4 c = \u0026quot;Python\u0026quot; d = [1, 2, 3, 4] print('Size of a = ', sys.getsizeof(a)) print('Type of a = ', type(a)) print('Size of b = ', sys.getsizeof(b)) print('Type of b = ', type(b)) print('Size of c = ', sys.getsizeof(c)) print('Type of c = ', type(c)) print('Size of d = ', sys.getsizeof(d)) print('Type of d = ', type(d)) del a del b, c, d if 'a' in locals(): print(\u0026quot;a is exist\u0026quot;) else: print(\u0026quot;a is not exist\u0026quot;)  ในตัวอย่าง เราได้ประกาศตัวแปรกับประเภทต่างๆ เราได้ฟังก์ชัน getsizeof() สำหรับหาขนาดของตัวแปรที่มีหน่วยเป็น Byte และฟังก์ชัน type() สำหรับประเภทของตัวแปรว่าอยู่ในคลาสไหน ฟังก์ชัน del() สำหรับยกเลิกหรือลบการประกาศตัวแปรออกไปจากหน่วยความจำ และสุดท้ายเป็นการตรวจสอบว่าตัวแปรถูกประกาศและหรือยังในฟังก์ชัน locals() สำหรับตรวจสอบตัวแปรในโมดูลปัจจึบัน หรือ globals() สำหรับตรวจสอบตัวแปรในโปรแกรมทั้งหมด\nSize of a = 14 Type of a = \u0026lt;class 'int'\u0026gt; Size of b = 16 Type of b = \u0026lt;class 'float'\u0026gt; Size of c = 31 Type of c = \u0026lt;class 'str'\u0026gt; Size of d = 52 Type of d = \u0026lt;class 'list'\u0026gt; a is not exist  นี่เป็นผลลัพธ์การทำงานของโปรแกรมในการใช้ฟังก์ชันที่จำเป็นกับตัวแปร\nในบทนี้ คุณได้เรียนรู้เกี่ยวกับตัวแปรและประเภทข้อมูลในภาษา Python เราได้พูดถึงการประกาศและการใช้งานตัวแปร รวมถึงข้อมูลประเภทต่างๆ ในภาษา Python เช่น ตัวเลข String และ List และนอกจากนี้เรายังแนะนำให้คุณรู้จักกับฟังก์ชันที่มีความจำเป็นในการทำงานกับตัวแปร\n"});index.add({'id':30,'href':'/library/tutorials/docs/python/beginer/dictionary/dictionary/','title':"โครงสร้างข้อมูล Dictionary",'content':" โครงสร้างข้อมูล Dictionary ในบทนี้ คุณจะได้เรียนรู้เกี่ยวกับโครงสร้างข้อมูล Dictionary ในภาษา Python เราจะแนะนำให้คุณรู้จักกับ Dictionary คืออะไร และการประกาศและใช้งานสำหรับเก็บข้อมูลในการเขียนโปรแกรม นอกจากนี้ เรายังจะพูดถึงการใช้งานเมธอดและ built-in functions ของ Dictionary และตัวอย่างการใช้งานกับการเขียนโปรแกรมใบรูปแบบต่างๆ ในภาษา Python\nDictionary คือประเภทข้อมูลที่เก็บข้อมูลในรูปแบบคู่ของ Key และ Value โดยที่ Key ใช้สำหรับเป็น Index ในการเข้าถึงข้อมูลและ Value เป็นค่าข้อมูลที่สอดคล้องกับ Key ของมัน การเข้าถึงข้อมูลใน Dictionary นั้นรวดเร็วเพราะว่าข้อมูลได้ถูกทำ Index ไว้อัตโนมัติโดยใช้ Key นอกจากนี้ Dictionary ยังมีเมธอดและฟังก์ชันอำนวยความสะดวกสำหรับการทำงานทั่วไป\nการประกาศ Dictionary ในภาษา Python ในการใช้งาน Dictionary เรามักจะใช้เก็บข้อมูลที่สามารถใช้บางอย่างที่สามารถจำแนกข้อมูลออกจากกันได้ โดยกำหนดให้สิ่งนั้นเป็น Key ในการประกาศ Dictionary สมาชิกของมันจะอยู่ภายในวงเล็บปีกกา {} มาดูตัวอย่างในการประกาศ Dictionary ในภาษา Python\nscores = {'james': 1828, 'thomas': 3628, 'danny': 9310} scores['bobby'] = 4401 numbers = {1: 'One', 2: 'Two', 3: 'Three'} print(scores) print(numbers)  ในตัวอย่าง เราได้ประกาศตัวแปร Dictionary ที่มีชื่อว่า scores สำหรับเก็บคะแนนของแต่ละคนโดยใช้ชื่อเป็น Key และค่าของมันก็คือคะแนน สมาชิกของ Dictionary แต่ละตัวจะถูกกำหนดในรูปแบบ key: value และคั่นสมาชิกแต่ละตัวด้วยเครื่องหมายคอมมา เราได้กำหนดค่าเริ่มต้นสามค่าให้กับ Dictionary และสามารถกำหนดค่าให้กับ Dictionary ในรูปแบบ scores['bobby'] ได้หลังจากที่ตัวแปรถูกสร้างแล้ว สังเกตว่าเราสามารถใช้ Key เป็น String หรือประเภทข้อมูลอื่นๆ ได้ ต่อมาตัวแปร numbers เป็น Dictionary ที่มี Key เป็นตัวเลข\n{'james': 1828, 'thomas': 3628, 'danny': 9310, 'bobby': 4401} {1: 'One', 2: 'Two', 3: 'Three'}  นี่เป็นผลลัพธ์ของโปรแกรมในการแสดงผลข้อมูลภายในตัวแปร Dictionary ทั้งสองที่เราได้สร้างขึ้น\nการเข้าถึงข้อมูลภายใน Dictionary หลังจากที่เราได้ประกาศ Dictionary ไปแล้ว ต่อไปจะการเข้าถึงข้อมูลเพื่ออ่านและอัพเดทข้อมูลโดยผ่านทาง Key ของมัน มาดูตัวอย่างการเข้าถึงข้อมูลใน Dictionary\nscores = {'james': 1828, 'thomas': 3628, 'danny': 9310, 'bobby': 4401} # display data print('james =\u0026gt;', scores['james']) print('thomas =\u0026gt;', scores['thomas']) print('danny =\u0026gt;', scores['danny']) print('bobby =\u0026gt;', scores['bobby']) # update data scores['james'] = scores['james'] + 1000 scores['thomas'] = 100 print('james =\u0026gt;', scores['james']) print('thomas =\u0026gt;', scores['thomas'])  ในตัวอย่าง เรามีตัวแปร scores สำหรับเก็บคะแนนของผู้เล่นโดยชื่อเป็น Key ของ Dictionary ในการเข้าถึงข้อมูลนั้นจะใช้ Key ของมัน ในส่วนแรกเป็นการเข้าถึงข้อมูลภายใน Dictionary เพื่อแสดงผลคะแนนของแต่ละ Key ออกมาทางหน้าจอ ต่อมาเป็นการอัพเดทข้อมูลใน Dictionary โดยเราได้เพิ่มค่าให้กับ Key 'james' ขึ้นไปอีก 1000 และกำหนดค่าให้กับ Key 'thomas' เป็น 100 และแสดงผลอีกครั้ง\njames =\u0026gt; 1828 thomas =\u0026gt; 3628 danny =\u0026gt; 9310 bobby =\u0026gt; 4401 james =\u0026gt; 2828 thomas =\u0026gt; 100  นี่เป็นผลลัพธ์การทำงานของโปรแกรม ในการเข้าถึงข้อมูลภายใน Dictionary เพื่ออ่านค่าและอัพเดทข้อมูล\nในการเข้าถึงข้อมูลภายใน Dictionary นั้น คุณต้องตรวจสอบให้แน่ใจว่า Key นั้นมีอยู่จริง ไม่เช่นนั้นโปรแกรมจะเกิดข้อผิดพลาดขึ้น ยกตัวอย่างเช่น\nscores = {'james': 1828, 'thomas': 3628, 'danny': 9310, 'bobby': 4401} print(scores['smith']) # Error # check if key smith exist if 'smith' in scores.keys(): print(scores['smith'])  ในตัวอย่างข้างบน โปรแกรมจะเกิดความผิดพลาดขึ้นเพราะเราได้เข้าถึง Key 'smith' ซึ่งไม่มีอยู่ใน scores อย่าไรก็ตาม เราสามารถตรวจว่า Key มีอยู่หรือไม่ได้โดยการใช้คำสั่ง in เพื่อตรวจสอบจาก Key ในเมธอด keys() ของ Dictionary\nการอ่านค่าใน Dictionary ด้วยคำสั่ง For loop คำสั่ง For loop นั้นเป็นคำสั่งที่ยืดหยุ่นและสามารถใช้งานได้อย่างหลากหลาย ในการอ่านค่าใน Dictionary นั้นเราสามารถใช้ For loop เพื่อวนอ่านค่าทั้ง Key และ Values ใน Dictionary ได้ มาดูตัวอย่างของโปรแกรม\ncountries = {'de': 'Germany', 'ua': 'Ukraine', 'th': 'Thailand', 'nl': 'Netherlands'} for k, v in countries.items(): print(k, v) # iterate through keys print('Key:', end = ' ') for k in countries.keys(): print(k, end = ' ') # iterate through values print('\\nValue:', end = ' ') for v in countries.values(): print(v, end = ' ')  ในตัวอย่าง เป็นการใช้งานคำสั่ง For loop วนอ่านค่าใน Dictionary ซึ่งมี 3 loop ด้วยกัน ในลูปแรกเป็นการอ่านค่าแบบ Key และ Value ในแต่ละรอบของการทำงานเราเอาข้อมูลใน Dictionary ด้วยเมธอด items() ซึ่งจะส่งค่ากลับเป็น Key และ Value กับมาและโหลดใส่ในตัวแปร k และ v ตามลำดับ\nในลูปที่สอง เป็นการวนอ่าน Key ทั้งหมดภายใน Dictionary โดยเมธอด keys() จะส่งค่ากลับเป็น List ของ Key ทั้งหมดและโหลดใส่ในตัวแปร k แต่ละรอบของลูป และในลูปสุดท้ายนั้นเป็นการอ่าน Value ทั้งหมด และเมธอด values() เพื่อรับค่าของ Value ทั้งหมดมาและใส่ในตัวแปร v ในแต่ละรอบของลูป\nde Germany ua Ukraine th Thailand nl Netherlands Key: de ua th nl Value: Germany Ukraine Thailand Netherlands  นี่เป็นผลลัพธ์การทำงานของโปรแกรม ในการใช้คำสั่ง For loop เพื่ออ่านข้อมูลใน Dictionary ในภาษา Python\nPython Dictionary methods เช่นเดียวกับข้อมูลประเภทอื่นๆ Dictionary มีเมธอดที่ให้คุณสามารถทำงานกับมันได้ง่ายขึ้น โดยส่วนมากแล้วมักจะเป็นเมธอดในการอัพเดทและรับค่าข้อมูลภายใน Dictionary ต่อไปมาดูตัวอย่างการใช้งานเมธอดของ Dictionary ในภาษา Python\ncountries = {'de': 'Germany', 'ua': 'Ukraine', 'th': 'Thailand', 'nl': 'Netherlands'} print(countries.keys()) print(countries.values()) print(countries.get('de')) # equal to countries['de'] countries.setdefault('tr', 'Turkey') print(countries.popitem()) print(countries.popitem()) print(countries.items())  ในตัวอย่าง เป็นโปรแกรมในการใช้งานเมธอดของ Dictionary ตัวแปรของเรา countries มาจากตัวอย่างก่อนหน้าที่มี Key เป็นชื่อย่อของประเทศและ Value เป็นชื่อเต็มของประเทศ เมธอด keys() ส่งค่ากลับเป็น List ของ Key ทั้งหมดภายใน Dictionary และเมธอด values() นั้นจะส่งเป็น List ของ Value\nหลังจากนั้นเป็นการเข้าถึงข้อมูลด้วยเมธอด get() โดยมี Key เป็นอาร์กิวเมนต์ซึ่งผลลัพธ์การทำงานของมันจะเหมือนกับการเข้าถึงข้อมูลโดยตรง เช่น countries['de'] และเมธอด setdefault() ใช้รับค่าจากคีย์ที่กำหนด ถ้าไม่มีจะเป็นการเพิ่มค่าดังกล่าวเข้าไปใน Dictionary และต่อมาเมธอด popitem() จะนำสมาชิกตัวสุดท้ายออกจาก Dictionary และส่งค่าดังกล่าวกลับมาเป็น Tuple ออบเจ็ค ส่วนเมธอด items() นั้นจะค่ากลับมาเป็น List ของ Tuple ของออบเจ็คของ Key และ Value ทั้งหมด\ndict_keys(['de', 'ua', 'th', 'nl']) dict_values(['Germany', 'Ukraine', 'Thailand', 'Netherlands']) Germany ('tr', 'Turkey') ('nl', 'Netherlands') dict_items([('de', 'Germany'), ('ua', 'Ukraine'), ('th', 'Thailand')])  นี่เป็นผลลัพธ์การทำงานของโปรแกรม ในการใช้เมธอดใน Dictionary ในภาษา Python และจากในตัวอย่างนั้นเป็นเพียงส่วนหนึ่งของเมธอดที่มีเท่านั้น สำหรับเมธอดทั้งหมดใน Dictionary นั้นแสดงดังตารางข้างล่างนี้\n   Methods Description     clear() ลบข้อมูลทั้งหมดภายใน Dictionary   copy() คัดลอก Dictionary ทั้งหมดไปยังอันใหม่   get(key[, default]) ส่งค่าข้อมูลใน Dictionary จาก Key ที่กำหนด ถ้าหากไม่มี Key อยู่และไม่ได้กำหนด default จะทำให้เกิดข้อผิดพลาด KeyError   items() ส่งค่ากลับเป็นออบเจ็คของ Key และ Value   keys() ส่งค่ากลับเป็น List ของ Key ทั้งหมดใน Dictionary   pop(key[, default]) ส่งค่ากลับเป็นค่าสุดท้ายใน Dictionary   popitem() ส่งค่ากลับเป็น Tuple ออบเจ็คของ Key และ Value   setdefault(key[, default]) ส่งค่ากลับเป็นค่าของ Key ที่กำหนด ถ้าหากไม่มี Key อยู่ใส่ข้อมูลเข้าไปใน Dictionary   update([other]) อัพเดท Dictionary กับคู่ของ Key และ Value จากออบเจ็คอื่น และเขียนทับ Key ที่มีอยู่   values() ส่งค่ากลับเป็น List ของ Value ทั้งหมดใน Dictionary    Python Dictionary functions ฟังก์ชันที่เป็นพื้นฐานและสามารถใช้ได้กับโครงสร้างข้อมูลทุกประเภทคือฟังก์ชัน len() เป็นฟังก์ชันที่ใช้สำหรับนับจำนวนสมาชิกของเจ็ค และ Dictionary ยังมีฟังก์ชัน iter() ที่ทำงานเหมือนกับเมธอด items() นี่เป็นตารางของฟังก์ชันที่สามารถใช้ได้กับ Dictionary\n   Function Description     len(dict) ส่งค่ากลับเป็นจำนวนของออบเจ็คใน Dictionary   iter(dict) ส่งค่ากลับเป็นออบเจ็คของ Key และ Value    คุณสามารถใช้คำสั่ง del เพื่อลบข้อมูลภายใน Dictionary ได้ เช่น คำสั่ง del countries['de'] เพื่อลบสมาชิกที่มี Key ที่กำหนดออกไป และคำสั่ง del countries นั้นเป็นการลบทั้งตัวแปร\nในบทนี้ คุณได้เรียนรู้เกี่ยวกับ Dictionary ในภาษา Python คุณได้ทราบวิธีการสร้างและใช้งาน Dictionary และสถานการณ์ที่เหมาะสมที่จะใช้ข้อมูลประเภทนี้ เราได้แสดงให้เห็นถึงการเข้าถึงข้อมูลภายใน Dictionary แบบพื้นฐานและด้วยการใช้คำสั่งวนซ้ำ For loop รวมถึงการใช้งานเมธอดและฟังก์ชันสำหรับจัดการ Dictionary\nReference : http://marcuscode.com/lang/python/dictionary\n"});index.add({'id':31,'href':'/library/tutorials/docs/articles/data-science/finance/','title':"Finance",'content':" Finance "});index.add({'id':32,'href':'/library/tutorials/docs/articles/python/from-zero/','title':"From Zero to Hero",'content':" Learning Python: From Zero to Hero First of all, what is Python? According to its creator, Guido van Rossum, Python is a:\n “high-level programming language, and its core design philosophy is all about code readability and a syntax which allows programmers to express concepts in a few lines of code.”\n For me, the first reason to learn Python was that it is, in fact, a beautiful programming language. It was really natural to code in it and express my thoughts.\nAnother reason was that we can use coding in Python in multiple ways: data science, web development, and machine learning all shine here. Quora, Pinterest and Spotify all use Python for their backend web development. So let’s learn a bit about it.\nThe Basics 1. Variables You can think about variables as words that store a value. Simple as that.\nIn Python, it is really easy to define a variable and set a value to it. Imagine you want to store number 1 in a variable called “one.” Let’s do it:\none = 1  How simple was that? You just assigned the value 1 to the variable “one.”\ntwo = 2 some_number = 10000  And you can assign any other value to whatever other variables you want. As you see in the table above, the variable “two” stores the integer 2, and “some_number” stores 10,000.\nBesides integers, we can also use booleans (True / False), strings, float, and so many other data types.\n# booleans true_boolean = True false_boolean = False # string my_name = \u0026quot;Leandro Tk\u0026quot; # float book_price = 15.80  2. Control Flow: conditional statements “If” uses an expression to evaluate whether a statement is True or False. If it is True, it executes what is inside the “if” statement. For example:\nif True: print(\u0026quot;Hello Python If\u0026quot;) if 2 \u0026gt; 1: print(\u0026quot;2 is greater than 1\u0026quot;)  2 is greater than 1, so the “print” code is executed.\nThe “else” statement will be executed if the “if” expression is false.\nif 1 \u0026gt; 2: print(\u0026quot;1 is greater than 2\u0026quot;) else: print(\u0026quot;1 is not greater than 2\u0026quot;)  1 is not greater than 2, so the code inside the “else” statement will be executed.\nYou can also use an “elif” statement:\nif 1 \u0026gt; 2: print(\u0026quot;1 is greater than 2\u0026quot;) elif 2 \u0026gt; 1: print(\u0026quot;1 is not greater than 2\u0026quot;) else: print(\u0026quot;1 is equal to 2\u0026quot;)  3. Looping / Iterator In Python, we can iterate in different forms. I’ll talk about two: while and for.\nWhile Looping: while the statement is True, the code inside the block will be executed. So, this code will print the number from 1 to 10.\nnum = 1 while num \u0026lt;= 10: print(num) num += 1  The while loop needs a “loop condition.” If it stays True, it continues iterating. In this example, when num is 11 the loop condition equals False.\nAnother basic bit of code to better understand it:\nloop_condition = True while loop_condition: print(\u0026quot;Loop Condition keeps: %s\u0026quot; %(loop_condition)) loop_condition = False  The loop condition is True so it keeps iterating — until we set it to False.\nFor Looping: you apply the variable “num” to the block, and the “for” statement will iterate it for you. This code will print the same as while code: from 1 to 10.\nfor i in range(1, 11): print(i)  See? It is so simple. The range starts with 1 and goes until the 11th element (10 is the 10th element).\nList: Collection | Array | Data Structure Imagine you want to store the integer 1 in a variable. But maybe now you want to store 2. And 3, 4, 5 …\nDo I have another way to store all the integers that I want, but not in millions of variables? You guessed it — there is indeed another way to store them.\nList is a collection that can be used to store a list of values (like these integers that you want). So let’s use it:\nmy_integers = [1, 2, 3, 4, 5]  It is really simple. We created an array and stored it on my_integer.\nBut maybe you are asking: “How can I get a value from this array?”\nGreat question. List has a concept called index. The first element gets the index 0 (zero). The second gets 1, and so on. You get the idea.\nTo make it clearer, we can represent the array and each element with its index. I can draw it:\nUsing the Python syntax, it’s also simple to understand:\nmy_integers = [5, 7, 1, 3, 4] print(my_integers[0]) # 5 print(my_integers[1]) # 7 print(my_integers[4]) # 4  Imagine that you don’t want to store integers. You just want to store strings, like a list of your relatives’ names. Mine would look something like this:\nrelatives_names = [ \u0026quot;Toshiaki\u0026quot;, \u0026quot;Juliana\u0026quot;, \u0026quot;Yuji\u0026quot;, \u0026quot;Bruno\u0026quot;, \u0026quot;Kaio\u0026quot; ] print(relatives_names[4]) # Kaio  It works the same way as integers. Nice.\nWe just learned how Lists indices work. But I still need to show you how we can add an element to the List data structure (an item to a list).\nThe most common method to add a new value to a List is append. Let’s see how it works:\nbookshelf = [] bookshelf.append(\u0026quot;The Effective Engineer\u0026quot;) bookshelf.append(\u0026quot;The 4 Hour Work Week\u0026quot;) print(bookshelf[0]) # The Effective Engineer print(bookshelf[1]) # The 4 Hour Work Week  append is super simple. You just need to apply the element (eg. “The Effective Engineer”) as the append parameter.\nWell, enough about Lists. Let’s talk about another data structure.\nDictionary: Key-Value Data Structure Now we know that Lists are indexed with integer numbers. But what if we don’t want to use integer numbers as indices? Some data structures that we can use are numeric, string, or other types of indices.\nLet’s learn about the Dictionary data structure. Dictionary is a collection of key-value pairs. Here’s what it looks like:\ndictionary_example = { \u0026quot;key1\u0026quot;: \u0026quot;value1\u0026quot;, \u0026quot;key2\u0026quot;: \u0026quot;value2\u0026quot;, \u0026quot;key3\u0026quot;: \u0026quot;value3\u0026quot; }  The key is the index pointing to the value. How do we access the Dictionary value? You guessed it — using the key. Let’s try it:\ndictionary_tk = { \u0026quot;name\u0026quot;: \u0026quot;Leandro\u0026quot;, \u0026quot;nickname\u0026quot;: \u0026quot;Tk\u0026quot;, \u0026quot;nationality\u0026quot;: \u0026quot;Brazilian\u0026quot; } print(\u0026quot;My name is %s\u0026quot; %(dictionary_tk[\u0026quot;name\u0026quot;])) # My name is Leandro print(\u0026quot;But you can call me %s\u0026quot; %(dictionary_tk[\u0026quot;nickname\u0026quot;])) # But you can call me Tk print(\u0026quot;And by the way I'm %s\u0026quot; %(dictionary_tk[\u0026quot;nationality\u0026quot;])) # And by the way I'm Brazilian  I created a Dictionary about me. My name, nickname, and nationality. Those attributes are the Dictionary keys.\nAs we learned how to access the List using index, we also use indices (keys in the Dictionary context) to access the value stored in the Dictionary.\nIn the example, I printed a phrase about me using all the values stored in the Dictionary. Pretty simple, right?\nAnother cool thing about Dictionary is that we can use anything as the value. In the Dictionary I created, I want to add the key “age” and my real integer age in it:\ndictionary_tk = { \u0026quot;name\u0026quot;: \u0026quot;Leandro\u0026quot;, \u0026quot;nickname\u0026quot;: \u0026quot;Tk\u0026quot;, \u0026quot;nationality\u0026quot;: \u0026quot;Brazilian\u0026quot;, \u0026quot;age\u0026quot;: 24 } print(\u0026quot;My name is %s\u0026quot; %(dictionary_tk[\u0026quot;name\u0026quot;])) # My name is Leandro print(\u0026quot;But you can call me %s\u0026quot; %(dictionary_tk[\u0026quot;nickname\u0026quot;])) # But you can call me Tk print(\u0026quot;And by the way I'm %i and %s\u0026quot; %(dictionary_tk[\u0026quot;age\u0026quot;], dictionary_tk[\u0026quot;nationality\u0026quot;])) # And by the way I'm Brazilian  Here we have a key (age) value (24) pair using string as the key and integer as the value.\nAs we did with Lists, let’s learn how to add elements to a Dictionary. The key pointing to a value is a big part of what Dictionary is. This is also true when we are talking about adding elements to it:\ndictionary_tk = { \u0026quot;name\u0026quot;: \u0026quot;Leandro\u0026quot;, \u0026quot;nickname\u0026quot;: \u0026quot;Tk\u0026quot;, \u0026quot;nationality\u0026quot;: \u0026quot;Brazilian\u0026quot; } dictionary_tk['age'] = 24 print(dictionary_tk) # {'nationality': 'Brazilian', 'age': 24, 'nickname': 'Tk', 'name': 'Leandro'}  We just need to assign a value to a Dictionary key. Nothing complicated here, right?\nIteration: Looping Through Data Structures As we learned in the Python Basics, the List iteration is very simple. We Python developers commonly use For looping. Let’s do it:\nbookshelf = [ \u0026quot;The Effective Engineer\u0026quot;, \u0026quot;The 4-hour Workweek\u0026quot;, \u0026quot;Zero to One\u0026quot;, \u0026quot;Lean Startup\u0026quot;, \u0026quot;Hooked\u0026quot; ] for book in bookshelf: print(book)  So for each book in the bookshelf, we (can do everything with it) print it. Pretty simple and intuitive. That’s Python.\nFor a hash data structure, we can also use the for loop, but we apply the key :\ndictionary = { \u0026quot;some_key\u0026quot;: \u0026quot;some_value\u0026quot; } for key in dictionary: print(\u0026quot;%s --\u0026gt; %s\u0026quot; %(key, dictionary[key])) # some_key --\u0026gt; some_value  This is an example how to use it. For each key in the dictionary , we print the key and its corresponding value.\nAnother way to do it is to use the iteritems method.\ndictionary = { \u0026quot;some_key\u0026quot;: \u0026quot;some_value\u0026quot; } for key, value in dictionary.items(): print(\u0026quot;%s --\u0026gt; %s\u0026quot; %(key, value)) # some_key --\u0026gt; some_value  We did name the two parameters as key and value, but it is not necessary. We can name them anything. Let’s see it:\ndictionary_tk = { \u0026quot;name\u0026quot;: \u0026quot;Leandro\u0026quot;, \u0026quot;nickname\u0026quot;: \u0026quot;Tk\u0026quot;, \u0026quot;nationality\u0026quot;: \u0026quot;Brazilian\u0026quot;, \u0026quot;age\u0026quot;: 24 } for attribute, value in dictionary_tk.items(): print(\u0026quot;My %s is %s\u0026quot; %(attribute, value)) # My name is Leandro # My nickname is Tk # My nationality is Brazilian # My age is 24  We can see we used attribute as a parameter for the Dictionary key, and it works properly. Great!\nClasses \u0026amp; Objects A little bit of theory: Objects are a representation of real world objects like cars, dogs, or bikes. The objects share two main characteristics: data and behavior.\nCars have data, like number of wheels, number of doors, and seating capacity They also exhibit behavior: they can accelerate, stop, show how much fuel is left, and so many other things.\nWe identify data as attributes and behavior as methods in object-oriented programming. Again:\nData → Attributes and Behavior → Methods\nAnd a Class is the blueprint from which individual objects are created. In the real world, we often find many objects with the same type. Like cars. All the same make and model (and all have an engine, wheels, doors, and so on). Each car was built from the same set of blueprints and has the same components.\nPython Object-Oriented Programming mode: ON Python, as an Object-Oriented programming language, has these concepts: class and object.\nA class is a blueprint, a model for its objects.\nSo again, a class it is just a model, or a way to define attributes and behavior (as we talked about in the theory section). As an example, a vehicle class has its own attributes that define what objects are vehicles. The number of wheels, type of tank, seating capacity, and maximum velocity are all attributes of a vehicle.\nWith this in mind, let’s look at Python syntax for classes:\nclass Vehicle: pass  We define classes with a class statement — and that’s it. Easy, isn’t it?\nObjects are instances of a class. We create an instance by naming the class.\ncar = Vehicle() print(car) # \u0026lt;__main__.Vehicle instance at 0x7fb1de6c2638\u0026gt;  Here car is an object (or instance) of the class Vehicle.\nRemember that our vehicle class has four attributes: number of wheels, type of tank, seating capacity, and maximum velocity. We set all these attributes when creating a vehicle object. So here, we define our class to receive data when it initiates it:\nclass Vehicle: def __init__(self, number_of_wheels, type_of_tank, seating_capacity, maximum_velocity): self.number_of_wheels = number_of_wheels self.type_of_tank = type_of_tank self.seating_capacity = seating_capacity self.maximum_velocity = maximum_velocity  We use the init method. We call it a constructor method. So when we create the vehicle object, we can define these attributes. Imagine that we love the Tesla Model S, and we want to create this kind of object. It has four wheels, runs on electric energy, has space for five seats, and the maximum velocity is 250km/hour (155 mph). Let’s create this object:\ntesla_model_s = Vehicle(4, 'electric', 5, 250)  Four wheels + electric “tank type” + five seats + 250km/hour maximum speed.\nAll attributes are set. But how can we access these attributes’ values? We send a message to the object asking about them. We call it a method. It’s the object’s behavior. Let’s implement it:\nclass Vehicle: def __init__(self, number_of_wheels, type_of_tank, seating_capacity, maximum_velocity): self.number_of_wheels = number_of_wheels self.type_of_tank = type_of_tank self.seating_capacity = seating_capacity self.maximum_velocity = maximum_velocity def number_of_wheels(self): return self.number_of_wheels def set_number_of_wheels(self, number): self.number_of_wheels = number  This is an implementation of two methods: number_of_wheels and set_number_of_wheels. We call it getter \u0026amp; setter. Because the first gets the attribute value, and the second sets a new value for the attribute.\nIn Python, we can do that using @property (decorators) to define getters and setters. Let’s see it with code:\nclass Vehicle: def __init__(self, number_of_wheels, type_of_tank, seating_capacity, maximum_velocity): self.number_of_wheels = number_of_wheels self.type_of_tank = type_of_tank self.seating_capacity = seating_capacity self.maximum_velocity = maximum_velocity @property def number_of_wheels(self): return self.__number_of_wheels @number_of_wheels.setter def number_of_wheels(self, number): self.__number_of_wheels = number  And we can use these methods as attributes:\ntesla_model_s = Vehicle(4, 'electric', 5, 250) print(tesla_model_s.number_of_wheels) # 4 tesla_model_s.number_of_wheels = 2 # setting number of wheels to 2 print(tesla_model_s.number_of_wheels) # 2  This is slightly different than defining methods. The methods work as attributes. For example, when we set the new number of wheels, we don’t apply two as a parameter, but set the value 2 to number_of_wheels. This is one way to write pythonic getter and setter code.\nBut we can also use methods for other things, like the “make_noise” method. Let’s see it:\nclass Vehicle: def __init__(self, number_of_wheels, type_of_tank, seating_capacity, maximum_velocity): self.number_of_wheels = number_of_wheels self.type_of_tank = type_of_tank self.seating_capacity = seating_capacity self.maximum_velocity = maximum_velocity def make_noise(self): print('VRUUUUUUUM')  When we call this method, it just returns a string _“_VRRRRUUUUM.”\ntesla_model_s = Vehicle(4, 'electric', 5, 250) tesla_model_s.make_noise() # VRUUUUUUUM  Encapsulation: Hiding Information Encapsulation is a mechanism that restricts direct access to objects’ data and methods. But at the same time, it facilitates operation on that data (objects’ methods).\n “Encapsulation can be used to hide data members and members function. Under this definition, encapsulation means that the internal representation of an object is generally hidden from view outside of the object’s definition.” — Wikipedia\n All internal representation of an object is hidden from the outside. Only the object can interact with its internal data.\nFirst, we need to understand how public and non-public instance variables and methods work.\nPublic Instance Variables For a Python class, we can initialize a public instance variable within our constructor method. Let’s see this:\nWithin the constructor method:\nclass Person: def __init__(self, first_name): self.first_name = first_name  Here we apply the first_name value as an argument to the public instance variable.\ntk = Person('TK') print(tk.first_name) # =\u0026gt; TK  Within the class:\nclass Person: first_name = 'TK'  Here, we do not need to apply the first_name as an argument, and all instance objects will have a class attribute initialized with TK.\ntk = Person() print(tk.first_name) # =\u0026gt; TK  Cool. We have now learned that we can use public instance variables and class attributes. Another interesting thing about the public part is that we can manage the variable value. What do I mean by that? Our object can manage its variable value: Get and Set variable values.\nKeeping the Person class in mind, we want to set another value to its first_name variable:\ntk = Person('TK') tk.first_name = 'Kaio' print(tk.first_name) # =\u0026gt; Kaio  There we go. We just set another value (kaio) to the first_name instance variable and it updated the value. Simple as that. Since it’s a public variable, we can do that.\nNon-public Instance Variable  We don’t use the term “private” here, since no attribute is really private in Python (without a generally unnecessary amount of work). — PEP 8\n As the public instance variable , we can define the non-public instance variable both within the constructor method or within the class. The syntax difference is: for non-public instance variables , use an underscore (_) before the variable name.\n “‘Private’ instance variables that cannot be accessed except from inside an object don’t exist in Python. However, there is a convention that is followed by most Python code: a name prefixed with an underscore (e.g. _spam) should be treated as a non-public part of the API (whether it is a function, a method or a data member)” — Python Software Foundation\n Here’s an example:\nclass Person: def __init__(self, first_name, email): self.first_name = first_name self._email = email  Did you see the email variable? This is how we define a non-public variable :\ntk = Person('TK', 'tk@mail.com') print(tk._email) # tk@mail.com   We can access and update it. Non-public variables are just a convention and should be treated as a non-public part of the API.\n So we use a method that allows us to do it inside our class definition. Let’s implement two methods (email and update_email) to understand it:\nclass Person: def __init__(self, first_name, email): self.first_name = first_name self._email = email def update_email(self, new_email): self._email = new_email def email(self): return self._email  Now we can update and access non-public variables using those methods. Let’s see:\ntk = Person('TK', 'tk@mail.com') print(tk.email()) # =\u0026gt; tk@mail.com # tk._email = 'new_tk@mail.com' -- treat as a non-public part of the class API print(tk.email()) # =\u0026gt; tk@mail.com tk.update_email('new_tk@mail.com') print(tk.email()) # =\u0026gt; new_tk@mail.com   We initiated a new object with first_name TK and email tk@mail.com Printed the email by accessing the non-public variable with a method Tried to set a new email out of our class We need to treat non-public variable as non-public part of the API Updated the non-public variable with our instance method Success! We can update it inside our class with the helper method  Public Method With public methods, we can also use them out of our class:\nclass Person: def __init__(self, first_name, age): self.first_name = first_name self._age = age def show_age(self): return self._age  Let’s test it:\ntk = Person('TK', 25) print(tk.show_age()) # =\u0026gt; 25  Great — we can use it without any problem.\nNon-public Method But with non-public methods we aren’t able to do it. Let’s implement the same Person class, but now with a show_age non-public method using an underscore (_).\nclass Person: def __init__(self, first_name, age): self.first_name = first_name self._age = age def _show_age(self): return self._age  And now, we’ll try to call this non-public method with our object:\ntk = Person('TK', 25) print(tk._show_age()) # =\u0026gt; 25   We can access and update it. Non-public methods are just a convention and should be treated as a non-public part of the API.\n Here’s an example for how we can use it:\nclass Person: def __init__(self, first_name, age): self.first_name = first_name self._age = age def show_age(self): return self._get_age() def _get_age(self): return self._age tk = Person('TK', 25) print(tk.show_age()) # =\u0026gt; 25  Here we have a _get_age non-public method and a show_age public method. The show_age can be used by our object (out of our class) and the _get_age only used inside our class definition (inside show_age method). But again: as a matter of convention.\nEncapsulation Summary With encapsulation we can ensure that the internal representation of the object is hidden from the outside.\nInheritance: behaviors and characteristics Certain objects have some things in common: their behavior and characteristics.\nFor example, I inherited some characteristics and behaviors from my father. I inherited his eyes and hair as characteristics, and his impatience and introversion as behaviors.\nIn object-oriented programming, classes can inherit common characteristics (data) and behavior (methods) from another class.\nLet’s see another example and implement it in Python.\nImagine a car. Number of wheels, seating capacity and maximum velocity are all attributes of a car. We can say that an ElectricCar class inherits these same attributes from the regular Car class.\nclass Car: def __init__(self, number_of_wheels, seating_capacity, maximum_velocity): self.number_of_wheels = number_of_wheels self.seating_capacity = seating_capacity self.maximum_velocity = maximum_velocity  Our Car class implemented:\nmy_car = Car(4, 5, 250) print(my_car.number_of_wheels) print(my_car.seating_capacity) print(my_car.maximum_velocity)  Once initiated, we can use all instance variables created. Nice.\nIn Python, we apply a parent class to the child class as a parameter. An ElectricCar class can inherit from our Car class.\nclass ElectricCar(Car): def __init__(self, number_of_wheels, seating_capacity, maximum_velocity): Car.__init__(self, number_of_wheels, seating_capacity, maximum_velocity)  Simple as that. We don’t need to implement any other method, because this class already has it (inherited from Car class). Let’s prove it:\nmy_electric_car = ElectricCar(4, 5, 250) print(my_electric_car.number_of_wheels) # =\u0026gt; 4 print(my_electric_car.seating_capacity) # =\u0026gt; 5 print(my_electric_car.maximum_velocity) # =\u0026gt; 250  Beautiful.\nThat’s it! We learned a lot of things about Python basics:\n How Python variables work How Python conditional statements work How Python looping (while \u0026amp; for) works How to use Lists: Collection | Array Dictionary Key-Value Collection How we can iterate through these data structures Objects and Classes Attributes as objects’ data Methods as objects’ behavior Using Python getters and setters \u0026amp; property decorator Encapsulation: hiding information Inheritance: behaviors and characteristics  Ref : FreeCodeCamp\n"});index.add({'id':33,'href':'/library/tutorials/docs/python/awesome/','title':"Awesome Python",'content':" Awesome Python A curated list of awesome Python frameworks, libraries, software and resources.\nInspired by awesome-php.\n Awesome Python  Admin Panels Algorithms and Design Patterns Audio Authentication Build Tools Built-in Classes Enhancement Caching ChatOps Tools CMS Code Analysis Command-line Interface Development Command-line Tools Compatibility Computer Vision Concurrency and Parallelism Configuration Cryptography Data Analysis Data Validation Data Visualization Database Database Drivers Date and Time Debugging Tools Deep Learning DevOps Tools Distributed Computing Distribution Documentation Downloader E-commerce Editor Plugins and IDEs Email Environment Management Files Foreign Function Interface Forms Functional Programming Game Development Geolocation GUI Development Hardware HTML Manipulation HTTP Clients Image Processing Implementations Interactive Interpreter Internationalization Job Scheduler Logging Machine Learning Miscellaneous Natural Language Processing Network Virtualization Networking News Feed ORM Package Management Package Repositories Permissions Processes Queue Recommender Systems RESTful API Robotics RPC Servers Science Search Serialization Serverless Frameworks Specific Formats Processing Static Site Generator Tagging Template Engine Testing Text Processing Third-party APIs URL Manipulation Video Web Asset Management Web Content Extracting Web Crawling Web Frameworks WebSocket WSGI Servers  Services  Code Quality Continuous Integration  Resources  Podcasts Twitter Websites Weekly  Contributing  [](https://github.com/vinta/awesome-python#admin-panels)Admin Panels Libraries for administrative interfaces.\n ajenti - The admin panel your servers deserve. django-grappelli - A jazzy skin for the Django Admin-Interface. django-jet - Modern responsive template for the Django admin interface with improved functionality. django-suit - Alternative Django Admin-Interface (free only for Non-commercial use). django-xadmin - Drop-in replacement of Django admin comes with lots of goodies. flask-admin - Simple and extensible administrative interface framework for Flask. flower - Real-time monitor and web admin for Celery. wooey - A Django app which creates automatic web UIs for Python scripts.  [](https://github.com/vinta/awesome-python#algorithms-and-design-patterns)Algorithms and Design Patterns Python implementation of algorithms and design patterns.\n algorithms - Minimal examples of data structures and algorithms in Python. PyPattyrn - A simple yet effective library for implementing common design patterns. python-patterns - A collection of design patterns in Python. sortedcontainers - Fast, pure-Python implementation of SortedList, SortedDict, and SortedSet types.  [](https://github.com/vinta/awesome-python#audio)Audio Libraries for manipulating audio and its metadata.\n Audio  audioread - Cross-library (GStreamer + Core Audio + MAD + FFmpeg) audio decoding. dejavu - Audio fingerprinting and recognition. mingus - An advanced music theory and notation package with MIDI file and playback support. pyAudioAnalysis - Audio feature extraction, classification, segmentation and applications. pydub - Manipulate audio with a simple and easy high level interface. TimeSide - Open web audio processing framework.  Metadata  beets - A music library manager and MusicBrainz tagger. eyeD3 - A tool for working with audio files, specifically MP3 files containing ID3 metadata. mutagen - A Python module to handle audio metadata. tinytag - A library for reading music meta data of MP3, OGG, FLAC and Wave files.   [](https://github.com/vinta/awesome-python#authentication)Authentication Libraries for implementing authentications schemes.\n OAuth  authlib - JavaScript Object Signing and Encryption draft implementation. django-allauth - Authentication app for Django that \u0026ldquo;just works.\u0026rdquo; django-oauth-toolkit - OAuth 2 goodies for Django. oauthlib - A generic and thorough implementation of the OAuth request-signing logic. python-oauth2 - A fully tested, abstract interface to creating OAuth clients and servers. python-social-auth - An easy-to-setup social authentication mechanism.  JWT  pyjwt - JSON Web Token implementation in Python. python-jose - A JOSE implementation in Python. python-jwt - A module for generating and verifying JSON Web Tokens.   [](https://github.com/vinta/awesome-python#build-tools)Build Tools Compile software from source code.\n BitBake - A make-like build tool for embedded Linux. buildout - A build system for creating, assembling and deploying applications from multiple parts. PlatformIO - A console tool to build code with different development platforms. pybuilder - A continuous build tool written in pure Python. SCons - A software construction tool.  [](https://github.com/vinta/awesome-python#built-in-classes-enhancement)Built-in Classes Enhancement Libraries for enhancing Python built-in classes.\n dataclasses - (Python standard library) Data classes. attrs - Replacement for __init__, __eq__, __repr__, etc. boilerplate in class definitions. bidict - Efficient, Pythonic bidirectional map data structures and related functionality.. Box - Python dictionaries with advanced dot notation access. DottedDict - A library that provides a method of accessing lists and dicts with a dotted path notation.  [](https://github.com/vinta/awesome-python#cms)CMS Content Management Systems.\n wagtail - A Django content management system. django-cms - An Open source enterprise CMS based on the Django. feincms - One of the most advanced Content Management Systems built on Django. Kotti - A high-level, Pythonic web application framework built on Pyramid. mezzanine - A powerful, consistent, and flexible content management platform. plone - A CMS built on top of the open source application server Zope. quokka - Flexible, extensible, small CMS powered by Flask and MongoDB.  [](https://github.com/vinta/awesome-python#caching)Caching Libraries for caching data.\n beaker - A WSGI middleware for sessions and caching. django-cache-machine - Automatic caching and invalidation for Django models. django-cacheops - A slick ORM cache with automatic granular event-driven invalidation. dogpile.cache - dogpile.cache is next generation replacement for Beaker made by same authors. HermesCache - Python caching library with tag-based invalidation and dogpile effect prevention. pylibmc - A Python wrapper around the libmemcached interface. python-diskcache - SQLite and file backed cache backend with faster lookups than memcached and redis.  [](https://github.com/vinta/awesome-python#chatops-tools)ChatOps Tools Libraries for chatbot development.\n errbot - The easiest and most popular chatbot to implement ChatOps.  [](https://github.com/vinta/awesome-python#code-analysis)Code Analysis Tools of static analysis, linters and code quality checkers. Also see awesome-static-analysis.\n Code Analysis  coala - Language independent and easily extendable code analysis application. code2flow - Turn your Python and JavaScript code into DOT flowcharts. prospector - A tool to analyse Python code. pycallgraph - A library that visualises the flow (call graph) of your Python application.  Code Linters  flake8 - A wrapper around pycodestyle, pyflakes and McCabe. pylint - A fully customizable source code analyzer. pylama - A code audit tool for Python and JavaScript.  Code Formatters  black - The uncompromising Python code formatter. yapf - Yet another Python code formatter from Google.  Static Type Checkers  mypy - Check variable types during compile time. pyre-check - Performant type checking.  Static Type Annotations Generators  MonkeyType - A system for Python that generates static type annotations by collecting runtime types   [](https://github.com/vinta/awesome-python#command-line-interface-development)Command-line Interface Development Libraries for building command-line applications.\n Command-line Application Development  cement - CLI Application Framework for Python. click - A package for creating beautiful command line interfaces in a composable way. cliff - A framework for creating command-line programs with multi-level commands. clint - Python Command-line Application Tools. docopt - Pythonic command line arguments parser. python-fire - A library for creating command line interfaces from absolutely any Python object. python-prompt-toolkit - A library for building powerful interactive command lines.  Terminal Rendering  asciimatics - A package to create full-screen text UIs (from interactive forms to ASCII animations). bashplotlib - Making basic plots in the terminal. colorama - Cross-platform colored terminal text. tqdm - Fast, extensible progress bar for loops and CLI.   [](https://github.com/vinta/awesome-python#command-line-tools)Command-line Tools Useful CLI-based tools for productivity.\n Productivity Tools  cookiecutter - A command-line utility that creates projects from cookiecutters (project templates). doitlive - A tool for live presentations in the terminal. howdoi - Instant coding answers via the command line. PathPicker - Select files out of bash output. percol - Adds flavor of interactive selection to the traditional pipe concept on UNIX. thefuck - Correcting your previous console command. tmuxp - A tmux session manager. try - A dead simple CLI to try out python packages - it\u0026rsquo;s never been easier.  CLI Enhancements  httpie - A command line HTTP client, a user-friendly cURL replacement. kube-shell - An integrated shell for working with the Kubernetes CLI. mycli - A Terminal Client for MySQL with AutoCompletion and Syntax Highlighting. pgcli - Postgres CLI with autocompletion and syntax highlighting. saws - A Supercharged aws-cli.   [](https://github.com/vinta/awesome-python#compatibility)Compatibility Libraries for migrating from Python 2 to 3.\n python-future - The missing compatibility layer between Python 2 and Python 3. python-modernize - Modernizes Python code for eventual Python 3 migration. six - Python 2 and 3 compatibility utilities.  [](https://github.com/vinta/awesome-python#computer-vision)Computer Vision Libraries for computer vision.\n OpenCV - Open Source Computer Vision Library. pytesseract - Another wrapper for Google Tesseract OCR. SimpleCV - An open source framework for building computer vision applications.  [](https://github.com/vinta/awesome-python#concurrency-and-parallelism)Concurrency and Parallelism Libraries for concurrent and parallel execution. Also see awesome-asyncio.\n concurrent.futures - (Python standard library) A high-level interface for asynchronously executing callables. multiprocessing - (Python standard library) Process-based parallelism. eventlet - Asynchronous framework with WSGI support. gevent - A coroutine-based Python networking library that uses greenlet. uvloop - Ultra fast implementation of asyncio event loop on top of libuv. scoop - Scalable Concurrent Operations in Python.  [](https://github.com/vinta/awesome-python#configuration)Configuration Libraries for storing and parsing configuration options.\n configobj - INI file parser with validation. configparser - (Python standard library) INI file parser. profig - Config from multiple formats with value conversion. python-decouple - Strict separation of settings from code.  [](https://github.com/vinta/awesome-python#cryptography)Cryptography  cryptography - A package designed to expose cryptographic primitives and recipes to Python developers. paramiko - The leading native Python SSHv2 protocol library. passlib - Secure password storage/hashing library, very high level. pynacl - Python binding to the Networking and Cryptography (NaCl) library.  [](https://github.com/vinta/awesome-python#data-analysis)Data Analysis Libraries for data analyzing.\n Blaze - NumPy and Pandas interface to Big Data. Open Mining - Business Intelligence (BI) in Pandas interface. Orange - Data mining, data visualization, analysis and machine learning through visual programming or scripts. Pandas - A library providing high-performance, easy-to-use data structures and data analysis tools. Optimus - Agile Data Science Workflows made easy with PySpark.  [](https://github.com/vinta/awesome-python#data-validation)Data Validation Libraries for validating data. Used for forms in many cases.\n Cerberus - A lightweight and extensible data validation library. colander - Validating and deserializing data obtained via XML, JSON, an HTML form post. jsonschema - An implementation of JSON Schema for Python. schema - A library for validating Python data structures. Schematics - Data Structure Validation. valideer - Lightweight extensible data validation and adaptation library. voluptuous - A Python data validation library.  [](https://github.com/vinta/awesome-python#data-visualization)Data Visualization Libraries for visualizing data. Also see awesome-javascript.\n Altair - Declarative statistical visualization library for Python. Bokeh - Interactive Web Plotting for Python. bqplot - Interactive Plotting Library for the Jupyter Notebook Dash - Built on top of Flask, React and Plotly aimed at analytical web applications.  awesome-dash  plotnine - A grammar of graphics for Python based on ggplot2. Matplotlib - A Python 2D plotting library. Pygal - A Python SVG Charts Creator. PyGraphviz - Python interface to Graphviz. PyQtGraph - Interactive and realtime 2D/3D/Image plotting and science/engineering widgets. Seaborn - Statistical data visualization using Matplotlib. VisPy - High-performance scientific visualization based on OpenGL.  [](https://github.com/vinta/awesome-python#database)Database Databases implemented in Python.\n pickleDB - A simple and lightweight key-value store for Python. tinydb - A tiny, document-oriented database. ZODB - A native object database for Python. A key-value and object graph database.  [](https://github.com/vinta/awesome-python#database-drivers)Database Drivers Libraries for connecting and operating databases.\n MySQL - awesome-mysql  mysqlclient - MySQL connector with Python 3 support (mysql-python fork). PyMySQL - A pure Python MySQL driver compatible to mysql-python.  PostgreSQL - awesome-postgres  psycopg2 - The most popular PostgreSQL adapter for Python. queries - A wrapper of the psycopg2 library for interacting with PostgreSQL.  Other Relational Databases  pymssql - A simple database interface to Microsoft SQL Server.  NoSQL Databases  cassandra-driver - The Python Driver for Apache Cassandra. happybase - A developer-friendly library for Apache HBase. kafka-python - The Python client for Apache Kafka. py2neo - Python wrapper client for Neo4j\u0026rsquo;s restful interface. pymongo - The official Python client for MongoDB. redis-py - The Python client for Redis.  Asynchronous Clients  motor - The async Python driver for MongoDB. Telephus - Twisted based client for Cassandra. txpostgres - Twisted based asynchronous driver for PostgreSQL. txRedis - Twisted based client for Redis.   [](https://github.com/vinta/awesome-python#date-and-time)Date and Time Libraries for working with dates and times.\n Chronyk - A Python 3 library for parsing human-written times and dates. dateutil - Extensions to the standard Python datetime module. delorean - A library for clearing up the inconvenient truths that arise dealing with datetimes. moment - A Python library for dealing with dates/times. Inspired by Moment.js. Pendulum - Python datetimes made easy. PyTime - A easy-use Python module which aims to operate date/time/datetime by string. pytz - World timezone definitions, modern and historical. Brings the tz database into Python. when.py - Providing user-friendly functions to help perform common date and time actions. maya - Datetimes for Humans.  [](https://github.com/vinta/awesome-python#debugging-tools)Debugging Tools Libraries for debugging code.\n pdb-like Debugger  ipdb - IPython-enabled pdb. pdb++ - Another drop-in replacement for pdb. pudb - A full-screen, console-based Python debugger. wdb - An improbable web debugger through WebSockets.  Tracing  lptrace - strace for Python programs. manhole - Debugging UNIX socket connections and present the stacktraces for all threads and an interactive prompt. pyringe - Debugger capable of attaching to and injecting code into Python processes. python-hunter - A flexible code tracing toolkit.  Profiler  line_profiler - Line-by-line profiling. memory_profiler - Monitor Memory usage of Python code. profiling - An interactive Python profiler. py-spy - A sampling profiler for Python programs. Written in Rust. pyflame - A ptracing profiler For Python. vprof - Visual Python profiler.  Others  icecream - Inspect variables, expressions, and program execution with a single, simple function call. django-debug-toolbar - Display various debug information for Django. django-devserver - A drop-in replacement for Django\u0026rsquo;s runserver. flask-debugtoolbar - A port of the django-debug-toolbar to flask. pyelftools - Parsing and analyzing ELF files and DWARF debugging information.   [](https://github.com/vinta/awesome-python#deep-learning)Deep Learning Frameworks for Neural Networks and Deep Learning. Also see awesome-deep-learning.\n caffe - A fast open framework for deep learning.. keras - A high-level neural networks library and capable of running on top of either TensorFlow or Theano. mxnet - A deep learning framework designed for both efficiency and flexibility. pytorch - Tensors and Dynamic neural networks in Python with strong GPU acceleration. SerpentAI - Game agent framework. Use any video game as a deep learning sandbox. tensorflow - The most popular Deep Learning framework created by Google. Theano - A library for fast numerical computation.  [](https://github.com/vinta/awesome-python#devops-tools)DevOps Tools Software and libraries for DevOps.\n ansible - A radically simple IT automation platform. cloudinit - A multi-distribution package that handles early initialization of a cloud instance. cuisine - Chef-like functionality for Fabric. docker-compose - Fast, isolated development environments using Docker. fabric - A simple, Pythonic tool for remote execution and deployment. fabtools - Tools for writing awesome Fabric files. honcho - A Python clone of Foreman, for managing Procfile-based applications. OpenStack - Open source software for building private and public clouds. pexpect - Controlling interactive programs in a pseudo-terminal like GNU expect. psutil - A cross-platform process and system utilities module. saltstack - Infrastructure automation and management system. supervisor - Supervisor process control system for UNIX.  [](https://github.com/vinta/awesome-python#distributed-computing)Distributed Computing Frameworks and libraries for Distributed Computing.\n Batch Processing  PySpark - Apache Spark Python API. dask - A flexible parallel computing library for analytic computing. luigi - A module that helps you build complex pipelines of batch jobs. mrjob - Run MapReduce jobs on Hadoop or Amazon Web Services. Ray - A system for parallel and distributed Python that unifies the machine learning ecosystem.  Stream Processing  faust - A stream processing library, porting the ideas from Kafka Streams to Python. streamparse - Run Python code against real-time streams of data via Apache Storm.   [](https://github.com/vinta/awesome-python#distribution)Distribution Libraries to create packaged executables for release distribution.\n dh-virtualenv - Build and distribute a virtualenv as a Debian package. Nuitka - Compile scripts, modules, packages to an executable or extension module. py2app - Freezes Python scripts (Mac OS X). py2exe - Freezes Python scripts (Windows). PyInstaller - Converts Python programs into stand-alone executables (cross-platform). pynsist - A tool to build Windows installers, installers bundle Python itself.  [](https://github.com/vinta/awesome-python#documentation)Documentation Libraries for generating project documentation.\n sphinx - Python Documentation generator.  awesome-sphinxdoc  pdoc - Epydoc replacement to auto generate API documentation for Python libraries. pycco - The literate-programming-style documentation generator.  [](https://github.com/vinta/awesome-python#downloader)Downloader Libraries for downloading.\n s3cmd - A command line tool for managing Amazon S3 and CloudFront. s4cmd - Super S3 command line tool, good for higher performance. you-get - A YouTube/Youku/Niconico video downloader written in Python 3. youtube-dl - A small command-line program to download videos from YouTube.  [](https://github.com/vinta/awesome-python#e-commerce)E-commerce Frameworks and libraries for e-commerce and payments.\n alipay - Unofficial Alipay API for Python. Cartridge - A shopping cart app built using the Mezzanine. django-oscar - An open-source e-commerce framework for Django. django-shop - A Django based shop system. merchant - A Django app to accept payments from various payment processors. money - Money class with optional CLDR-backed locale-aware formatting and an extensible currency exchange. python-currencies - Display money format and its filthy currencies. forex-python - Foreign exchange rates, Bitcoin price index and currency conversion. saleor - An e-commerce storefront for Django. shoop - An open source E-Commerce platform based on Django.  [](https://github.com/vinta/awesome-python#editor-plugins-and-ides)Editor Plugins and IDEs  Emacs  elpy - Emacs Python Development Environment.  Sublime Text  anaconda - Anaconda turns your Sublime Text 3 in a full featured Python development IDE. SublimeJEDI - A Sublime Text plugin to the awesome auto-complete library Jedi.  Vim  jedi-vim - Vim bindings for the Jedi auto-completion library for Python. python-mode - An all in one plugin for turning Vim into a Python IDE. YouCompleteMe - Includes Jedi-based completion engine for Python.  Visual Studio  PTVS - Python Tools for Visual Studio.  Visual Studio Code  Python - The official VSCode extension with rich support for Python.  IDE  PyCharm - Commercial Python IDE by JetBrains. Has free community edition available. spyder - Open Source Python IDE.   [](https://github.com/vinta/awesome-python#email)Email Libraries for sending and parsing email.\n envelopes - Mailing for human beings. flanker - A email address and Mime parsing library. imbox - Python IMAP for Humans. inbox.py - Python SMTP Server for Humans. lamson - Pythonic SMTP Application Server. Marrow Mailer - High-performance extensible mail delivery framework. modoboa - A mail hosting and management platform including a modern and simplified Web UI. Nylas Sync Engine - Providing a RESTful API on top of a powerful email sync platform. yagmail - Yet another Gmail/SMTP client.  [](https://github.com/vinta/awesome-python#environment-management)Environment Management Libraries for Python version and virtual environment management.\n pyenv - Simple Python version management. pipenv - Python Development Workflow for Humans. poetry - Python dependency management and packaging made easy. virtualenv - A tool to create isolated Python environments.  [](https://github.com/vinta/awesome-python#files)Files Libraries for file manipulation and MIME type detection.\n mimetypes - (Python standard library) Map filenames to MIME types. path.py - A module wrapper for os.path. pathlib - (Python standard library) An cross-platform, object-oriented path library. PyFilesystem2 - Python\u0026rsquo;s filesystem abstraction layer. python-magic - A Python interface to the libmagic file type identification library. Unipath - An object-oriented approach to file/directory operations. watchdog - API and shell utilities to monitor file system events.  [](https://github.com/vinta/awesome-python#foreign-function-interface)Foreign Function Interface Libraries for providing foreign function interface.\n cffi - Foreign Function Interface for Python calling C code. ctypes - (Python standard library) Foreign Function Interface for Python calling C code. PyCUDA - A Python wrapper for Nvidia\u0026rsquo;s CUDA API. SWIG - Simplified Wrapper and Interface Generator.  [](https://github.com/vinta/awesome-python#forms)Forms Libraries for working with forms.\n Deform - Python HTML form generation library influenced by the formish form generation library. django-bootstrap3 - Bootstrap 3 integration with Django. django-bootstrap4 - Bootstrap 4 integration with Django. django-crispy-forms - A Django app which lets you create beautiful forms in a very elegant and DRY way. django-remote-forms - A platform independent Django form serializer. WTForms - A flexible forms validation and rendering library.  [](https://github.com/vinta/awesome-python#functional-programming)Functional Programming Functional Programming with Python.\n Coconut - Coconut is a variant of Python built for simple, elegant, Pythonic functional programming. CyToolz - Cython implementation of Toolz: High performance functional utilities. fn.py - Functional programming in Python: implementation of missing features to enjoy FP. funcy - A fancy and practical functional tools. Toolz - A collection of functional utilities for iterators, functions, and dictionaries.  [](https://github.com/vinta/awesome-python#gui-development)GUI Development Libraries for working with graphical user interface applications.\n curses - Built-in wrapper for ncurses used to create terminal GUI applications. Eel - A library for making simple Electron-like offline HTML/JS GUI apps. enaml - Creating beautiful user-interfaces with Declaratic Syntax like QML. Flexx - Flexx is a pure Python toolkit for creating GUI\u0026rsquo;s, that uses web technology for its rendering. Gooey - Turn command line programs into a full GUI application with one line. kivy - A library for creating NUI applications, running on Windows, Linux, Mac OS X, Android and iOS. pyglet - A cross-platform windowing and multimedia library for Python. PyGObject - Python Bindings for GLib/GObject/GIO/GTK+ (GTK+3). PyQt - Python bindings for the Qt cross-platform application and UI framework. PySimpleGUI - Wrapper for tkinter, Qt, WxPython and Remi. pywebview - A lightweight cross-platform native wrapper around a webview component. Tkinter - Tkinter is Python\u0026rsquo;s de-facto standard GUI package. Toga - A Python native, OS native GUI toolkit. urwid - A library for creating terminal GUI applications with strong support for widgets, events, rich colors, etc. wxPython - A blending of the wxWidgets C++ class library with the Python.  [](https://github.com/vinta/awesome-python#game-development)Game Development Awesome game development libraries.\n Cocos2d - cocos2d is a framework for building 2D games, demos, and other graphical/interactive applications. Harfang3D - Python framework for 3D, VR and game development. Panda3D - 3D game engine developed by Disney. Pygame - Pygame is a set of Python modules designed for writing games. PyOgre - Python bindings for the Ogre 3D render engine, can be used for games, simulations, anything 3D. PyOpenGL - Python ctypes bindings for OpenGL and it\u0026rsquo;s related APIs. PySDL2 - A ctypes based wrapper for the SDL2 library. RenPy - A Visual Novel engine.  [](https://github.com/vinta/awesome-python#geolocation)Geolocation Libraries for geocoding addresses and working with latitudes and longitudes.\n django-countries - A Django app that provides a country field for models and forms. GeoDjango - A world-class geographic web framework. GeoIP - Python API for MaxMind GeoIP Legacy Database. geojson - Python bindings and utilities for GeoJSON. geopy - Python Geocoding Toolbox. pygeoip - Pure Python GeoIP API.  [](https://github.com/vinta/awesome-python#html-manipulation)HTML Manipulation Libraries for working with HTML and XML.\n BeautifulSoup - Providing Pythonic idioms for iterating, searching, and modifying HTML or XML. bleach - A whitelist-based HTML sanitization and text linkification library. cssutils - A CSS library for Python. html5lib - A standards-compliant library for parsing and serializing HTML documents and fragments. lxml - A very fast, easy-to-use and versatile library for handling HTML and XML. MarkupSafe - Implements a XML/HTML/XHTML Markup safe string for Python. pyquery - A jQuery-like library for parsing HTML. untangle - Converts XML documents to Python objects for easy access. WeasyPrint - A visual rendering engine for HTML and CSS that can export to PDF. xmldataset - Simple XML Parsing. xmltodict - Working with XML feel like you are working with JSON.  [](https://github.com/vinta/awesome-python#http-clients)HTTP Clients Libraries for working with HTTP.\n grequests - requests + gevent for asynchronous HTTP requests. httplib2 - Comprehensive HTTP client library. requests - HTTP Requests for Humans™. treq - Python requests like API built on top of Twisted\u0026rsquo;s HTTP client. urllib3 - A HTTP library with thread-safe connection pooling, file post support, sanity friendly.  [](https://github.com/vinta/awesome-python#hardware)Hardware Libraries for programming with hardware.\n ino - Command line toolkit for working with Arduino. keyboard - Hook and simulate global keyboard events on Windows and Linux. mouse - Hook and simulate global mouse events on Windows and Linux. Pingo - Pingo provides a uniform API to program devices like the Raspberry Pi, pcDuino, Intel Galileo, etc. PyUserInput - A module for cross-platform control of the mouse and keyboard. scapy - A brilliant packet manipulation library. wifi - A Python library and command line tool for working with WiFi on Linux.  [](https://github.com/vinta/awesome-python#image-processing)Image Processing Libraries for manipulating images.\n hmap - Image histogram remapping. imgSeek - A project for searching a collection of images using visual similarity. nude.py - Nudity detection. pagan - Retro identicon (Avatar) generation based on input string and hash. pillow - Pillow is the friendly PIL fork. pyBarcode - Create barcodes in Python without needing PIL. pygram - Instagram-like image filters. python-qrcode - A pure Python QR Code generator. Quads - Computer art based on quadtrees. scikit-image - A Python library for (scientific) image processing. thumbor - A smart imaging service. It enables on-demand crop, re-sizing and flipping of images. wand - Python bindings for MagickWand, C API for ImageMagick.  [](https://github.com/vinta/awesome-python#implementations)Implementations Implementations of Python.\n CPython - Default, most widely used implementation of the Python programming language written in C. Cython - Optimizing Static Compiler for Python. CLPython - Implementation of the Python programming language written in Common Lisp. Grumpy - More compiler than interpreter as more powerful CPython2.7 replacement (alpha). IronPython - Implementation of the Python programming language written in C#. Jython - Implementation of Python programming language written in Java for the JVM. MicroPython - A lean and efficient Python programming language implementation. Numba - Python JIT compiler to LLVM aimed at scientific Python. PeachPy - x86-64 assembler embedded in Python. Pyjion - A JIT for Python based upon CoreCLR. PyPy - A very fast and compliant implementation of the Python language. Pyston - A Python implementation using JIT techniques. Stackless Python - An enhanced version of the Python programming language.  [](https://github.com/vinta/awesome-python#interactive-interpreter)Interactive Interpreter Interactive Python interpreters (REPL).\n bpython - A fancy interface to the Python interpreter. Jupyter Notebook (IPython) - A rich toolkit to help you make the most out of using Python interactively.  awesome-jupyter  ptpython - Advanced Python REPL built on top of the python-prompt-toolkit.  [](https://github.com/vinta/awesome-python#internationalization)Internationalization Libraries for working with i18n.\n Babel - An internationalization library for Python. PyICU - A wrapper of International Components for Unicode C++ library (ICU).  [](https://github.com/vinta/awesome-python#job-scheduler)Job Scheduler Libraries for scheduling jobs.\n APScheduler - A light but powerful in-process task scheduler that lets you schedule functions. django-schedule - A calendaring app for Django. doit - A task runner and build tool. gunnery - Multipurpose task execution tool for distributed systems with web-based interface. Joblib - A set of tools to provide lightweight pipelining in Python. Plan - Writing crontab file in Python like a charm. schedule - Python job scheduling for humans. Spiff - A powerful workflow engine implemented in pure Python. TaskFlow - A Python library that helps to make task execution easy, consistent and reliable. Airflow - Airflow is a platform to programmatically author, schedule and monitor workflows.  [](https://github.com/vinta/awesome-python#logging)Logging Libraries for generating and working with logs.\n Eliot - Logging for complex \u0026amp; distributed systems. logbook - Logging replacement for Python. logging - (Python standard library) Logging facility for Python. raven - Python client for Sentry, a log/error tracking, crash reporting and aggregation platform for web applications.  [](https://github.com/vinta/awesome-python#machine-learning)Machine Learning Libraries for Machine Learning. Also see awesome-machine-learning.\n H2O - Open Source Fast Scalable Machine Learning Platform. Metrics - Machine learning evaluation metrics. NuPIC - Numenta Platform for Intelligent Computing. scikit-learn - The most popular Python library for Machine Learning. Spark ML - Apache Spark\u0026rsquo;s scalable Machine Learning library. vowpal_porpoise - A lightweight Python wrapper for Vowpal Wabbit. xgboost - A scalable, portable, and distributed gradient boosting library.  [](https://github.com/vinta/awesome-python#microsoft-windows)Microsoft Windows Python programming on Microsoft Windows.\n Python(x,y) - Scientific-applications-oriented Python Distribution based on Qt and Spyder. pythonlibs - Unofficial Windows binaries for Python extension packages. PythonNet - Python Integration with the .NET Common Language Runtime (CLR). PyWin32 - Python Extensions for Windows. WinPython - Portable development environment for Windows 7\u0026frasl;8.  [](https://github.com/vinta/awesome-python#miscellaneous)Miscellaneous Useful libraries or tools that don\u0026rsquo;t fit in the categories above.\n blinker - A fast Python in-process signal/event dispatching system. boltons - A set of pure-Python utilities. itsdangerous - Various helpers to pass trusted data to untrusted environments. pluginbase - A simple but flexible plugin system for Python. tryton - A general purpose business framework.  [](https://github.com/vinta/awesome-python#natural-language-processing)Natural Language Processing Libraries for working with human languages.\n General  gensim - Topic Modelling for Humans. langid.py - Stand-alone language identification system. nltk - A leading platform for building Python programs to work with human language data. pattern - A web mining module for the Python. polyglot - Natural language pipeline supporting hundreds of languages. pytext - A natural language modeling framework based on PyTorch. PyTorch-NLP - A toolkit enabling rapid deep learning NLP prototyping for research. spacy - A library for industrial-strength natural language processing in Python and Cython. stanfordnlp - The Stanford NLP Group\u0026rsquo;s official Python library, supporting 50+ languages.  Chinese  jieba - The most popular Chinese text segmentation library. pkuseg-python - A toolkit for Chinese word segmentation in various domains. snownlp - A library for processing Chinese text. funNLP - A collection of tools and datasets for Chinese NLP.   [](https://github.com/vinta/awesome-python#network-virtualization)Network Virtualization Tools and libraries for Virtual Networking and SDN (Software Defined Networking).\n mininet - A popular network emulator and API written in Python. pox - A Python-based SDN control applications, such as OpenFlow SDN controllers.  [](https://github.com/vinta/awesome-python#networking)Networking Libraries for networking programming.\n asyncio - (Python standard library) Asynchronous I/O, event loop, coroutines and tasks.  awesome-asyncio  pulsar - Event-driven concurrent framework for Python. pyzmq - A Python wrapper for the ZeroMQ message library. Twisted - An event-driven networking engine. napalm - Cross-vendor API to manipulate network devices.  [](https://github.com/vinta/awesome-python#news-feed)News Feed Libraries for building user\u0026rsquo;s activities.\n django-activity-stream - Generating generic activity streams from the actions on your site. Stream Framework - Building newsfeed and notification systems using Cassandra and Redis.  [](https://github.com/vinta/awesome-python#orm)ORM Libraries that implement Object-Relational Mapping or data mapping techniques.\n Relational Databases  Django Models - A part of Django. SQLAlchemy - The Python SQL Toolkit and Object Relational Mapper.  awesome-sqlalchemy  dataset - Store Python dicts in a database - works with SQLite, MySQL, and PostgreSQL. orator - The Orator ORM provides a simple yet beautiful ActiveRecord implementation. peewee - A small, expressive ORM. pony - ORM that provides a generator-oriented interface to SQL. pydal - A pure Python Database Abstraction Layer.  NoSQL Databases  hot-redis - Rich Python data types for Redis. mongoengine - A Python Object-Document-Mapper for working with MongoDB. PynamoDB - A Pythonic interface for Amazon DynamoDB. redisco - A Python Library for Simple Models and Containers Persisted in Redis.   [](https://github.com/vinta/awesome-python#package-management)Package Management Libraries for package and dependency management.\n pip - The Python package and dependency manager.  PyPI pip-tools - A set of tools to keep your pinned Python dependencies fresh.  conda - Cross-platform, Python-agnostic binary package manager.  [](https://github.com/vinta/awesome-python#package-repositories)Package Repositories Local PyPI repository server and proxies.\n warehouse - Next generation Python Package Repository (PyPI). bandersnatch - PyPI mirroring tool provided by Python Packaging Authority (PyPA). devpi - PyPI server and packaging/testing/release tool. localshop - Local PyPI server (custom packages and auto-mirroring of pypi).  [](https://github.com/vinta/awesome-python#permissions)Permissions Libraries that allow or deny users access to data or functionality.\n django-guardian - Implementation of per object permissions for Django 1.2+ django-rules - A tiny but powerful app providing object-level permissions to Django, without requiring a database.  [](https://github.com/vinta/awesome-python#processes)Processes Libraries for starting and communicating with OS processes.\n delegator.py - Subprocesses for Humans™ 2.0. sarge - Yet another wrapper for subprocess. sh - A full-fledged subprocess replacement for Python.  [](https://github.com/vinta/awesome-python#queue)Queue Libraries for working with event and task queues.\n celery - An asynchronous task queue/job queue based on distributed message passing. huey - Little multi-threaded task queue. mrq - Mr. Queue - A distributed worker task queue in Python using Redis \u0026amp; gevent. rq - Simple job queues for Python.  [](https://github.com/vinta/awesome-python#recommender-systems)Recommender Systems Libraries for building recommender systems.\n annoy - Approximate Nearest Neighbors in C++/Python optimized for memory usage. fastFM - A library for Factorization Machines. implicit - A fast Python implementation of collaborative filtering for implicit datasets. libffm - A library for Field-aware Factorization Machine (FFM). lightfm - A Python implementation of a number of popular recommendation algorithms. spotlight - Deep recommender models using PyTorch. Surprise - A scikit for building and analyzing recommender systems. tensorrec - A Recommendation Engine Framework in TensorFlow.  [](https://github.com/vinta/awesome-python#restful-api)RESTful API Libraries for developing RESTful APIs.\n Django  django-rest-framework - A powerful and flexible toolkit to build web APIs. django-tastypie - Creating delicious APIs for Django apps.  Flask  eve - REST API framework powered by Flask, MongoDB and good intentions. flask-api-utils - Taking care of API representation and authentication for Flask. flask-api - Browsable Web APIs for Flask. flask-restful - Quickly building REST APIs for Flask. flask-restless - Generating RESTful APIs for database models defined with SQLAlchemy.  Pyramid  cornice - A RESTful framework for Pyramid.  Framework agnostic  apistar - A smart Web API framework, designed for Python 3. falcon - A high-performance framework for building cloud APIs and web app backends. hug - A Python 3 framework for cleanly exposing APIs. restless - Framework agnostic REST framework based on lessons learned from Tastypie. ripozo - Quickly creating REST/HATEOAS/Hypermedia APIs. sandman - Automated REST APIs for existing database-driven systems.   [](https://github.com/vinta/awesome-python#robotics)Robotics Libraries for robotics.\n PythonRobotics - This is a compilation of various robotics algorithms with visualizations. rospy - This is a library for ROS (Robot Operating System).  [](https://github.com/vinta/awesome-python#rpc-servers)RPC Servers RPC-compatible servers.\n SimpleJSONRPCServer - This library is an implementation of the JSON-RPC specification. SimpleXMLRPCServer - (Python standard library) Simple XML-RPC server implementation, single-threaded. zeroRPC - zerorpc is a flexible RPC implementation based on ZeroMQ and MessagePack.  [](https://github.com/vinta/awesome-python#science)Science Libraries for scientific computing. Also see Python-for-Scientists\n astropy - A community Python library for Astronomy. bcbio-nextgen - Providing best-practice pipelines for fully automated high throughput sequencing analysis. bccb - Collection of useful code related to biological analysis. Biopython - Biopython is a set of freely available tools for biological computation. cclib - A library for parsing and interpreting the results of computational chemistry packages. Colour - Implementing a comprehensive number of colour theory transformations and algorithms. NetworkX - A high-productivity software for complex networks. NIPY - A collection of neuroimaging toolkits. NumPy - A fundamental package for scientific computing with Python. Open Babel - A chemical toolbox designed to speak the many languages of chemical data. ObsPy - A Python toolbox for seismology. PyDy - Short for Python Dynamics, used to assist with workflow in the modeling of dynamic motion. PyMC - Markov Chain Monte Carlo sampling toolkit. QuTiP - Quantum Toolbox in Python. RDKit - Cheminformatics and Machine Learning Software. SciPy - A Python-based ecosystem of open-source software for mathematics, science, and engineering. statsmodels - Statistical modeling and econometrics in Python. SymPy - A Python library for symbolic mathematics. Zipline - A Pythonic algorithmic trading library. SimPy - A process-based discrete-event simulation framework.  [](https://github.com/vinta/awesome-python#search)Search Libraries and software for indexing and performing search queries on data.\n elasticsearch-py - The official low-level Python client for Elasticsearch. elasticsearch-dsl-py - The official high-level Python client for Elasticsearch. django-haystack - Modular search for Django. pysolr - A lightweight Python wrapper for Apache Solr. whoosh - A fast, pure Python search engine library.  [](https://github.com/vinta/awesome-python#serialization)Serialization Libraries for serializing complex data types\n marshmallow - A lightweight library for converting complex objects to and from simple Python datatypes. pysimdjson - A Python bindings for simdjson. python-rapidjson - A Python wrapper around RapidJSON.  [](https://github.com/vinta/awesome-python#serverless-frameworks)Serverless Frameworks Frameworks for developing serverless Python code.\n python-lambda - A toolkit for developing and deploying Python code in AWS Lambda. Zappa - A tool for deploying WSGI applications on AWS Lambda and API Gateway.  [](https://github.com/vinta/awesome-python#specific-formats-processing)Specific Formats Processing Libraries for parsing and manipulating specific text formats.\n General  tablib - A module for Tabular Datasets in XLS, CSV, JSON, YAML.  Office  openpyxl - A library for reading and writing Excel 2010 xlsx/xlsm/xltx/xltm files. pyexcel - Providing one API for reading, manipulating and writing csv, ods, xls, xlsx and xlsm files. python-docx - Reads, queries and modifies Microsoft Word 2007\u0026frasl;2008 docx files. python-pptx - Python library for creating and updating PowerPoint (.pptx) files. unoconv - Convert between any document format supported by LibreOffice/OpenOffice. XlsxWriter - A Python module for creating Excel .xlsx files. xlwings - A BSD-licensed library that makes it easy to call Python from Excel and vice versa. xlwt / xlrd - Writing and reading data and formatting information from Excel files.  PDF  PDFMiner - A tool for extracting information from PDF documents. PyPDF2 - A library capable of splitting, merging and transforming PDF pages. ReportLab - Allowing Rapid creation of rich PDF documents.  Markdown  Mistune - Fastest and full featured pure Python parsers of Markdown. Python-Markdown - A Python implementation of John Gruber’s Markdown.  YAML  PyYAML - YAML implementations for Python.  CSV  csvkit - Utilities for converting to and working with CSV.  Archive  unp - A command line tool that can unpack archives easily.   [](https://github.com/vinta/awesome-python#static-site-generator)Static Site Generator Static site generator is a software that takes some text + templates as input and produces HTML files on the output.\n mkdocs - Markdown friendly documentation generator. pelican - Static site generator that supports Markdown and reST syntax. lektor - An easy to use static CMS and blog engine. nikola - A static website and blog generator.  [](https://github.com/vinta/awesome-python#tagging)Tagging Libraries for tagging items.\n django-taggit - Simple tagging for Django.  [](https://github.com/vinta/awesome-python#template-engine)Template Engine Libraries and tools for templating and lexing.\n Jinja2 - A modern and designer friendly templating language. Genshi - Python templating toolkit for generation of web-aware output. Mako - Hyperfast and lightweight templating for the Python platform.  [](https://github.com/vinta/awesome-python#testing)Testing Libraries for testing codebases and generating test data.\n Testing Frameworks  pytest - A mature full-featured Python testing tool. hypothesis - Hypothesis is an advanced Quickcheck style property based testing library. nose2 - The successor to nose, based on `unittest2. Robot Framework - A generic test automation framework. unittest - (Python standard library) Unit testing framework.  Test Runners  green - A clean, colorful test runner. mamba - The definitive testing tool for Python. Born under the banner of BDD. tox - Auto builds and tests distributions in multiple Python versions  GUI / Web Testing  locust - Scalable user load testing tool written in Python. PyAutoGUI - PyAutoGUI is a cross-platform GUI automation Python module for human beings. Selenium - Python bindings for Selenium WebDriver. sixpack - A language-agnostic A/B Testing framework. splinter - Open source tool for testing web applications.  Mock  mock - (Python standard library) A mocking and patching library. doublex - Powerful test doubles framework for Python. freezegun - Travel through time by mocking the datetime module. httmock - A mocking library for requests for Python 2.6+ and 3.2+. httpretty - HTTP request mock tool for Python. mocket - A socket mock framework with gevent/asyncio/SSL support. responses - A utility library for mocking out the requests Python library. VCR.py - Record and replay HTTP interactions on your tests.  Object Factories  factory_boy - A test fixtures replacement for Python. mixer - Another fixtures replacement. Supported Django, Flask, SQLAlchemy, Peewee and etc. model_mommy - Creating random fixtures for testing in Django.  Code Coverage  coverage - Code coverage measurement.  Fake Data  mimesis - is a Python library that help you generate fake data. fake2db - Fake database generator. faker - A Python package that generates fake data. radar - Generate random datetime / time.   [](https://github.com/vinta/awesome-python#text-processing)Text Processing Libraries for parsing and manipulating plain texts.\n General  chardet - Python 2\u0026frasl;3 compatible character encoding detector. difflib - (Python standard library) Helpers for computing deltas. ftfy - Makes Unicode text less broken and more consistent automagically. fuzzywuzzy - Fuzzy String Matching. Levenshtein - Fast computation of Levenshtein distance and string similarity. pangu.py - Paranoid text spacing. pyfiglet - An implementation of figlet written in Python. pypinyin - Convert Chinese hanzi (漢字) to pinyin (拼音). textdistance - Compute distance between sequences with 30+ algorithms. unidecode - ASCII transliterations of Unicode text.  Slugify  awesome-slugify - A Python slugify library that can preserve unicode. python-slugify - A Python slugify library that translates unicode to ASCII. unicode-slugify - A slugifier that generates unicode slugs with Django as a dependency.  Unique identifiers  hashids - Implementation of hashids in Python. shortuuid - A generator library for concise, unambiguous and URL-safe UUIDs.  Parser  ply - Implementation of lex and yacc parsing tools for Python. pygments - A generic syntax highlighter. pyparsing - A general purpose framework for generating parsers. python-nameparser - Parsing human names into their individual components. python-phonenumbers - Parsing, formatting, storing and validating international phone numbers. python-user-agents - Browser user agent parser. sqlparse - A non-validating SQL parser.   [](https://github.com/vinta/awesome-python#third-party-apis)Third-party APIs Libraries for accessing third party services APIs. Also see List of Python API Wrappers and Libraries.\n apache-libcloud - One Python library for all clouds. boto3 - Python interface to Amazon Web Services. django-wordpress - WordPress models and views for Django. facebook-sdk - Facebook Platform Python SDK. google-api-python-client - Google APIs Client Library for Python. gspread - Google Spreadsheets Python API. twython - A Python wrapper for the Twitter API.  [](https://github.com/vinta/awesome-python#url-manipulation)URL Manipulation Libraries for parsing URLs.\n furl - A small Python library that makes parsing and manipulating URLs easy. purl - A simple, immutable URL class with a clean API for interrogation and manipulation. pyshorteners - A pure Python URL shortening lib. webargs - A friendly library for parsing HTTP request arguments with built-in support for popular web frameworks.  [](https://github.com/vinta/awesome-python#video)Video Libraries for manipulating video and GIFs.\n moviepy - A module for script-based movie editing with many formats, including animated GIFs. scikit-video - Video processing routines for SciPy.  [](https://github.com/vinta/awesome-python#wsgi-servers)WSGI Servers WSGI-compatible web servers.\n bjoern - Asynchronous, very fast and written in C. gunicorn - Pre-forked, partly written in C. uWSGI - A project aims at developing a full stack for building hosting services, written in C. waitress - Multi-threaded, powers Pyramid. werkzeug - A WSGI utility library for Python that powers Flask and can easily be embedded into your own projects.  [](https://github.com/vinta/awesome-python#web-asset-management)Web Asset Management Tools for managing, compressing and minifying website assets.\n django-compressor - Compresses linked and inline JavaScript or CSS into a single cached file. django-pipeline - An asset packaging library for Django. django-storages - A collection of custom storage back ends for Django. fanstatic - Packages, optimizes, and serves static file dependencies as Python packages. fileconveyor - A daemon to detect and sync files to CDNs, S3 and FTP. flask-assets - Helps you integrate webassets into your Flask app. webassets - Bundles, optimizes, and manages unique cache-busting URLs for static resources.  [](https://github.com/vinta/awesome-python#web-content-extracting)Web Content Extracting Libraries for extracting web contents.\n html2text - Convert HTML to Markdown-formatted text. lassie - Web Content Retrieval for Humans. micawber - A small library for extracting rich content from URLs. newspaper - News extraction, article extraction and content curation in Python. python-readability - Fast Python port of arc90\u0026rsquo;s readability tool. requests-html - Pythonic HTML Parsing for Humans. sumy - A module for automatic summarization of text documents and HTML pages. textract - Extract text from any document, Word, PowerPoint, PDFs, etc. toapi - Every web site provides APIs.  [](https://github.com/vinta/awesome-python#web-crawling)Web Crawling Libraries to automate web scraping.\n cola - A distributed crawling framework. feedparser - Universal feed parser. grab - Site scraping framework. MechanicalSoup - A Python library for automating interaction with websites. pyspider - A powerful spider system. robobrowser - A simple, Pythonic library for browsing the web without a standalone web browser. scrapy - A fast high-level screen scraping and web crawling framework. portia - Visual scraping for Scrapy.  [](https://github.com/vinta/awesome-python#web-frameworks)Web Frameworks Full stack web frameworks.\n Django - The most popular web framework in Python.  awesome-django  Flask - A microframework for Python.  awesome-flask  Masonite - The modern and developer centric Python web framework. Pyramid - A small, fast, down-to-earth, open source Python web framework.  awesome-pyramid  Sanic - Web server that\u0026rsquo;s written to go fast. Vibora - Fast, efficient and asynchronous Web framework inspired by Flask. Tornado - A Web framework and asynchronous networking library.  [](https://github.com/vinta/awesome-python#websocket)WebSocket Libraries for working with WebSocket.\n autobahn-python - WebSocket \u0026amp; WAMP for Python on Twisted and asyncio. crossbar - Open-source Unified Application Router (Websocket \u0026amp; WAMP for Python on Autobahn). django-channels - Developer-friendly asynchrony for Django. django-socketio - WebSockets for Django. WebSocket-for-Python - WebSocket client and server library for Python 2 and 3 as well as PyPy.  [](https://github.com/vinta/awesome-python#services)Services Online tools and APIs to simplify development.\n[](https://github.com/vinta/awesome-python#continuous-integration)Continuous Integration Also see awesome-CIandCD.\n CircleCI - A CI service that can run very fast parallel testing. Travis CI - A popular CI service for your open source and private projects. (GitHub only) Vexor CI - A continuous integration tool for private apps with pay-per-minute billing model. Wercker - A Docker-based platform for building and deploying applications and microservices.  [](https://github.com/vinta/awesome-python#code-quality)Code Quality  Codacy - Automated Code Review to ship better code, faster. Codecov - Code coverage dashboard. CodeFactor - Automated Code Review for Git. Landscape - Hosted continuous Python code metrics. PEP 8 Speaks - GitHub integration to review code style.  [](https://github.com/vinta/awesome-python#resources)Resources Where to discover new Python libraries.\n[](https://github.com/vinta/awesome-python#podcasts)Podcasts  From Python Import Podcast Podcast.init Python Bytes Python Testing Radio Free Python Talk Python To Me Test and Code  [](https://github.com/vinta/awesome-python#twitter)Twitter  @codetengu @getpy @importpython @planetpython @pycoders @pypi @pythontrending @PythonWeekly @TalkPython @realpython  [](https://github.com/vinta/awesome-python#websites)Websites  /r/CoolGithubProjects /r/Python Awesome Python @LibHunt Django Packages Full Stack Python Python Cheatsheet Python Hackers Python ZEEF Python 开发社区 Real Python Trending Python repositories on GitHub today Сообщество Python Программистов  [](https://github.com/vinta/awesome-python#weekly)Weekly  CodeTengu Weekly 碼天狗週刊 Import Python Newsletter Pycoder\u0026rsquo;s Weekly Python Weekly Python Tricks   Source : https://github.com/vinta/awesome-python\n "});index.add({'id':34,'href':'/library/tutorials/docs/front-end/bootstrap/basic-bootstap/ep-2/','title':"Bootstrap 4 แบบพื้นฐาน ตอนที่ 2",'content':" สรุปการใช้งาน Bootstrap 4 แบบพื้นฐาน ตอนที่ 2 Table สร้างไฟล์ใหม่ชื่อ portal.html\nใส่โค้ดพื้นฐาน html ลงไปแล้วก็เพิ่ม bootstrap.css ด้วย\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;UTF-8\u0026quot; /\u0026gt; \u0026lt;meta name=\u0026quot;viewport\u0026quot; content=\u0026quot;width=device-width, initial-scale=1.0\u0026quot; /\u0026gt; \u0026lt;meta http-equiv=\u0026quot;X-UA-Compatible\u0026quot; content=\u0026quot;ie=edge\u0026quot; /\u0026gt; \u0026lt;title\u0026gt;Portal\u0026lt;/title\u0026gt; \u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;css/bootstrap.min.css\u0026quot; /\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div class=\u0026quot;container\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col\u0026quot;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  ใส่ตารางลงไปใน container\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;UTF-8\u0026quot; /\u0026gt; \u0026lt;meta name=\u0026quot;viewport\u0026quot; content=\u0026quot;width=device-width, initial-scale=1.0\u0026quot; /\u0026gt; \u0026lt;meta http-equiv=\u0026quot;X-UA-Compatible\u0026quot; content=\u0026quot;ie=edge\u0026quot; /\u0026gt; \u0026lt;title\u0026gt;Portal\u0026lt;/title\u0026gt; \u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;css/bootstrap.min.css\u0026quot; /\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div class=\u0026quot;container\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col\u0026quot;\u0026gt; \u0026lt;h1\u0026gt;Portal\u0026lt;/h1\u0026gt; \u0026lt;table\u0026gt; \u0026lt;thead\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th\u0026gt;No...\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;Name\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;Status\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;Age\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;Address\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;Department\u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/thead\u0026gt; \u0026lt;tbody\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;1\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;Benz\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;Normal\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;35\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;Bangkok 10000\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;IT\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;2\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;Namnueng\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;NA\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;35\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;Bangkok 10000\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;IT\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;3\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;Pare\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;NA\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;35\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;Bangkok 10000\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;IT\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/tbody\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  จะได้แบบนี้\nBootstrap มี class ชื่อว่า table ทำให้ตารางสวยขึ้น\n\u0026lt;table class=\u0026quot;table\u0026quot;\u0026gt;\u0026lt;/table\u0026gt;  ปรับแต่งหัวตารางโดยใช้ utility class คือ bg- และ text-\n\u0026lt;table class=\u0026quot;table\u0026quot;\u0026gt; \u0026lt;thead\u0026gt; \u0026lt;tr class=\u0026quot;bg-primary text-white\u0026quot;\u0026gt; ... \u0026lt;/tr\u0026gt; \u0026lt;/thead\u0026gt; \u0026lt;/table\u0026gt;  ทำให้ตารางสลับสี ใช้ table-striped เพิ่มเข้าไป\n\u0026lt;table class=\u0026quot;table table-striped\u0026quot;\u0026gt;\u0026lt;/table\u0026gt;  ทำให้ตารางเลื่อสีไปตาม cursor ใช้ table-hover เพิ่มเข้าไป\n\u0026lt;table class=\u0026quot;table table-hover\u0026quot;\u0026gt;\u0026lt;/table\u0026gt;  ใส่ขอบให้ตารางใช้ table-bordered\n\u0026lt;table class=\u0026quot;table table-hover table-bordered\u0026quot;\u0026gt;\u0026lt;/table\u0026gt;  ลองย่อหน้าต่างให้เล็กเป็นมุมมองมือถือ จะพบว่าตารางไม่รองรับ responsive\n[วิธีการแก้ก็คือเอาตารางไปใส่ใน div class table-responsive\n\u0026lt;div class=\u0026quot;table-responsive\u0026quot;\u0026gt; \u0026lt;table class=\u0026quot;table table-hover table-bordered\u0026quot;\u0026gt; ... \u0026lt;/table\u0026gt; \u0026lt;/div\u0026gt;  มันจะสามารถเลื่อน ซ้ายขวาได้\nใน VS Code ตรงไหนโค้ดยาวก็ย่อโค้ดได้นะ\n[Source code https://gist.github.com/benznest/d7b07ec41ffef49429ec4c95112c1dcb\nForm สร้างไฟล์ใหม่ login.html จะลองทำหน้า login กัน อย่าลืมเพิ่ม boostrap.css เข้ามาด้วย\nฟอร์มล้อคอินที่จะทำ หน้าตาประมาณนี้\nลองใส่ฟอร์มล็อกอิน แบบง่ายๆ\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;UTF-8\u0026quot;\u0026gt; \u0026lt;meta name=\u0026quot;viewport\u0026quot; content=\u0026quot;width=device-width, initial-scale=1.0\u0026quot;\u0026gt; \u0026lt;meta http-equiv=\u0026quot;X-UA-Compatible\u0026quot; content=\u0026quot;ie=edge\u0026quot;\u0026gt; \u0026lt;title\u0026gt;Portal\u0026lt;/title\u0026gt; \u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;css/bootstrap.min.css\u0026quot; /\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div class=\u0026quot;container\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col\u0026quot;\u0026gt; \u0026lt;form action=\u0026quot;#\u0026quot;\u0026gt; \u0026lt;label for=\u0026quot;usernmae\u0026quot;\u0026gt;Username: \u0026lt;/label\u0026gt; \u0026lt;input type=\u0026quot;text\u0026quot; id=\u0026quot;username\u0026quot; name=\u0026quot;username\u0026quot;\u0026gt; \u0026lt;label for=\u0026quot;pwd\u0026quot;\u0026gt;Password: \u0026lt;/label\u0026gt; \u0026lt;input type=\u0026quot;password\u0026quot; id=\u0026quot;pwd\u0026quot; name=\u0026quot;pwd\u0026quot;\u0026gt; \u0026lt;button type=\u0026quot;submit\u0026quot;\u0026gt;Sign in\u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  ให้ใช้ class form-group จัดการแถวของฟอร์ม\n\u0026lt;form action=\u0026quot;#\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;form-group\u0026quot;\u0026gt; \u0026lt;label for=\u0026quot;usernmae\u0026quot;\u0026gt;Username: \u0026lt;/label\u0026gt; \u0026lt;input type=\u0026quot;text\u0026quot; id=\u0026quot;username\u0026quot; name=\u0026quot;username\u0026quot; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;form-group\u0026quot;\u0026gt; \u0026lt;label for=\u0026quot;pwd\u0026quot;\u0026gt;Password: \u0026lt;/label\u0026gt; \u0026lt;input type=\u0026quot;password\u0026quot; id=\u0026quot;pwd\u0026quot; name=\u0026quot;pwd\u0026quot; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;button type=\u0026quot;submit\u0026quot;\u0026gt;Login\u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt;  ใช้ class form-control ให้กับ input เพื่อให้มันรองรับ responsive และความสวยงาม\n\u0026lt;input class=\u0026quot;form-control\u0026quot; type=\u0026quot;text\u0026quot; id=\u0026quot;username\u0026quot; name=\u0026quot;username\u0026quot; /\u0026gt;  ส่วนปุ่มใช้ class ชื่อว่า btn และอยากได้ส้มๆก็ใส่ btn-warning\n\u0026lt;button class=\u0026quot;btn btn-warning text-white\u0026quot; type=\u0026quot;submit\u0026quot;\u0026gt;Login\u0026lt;/button\u0026gt;  ถ้าต้องการให้ปุ่มแสดงตามขนาดจอ ก็ใช้ btn-block\n\u0026lt;button class=\u0026quot;btn btn-block btn-warning text-white\u0026quot; type=\u0026quot;submit\u0026quot;\u0026gt; Login \u0026lt;/button\u0026gt;  ถ้าต้องการให้แสดงแบบแถวเดียวใช้ form-inline\n\u0026lt;form action=\u0026quot;#\u0026quot; class=\u0026quot;form-inline\u0026quot;\u0026gt;\u0026lt;/form\u0026gt;  ฟอร์มมันชิดไป ไม่สวยก็สามารถใช้ class margin มาร่วมได้\n\u0026lt;form action=\u0026quot;#\u0026quot; class=\u0026quot;form-inline mt-3\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;form-group\u0026quot;\u0026gt; \u0026lt;label class=\u0026quot;mr-2\u0026quot; for=\u0026quot;usernmae\u0026quot;\u0026gt;Username: \u0026lt;/label\u0026gt; \u0026lt;input class=\u0026quot;form-control mr-3\u0026quot; type=\u0026quot;text\u0026quot; id=\u0026quot;username\u0026quot; name=\u0026quot;username\u0026quot; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;form-group\u0026quot;\u0026gt; \u0026lt;label class=\u0026quot;mr-2\u0026quot; for=\u0026quot;pwd\u0026quot;\u0026gt;Password: \u0026lt;/label\u0026gt; \u0026lt;input class=\u0026quot;form-control mr-3\u0026quot; type=\u0026quot;password\u0026quot; id=\u0026quot;pwd\u0026quot; name=\u0026quot;pwd\u0026quot; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;button class=\u0026quot;btn btn-warning text-white\u0026quot; type=\u0026quot;submit\u0026quot;\u0026gt;Login\u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt;  Source code https://gist.github.com/benznest/1d77e1a799253e5546b8d4c836cd2f1c\nCard อีกอันที่ใช้บ่อยๆ คือ card มันคือการทำเนื้อหาเป็นบล็อกๆ\nสร้างไฟล์ใหม่ชื่อว่า news.html ทำ grid ไว้ 2 คอลัมภ์\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;UTF-8\u0026quot; /\u0026gt; \u0026lt;meta name=\u0026quot;viewport\u0026quot; content=\u0026quot;width=device-width, initial-scale=1.0\u0026quot; /\u0026gt; \u0026lt;meta http-equiv=\u0026quot;X-UA-Compatible\u0026quot; content=\u0026quot;ie=edge\u0026quot; /\u0026gt; \u0026lt;title\u0026gt;News\u0026lt;/title\u0026gt; \u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;css/bootstrap.min.css\u0026quot; /\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div class=\u0026quot;container\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col\u0026quot;\u0026gt; \u0026lt;!-- Col 1 --\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;col\u0026quot;\u0026gt; \u0026lt;!-- Col 2 --\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  Card โครงสร้างจะเป็นประมาณนี้\n\u0026lt;div class=\u0026quot;container\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;card\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;card-header\u0026quot;\u0026gt; \u0026lt;h4\u0026gt;Hot news\u0026lt;/h4\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;card-body\u0026quot;\u0026gt; \u0026lt;p\u0026gt; Lorem ipsum dolor, sit amet consectetur adipisicing elit. Dolorem minus accusantium rerum suscipit, commodi sapiente, saepe doloremque beatae quod architecto voluptatibus. Nobis ratione excepturi omnis incidunt laboriosam quidem quae quibusdam! \u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;card-footer\u0026quot;\u0026gt; By Benznest \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;col\u0026quot;\u0026gt; \u0026lt;!-- Col 2 --\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt;  สามารถจัดแต่งโดยใช้ utilities class ได้ตามปกติ เช่น bg และ text\n\u0026lt;div class=\u0026quot;card-header bg-danger text-white\u0026quot;\u0026gt;\u0026lt;/div\u0026gt;  สามารถนำรูปมาเป็น Header ได้ โดยใช้ class ชือว่า card-img-top\n\u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col\u0026quot;\u0026gt; ... \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;col\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;card\u0026quot;\u0026gt; \u0026lt;img class=\u0026quot;card-img-top\u0026quot; src=\u0026quot;img/staffs/staff4.jpg\u0026quot; /\u0026gt; \u0026lt;div class=\u0026quot;card-body\u0026quot;\u0026gt; \u0026lt;h4 class=\u0026quot;card-title\u0026quot;\u0026gt;Our Staff\u0026lt;/h4\u0026gt; \u0026lt;p class=\u0026quot;card-text\u0026quot;\u0026gt; Lorem ipsum dolor sit amet consectetur adipisicing elit. Dolores excepturi modi voluptate animi repellat? Animi accusantium numquam iste non voluptatem ipsum totam, odio sequi. Fuga amet qui vitae atque. Illo. \u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt;  เพิ่มปุ่มใน card ให้ดูสวยงาม\n\u0026lt;a href=\u0026quot;#\u0026quot; class=\u0026quot;btn btn-primary\u0026quot;\u0026gt;Read more\u0026lt;/a\u0026gt;  ซึ่งถ้าจะทำสวยๆ ก็ต้องมีรูป และเนื้อหาที่เหมาะสมกัน\nสามารถนำรูปมาวางด้านล่างแทนได้ โดยใช้ class ชื่อว่า card-img-bottom\n\u0026lt;div class=\u0026quot;card-body\u0026quot;\u0026gt; ... \u0026lt;/div\u0026gt;  Source code https://gist.github.com/benznest/bb45d6f0affd79d462a837055408f3c8\nการใช้ Media การนำคลิป youtube embed มาใช้ใน bootstrap\nไปที่ youtube คลิกขวาที่คลิป \u0026gt; Copy embed code\nมันจะเป็น iframe ถ้ามี width height ให้ลบออก เพราะ เราจะทำให้ responsive\n\u0026lt;iframe src=\u0026quot;https://www.youtube.com/embed/5nLWk7kzXgI?ecver=1\u0026quot; frameborder=\u0026quot;0\u0026quot; allow=\u0026quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\u0026quot; allowfullscreen \u0026gt;\u0026lt;/iframe\u0026gt;  เพิ่ม \u0026lt;div\u0026gt;ครอบตัว video โดยเพิ่ม class ชื่อว่า embed-responsive embed-responsive-4by3 4by3 คือขนาด 4:3 สามารถใช้ตัวอื่นได้เช่น 16by9, 21by9, 1by1และที่ iframe เพิ่ม class ชื่อว่า embed-responsive-item\nโดยจะลองเพิ่มแถวเข้าไปต่อจากเดิม\n\u0026lt;div class=\u0026quot;row mt-5\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col\u0026quot;\u0026gt; \u0026lt;h3\u0026gt;Video gallery\u0026lt;/h3\u0026gt; \u0026lt;div class=\u0026quot;embed-responsive embed-responsive-4by3\u0026quot;\u0026gt; \u0026lt;iframe class=\u0026quot;embed-responsive-item\u0026quot; src=\u0026quot;https://www.youtube.com/embed/5nLWk7kzXgI?ecver=1\u0026quot; frameborder=\u0026quot;0\u0026quot; allow=\u0026quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\u0026quot; allowfullscreen \u0026gt;\u0026lt;/iframe\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt;  ลองเพิ่มคอมลัมภ์อีกอันเพื่อทำ photo gallery ด้านขวาของ video\nซึ่งสามารถใช้ class ชื่อว่า media การทำงานของมันจะเรียงไปแนวนอน\n\u0026lt;div class=\u0026quot;row mt-5\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col-md-6\u0026quot;\u0026gt; ... \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;col-md-6\u0026quot;\u0026gt; \u0026lt;h3\u0026gt;Photo gallery\u0026lt;/h3\u0026gt; \u0026lt;div class=\u0026quot;media\u0026quot;\u0026gt; \u0026lt;img class=\u0026quot;w-50\u0026quot; src=\u0026quot;img/content/office10.jpg\u0026quot; /\u0026gt; \u0026lt;div class=\u0026quot;media-body pl-3\u0026quot;\u0026gt; \u0026lt;p\u0026gt; Lorem, ipsum dolor sit amet consectetur adipisicing elit. Neque aliquam nisi officiis aut beatae. Voluptas, aliquid! Nostrum quam architecto \u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt;  การจะเพิ่มแถวของเนื้อหาที่ใช้ class media สามารถใช้ \u0026lt;ul class=”list-unstyled”\u0026gt; และ \u0026lt;li\u0026gt; เข้ามาได้\n\u0026lt;div class=\u0026quot;col-md-6\u0026quot;\u0026gt; \u0026lt;h3\u0026gt;Photo gallery\u0026lt;/h3\u0026gt; \u0026lt;ul class=\u0026quot;list-unstyled\u0026quot;\u0026gt; \u0026lt;li\u0026gt; \u0026lt;div class=\u0026quot;media\u0026quot;\u0026gt; \u0026lt;img class=\u0026quot;w-50\u0026quot; src=\u0026quot;img/content/office1.jpg\u0026quot; /\u0026gt; \u0026lt;div class=\u0026quot;media-body pl-3\u0026quot;\u0026gt; \u0026lt;p\u0026gt; Lorem, ipsum dolor sit amet consectetur adipisicing elit. Neque aliquam nisi officiis aut beatae. Voluptas, aliquid! Nostrum quam architecto \u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li\u0026gt; \u0026lt;div class=\u0026quot;media\u0026quot;\u0026gt; \u0026lt;img class=\u0026quot;w-50\u0026quot; src=\u0026quot;img/content/office3.jpg\u0026quot; /\u0026gt; \u0026lt;div class=\u0026quot;media-body pl-3\u0026quot;\u0026gt; \u0026lt;p\u0026gt; Lorem, ipsum dolor sit amet consectetur adipisicing elit. Neque aliquam nisi officiis aut beatae. Voluptas, aliquid! Nostrum quam architecto \u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li\u0026gt; \u0026lt;div class=\u0026quot;media\u0026quot;\u0026gt; \u0026lt;img class=\u0026quot;w-50\u0026quot; src=\u0026quot;img/content/office2.jpg\u0026quot; /\u0026gt; \u0026lt;div class=\u0026quot;media-body pl-3\u0026quot;\u0026gt; \u0026lt;p\u0026gt; Lorem, ipsum dolor sit amet consectetur adipisicing elit. Neque aliquam nisi officiis aut beatae. Voluptas, aliquid! Nostrum quam architecto \u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt;  Source code https://gist.github.com/benznest/17e5753cff346c5ed5ba8f4689377801\nNavigation เพิ่ม row ไปที่บนสุดของ container ข้างในใช้ list คือ \u0026lt;ul\u0026gt;\u0026lt;li\u0026gt; … \u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\n\u0026lt;body\u0026gt; \u0026lt;div class=\u0026quot;container\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col\u0026quot;\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;#\u0026quot;\u0026gt;Home\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt;  ใน bootstrap จะใช้ class ชื่อ nav ใน \u0026lt;ul\u0026gt; class ชื่อ nav-item ใน \u0026lt;li\u0026gt;class ชื่อ nav-link ใน \u0026lt;a\u0026gt; ที่เป็นป้ายลิงค์\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt;  \u0026lt;div class=\u0026quot;row pt-3 pb-3\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col\u0026quot;\u0026gt; \u0026lt;ul class=\u0026quot;nav\u0026quot;\u0026gt; \u0026lt;li class=\u0026quot;nav-item\u0026quot;\u0026gt;\u0026lt;a class=\u0026quot;nav-link\u0026quot; href=\u0026quot;#\u0026quot;\u0026gt;Home\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;nav-item\u0026quot;\u0026gt;\u0026lt;a class=\u0026quot;nav-link\u0026quot; href=\u0026quot;#\u0026quot;\u0026gt;Service\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;nav-item\u0026quot;\u0026gt;\u0026lt;a class=\u0026quot;nav-link\u0026quot; href=\u0026quot;#\u0026quot;\u0026gt;About\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;nav-item\u0026quot;\u0026gt;\u0026lt;a class=\u0026quot;nav-link\u0026quot; href=\u0026quot;#\u0026quot;\u0026gt;Contact\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt;  เพิ่ม ให้เมนูนึงถูกเลือกใช้ class ชื่อว่า active\n\u0026lt;li class=\u0026quot;nav-item\u0026quot;\u0026gt;\u0026lt;a class=\u0026quot;nav-link active\u0026quot; href=\u0026quot;#\u0026quot;\u0026gt;Home\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;  เพิ่ม class nav-pills ให้กับ \u0026lt;ul\u0026gt;\n\u0026lt;ul class=\u0026quot;nav nav-pills\u0026quot;\u0026gt;\u0026lt;/ul\u0026gt;  หรือจะใช้ class nav-tabs\n\u0026lt;ul class=\u0026quot;nav nav-tabs\u0026quot;\u0026gt;\u0026lt;/ul\u0026gt;  รายละเอียด\nhttps://getbootstrap.com/docs/4.1/components/navs/\nการใช้ Javascript ของ Bootstrap Bootstrap ต้องใช้ library เพิ่มคือ jquery กับ popper ถึงจะใช้งานได้เต็มประสิทธิภาพ ซึ่ง bootstrap ไม่มีติดมาให้ เพราะ ติด license จำเป็นต้องไปดาวน์ดหลดมาจากต้นทางผู้พัฒนา\nให้ดาวน์โหลด jquery js กับ popper js มาติดตั้งไว้ในโปรเจค ในโฟลดเดอร์ js\n[เพิ่ม jquery , popper , bootstrap ไปที่ท้าย body โดยใช้คำสั่ง \u0026lt;script\u0026gt;\u0026lt;/script\u0026gt; โดยให้ jquery และ popper อยู่ด้านบนของ bootstrap.js เพราะการอ่านโค้ดจะอ่านจากบนลงล่าง วึ่ง bootstrap เรียกใช้งาน jquery\nจึงจำเป็นต้องอ่าน jquery มาก่อนนั่นเอง\n\u0026lt;script src=\u0026quot;js/jquery-3.3.1.min.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026quot;js/popper_1_14_3.min.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026quot;js/bootstrap.min.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  ถ้าใส่ผิด สามารถ Inspect ดูที่เมนู console\nการทำ dropdown เพิ่ม dropdown ให้เมนู ได้ โดยใช้ dropdown-menu\n\u0026lt;li class=\u0026quot;nav-item dropdown\u0026quot;\u0026gt; \u0026lt;a class=\u0026quot;nav-link dropdown-toggle\u0026quot; href=\u0026quot;#\u0026quot; data-toggle=\u0026quot;dropdown\u0026quot; \u0026gt;Service\u0026lt;/a \u0026gt; \u0026lt;div class=\u0026quot;dropdown-menu\u0026quot;\u0026gt; \u0026lt;a class=\u0026quot;dropdown-item\u0026quot; href=\u0026quot;#\u0026quot;\u0026gt;App\u0026lt;/a\u0026gt; \u0026lt;a class=\u0026quot;dropdown-item\u0026quot; href=\u0026quot;#\u0026quot;\u0026gt;Website\u0026lt;/a\u0026gt; \u0026lt;a class=\u0026quot;dropdown-item\u0026quot; href=\u0026quot;#\u0026quot;\u0026gt;Desktop\u0026lt;/a\u0026gt; \u0026lt;a class=\u0026quot;dropdown-item\u0026quot; href=\u0026quot;#\u0026quot;\u0026gt;IoT\u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/li\u0026gt;  ปัญหาที่ตามมาคือ เมนูแบบนี้ไม่รองรับ responsive ดังนั้นต้องไปใช้ Navbar แบบใหม่\nติตดั้ง extension ติดตั้ง Bootstrap v4 Snippets\n[Navbar responsive พิมพ์ b-navbar มันจะ generate โค้ดมาให้\nซึ่งเยอะมาก เรามีหน้าที่แก้เนื้อหาก็พอ นี่คือการใช้เครื่องมือให้เป็นประโยชน์\n\u0026lt;nav class=\u0026quot;navbar navbar-expand-lg navbar-light bg-light fixed-top\u0026quot;\u0026gt; \u0026lt;a class=\u0026quot;navbar-brand\u0026quot;\u0026gt;Benznest's blog\u0026lt;/a\u0026gt; \u0026lt;button class=\u0026quot;navbar-toggler\u0026quot; data-target=\u0026quot;#my-nav\u0026quot; data-toggle=\u0026quot;collapse\u0026quot;\u0026gt; \u0026lt;span class=\u0026quot;navbar-toggler-icon\u0026quot;\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;/button\u0026gt; \u0026lt;div id=\u0026quot;my-nav\u0026quot; class=\u0026quot;collapse navbar-collapse\u0026quot;\u0026gt; \u0026lt;ul class=\u0026quot;navbar-nav mr-auto\u0026quot;\u0026gt; \u0026lt;li class=\u0026quot;nav-item\u0026quot;\u0026gt;\u0026lt;a class=\u0026quot;nav-link active\u0026quot; href=\u0026quot;#\u0026quot;\u0026gt;Home\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;nav-item dropdown\u0026quot;\u0026gt; \u0026lt;a class=\u0026quot;nav-link dropdown-toggle\u0026quot; href=\u0026quot;#\u0026quot; data-toggle=\u0026quot;dropdown\u0026quot; \u0026gt;Service\u0026lt;/a \u0026gt; \u0026lt;div class=\u0026quot;dropdown-menu\u0026quot;\u0026gt; \u0026lt;a class=\u0026quot;dropdown-item\u0026quot; href=\u0026quot;#\u0026quot;\u0026gt;App\u0026lt;/a\u0026gt; \u0026lt;a class=\u0026quot;dropdown-item\u0026quot; href=\u0026quot;#\u0026quot;\u0026gt;Website\u0026lt;/a\u0026gt; \u0026lt;a class=\u0026quot;dropdown-item\u0026quot; href=\u0026quot;#\u0026quot;\u0026gt;Desktop\u0026lt;/a\u0026gt; \u0026lt;a class=\u0026quot;dropdown-item\u0026quot; href=\u0026quot;#\u0026quot;\u0026gt;IoT\u0026lt;/a\u0026gt; \u0026lt;a class=\u0026quot;dropdown-item\u0026quot; href=\u0026quot;#\u0026quot;\u0026gt;Android\u0026lt;/a\u0026gt; \u0026lt;a class=\u0026quot;dropdown-item\u0026quot; href=\u0026quot;#\u0026quot;\u0026gt;iOS\u0026lt;/a\u0026gt; \u0026lt;a class=\u0026quot;dropdown-item\u0026quot; href=\u0026quot;#\u0026quot;\u0026gt;Windows\u0026lt;/a\u0026gt; \u0026lt;a class=\u0026quot;dropdown-item\u0026quot; href=\u0026quot;#\u0026quot;\u0026gt;Linux\u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;nav-item\u0026quot;\u0026gt;\u0026lt;a class=\u0026quot;nav-link\u0026quot; href=\u0026quot;#\u0026quot;\u0026gt;About\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;nav-item\u0026quot;\u0026gt;\u0026lt;a class=\u0026quot;nav-link\u0026quot; href=\u0026quot;#\u0026quot;\u0026gt;Contact\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/nav\u0026gt;  Navbar อันใหม่จะรองรับ responsive\nปรับสีของ Navbar โดยใช้ class uitility\n\u0026lt;nav class=\u0026quot;navbar navbar-expand-lg navbar-dark bg-primary fixed-top\u0026quot;\u0026gt; \u0026lt;a class=\u0026quot;navbar-brand text-white\u0026quot;\u0026gt;Benznest's blog\u0026lt;/a\u0026gt; \u0026lt;/nav\u0026gt;  และเนื่องจาก Navbar มันใช้ Fix-top มันจะทำให้กินเนื้อด้านบน ก็ให้เนื้อหาของเราเว้นว่างด้านบนนิดนึง โดยใช้ pt-5 ก็คือ padding top 5 rem\n\u0026lt;/nav\u0026gt; \u0026lt;div class=\u0026quot;container pt-5\u0026quot;\u0026gt;  แนะนำ Bootswatch bootswatch เป็นเว็บที่รวมแหล่งธีม css ของ bootstrap มาไว้ในที่เดียว เราสามารถดาวน์โหลดธีมที่ชอบมาใช้ได้ ซึ่งมันคือ css ของ bootstrap ดังนั้นสามารถนำมาใช้กับ bootstrap ได้เลย\nhttps://bootswatch.com/\nกดดาวน์โหลดธีมที่ชอบ แล้วจะได้ไฟล์ .css\n[เอาไฟล์ .css ไปไว้ในโฟลเดอร์ css แนะนำเปลี่ยนชื่อเป็นชื่อธีม ไม่ควรใช้ชื่อ bootstrap ทับอันเดิม\nใน html ให้เปลี่ยนการใช้ bootstrap.min.css มาใช้ธีมอันใหม่\n\u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;css/minty.min.css\u0026quot; /\u0026gt;  Refresh หน้าเว็บ\nการใช้ Carousel carousel คือ ตัวสไลด์รูปภาพ\nใช้โค้ดลัด พิมพ์ว่า b-carousel เลือก carousel-full\nจากนั้นก็ปรับแต่ง carousel จะมีสามส่วน คือ\nindicator ที่เป็นจุด ว่ารูปภาพเราคือรูปไหน\nSlide คือรูปภาพ\nButton คือปุ่มซ้าย ขวา\nactive คืออันที่ถูกเลือกอยู่\n\u0026lt;div class=\u0026quot;container-fluid mt-5 p-0\u0026quot;\u0026gt; \u0026lt;div id=\u0026quot;my-carousel\u0026quot; class=\u0026quot;carousel slide\u0026quot; data-ride=\u0026quot;carousel\u0026quot; data-interval=\u0026quot;500\u0026quot; \u0026gt; \u0026lt;ol class=\u0026quot;carousel-indicators\u0026quot;\u0026gt; \u0026lt;li class=\u0026quot;active\u0026quot; data-target=\u0026quot;#my-carousel\u0026quot; data-slide-to=\u0026quot;0\u0026quot;\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;\u0026quot; data-target=\u0026quot;#my-carousel\u0026quot; data-slide-to=\u0026quot;1\u0026quot;\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;\u0026quot; data-target=\u0026quot;#my-carousel\u0026quot; data-slide-to=\u0026quot;2\u0026quot;\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;/ol\u0026gt; \u0026lt;div class=\u0026quot;carousel-inner\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;carousel-item active\u0026quot;\u0026gt; \u0026lt;img class=\u0026quot;d-block w-100\u0026quot; src=\u0026quot;img/banner/banner3.jpg\u0026quot; /\u0026gt; \u0026lt;div class=\u0026quot;carousel-caption d-none d-md-block\u0026quot;\u0026gt; \u0026lt;h5\u0026gt;Hello , world\u0026lt;/h5\u0026gt; \u0026lt;p\u0026gt; Lorem ipsum dolor sit amet consectetur adipisicing elit. Ullam aliquid doloremque, \u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;carousel-item\u0026quot;\u0026gt; \u0026lt;img class=\u0026quot;d-block w-100\u0026quot; src=\u0026quot;img/banner/banner4.jpg\u0026quot; /\u0026gt; \u0026lt;div class=\u0026quot;carousel-caption d-none d-md-block\u0026quot;\u0026gt; \u0026lt;h5\u0026gt;Hello , world\u0026lt;/h5\u0026gt; \u0026lt;p\u0026gt; Lorem ipsum dolor sit amet consectetur adipisicing elit. Ullam aliquid doloremque, \u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;carousel-item\u0026quot;\u0026gt; \u0026lt;img class=\u0026quot;d-block w-100\u0026quot; src=\u0026quot;img/banner/banner5.jpg\u0026quot; /\u0026gt; \u0026lt;div class=\u0026quot;carousel-caption d-none d-md-block\u0026quot;\u0026gt; \u0026lt;h5\u0026gt;Hello , world\u0026lt;/h5\u0026gt; \u0026lt;p\u0026gt; Lorem ipsum dolor sit amet consectetur adipisicing elit. Ullam aliquid doloremque, \u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;a class=\u0026quot;carousel-control-prev\u0026quot; href=\u0026quot;#my-carousel\u0026quot; data-slide=\u0026quot;prev\u0026quot;\u0026gt; \u0026lt;span class=\u0026quot;carousel-control-prev-icon\u0026quot;\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;/a\u0026gt; \u0026lt;a class=\u0026quot;carousel-control-next\u0026quot; href=\u0026quot;#my-carousel\u0026quot; data-slide=\u0026quot;next\u0026quot;\u0026gt; \u0026lt;span class=\u0026quot;carousel-control-next-icon\u0026quot;\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt;  การปรับเวลาในการเลื่อนอัตโนมัติ ทำได้โดยใช้ data-interval หน่วยเป็นมิลลิวินาที\n\u0026lt;div id=\u0026quot;my-carousel\u0026quot; class=\u0026quot;carousel slide\u0026quot; data-ride=\u0026quot;carousel\u0026quot; data-interval=\u0026quot;500\u0026quot; \u0026gt;\u0026lt;/div\u0026gt;  Source code https://gist.github.com/benznest/a2c5683a2f19ddd26617415821a2b141\nModal Modal คือป๊อบอัพแบบสวยๆ อันนี้ก็ใช้บ่อยมากๆ\nใช้โค้ดลัดสร้าง Modal คือพิมพ์ว่ b-modal แล้วเลือก modal-full\n[Modal ปกติมันจะถูกซ่อนเอาไว้ รอให้เรียกใช้งาน\nให้เพิ่ม id ให้กับ div modal หลัก\n\u0026lt;div class=\u0026quot;modal fade\u0026quot; id=\u0026quot;myModal\u0026quot;\u0026gt;\u0026lt;/div\u0026gt;  ปรับแต่ง modal ตามใจ โดยภายในก็แบ่งเป็น header, content , footer\n\u0026lt;div class=\u0026quot;modal fade\u0026quot; id=\u0026quot;myModal\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;modal-dialog\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;modal-content\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;modal-header\u0026quot;\u0026gt; \u0026lt;h5 class=\u0026quot;modal-title\u0026quot;\u0026gt;Hello Modal\u0026lt;/h5\u0026gt; \u0026lt;button class=\u0026quot;close\u0026quot; data-dismiss=\u0026quot;modal\u0026quot;\u0026gt; \u0026lt;span\u0026gt;\u0026amp;times;\u0026lt;/span\u0026gt; \u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;modal-body\u0026quot;\u0026gt; \u0026lt;p\u0026gt;Content\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;modal-footer\u0026quot;\u0026gt; \u0026lt;a class=\u0026quot;btn btn-danger text-white\u0026quot; data-dismiss=\u0026quot;modal\u0026quot;\u0026gt;Close\u0026lt;/a\u0026gt; \u0026lt;a class=\u0026quot;btn btn-success text-white\u0026quot; data-dismiss=\u0026quot;modal\u0026quot;\u0026gt;Save\u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt;  ปุ่มไหนที่อยากให้กดแล้วแสดง modal ก็เพิ่ม **data-toggle=”modal” data-target=”#myModal”\n**โดย target คือ id ของ modal\n\u0026lt;a class=\u0026quot;btn btn-primary text-white\u0026quot; data-toggle=\u0026quot;modal\u0026quot; data-target=\u0026quot;#myModal\u0026quot; \u0026gt;Read more\u0026lt;/a \u0026gt;  แนะนำ bootsnipp bootsnipp จะเป็นเว็บที่รวม code หรือ component ต่างๆ เอาไว้สำหรับ bootstrap\nhttps://bootsnipp.com\nเช่นอยากลองใช้ตัวที่ชื่อว่า Timeline vertical ในเว็บของเรา\nกดเข้าไป ข้างในจะมีรายละเอียด เช่น HTML , CSS\nให้ copy โค้ด HTML มาไว้ในที่ต้องการ และ copy CSS ของมันมาด้วย โดยเอาไปวางไว้ใน custom.css ของเรา\nจากนั้น มาเพิ่ม custom.css\n\u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;css/custom.css\u0026quot; /\u0026gt; \u0026lt;/head\u0026gt;  แนะนำ Startbootstrap.com ตัวนี้เป็นแหล่งรวมธีมของ Bootstrap แบบมาทั้ง pack เลย เช่น ธีมสำหรับทำเว็บบริษัท ธีมสำหรับแสดงผลงาน\nhttps://startbootstrap.com/\n[การใช้ class display อันนี้เป็นความสามารถใหม่ใน ฺbootstrap4 เช่น อยากให้หน้าจอใหญ่แสดง Carousel แต่ในจอเล็กให้ซ่อน\nใน Bootstrap 4 สามารถใช้ class d-\n\u0026lt;div class=\u0026quot;container-fluid mt-5 p-0 d-none d-sm-none d-md-block\u0026quot;\u0026gt;\u0026lt;/div\u0026gt;  Media query Media query คือการระบุเงื่อนไขเจาะจงสำหรับ css เช่น ถ้าหน้าจอขนาดมากกว่า 700px ให้ h1 , h2, h3 ขนาด 1 rem\n@media (max-width: 700px) { h1, h2, h3 { font-size: 1rem; } }  สิ่งที่ใช้ร่วมกับ Bootstrap ไม่ได้ เช่น คู่แข่ง ชื่อว่า Foundation เพราะใช้ชื่อ class เหมือนกัน ตัว Foundation มีความสามารถมากกว่า Bootstrap ทำอะไร Advance ได้มากกว่า แต่ก็ต้องเรียนรู้มากกว่า\n[สรุป บทความนี้ก็พาไปทำ component ที่ใช้งานบ่อย เช่น Table , Form , Carousel , Modal , Navbar รวมทั้งแนะนำเว็บที่เกี่ยวกับ bootstrap ที่จะช่วยให้ใช้งานได้ง่ายขึ้นอีกด้วย\n Written with StackEdit.\n "});index.add({'id':35,'href':'/library/tutorials/docs/articles/webapp/css/','title':"CSS",'content':" CSS "});index.add({'id':36,'href':'/library/tutorials/docs/articles/data-science/','title':"Data Sciene",'content':" Data Sciene "});index.add({'id':37,'href':'/library/tutorials/docs/python/e-book/','title':"e-Book",'content':" e-Book "});index.add({'id':38,'href':'/library/tutorials/docs/python/flask/learning-flask/ep-2/','title':"Ep.2 Flask application structure",'content':" Flask application structure | Learning Flask Ep. 2 Structuring your Flask application for\nIn this part of the Learning Flask series, you\u0026rsquo;ll learn how to structure files and directories in your Flask application.\nFlask is a very flexible framework and doesn\u0026rsquo;t enforce that you follow any specific pattern for structuring your application. However there are some best practices and tips to make sure you don\u0026rsquo;t run into issues down the line as your application grows!\nLike I said, there\u0026rsquo;s many ways to setup your structure. This is a pattern I\u0026rsquo;ve been using for the last couple of years and has worked very well for me.\nLet\u0026rsquo;s get started.\nYou application as a package By far the most popular way to structure your application is by using the package method, where we define our Flask application as a package and can import it! Just like we would any other Python package.\nThe package method allows you much more flexibility, as we can split our application up into multiple logical files, making working with our app much cleaner and easier to navigate.\nAs this is a beginner series, we\u0026rsquo;re going to expand from our simple, single file application and break it up into multiple files and package it up.\nIn the last part of this series, we created a single directory called app in our home directory containing a single file called app.py.\nLet\u0026rsquo;s take a look at how our new project structure is going to look from inside our app project directory:\n├── app │ ├── __init__.py │ └── views.py ├── env ├── requirements.txt └── run.py`  We\u0026rsquo;re going to go through each file step by step. But for now, let\u0026rsquo;s go ahead and create our structure!\nMake your way to the app directory you created in your home folder:\ncd ~/app\nRunning the ls command, your should see the single app.py file along with the virtual environment direcory named env\nWe\u0026rsquo;re going to keep our virtual environment but delete app.py and start from scratch. Delete the file with the following:\nrm app.py\nWhile we\u0026rsquo;re here in the root of our app directory. Go ahead and create a file called run.py\nWe\u0026rsquo;ll use this file as the entrypoint to our Flask app.\nNow create another directory called app and move into it. This is going to contain our Flask application and become our package\nmkdir app cd app\nOnce we\u0026rsquo;re in our newly created app directory, we need to create the __init__.py and views.py files:\ntouch __init__.py views.py\nGreat, we\u0026rsquo;ve created our basic application structure. Let\u0026rsquo;s go through each file, add some code and explain what we\u0026rsquo;ve done.\nWe\u0026rsquo;ll start with the __init__.py file. Go ahead and open it up in an editor and enter the following:\napp/app/init.py\nfrom flask import Flask app = Flask(__name__) from app import views`  You\u0026rsquo;ll be familiar with the first 2 lines, just like we did in the last episode we\u0026rsquo;re importing Flask and setting our app variable, however you\u0026rsquo;ll noticed we\u0026rsquo;ve added from app import views at the bottom.\nUsing this method, we can import multiple python files into our Flask app (as you\u0026rsquo;ll see later)\nThink of the __init__.py file as a contructor that pulls all of the parts of our application together into a package and then tells Python to treat it as a package!\nNow, let\u0026rsquo;s add some views in views.py\napp/app/views.py\nfrom app import app @app.route(\u0026quot;/\u0026quot;) def index(): return \u0026quot;Hello world\u0026quot;  Just like in our first app, we\u0026rsquo;re creating a new view using the @app.route decorator and passing it a URL. The only difference is the from app import app statement at the top of the file.\nWe\u0026rsquo;re actually importing the app variable we created in the __init__.py. Meaning we can access it anywhere in our package!\nLet\u0026rsquo;s add another view and pass it a different URL:\napp/app/views.py\nfrom app import app @app.route(\u0026quot;/\u0026quot;) def index(): return \u0026quot;Hello world\u0026quot; @app.route(\u0026quot;/about\u0026quot;) def about(): return \u0026quot;All about Flask\u0026quot;  We\u0026rsquo;ve added another route with the URL \u0026quot;/about\u0026quot;, changed the function name to about and then told it to return \u0026quot;All about Flask\u0026quot;\n Tip - Routes in Flask must always start with a / slash\n You\u0026rsquo;ll learn more about routing in the next few parts of this series!\nBefore we can run our app, we need to create an entrypoint. This is where we\u0026rsquo;ll instruct our app to run.\nGo back up one directory into the parent app folder, open up run.py and add the following:\napp/run.py\nfrom app import app if __name__ == \u0026quot;__main__\u0026quot;: app.run()  We\u0026rsquo;re importing the app variable from the app package that we\u0026rsquo;ve just created.\nWe\u0026rsquo;re then calling the app.run() method, just like in the previous tutorial by wrapping it in an if __name__ == \u0026quot;__main__\u0026quot;: block.\nBefore we run our app, we need to set our environment variables\nFlask environment variables  Tip - If you deactivated the virtual environment. Go ahead and re-activate it with source env.bin/activate from within the parent app directory\n Just like last time, we\u0026rsquo;re going to set 2 environment variables:\npain export FLASK_APP=run.py export FLASK_ENV=development  We\u0026rsquo;ve set the FLASK_APP variable to run.py which is our Flask entry point.\nRunning our app Run the app with the following:\nflask run\nYou\u0026rsquo;ll see the following message, just like last time:\n* Serving Flask app \u0026quot;run.py\u0026quot; (lazy loading) * Environment: development * Debug mode: on * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit) * Restarting with stat * Debugger is active! * Debugger PIN: 306-421-612  Open up a new browser tab and head to:\nhttp://127.0.0.1:5000/\nYou\u0026rsquo;ll see our \u0026ldquo;Hello world!\u0026rdquo; message just as before.\nNow head over to the other route we created at http://127.0.0.1:5000/about\nYou should see \u0026ldquo;All about Flask\u0026rdquo;\nBoom! We\u0026rsquo;re up and running with our application as a package.\nLet\u0026rsquo;s add some more views in another file and import them into our __init__.py file.\nSplitting up views Let\u0026rsquo;s say we want an admin section of our app. Rather than stuffing all of our views into one folder, let\u0026rsquo;s separate them out into their own seperate file.\nStop your app by hitting Ctrl + c in your terminal.\nMove into the app package directory\ncd app\nCreate a new file called admin_views.py\ntouch admin_views.py\nYour project file structure should now look like this:\n├── app │ ├── __init__.py │ ├── admin_views.py │ └── views.py └── run.py`  Open up admin_views.py and add the following:\napp/app/admin_views.py\nfrom app import app @app.route(\u0026quot;/admin/dashboard\u0026quot;) def admin_dashboard(): return \u0026quot;Admin dashboard\u0026quot;  We\u0026rsquo;ve done exactly the same as what we did in views.py. Imported app from app and declared a new route.\nYou\u0026rsquo;ll also notice the URL is longer and contains 2 parts! You\u0026rsquo;ll learn all about routing in detail later on in this series.\nBut before we can access this new route, we need to import admin_views.py in out __init__.py file.\nGot ahead and open up __init__.py and from app import admin_views down at the bottom. It should then look like this:\napp/app/init.py\nfrom flask import Flask app = Flask(__name__) from app import views from app import admin_views  Save the file and head back to the root app directory containing run.py. It\u0026rsquo;s time to run our app again.\nOnce there, run the following command to run the app:\nflask run\nOpen up your browser. Let\u0026rsquo;s check out our new admin route.\nhttp://127.0.0.1:5000/admin/dashboard\nYou\u0026rsquo;ll see \u0026ldquo;Admin dashboard\u0026rdquo;, just like we told the view to return!\nWe\u0026rsquo;re still missing our requirements.txt file from our original structure. Let\u0026rsquo;s go ahead and generate it with pip\nHit Ctrl + c to stop your application.\nRequirements From the root app directory, run the following command:\npip freeze \u0026gt; requirements.txt\nThis command will create a requirements.txt file and place it in our current directory, listing all of the packages we\u0026rsquo;ve installed.\nIt will look like this:\nClick==7.0 Flask==1.0.2 itsdangerous==1.1.0 Jinja2==2.10 MarkupSafe==1.1.0 Werkzeug==0.14.1`   Tip - To install packages from a requirements.txt file, run pip install -r requirements.txt\n Wrapping up Awesome. You\u0026rsquo;ve learned how to structure your Flask application as a package, break out your code into separate files and work with requirements.txt files.\nNext up, You\u0026rsquo;ll learn how to build a website and render HTML files!\nLast modified · 28 Feb 2019\n Source : pythonise.com.\n "});index.add({'id':39,'href':'/library/tutorials/docs/python/flask/','title':"Flask",'content':" Flask  Flask’s Documentation  "});index.add({'id':40,'href':'/library/tutorials/docs/python/pandas/1_io/html/','title':"HTML",'content':" HTML Reading HTML content  Warning\nWe highly encourage you to read the HTML Table Parsing gotchas below regarding the issues surrounding the BeautifulSoup4/html5lib/lxml parsers.\n The top-level read_html() function can accept an HTML string/file/URL and will parse HTML tables into list of pandas DataFrames. Let’s look at a few examples.\n Note read_html returns a list of DataFrame objects, even if there is only a single table contained in the HTML content.\n Read a URL with no options:\nIn [296]: url = 'https://www.fdic.gov/bank/individual/failed/banklist.html' In [297]: dfs = pd.read_html(url) In [298]: dfs  Out[298]: [ Bank Name City ST CERT Acquiring Institution Closing Date 0 City National Bank of New Jersey Newark NJ 21111 Industrial Bank November 1, 2019 1 Resolute Bank Maumee OH 58317 Buckeye State Bank October 25, 2019 2 Louisa Community Bank Louisa KY 58112 Kentucky Farmers Bank Corporation October 25, 2019 3 The Enloe State Bank Cooper TX 10716 Legend Bank, N. A. May 31, 2019 4 Washington Federal Bank for Savings Chicago IL 30570 Royal Savings Bank December 15, 2017 .. ... ... .. ... ... ... 554 Superior Bank, FSB Hinsdale IL 32646 Superior Federal, FSB July 27, 2001 555 Malta National Bank Malta OH 6629 North Valley Bank May 3, 2001 556 First Alliance Bank \u0026amp; Trust Co. Manchester NH 34264 Southern New Hampshire Bank \u0026amp; Trust February 2, 2001 557 National State Bank of Metropolis Metropolis IL 3815 Banterra Bank of Marion December 14, 2000 558 Bank of Honolulu Honolulu HI 21029 Bank of the Orient October 13, 2000 [559 rows x 6 columns]]   Note The data from the above URL changes every Monday so the resulting data above and the data below may be slightly different.\n Read in the content of the file from the above URL and pass it to read_html as a string:\nIn [299]: with open(file_path, 'r') as f: .....: dfs = pd.read_html(f.read()) .....: In [300]: dfs  Out[300]: [ Bank Name City ST CERT Acquiring Institution Closing Date Updated Date 0 Banks of Wisconsin d/b/a Bank of Kenosha Kenosha WI 35386 North Shore Bank, FSB May 31, 2013 May 31, 2013 1 Central Arizona Bank Scottsdale AZ 34527 Western State Bank May 14, 2013 May 20, 2013 2 Sunrise Bank Valdosta GA 58185 Synovus Bank May 10, 2013 May 21, 2013 3 Pisgah Community Bank Asheville NC 58701 Capital Bank, N.A. May 10, 2013 May 14, 2013 4 Douglas County Bank Douglasville GA 21649 Hamilton State Bank April 26, 2013 May 16, 2013 .. ... ... .. ... ... ... ... 500 Superior Bank, FSB Hinsdale IL 32646 Superior Federal, FSB July 27, 2001 June 5, 2012 501 Malta National Bank Malta OH 6629 North Valley Bank May 3, 2001 November 18, 2002 502 First Alliance Bank \u0026amp; Trust Co. Manchester NH 34264 Southern New Hampshire Bank \u0026amp; Trust February 2, 2001 February 18, 2003 503 National State Bank of Metropolis Metropolis IL 3815 Banterra Bank of Marion December 14, 2000 March 17, 2005 504 Bank of Honolulu Honolulu HI 21029 Bank of the Orient October 13, 2000 March 17, 2005 [505 rows x 7 columns]]  You can even pass in an instance of StringIO if you so desire:\nIn [301]: with open(file_path, 'r') as f: .....: sio = StringIO(f.read()) In [302]: dfs = pd.read_html(sio) In [303]: dfs  Out[303]: [ Bank Name City ST CERT Acquiring Institution Closing Date Updated Date 0 Banks of Wisconsin d/b/a Bank of Kenosha Kenosha WI 35386 North Shore Bank, FSB May 31, 2013 May 31, 2013 1 Central Arizona Bank Scottsdale AZ 34527 Western State Bank May 14, 2013 May 20, 2013 2 Sunrise Bank Valdosta GA 58185 Synovus Bank May 10, 2013 May 21, 2013 3 Pisgah Community Bank Asheville NC 58701 Capital Bank, N.A. May 10, 2013 May 14, 2013 4 Douglas County Bank Douglasville GA 21649 Hamilton State Bank April 26, 2013 May 16, 2013 .. ... ... .. ... ... ... ... 500 Superior Bank, FSB Hinsdale IL 32646 Superior Federal, FSB July 27, 2001 June 5, 2012 501 Malta National Bank Malta OH 6629 North Valley Bank May 3, 2001 November 18, 2002 502 First Alliance Bank \u0026amp; Trust Co. Manchester NH 34264 Southern New Hampshire Bank \u0026amp; Trust February 2, 2001 February 18, 2003 503 National State Bank of Metropolis Metropolis IL 3815 Banterra Bank of Marion December 14, 2000 March 17, 2005 504 Bank of Honolulu Honolulu HI 21029 Bank of the Orient October 13, 2000 March 17, 2005 [505 rows x 7 columns]]   Note The following examples are not run by the IPython evaluator due to the fact that having so many network-accessing functions slows down the documentation build. If you spot an error or an example that doesn’t run, please do not hesitate to report it over on pandas GitHub issues page.\n Read a URL and match a table that contains specific text:\nmatch = 'Metcalf Bank' df_list = pd.read_html(url, match=match)  Specify a header row (by default \u0026lt;th\u0026gt; or \u0026lt;td\u0026gt; elements located within a \u0026lt;thead\u0026gt; are used to form the column index, if multiple rows are contained within \u0026lt;thead\u0026gt; then a MultiIndex is created); if specified, the header row is taken from the data minus the parsed header elements (\u0026lt;th\u0026gt; elements).\ndfs = pd.read_html(url, header=0)  Specify an index column:\ndfs = pd.read_html(url, index_col=0)  Specify a number of rows to skip:\ndfs = pd.read_html(url, skiprows=0)  Specify a number of rows to skip using a list (xrange (Python 2 only) works as well):\ndfs = pd.read_html(url, skiprows=range(2))  Specify an HTML attribute:\ndfs1 = pd.read_html(url, attrs={'id': 'table'}) dfs2 = pd.read_html(url, attrs={'class': 'sortable'}) print(np.array_equal(dfs1[0], dfs2[0])) # Should be True  Specify values that should be converted to NaN:\ndfs = pd.read_html(url, na_values=['No Acquirer'])  Specify whether to keep the default set of NaN values:\ndfs = pd.read_html(url, keep_default_na=False)  Specify converters for columns. This is useful for numerical text data that has leading zeros. By default columns that are numerical are cast to numeric types and the leading zeros are lost. To avoid this, we can convert these columns to strings.\nurl_mcc = 'https://en.wikipedia.org/wiki/Mobile_country_code' dfs = pd.read_html(url_mcc, match='Telekom Albania', header=0, converters={'MNC': str})  Use some combination of the above:\ndfs = pd.read_html(url, match='Metcalf Bank', index_col=0)  Read in pandas to_html output (with some loss of floating point precision):\ndf = pd.DataFrame(np.random.randn(2, 2)) s = df.to_html(float_format='{0:.40g}'.format) dfin = pd.read_html(s, index_col=0)  The lxml backend will raise an error on a failed parse if that is the only parser you provide. If you only have a single parser you can provide just a string, but it is considered good practice to pass a list with one string if, for example, the function expects a sequence of strings. You may use:\ndfs = pd.read_html(url, 'Metcalf Bank', index_col=0, flavor=['lxml'])  Or you could pass flavor='lxml' without a list:\ndfs = pd.read_html(url, 'Metcalf Bank', index_col=0, flavor='lxml')  However, if you have bs4 and html5lib installed and pass None or ['lxml', 'bs4'] then the parse will most likely succeed. Note that as soon as a parse succeeds, the function will return.\ndfs = pd.read_html(url, 'Metcalf Bank', index_col=0, flavor=['lxml', 'bs4'])  Writing to HTML files DataFrame objects have an instance method to_html which renders the contents of the DataFrame as an HTML table. The function arguments are as in the method to_string described above.\n Note Not all of the possible options for DataFrame.to_html are shown here for brevity’s sake. See to_html() for the full set of options.\n In [304]: df = pd.DataFrame(np.random.randn(2, 2)) In [305]: df  Out[305]: 0 1 0 -0.184744 0.496971 1 -0.856240 1.857977  In [306]: print(df.to_html()) # raw html \u0026lt;table border=\u0026quot;1\u0026quot; class=\u0026quot;dataframe\u0026quot;\u0026gt; \u0026lt;thead\u0026gt; \u0026lt;tr style=\u0026quot;text-align: right;\u0026quot;\u0026gt; \u0026lt;th\u0026gt;\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;0\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;1\u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/thead\u0026gt; \u0026lt;tbody\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th\u0026gt;0\u0026lt;/th\u0026gt; \u0026lt;td\u0026gt;-0.184744\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;0.496971\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th\u0026gt;1\u0026lt;/th\u0026gt; \u0026lt;td\u0026gt;-0.856240\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;1.857977\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/tbody\u0026gt; \u0026lt;/table\u0026gt;     Operator Description Example     is จะให้ค่า true หรือ false เมื่อเช็คว่าค่าของสิ่งนั้นชี้ไปที่ object เดียวกัน x is y จะ return true เมื่อ x ชี้ไปที่ object เดียวกับ y หรือจะ return false เมื่อ x ไม่ได้ชี้ไปที่ object เดียวกับ y ชี้   not is จะให้ค่า true หรือ false เมื่อเช็คว่าค่าของสิ่งนั้นไม่ได้ชี้ไปที่ object เดียวกัน x is y จะ r    The columns argument will limit the columns shown:\nIn [307]: print(df.to_html(columns=[0]))     # 0     0 -0.18474400000000002   1 -0.85624    float_format takes a Python callable to control the precision of floating point values:\nIn [308]: print(df.to_html(float_format='{0:.10f}'.format)) \u0026lt;table border=\u0026quot;1\u0026quot; class=\u0026quot;dataframe\u0026quot;\u0026gt; \u0026lt;thead\u0026gt; \u0026lt;tr style=\u0026quot;text-align: right;\u0026quot;\u0026gt; \u0026lt;th\u0026gt;\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;0\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;1\u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/thead\u0026gt; \u0026lt;tbody\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th\u0026gt;0\u0026lt;/th\u0026gt; \u0026lt;td\u0026gt;-0.1847438576\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;0.4969711327\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th\u0026gt;1\u0026lt;/th\u0026gt; \u0026lt;td\u0026gt;-0.8562396763\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;1.8579766508\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/tbody\u0026gt; \u0026lt;/table\u0026gt;     # 0 1     0 -0.18474400000000002 0.496971   1 -0.85624 1.857977    bold_rows will make the row labels bold by default, but you can turn that off:\nIn [309]: print(df.to_html(bold_rows=False)) \u0026lt;table border=\u0026quot;1\u0026quot; class=\u0026quot;dataframe\u0026quot;\u0026gt; \u0026lt;thead\u0026gt; \u0026lt;tr style=\u0026quot;text-align: right;\u0026quot;\u0026gt; \u0026lt;th\u0026gt;\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;0\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;1\u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/thead\u0026gt; \u0026lt;tbody\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;0\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;-0.184744\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;0.496971\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;1\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;-0.856240\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;1.857977\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/tbody\u0026gt; \u0026lt;/table\u0026gt;     0 1     -0.18474400000000002 0.496971   -0.85624 1.857977    The classes argument provides the ability to give the resulting HTML table CSS classes. Note that these classes are appended to the existing 'dataframe' class.\nIn [310]: print(df.to_html(classes=['awesome_table_class', 'even_more_awesome_class'])) \u0026lt;table border=\u0026quot;1\u0026quot; class=\u0026quot;dataframe awesome_table_class even_more_awesome_class\u0026quot;\u0026gt; \u0026lt;thead\u0026gt; \u0026lt;tr style=\u0026quot;text-align: right;\u0026quot;\u0026gt; \u0026lt;th\u0026gt;\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;0\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;1\u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/thead\u0026gt; \u0026lt;tbody\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th\u0026gt;0\u0026lt;/th\u0026gt; \u0026lt;td\u0026gt;-0.184744\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;0.496971\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th\u0026gt;1\u0026lt;/th\u0026gt; \u0026lt;td\u0026gt;-0.856240\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;1.857977\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/tbody\u0026gt; \u0026lt;/table\u0026gt;     0 1     -0.18474400000000002 0.496971   -0.85624 1.857977    The render_links argument provides the ability to add hyperlinks to cells that contain URLs.\nNew in version 0.24.\nIn [311]: url_df = pd.DataFrame({ .....: 'name': ['Python', 'Pandas'], .....: 'url': ['https://www.python.org/', 'https://pandas.pydata.org']}) .....: In [312]: print(url_df.to_html(render_links=True)) \u0026lt;table border=\u0026quot;1\u0026quot; class=\u0026quot;dataframe\u0026quot;\u0026gt; \u0026lt;thead\u0026gt; \u0026lt;tr style=\u0026quot;text-align: right;\u0026quot;\u0026gt; \u0026lt;th\u0026gt;\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;name\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;url\u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/thead\u0026gt; \u0026lt;tbody\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th\u0026gt;0\u0026lt;/th\u0026gt; \u0026lt;td\u0026gt;Python\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;a href=\u0026quot;https://www.python.org/\u0026quot; target=\u0026quot;_blank\u0026quot;\u0026gt;https://www.python.org/\u0026lt;/a\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th\u0026gt;1\u0026lt;/th\u0026gt; \u0026lt;td\u0026gt;Pandas\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;a href=\u0026quot;https://pandas.pydata.org\u0026quot; target=\u0026quot;_blank\u0026quot;\u0026gt;https://pandas.pydata.org\u0026lt;/a\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/tbody\u0026gt; \u0026lt;/table\u0026gt;     name url     Python https://www.python.org/   Pandas https://pandas.pydata.org    Finally, the escape argument allows you to control whether the “\u0026lt;”, “\u0026gt;” and “\u0026amp;” characters escaped in the resulting HTML (by default it is True). So to get the HTML without escaped characters pass escape=False\nIn [313]: df = pd.DataFrame({'a': list('\u0026amp;\u0026lt;\u0026gt;'), 'b': np.random.randn(3)})  Escaped:\nIn [314]: print(df.to_html()) \u0026lt;table border=\u0026quot;1\u0026quot; class=\u0026quot;dataframe\u0026quot;\u0026gt; \u0026lt;thead\u0026gt; \u0026lt;tr style=\u0026quot;text-align: right;\u0026quot;\u0026gt; \u0026lt;th\u0026gt;\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;a\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;b\u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/thead\u0026gt; \u0026lt;tbody\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th\u0026gt;0\u0026lt;/th\u0026gt; \u0026lt;td\u0026gt;\u0026amp;amp;\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;-0.474063\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th\u0026gt;1\u0026lt;/th\u0026gt; \u0026lt;td\u0026gt;\u0026amp;lt;\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;-0.230305\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th\u0026gt;2\u0026lt;/th\u0026gt; \u0026lt;td\u0026gt;\u0026amp;gt;\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;-0.400654\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/tbody\u0026gt; \u0026lt;/table\u0026gt;     # a b     0 \u0026amp; -0.474063   1 \u0026lt; -0.230305   2 \u0026gt; -0.400654    In [315]: print(df.to_html(escape=False)) \u0026lt;table border=\u0026quot;1\u0026quot; class=\u0026quot;dataframe\u0026quot;\u0026gt; \u0026lt;thead\u0026gt; \u0026lt;tr style=\u0026quot;text-align: right;\u0026quot;\u0026gt; \u0026lt;th\u0026gt;\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;a\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;b\u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/thead\u0026gt; \u0026lt;tbody\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th\u0026gt;0\u0026lt;/th\u0026gt; \u0026lt;td\u0026gt;\u0026amp;\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;-0.474063\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th\u0026gt;1\u0026lt;/th\u0026gt; \u0026lt;td\u0026gt;\u0026lt;\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;-0.230305\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th\u0026gt;2\u0026lt;/th\u0026gt; \u0026lt;td\u0026gt;\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;-0.400654\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/tbody\u0026gt; \u0026lt;/table\u0026gt;     # a b     0 \u0026amp; -0.474063   1 \u0026lt; -0.230305   2 \u0026gt; -0.400654     Note Some browsers may not show a difference in the rendering of the previous two HTML tables.\n HTML Table Parsing Gotchas There are some versioning issues surrounding the libraries that are used to parse HTML tables in the top-level pandas io function read_html.\nIssues with lxml\n Benefits\n  lxml is very fast.\n lxml requires Cython to install correctly.\n   Drawbacks\n lxml does not make any guarantees about the results of its parse unless it is given strictly valid markup.\n In light of the above, we have chosen to allow you, the user, to use the lxml backend, but this backend will use html5lib if lxml fails to parse\n It is therefore highly recommended that you install both BeautifulSoup4 and html5lib, so that you will still get a valid result (provided everything else is valid) even if lxml fails.\n   Issues with BeautifulSoup4 using lxml as a backend\n The above issues hold here as well since BeautifulSoup4 is essentially just a wrapper around a parser backend.   Issues with BeautifulSoup4 using html5lib as a backend\n Benefits\n html5lib is far more lenient than lxml and consequently deals with real-life markup in a much saner way rather than just, e.g., dropping an element without notifying you.\n html5lib generates valid HTML5 markup from invalid markup automatically. This is extremely important for parsing HTML tables, since it guarantees a valid document. However, that does NOT mean that it is “correct”, since the process of fixing markup does not have a single definition.\n html5lib is pure Python and requires no additional build steps beyond its own installation.\n  Drawbacks\n The biggest drawback to using html5lib is that it is slow as molasses. However consider the fact that many tables on the web are not big enough for the parsing algorithm runtime to matter. It is more likely that the bottleneck will be in the process of reading the raw text from the URL over the web, i.e., IO (input-output). For very large tables, this might not be true.     Source : .\n "});index.add({'id':41,'href':'/library/tutorials/docs/articles/webapp/javascript/','title':"JavaScript",'content':" JavaScript test "});index.add({'id':42,'href':'/library/tutorials/docs/articles/webapp/falsk/build-a-crud-web-app/part-2/','title':"Part. II",'content':" Python Flask for Beginners: Build a CRUD Web App with Python and Flask Part. II This is Part Two of a three-part tutorial to build an employee management web app, named Project Dream Team. In Part One) of the tutorial, we set up a MySQL database using MySQL-Python and Flask-SQLAlchemy. We created models, migrated the database, and worked on the home and auth blueprints and templates. By the end of Part One, we had a working app that had a homepage, registration page, login page, and dashboard. We could register a new user, login, and logout.\nIn Part Two, we will work on:\n Creating an admin user and admin dashboard Creating, listing, editing and deleting departments Creating, listing, editing and deleting roles Assigning departments and roles to employees  Admin User We\u0026rsquo;ll start by creating an admin user through the command line. Flask provides a handy command, flask shell, that allows us to use an interactive Python shell for use with Flask apps.\n$ flask shell from app.models import Employee from app import db admin = Employee(email=\u0026quot;admin@admin.com\u0026quot;,username=\u0026quot;admin\u0026quot;,password=\u0026quot;admin2016\u0026quot;,is_admin=True) db.session.add(admin) db.session.commit()  We\u0026rsquo;ve just created a user with a username, admin, and a password, admin2016. Recall that we set the is_admin field to default to False in the Employee model. To create the admin user above, we override the default value of is_admin and set it to True.\nAdmin Dashboard Now that we have an admin user, we need to add a view for an admin dashboard. We also need to ensure that once the admin user logs in, they are redirected to the admin dashboard and not the one for non-admin users. We will do this in the home blueprint.\n# app/home/views.py # update imports from flask import abort, render_template from flask_login import current_user, login_required # add admin dashboard view @home.route(\u0026amp;apos;/admin/dashboard\u0026amp;apos;) @login_required def admin_dashboard(): # prevent non-admins from accessing the page if not current_user.is_admin: abort(403) return render_template(\u0026amp;apos;home/admin_dashboard.html\u0026amp;apos;, title=\u0026quot;Dashboard\u0026quot;) # app/auth/views.py # Edit the login view to redirect to the admin dashboard if employee is an admin @auth.route(\u0026amp;apos;/login\u0026amp;apos;, methods=[\u0026amp;apos;GET\u0026amp;apos;, \u0026amp;apos;POST\u0026amp;apos;]) def login(): form = LoginForm() if form.validate_on_submit(): # check whether employee exists in the database and whether # the password entered matches the password in the database employee = Employee.query.filter_by(email=form.email.data).first() if employee is not None and employee.verify_password( form.password.data): # log employee in login_user(employee) # redirect to the appropriate dashboard page if employee.is_admin: return redirect(url_for(\u0026amp;apos;home.admin_dashboard\u0026amp;apos;)) else: return redirect(url_for(\u0026amp;apos;home.dashboard\u0026amp;apos;)) # when login details are incorrect else: flash(\u0026amp;apos;Invalid email or password.\u0026amp;apos;) # load login template return render_template(\u0026amp;apos;auth/login.html\u0026amp;apos;, form=form, title=\u0026amp;apos;Login\u0026amp;apos;)  Next we\u0026rsquo;ll create the admin dashboard template. Create an admin_dashboard.html file in the templates/home directory, and then add the following code in it:\n\u0026lt;!-- app/templates/home/admin_dashboard.html --\u0026gt; {% extends \u0026quot;base.html\u0026quot; %} {% block title %}Admin Dashboard{% endblock %} {% block body %} \u0026lt;div class=\u0026quot;intro-header\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;container\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col-lg-12\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;intro-message\u0026quot;\u0026gt; \u0026lt;h1\u0026gt;Admin Dashboard\u0026lt;/h1\u0026gt; \u0026lt;h3\u0026gt;For administrators only!\u0026lt;/h3\u0026gt; \u0026lt;hr class=\u0026quot;intro-divider\u0026quot;\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {% endblock %}  Now we need to edit the base template to show a different menu for the admin user.\n\u0026lt;!-- app/templates/base.html --\u0026gt; \u0026lt;!-- Modify nav bar menu --\u0026gt; \u0026lt;ul class=\u0026quot;nav navbar-nav navbar-right\u0026quot;\u0026gt; {% if current_user.is_authenticated %} {% if current_user.is_admin %} \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;{{ url_for(\u0026amp;apos;home.admin_dashboard\u0026amp;apos;) }}\u0026quot;\u0026gt;Dashboard\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;#\u0026quot;\u0026gt;Departments\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;#\u0026quot;\u0026gt;Roles\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;#\u0026quot;\u0026gt;Employees\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; {% else %} \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;{{ url_for(\u0026amp;apos;home.dashboard\u0026amp;apos;) }}\u0026quot;\u0026gt;Dashboard\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; {% endif %} \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;{{ url_for(\u0026amp;apos;auth.logout\u0026amp;apos;) }}\u0026quot;\u0026gt;Logout\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a\u0026gt;\u0026lt;i class=\u0026quot;fa fa-user\u0026quot;\u0026gt;\u0026lt;/i\u0026gt; Hi, {{ current_user.username }}!\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; {% else %} \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;{{ url_for(\u0026amp;apos;home.homepage\u0026amp;apos;) }}\u0026quot;\u0026gt;Home\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;{{ url_for(\u0026amp;apos;auth.register\u0026amp;apos;) }}\u0026quot;\u0026gt;Register\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;{{ url_for(\u0026amp;apos;auth.login\u0026amp;apos;) }}\u0026quot;\u0026gt;Login\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; {% endif %} \u0026lt;/ul\u0026gt;  In the menu above, we make use of the current_user proxy from Flask-Login to check whether the current user is an admin. If they are, we display the admin menu which will allow them to navigate to the Departments, Roles and Employees pages. Notice that we use # for the links in the admin menu. We will update this after we have created the respective views.\nNow run the app and login as the admin user that we just created. You should see the admin dashboard:\nLet\u0026rsquo;s test the error we set in the home/views.py file to prevent non-admin users from accessing the admin dashboard. Log out and then log in as a regular user. In your browser\u0026rsquo;s address bar, manually enter the following URL: \u0026lt;a href=\u0026quot;http://127.0.0.1:5000/admin/dashboard\u0026quot; target=\u0026quot;_blank\u0026quot;\u0026gt;http://127.0.0.1:5000/admin/dashboard\u0026lt;/a\u0026gt;. You should get a 403 Forbidden error. It looks pretty boring now, but don\u0026rsquo;t worry, we\u0026rsquo;ll create custom error pages in Part Three!\nDepartments Now we\u0026rsquo;ll start working on the admin blueprint, which has the bulk of the functionality in the application. We\u0026rsquo;ll begin by building out CRUD functionality for the departments.\nForms We\u0026rsquo;ll start with the admin/forms.py file, where we\u0026rsquo;ll create a form to add and edit departments.\n# app/admin/forms.py from flask_wtf import FlaskForm from wtforms import StringField, SubmitField from wtforms.validators import DataRequired class DepartmentForm(FlaskForm): \u0026quot;\u0026quot;\u0026quot; Form for admin to add or edit a department \u0026quot;\u0026quot;\u0026quot; name = StringField(\u0026amp;apos;Name\u0026amp;apos;, validators=[DataRequired()]) description = StringField(\u0026amp;apos;Description\u0026amp;apos;, validators=[DataRequired()]) submit = SubmitField(\u0026amp;apos;Submit\u0026amp;apos;)  The form is pretty simple and has only two fields, name and department, both of which are required. We enforce this using the DataRequired() validator from WTForms. Note that we will use the same form for adding and editing departments.\nViews Now, let\u0026rsquo;s work on the views:\n# app/admin/views.py from flask import abort, flash, redirect, render_template, url_for from flask_login import current_user, login_required from . import admin from forms import DepartmentForm from .. import db from ..models import Department def check_admin(): \u0026quot;\u0026quot;\u0026quot; Prevent non-admins from accessing the page \u0026quot;\u0026quot;\u0026quot; if not current_user.is_admin: abort(403) # Department Views @admin.route(\u0026amp;apos;/departments\u0026amp;apos;, methods=[\u0026amp;apos;GET\u0026amp;apos;, \u0026amp;apos;POST\u0026amp;apos;]) @login_required def list_departments(): \u0026quot;\u0026quot;\u0026quot; List all departments \u0026quot;\u0026quot;\u0026quot; check_admin() departments = Department.query.all() return render_template(\u0026amp;apos;admin/departments/departments.html\u0026amp;apos;, departments=departments, title=\u0026quot;Departments\u0026quot;) @admin.route(\u0026amp;apos;/departments/add\u0026amp;apos;, methods=[\u0026amp;apos;GET\u0026amp;apos;, \u0026amp;apos;POST\u0026amp;apos;]) @login_required def add_department(): \u0026quot;\u0026quot;\u0026quot; Add a department to the database \u0026quot;\u0026quot;\u0026quot; check_admin() add_department = True form = DepartmentForm() if form.validate_on_submit(): department = Department(name=form.name.data, description=form.description.data) try: # add department to the database db.session.add(department) db.session.commit() flash(\u0026amp;apos;You have successfully added a new department.\u0026amp;apos;) except: # in case department name already exists flash(\u0026amp;apos;Error: department name already exists.\u0026amp;apos;) # redirect to departments page return redirect(url_for(\u0026amp;apos;admin.list_departments\u0026amp;apos;)) # load department template return render_template(\u0026amp;apos;admin/departments/department.html\u0026amp;apos;, action=\u0026quot;Add\u0026quot;, add_department=add_department, form=form, title=\u0026quot;Add Department\u0026quot;) @admin.route(\u0026amp;apos;/departments/edit/\u0026lt;int:id\u0026gt;\u0026amp;apos;, methods=[\u0026amp;apos;GET\u0026amp;apos;, \u0026amp;apos;POST\u0026amp;apos;]) @login_required def edit_department(id): \u0026quot;\u0026quot;\u0026quot; Edit a department \u0026quot;\u0026quot;\u0026quot; check_admin() add_department = False department = Department.query.get_or_404(id) form = DepartmentForm(obj=department) if form.validate_on_submit(): department.name = form.name.data department.description = form.description.data db.session.commit() flash(\u0026amp;apos;You have successfully edited the department.\u0026amp;apos;) # redirect to the departments page return redirect(url_for(\u0026amp;apos;admin.list_departments\u0026amp;apos;)) form.description.data = department.description form.name.data = department.name return render_template(\u0026amp;apos;admin/departments/department.html\u0026amp;apos;, action=\u0026quot;Edit\u0026quot;, add_department=add_department, form=form, department=department, title=\u0026quot;Edit Department\u0026quot;) @admin.route(\u0026amp;apos;/departments/delete/\u0026lt;int:id\u0026gt;\u0026amp;apos;, methods=[\u0026amp;apos;GET\u0026amp;apos;, \u0026amp;apos;POST\u0026amp;apos;]) @login_required def delete_department(id): \u0026quot;\u0026quot;\u0026quot; Delete a department from the database \u0026quot;\u0026quot;\u0026quot; check_admin() department = Department.query.get_or_404(id) db.session.delete(department) db.session.commit() flash(\u0026amp;apos;You have successfully deleted the department.\u0026amp;apos;) # redirect to the departments page return redirect(url_for(\u0026amp;apos;admin.list_departments\u0026amp;apos;)) return render_template(title=\u0026quot;Delete Department\u0026quot;)  We begin by creating a function, check_admin, which throws a 403 Forbidden error if a non-admin user attempts to access these views. We will call this function in every admin view.\nThe list_departments view queries the database for all departments and assigns them to the variable departments, which we will use to list them in the template.\nThe add_department view creates a new department object using the form data, and adds it to the database. If the department name already exists, an error message is displayed. This view redirects to the list_departments. This means that once the admin user creates a new department, they will be redirected to the Departments page.\nThe edit_department view takes one parameter: id . This is the department ID, and will be passed to the view in the template. The view queries the database for a department with the ID specified. If the department doesn\u0026rsquo;t exist, a 404 Not Found error is thrown. If it does, it is updated with the form data.\nThe delete_department view is similar to the edit_department one, in that it takes a department ID as a parameter and throws an error if the specified department doesn\u0026rsquo;t exist. If it does, it is deleted from the database.\nNote that we render the same template for adding and editing individual departments: department.html. This is why we have the add_department variable in the add_department view (where it is set to True), as well as in the edit_department view (where it is set to False). We\u0026rsquo;ll use this variable in the department.html template to determine what wording to use for the title and heading.\nTemplates Create an templates/admin directory, and in it, add a departments directory. Inside it, add the departments.html and department.html files:\n\u0026lt;!-- app/templates/admin/departments/departments.html --\u0026gt; {% import \u0026quot;bootstrap/utils.html\u0026quot; as utils %} {% extends \u0026quot;base.html\u0026quot; %} {% block title %}Departments{% endblock %} {% block body %} \u0026lt;div class=\u0026quot;content-section\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;outer\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;middle\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;inner\u0026quot;\u0026gt; \u0026lt;br/\u0026gt; {{ utils.flashed_messages() }} \u0026lt;br/\u0026gt; \u0026lt;h1 style=\u0026quot;text-align:center;\u0026quot;\u0026gt;Departments\u0026lt;/h1\u0026gt; {% if departments %} \u0026lt;hr class=\u0026quot;intro-divider\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;center\u0026quot;\u0026gt; \u0026lt;table class=\u0026quot;table table-striped table-bordered\u0026quot;\u0026gt; \u0026lt;thead\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th width=\u0026quot;15%\u0026quot;\u0026gt; Name \u0026lt;/th\u0026gt; \u0026lt;th width=\u0026quot;40%\u0026quot;\u0026gt; Description \u0026lt;/th\u0026gt; \u0026lt;th width=\u0026quot;15%\u0026quot;\u0026gt; Employee Count \u0026lt;/th\u0026gt; \u0026lt;th width=\u0026quot;15%\u0026quot;\u0026gt; Edit \u0026lt;/th\u0026gt; \u0026lt;th width=\u0026quot;15%\u0026quot;\u0026gt; Delete \u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/thead\u0026gt; \u0026lt;tbody\u0026gt; {% for department in departments %} \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt; {{ department.name }} \u0026lt;/td\u0026gt; \u0026lt;td\u0026gt; {{ department.description }} \u0026lt;/td\u0026gt; \u0026lt;td\u0026gt; {% if department.employees %} {{ department.employees.count() }} {% else %} 0 {% endif %} \u0026lt;/td\u0026gt; \u0026lt;td\u0026gt; \u0026lt;a href=\u0026quot;{{ url_for(\u0026amp;apos;admin.edit_department\u0026amp;apos;, id=department.id) }}\u0026quot;\u0026gt; \u0026lt;i class=\u0026quot;fa fa-pencil\u0026quot;\u0026gt;\u0026lt;/i\u0026gt; Edit \u0026lt;/a\u0026gt; \u0026lt;/td\u0026gt; \u0026lt;td\u0026gt; \u0026lt;a href=\u0026quot;{{ url_for(\u0026amp;apos;admin.delete_department\u0026amp;apos;, id=department.id) }}\u0026quot;\u0026gt; \u0026lt;i class=\u0026quot;fa fa-trash\u0026quot;\u0026gt;\u0026lt;/i\u0026gt; Delete \u0026lt;/a\u0026gt; \u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; {% endfor %} \u0026lt;/tbody\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div style=\u0026quot;text-align: center\u0026quot;\u0026gt; {% else %} \u0026lt;div style=\u0026quot;text-align: center\u0026quot;\u0026gt; \u0026lt;h3\u0026gt; No departments have been added. \u0026lt;/h3\u0026gt; \u0026lt;hr class=\u0026quot;intro-divider\u0026quot;\u0026gt; {% endif %} \u0026lt;a href=\u0026quot;{{ url_for(\u0026amp;apos;admin.add_department\u0026amp;apos;) }}\u0026quot; class=\u0026quot;btn btn-default btn-lg\u0026quot;\u0026gt; \u0026lt;i class=\u0026quot;fa fa-plus\u0026quot;\u0026gt;\u0026lt;/i\u0026gt; Add Department \u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {% endblock %}  We\u0026rsquo;ve created a table in the template above, where we will display all the departments with their name, description, and number of employees. Take note of the count() function, which we use in this case to get the number of employees. Each department listed will have an edit and delete link. Notice how we pass the department.id value to the edit_department and delete_department views in the respective links.\nIf there are no departments, the page will display “No departments have been added”. There is also a button which can be clicked to add a new department.\nNow let\u0026rsquo;s work on the template for adding and editing departments:\n\u0026lt;!-- app/templates/admin/departments/department.html --\u0026gt; {% import \u0026quot;bootstrap/wtf.html\u0026quot; as wtf %} {% extends \u0026quot;base.html\u0026quot; %} {% block title %} {% if add_department %} Add Department {% else %} Edit Department {% endif %} {% endblock %} {% block body %} \u0026lt;div class=\u0026quot;content-section\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;outer\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;middle\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;inner\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;center\u0026quot;\u0026gt; {% if add_department %} \u0026lt;h1\u0026gt;Add Department\u0026lt;/h1\u0026gt; {% else %} \u0026lt;h1\u0026gt;Edit Department\u0026lt;/h1\u0026gt; {% endif %} \u0026lt;br/\u0026gt; {{ wtf.quick_form(form) }} \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {% endblock %}  Notice that we use the add_department variable which we initialized in the admin/views.py file, to determine whether the page title will be “Add Department” or “Edit Department”.\nAdd the following lines to your style.css file:\n/* app/static/css/style.css */ .outer { display: table; position: absolute; height: 70%; width: 100%; } .middle { display: table-cell; vertical-align: middle; } .inner { margin-left: auto; margin-right: auto; }  The .middle, .inner, and .outer classes are to center the content in the middle of the page.\nLastly, let\u0026rsquo;s put the correct link to the Departments page in the admin menu:\n\u0026lt;!-- app/templates/base.html --\u0026gt; \u0026lt;!-- Modify nav bar menu --\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;{{ url_for(\u0026amp;apos;admin.list_departments\u0026amp;apos;) }}\u0026quot;\u0026gt;Departments\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;  Re-start the flask server, and then log back in as the admin user and click on the Departments link. Because we have not added any departments, loading the page will display:\nLet\u0026rsquo;s try adding a department:\nIt worked! We get the success message we configured in the add_department view, and can now see the department displayed.\nNow let\u0026rsquo;s edit it:\nNotice that the current department name and description are already pre-loaded in the form. Also, take note of the URL, which has the ID of the department we are editing.\nEditing the department is successful as well. Clicking the Delete link deletes the department and redirects to the Departments page, where a confirmation message is displayed:\nRoles Now to work on the roles. This will be very similar to the departments code because the functionality for roles and departments is exactly the same.\nForms We\u0026rsquo;ll start by creating the form to add and edit roles. Add the following code to the admin/forms.py file:\n# app/admin/forms.py # existing code remains class RoleForm(FlaskForm): \u0026quot;\u0026quot;\u0026quot; Form for admin to add or edit a role \u0026quot;\u0026quot;\u0026quot; name = StringField(\u0026amp;apos;Name\u0026amp;apos;, validators=[DataRequired()]) description = StringField(\u0026amp;apos;Description\u0026amp;apos;, validators=[DataRequired()]) submit = SubmitField(\u0026amp;apos;Submit\u0026amp;apos;)  Views Next we\u0026rsquo;ll write the views to add, list, edit, and delete roles. Add the following code to the admin/views.py file:\n# app/admin/views.py # update imports from forms import DepartmentForm, RoleForm from ..models import Department, Role # existing code remains # Role Views @admin.route(\u0026amp;apos;/roles\u0026amp;apos;) @login_required def list_roles(): check_admin() \u0026quot;\u0026quot;\u0026quot; List all roles \u0026quot;\u0026quot;\u0026quot; roles = Role.query.all() return render_template(\u0026amp;apos;admin/roles/roles.html\u0026amp;apos;, roles=roles, title=\u0026amp;apos;Roles\u0026amp;apos;) @admin.route(\u0026amp;apos;/roles/add\u0026amp;apos;, methods=[\u0026amp;apos;GET\u0026amp;apos;, \u0026amp;apos;POST\u0026amp;apos;]) @login_required def add_role(): \u0026quot;\u0026quot;\u0026quot; Add a role to the database \u0026quot;\u0026quot;\u0026quot; check_admin() add_role = True form = RoleForm() if form.validate_on_submit(): role = Role(name=form.name.data, description=form.description.data) try: # add role to the database db.session.add(role) db.session.commit() flash(\u0026amp;apos;You have successfully added a new role.\u0026amp;apos;) except: # in case role name already exists flash(\u0026amp;apos;Error: role name already exists.\u0026amp;apos;) # redirect to the roles page return redirect(url_for(\u0026amp;apos;admin.list_roles\u0026amp;apos;)) # load role template return render_template(\u0026amp;apos;admin/roles/role.html\u0026amp;apos;, add_role=add_role, form=form, title=\u0026amp;apos;Add Role\u0026amp;apos;) @admin.route(\u0026amp;apos;/roles/edit/\u0026lt;int:id\u0026gt;\u0026amp;apos;, methods=[\u0026amp;apos;GET\u0026amp;apos;, \u0026amp;apos;POST\u0026amp;apos;]) @login_required def edit_role(id): \u0026quot;\u0026quot;\u0026quot; Edit a role \u0026quot;\u0026quot;\u0026quot; check_admin() add_role = False role = Role.query.get_or_404(id) form = RoleForm(obj=role) if form.validate_on_submit(): role.name = form.name.data role.description = form.description.data db.session.add(role) db.session.commit() flash(\u0026amp;apos;You have successfully edited the role.\u0026amp;apos;) # redirect to the roles page return redirect(url_for(\u0026amp;apos;admin.list_roles\u0026amp;apos;)) form.description.data = role.description form.name.data = role.name return render_template(\u0026amp;apos;admin/roles/role.html\u0026amp;apos;, add_role=add_role, form=form, title=\u0026quot;Edit Role\u0026quot;) @admin.route(\u0026amp;apos;/roles/delete/\u0026lt;int:id\u0026gt;\u0026amp;apos;, methods=[\u0026amp;apos;GET\u0026amp;apos;, \u0026amp;apos;POST\u0026amp;apos;]) @login_required def delete_role(id): \u0026quot;\u0026quot;\u0026quot; Delete a role from the database \u0026quot;\u0026quot;\u0026quot; check_admin() role = Role.query.get_or_404(id) db.session.delete(role) db.session.commit() flash(\u0026amp;apos;You have successfully deleted the role.\u0026amp;apos;) # redirect to the roles page return redirect(url_for(\u0026amp;apos;admin.list_roles\u0026amp;apos;)) return render_template(title=\u0026quot;Delete Role\u0026quot;)  These list, add, edit, and delete views are similar to the ones for departments that we created earlier.\nTemplates Create a roles directory in the templates/admin directory. In it, create the roles.html and role.html files:\n\u0026lt;!-- app/templates/admin/roles/roles.html --\u0026gt; {% import \u0026quot;bootstrap/utils.html\u0026quot; as utils %} {% extends \u0026quot;base.html\u0026quot; %} {% block title %}Roles{% endblock %} {% block body %} \u0026lt;div class=\u0026quot;content-section\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;outer\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;middle\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;inner\u0026quot;\u0026gt; \u0026lt;br/\u0026gt; {{ utils.flashed_messages() }} \u0026lt;br/\u0026gt; \u0026lt;h1 style=\u0026quot;text-align:center;\u0026quot;\u0026gt;Roles\u0026lt;/h1\u0026gt; {% if roles %} \u0026lt;hr class=\u0026quot;intro-divider\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;center\u0026quot;\u0026gt; \u0026lt;table class=\u0026quot;table table-striped table-bordered\u0026quot;\u0026gt; \u0026lt;thead\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th width=\u0026quot;15%\u0026quot;\u0026gt; Name \u0026lt;/th\u0026gt; \u0026lt;th width=\u0026quot;40%\u0026quot;\u0026gt; Description \u0026lt;/th\u0026gt; \u0026lt;th width=\u0026quot;15%\u0026quot;\u0026gt; Employee Count \u0026lt;/th\u0026gt; \u0026lt;th width=\u0026quot;15%\u0026quot;\u0026gt; Edit \u0026lt;/th\u0026gt; \u0026lt;th width=\u0026quot;15%\u0026quot;\u0026gt; Delete \u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/thead\u0026gt; \u0026lt;tbody\u0026gt; {% for role in roles %} \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt; {{ role.name }} \u0026lt;/td\u0026gt; \u0026lt;td\u0026gt; {{ role.description }} \u0026lt;/td\u0026gt; \u0026lt;td\u0026gt; {% if role.employees %} {{ role.employees.count() }} {% else %} 0 {% endif %} \u0026lt;/td\u0026gt; \u0026lt;td\u0026gt; \u0026lt;a href=\u0026quot;{{ url_for(\u0026amp;apos;admin.edit_role\u0026amp;apos;, id=role.id) }}\u0026quot;\u0026gt; \u0026lt;i class=\u0026quot;fa fa-pencil\u0026quot;\u0026gt;\u0026lt;/i\u0026gt; Edit \u0026lt;/a\u0026gt; \u0026lt;/td\u0026gt; \u0026lt;td\u0026gt; \u0026lt;a href=\u0026quot;{{ url_for(\u0026amp;apos;admin.delete_role\u0026amp;apos;, id=role.id) }}\u0026quot;\u0026gt; \u0026lt;i class=\u0026quot;fa fa-trash\u0026quot;\u0026gt;\u0026lt;/i\u0026gt; Delete \u0026lt;/a\u0026gt; \u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; {% endfor %} \u0026lt;/tbody\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div style=\u0026quot;text-align: center\u0026quot;\u0026gt; {% else %} \u0026lt;div style=\u0026quot;text-align: center\u0026quot;\u0026gt; \u0026lt;h3\u0026gt; No roles have been added. \u0026lt;/h3\u0026gt; \u0026lt;hr class=\u0026quot;intro-divider\u0026quot;\u0026gt; {% endif %} \u0026lt;a href=\u0026quot;{{ url_for(\u0026amp;apos;admin.add_role\u0026amp;apos;) }}\u0026quot; class=\u0026quot;btn btn-default btn-lg\u0026quot;\u0026gt; \u0026lt;i class=\u0026quot;fa fa-plus\u0026quot;\u0026gt;\u0026lt;/i\u0026gt; Add Role \u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {% endblock %}  Just like we did for the departments, we have created a table where we will display all the roles with their name, description, and number of employees. Each role listed will also have an edit and delete link. If there are no roles, a message of the same will be displayed. There is also a button which can be clicked to add a new role.\n\u0026lt;!-- app/templates/admin/roles/role.html --\u0026gt; {% import \u0026quot;bootstrap/wtf.html\u0026quot; as wtf %} {% extends \u0026quot;base.html\u0026quot; %} {% block title %} {% if add_department %} Add Role {% else %} Edit Role {% endif %} {% endblock %} {% block body %} \u0026lt;div class=\u0026quot;content-section\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;outer\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;middle\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;inner\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;center\u0026quot;\u0026gt; {% if add_role %} \u0026lt;h1\u0026gt;Add Role\u0026lt;/h1\u0026gt; {% else %} \u0026lt;h1\u0026gt;Edit Role\u0026lt;/h1\u0026gt; {% endif %} \u0026lt;br/\u0026gt; {{ wtf.quick_form(form) }} \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {% endblock %}  We use the add_role variable above the same way we used the add_department variable for the department.html template.\nOnce again, let\u0026rsquo;s update the admin menu with the correct link:\n\u0026lt;!-- app/templates/base.html --\u0026gt; \u0026lt;!-- Modify nav bar menu --\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;{{ url_for(\u0026amp;apos;admin.list_roles\u0026amp;apos;) }}\u0026quot;\u0026gt;Roles\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;  Re-start the server. You should now be able to access the Roles page, and add, edit and delete roles.\nEmployees Now to work on listing employees, as well as assigning them departments and roles.\nForms We\u0026rsquo;ll need a form to assign each employee a department and role. Add the following to the admin/forms.py file:\n# app/admin/forms.py # update imports from wtforms.ext.sqlalchemy.fields import QuerySelectField from ..models import Department, Role # existing code remains class EmployeeAssignForm(FlaskForm): \u0026quot;\u0026quot;\u0026quot; Form for admin to assign departments and roles to employees \u0026quot;\u0026quot;\u0026quot; department = QuerySelectField(query_factory=lambda: Department.query.all(), get_label=\u0026quot;name\u0026quot;) role = QuerySelectField(query_factory=lambda: Role.query.all(), get_label=\u0026quot;name\u0026quot;) submit = SubmitField(\u0026amp;apos;Submit\u0026amp;apos;)  We have imported a new field type, QuerySelectField, which we use for both the department and role fields. This will query the database for all departments and roles. The admin user will select one department and one role using the form on the front-end.\nViews Add the following code to the admin/views.py file:\n# app/admin/views.py # update imports from forms import DepartmentForm, EmployeeAssignForm, RoleForm from ..models import Department, Employee, Role # existing code remains # Employee Views @admin.route(\u0026amp;apos;/employees\u0026amp;apos;) @login_required def list_employees(): \u0026quot;\u0026quot;\u0026quot; List all employees \u0026quot;\u0026quot;\u0026quot; check_admin() employees = Employee.query.all() return render_template(\u0026amp;apos;admin/employees/employees.html\u0026amp;apos;, employees=employees, title=\u0026amp;apos;Employees\u0026amp;apos;) @admin.route(\u0026amp;apos;/employees/assign/\u0026lt;int:id\u0026gt;\u0026amp;apos;, methods=[\u0026amp;apos;GET\u0026amp;apos;, \u0026amp;apos;POST\u0026amp;apos;]) @login_required def assign_employee(id): \u0026quot;\u0026quot;\u0026quot; Assign a department and a role to an employee \u0026quot;\u0026quot;\u0026quot; check_admin() employee = Employee.query.get_or_404(id) # prevent admin from being assigned a department or role if employee.is_admin: abort(403) form = EmployeeAssignForm(obj=employee) if form.validate_on_submit(): employee.department = form.department.data employee.role = form.role.data db.session.add(employee) db.session.commit() flash(\u0026amp;apos;You have successfully assigned a department and role.\u0026amp;apos;) # redirect to the roles page return redirect(url_for(\u0026amp;apos;admin.list_employees\u0026amp;apos;)) return render_template(\u0026amp;apos;admin/employees/employee.html\u0026amp;apos;, employee=employee, form=form, title=\u0026amp;apos;Assign Employee\u0026amp;apos;)  The list_employees view queries the database for all employees and assigns them to the variable employees, which we will use to list them in the template.\nThe assign_employee view takes an employee ID. First, it checks whether the employee is an admin user; if it is, a 403 Forbidden error is thrown. If not, it updates the employee.department and employee.role with the selected data from the form, essentially assigning the employee a new department and role.\nTemplates Create a employees directory in the templates/admin directory. In it, create the employees.html and employee.html files:\n\u0026lt;!-- app/templates/admin/employees/employees.html --\u0026gt; {% import \u0026quot;bootstrap/utils.html\u0026quot; as utils %} {% extends \u0026quot;base.html\u0026quot; %} {% block title %}Employees{% endblock %} {% block body %} \u0026lt;div class=\u0026quot;content-section\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;outer\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;middle\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;inner\u0026quot;\u0026gt; \u0026lt;br/\u0026gt; {{ utils.flashed_messages() }} \u0026lt;br/\u0026gt; \u0026lt;h1 style=\u0026quot;text-align:center;\u0026quot;\u0026gt;Employees\u0026lt;/h1\u0026gt; {% if employees %} \u0026lt;hr class=\u0026quot;intro-divider\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;center\u0026quot;\u0026gt; \u0026lt;table class=\u0026quot;table table-striped table-bordered\u0026quot;\u0026gt; \u0026lt;thead\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th width=\u0026quot;15%\u0026quot;\u0026gt; Name \u0026lt;/th\u0026gt; \u0026lt;th width=\u0026quot;30%\u0026quot;\u0026gt; Department \u0026lt;/th\u0026gt; \u0026lt;th width=\u0026quot;30%\u0026quot;\u0026gt; Role \u0026lt;/th\u0026gt; \u0026lt;th width=\u0026quot;15%\u0026quot;\u0026gt; Assign \u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/thead\u0026gt; \u0026lt;tbody\u0026gt; {% for employee in employees %} {% if employee.is_admin %} \u0026lt;tr style=\u0026quot;background-color: #aec251; color: white;\u0026quot;\u0026gt; \u0026lt;td\u0026gt; \u0026lt;i class=\u0026quot;fa fa-key\u0026quot;\u0026gt;\u0026lt;/i\u0026gt; Admin \u0026lt;/td\u0026gt; \u0026lt;td\u0026gt; N/A \u0026lt;/td\u0026gt; \u0026lt;td\u0026gt; N/A \u0026lt;/td\u0026gt; \u0026lt;td\u0026gt; N/A \u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; {% else %} \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt; {{ employee.first_name }} {{ employee.last_name }} \u0026lt;/td\u0026gt; \u0026lt;td\u0026gt; {% if employee.department %} {{ employee.department.name }} {% else %} - {% endif %} \u0026lt;/td\u0026gt; \u0026lt;td\u0026gt; {% if employee.role %} {{ employee.role.name }} {% else %} - {% endif %} \u0026lt;/td\u0026gt; \u0026lt;td\u0026gt; \u0026lt;a href=\u0026quot;{{ url_for(\u0026amp;apos;admin.assign_employee\u0026amp;apos;, id=employee.id) }}\u0026quot;\u0026gt; \u0026lt;i class=\u0026quot;fa fa-user-plus\u0026quot;\u0026gt;\u0026lt;/i\u0026gt; Assign \u0026lt;/a\u0026gt; \u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; {% endif %} {% endfor %} \u0026lt;/tbody\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;/div\u0026gt; {% endif %} \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {% endblock %}  The employees.html template shows a table of all employees. The table shows their full name, department and role, or displays a - in case no department and role has been assigned. Each employee has an assign link, which the admin user can click to assign them a department and role.\nBecause the admin user is an employee as well, they will be displayed in the table. However, we have formatted the table such that admin users stand out with a green background and white text.\n\u0026lt;!-- app/templates/admin/employees/employee.html --\u0026gt; {% import \u0026quot;bootstrap/wtf.html\u0026quot; as wtf %} {% extends \u0026quot;base.html\u0026quot; %} {% block title %}Assign Employee{% endblock %} {% block body %} \u0026lt;div class=\u0026quot;content-section\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;outer\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;middle\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;inner\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;center\u0026quot;\u0026gt; \u0026lt;h1\u0026gt; Assign Departments and Roles \u0026lt;/h1\u0026gt; \u0026lt;br/\u0026gt; \u0026lt;p\u0026gt; Select a department and role to assign to \u0026lt;span style=\u0026quot;color: #aec251;\u0026quot;\u0026gt; {{ employee.first_name }} {{ employee.last_name }} \u0026lt;/span\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;br/\u0026gt; {{ wtf.quick_form(form) }} \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {% endblock %}  We need to update the admin menu once more:\n\u0026lt;!-- app/templates/base.html --\u0026gt; \u0026lt;!-- Modify nav bar menu --\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;{{ url_for(\u0026amp;apos;admin.list_employees\u0026amp;apos;) }}\u0026quot;\u0026gt;Employees\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;  Navigate to the Employees page now. If there are no users other than the admin, this is what you should see:\nWhen there is an employee registered, this is displayed:\nFeel free to add a variety of departments and roles so that you can start assigning them to employees.\nYou can re-assign departments and roles as well.\nConclusion We now have a completely functional CRUD web app! In Part Two of the tutorial, we\u0026rsquo;ve been able to create an admin user and an admin dashboard, as well as customise the menu for different types of users. We\u0026rsquo;ve also built out the core functionality of the app, and can now add, list, edit, and delete departments and roles, as well as assign them to employees. We have also taken security into consideration by protecting certain views from unauthorized access.\n Source : .\n "});index.add({'id':43,'href':'/library/tutorials/docs/backup/example/table-of-contents/without-toc/','title':"Without ToC",'content':" At me ipso nepotibus nunc celebratior genus Tanto oblite Lorem markdownum pectora novis patenti igne sua opus aurae feras materiaque illic demersit imago et aristas questaque posset. Vomit quoque suo inhaesuro clara. Esse cumque, per referri triste. Ut exponit solisque communis in tendens vincetis agisque iamque huic bene ante vetat omina Thebae rates. Aeacus servat admonitu concidit, ad resimas vultus et rugas vultu dignamque Siphnon.\nQuam iugulum regia simulacra, plus meruit humo pecorumque haesit, ab discedunt dixit: ritu pharetramque. Exul Laurenti orantem modo, per densum missisque labor manibus non colla unum, obiectat. Tu pervia collo, fessus quae Cretenque Myconon crate! Tegumenque quae invisi sudore per vocari quaque plus ventis fluidos. Nodo perque, fugisse pectora sorores.\nSumme promissa supple vadit lenius Quibus largis latebris aethera versato est, ait sentiat faciemque. Aequata alis nec Caeneus exululat inclite corpus est, ire tibi ostendens et tibi. Rigent et vires dique possent lumina; eadem dixit poma funeribus paret et felix reddebant ventis utile lignum.\n Remansit notam Stygia feroxque Et dabit materna Vipereas Phrygiaeque umbram sollicito cruore conlucere suus Quarum Elis corniger Nec ieiunia dixit  Vertitur mos ortu ramosam contudit dumque; placabat ac lumen. Coniunx Amoris spatium poenamque cavernis Thebae Pleiadasque ponunt, rapiare cum quae parum nimium rima.\nQuidem resupinus inducto solebat una facinus quae Credulitas iniqua praepetibus paruit prospexit, voce poena, sub rupit sinuatur, quin suum ventorumque arcadiae priori. Soporiferam erat formamque, fecit, invergens, nymphae mutat fessas ait finge.\n Baculum mandataque ne addere capiti violentior Altera duas quam hoc ille tenues inquit Sicula sidereus latrantis domoque ratae polluit comites Possit oro clausura namque se nunc iuvenisque Faciem posuit Quodque cum ponunt novercae nata vestrae aratra  Ite extrema Phrygiis, patre dentibus, tonso perculit, enim blanda, manibus fide quos caput armis, posse! Nocendo fas Alcyonae lacertis structa ferarum manus fulmen dubius, saxa caelum effuge extremis fixum tumor adfecit bella, potentes? Dum nec insidiosa tempora tegit spirarunt. Per lupi pars foliis, porreximus humum negant sunt subposuere Sidone steterant auro. Memoraverit sine: ferrum idem Orion caelum heres gerebat fixis?\n"});index.add({'id':44,'href':'/library/tutorials/docs/python/flask/learning-flask/ep-3/','title':"Ep.3 Serving HTML files",'content':" Serving HTML files | Learning Flask Ep. 3 How to render HTML files and structure template directories with Flask\nIn this part of the Learning Flask series, you\u0026rsquo;ll learn how to work with and serve HTML files.\nFlask provides a fast and easy way for us to serve static files! So building a simple website is a breeze.\nWe\u0026rsquo;re going to pick up the same application we created in the last episode and build upon it. If you haven\u0026rsquo;t read the last part of this series, I\u0026rsquo;d suggest doing so. If not, this is how our current application structure looks:\n├── app │ ├── __init__.py │ ├── admin_views.py │ └── views.py ├── requirements.txt └── run.py`  Ready to code? Fire up a new terminal and browser windows and let\u0026rsquo;s get started.\nLaunch your app From the root app directory, start Flask with the following command:\nflask run\nIn your browser, head to http://127.0.0.1:5000/ to see \u0026ldquo;Hello world!\u0026rdquo; at our app index route\nOk so the app is up and running. Now let\u0026rsquo;s start rendering some HTML.\nBefore we start working with any HTML files, I want to show you how we can return HTML from a flask view.\nGo ahead and open up views.py in your favourite editor. You should see the following:\napp/app/views.py\nfrom app import app @app.route(\u0026quot;/\u0026quot;) def index(): return \u0026quot;Hello world\u0026quot; @app.route(\u0026quot;/about\u0026quot;) def about(): return \u0026quot;All about Flask\u0026quot;`  Let\u0026rsquo;s modify the about route to return some HTML by simple passing an HTML string to return\nfrom app import app @app.route(\u0026quot;/\u0026quot;) def index(): return \u0026quot;Hello world\u0026quot; @app.route(\u0026quot;/about\u0026quot;) def about(): return \u0026quot;\u0026lt;h1 style='color: red;'\u0026gt;I'm a red H1 heading!\u0026lt;/h1\u0026gt;\u0026quot;   Tip - Flask will automatically reload when we make changes to any of the Python files assosiated with our app!\n Go to /about in your browser to see the changes. You\u0026rsquo;ll see a big red H1 heading at the top of the page!\nWe can also pass a multi line string of HTML to return, let\u0026rsquo;s do that now:\nfrom app import app @app.route(\u0026quot;/\u0026quot;) def index(): return \u0026quot;Hello world\u0026quot; @app.route(\u0026quot;/about\u0026quot;) def about(): return \u0026quot;\u0026quot;\u0026quot; \u0026lt;h1 style='color: red;'\u0026gt;I'm a red H1 heading!\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;This is a lovely little paragraph\u0026lt;/p\u0026gt; \u0026lt;code\u0026gt;Flask is \u0026lt;em\u0026gt;awesome\u0026lt;/em\u0026gt;\u0026lt;/code\u0026gt; \u0026quot;\u0026quot;\u0026quot;  Cool right? But not very practical.\nTo make things a bit more fun, let\u0026rsquo;s learn how to serve HTML files with Flask.\nServing HTML files Flask provides a very simple way for us to return HTML files to the client/browser, using the render_template function.\nHowever, before we start using this function, we need to create some new files and directories.\nFlask looks for a directory called templates in the root of the Flask application package. Let\u0026rsquo;s go ahead and create it now.\nStop the app with Ctrl + c\nMove into the app directory with:\ncd app\nCreate the templates directory and move into it:\nmkdir templates cd templates  Let\u0026rsquo;s create a template called index.html:\ntouch index.html\nOpen up index.html in your editor and add the following:\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;UTF-8\u0026quot;\u0026gt; \u0026lt;meta name=\u0026quot;viewport\u0026quot; content=\u0026quot;width=device-width, initial-scale=1.0\u0026quot;\u0026gt; \u0026lt;meta http-equiv=\u0026quot;X-UA-Compatible\u0026quot; content=\u0026quot;ie=edge\u0026quot;\u0026gt; \u0026lt;title\u0026gt;Index\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1 style=\u0026quot;color: blue\u0026quot;\u0026gt;Index\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;This is an HTML file served up by Flask\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  It\u0026rsquo;s not going to win any design awards but will illustrate how to render HTML files!\nSave and close the file.\nYour project file structure should now look like the following:\n├── app │ ├── __init__.py │ ├── admin_views.py │ ├── templates │ │ └── index.html │ └── views.py ├── requirements.txt └── run.py  In your terminal, navigate back to the root app directory containing run.py and run the flask run command to restart the app.\nBefore we can start serving up any HTML files, we need to import render_template from Flask. Go ahead and add the following import to the top of views.py\napp/app/views.py\nfrom flask import render_template\n Tip - Flask provides many useful functions that you\u0026rsquo;ll be learning about throughout this series\n Next up, we need to tell our view to serve up the HTML file we just created. Let\u0026rsquo;s serve index.html using the index route.\nTo return an HTML template, we use the following syntax:\nreturn render_template(\u0026quot;index.html\u0026quot;)\nFlask will look in the templates directory we\u0026rsquo;ve just created for index.html (It\u0026rsquo;s the default place Flask will go to look for HTML files when the render_template function is called)\nYour views.py file should now look like this:\nfrom app import app from flask import render_template @app.route(\u0026quot;/\u0026quot;) def index(): return render_template(\u0026quot;index.html\u0026quot;) @app.route(\u0026quot;/about\u0026quot;) def about(): return \u0026quot;\u0026quot;\u0026quot; \u0026lt;h1 style='color: red;'\u0026gt;I'm a red H1 heading!\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;This is a lovely little paragraph\u0026lt;/p\u0026gt; \u0026lt;code\u0026gt;Flask is \u0026lt;em\u0026gt;awesome\u0026lt;/em\u0026gt;\u0026lt;/code\u0026gt; \u0026quot;\u0026quot;\u0026quot;`  Go to /index in your browser at http://127.0.0.1:5000/ to see your HTML masterpiece.\nNice work. You\u0026rsquo;ve rendered your first HTML page with Flask!\nJust like how we split our views into multiple files, we can do something similar to our HTML template directories to make our life easier and working with our files more manegable.\nIn the last episode, we created an admin_views.py file to contain all of our admin routes.\nLet\u0026rsquo;s refactor our template directories and files to reflect that change.\nTemplate directories Our new file structure is going to look like the following:\n├── app │ ├── __init__.py │ ├── admin_views.py │ ├── templates │ │ ├── admin │ │ │ └── dashboard.html │ │ └── public │ │ └── index.html │ └── views.py ├── requirements.txt └── run.py`  We\u0026rsquo;re going to create 2 new directories within our templates directory:\n public - Will contain all of the HTML files we want to serve from views.py admin - Will contain any HTML files we\u0026rsquo;ll serve from our admin routes in admin_views.py  This keeps things separated and easy for us to navigate and work with.\nIn the terminal, stop the app with Ctrl + c and move into the templated directory with:\ncd app/templates/\nNow we\u0026rsquo;ll create our 2 new directories:\nmkdir public admin\nWe then need to move our index.html file into the public directory. Do so with:\nmv index.html /public\nWhilst we\u0026rsquo;re here, let\u0026rsquo;s create a new file in admin called dashboard.html\ncd admin touch dashboard.html\nOnce again, your app structure should now look like this:\n├── app │ ├── __init__.py │ ├── admin_views.py │ ├── templates │ │ ├── admin │ │ │ └── dashboard.html │ │ └── public │ │ └── index.html │ └── views.py ├── requirements.txt └── run.py`  Before we add any HTML to dashboard.html. Let\u0026rsquo;s refactor our view in views.py to serve index.html from the newly created directory.\nOpen up views.py. We\u0026rsquo;re going to change the path to the file we want to serve in render_template.\nChange this:\napp/app/views.py\n`@app.route(\u0026quot;/\u0026quot;) def index(): return render_template(\u0026quot;index.html\u0026quot;)`  To this:\napp/app/views.py\n`@app.route(\u0026quot;/\u0026quot;) def index(): return render_template(\u0026quot;public/index.html\u0026quot;)`  We\u0026rsquo;ve changed \u0026quot;index.html\u0026quot; to \u0026quot;public/index.html\u0026quot; to reflect our new directory structure.\nStart up your app and reload your browser to test everything works.\nAwesome! We\u0026rsquo;ve separated our HTML templates into something more logical and easy to manage.\nLet\u0026rsquo;s add some HTML to dashboard.html and refactor our admin_views.py file. Just like we just did with views.py\nOpen up dashboard.html and add the following:\napp/app/templates/admin/dashboard.html\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;UTF-8\u0026quot;\u0026gt; \u0026lt;meta name=\u0026quot;viewport\u0026quot; content=\u0026quot;width=device-width, initial-scale=1.0\u0026quot;\u0026gt; \u0026lt;meta http-equiv=\u0026quot;X-UA-Compatible\u0026quot; content=\u0026quot;ie=edge\u0026quot;\u0026gt; \u0026lt;title\u0026gt;Dashboard\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1 style=\u0026quot;color: green\u0026quot;\u0026gt;Admin dashboard\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;This HTML file is served from the admin templates directory\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  Save and close the file.\nWe now need to refactor the route in admin_views.py. Open the file and make the following changes.\nFirst up, we need to import render_template. Add the following to the top of admin_views.py\napp/app/admin_views.py\nfrom flask import render_template\nWe then need to change our file path in the render_template function.\nFrom this:\n@app.route(\u0026quot;/admin/dashboard\u0026quot;) def admin_dashboard(): return render_template(\u0026quot;dashboard.html\u0026quot;)  To this:\n@app.route(\u0026quot;/admin/dashboard\u0026quot;) def admin_dashboard(): return render_template(\u0026quot;admin/dashboard.html\u0026quot;)  Save the file and go to admin/dashboard in your browser to see the changes.\nAnd we\u0026rsquo;re done! We\u0026rsquo;ve split up our app and created a logical file structure within our app.\nIf you\u0026rsquo;re feeling adventurous, I want you to try the following:\n Create a new Python file containing a new view Import that file into the __init__.py file Create a new template directory for those views Add an HTML template to it Render that template  If you\u0026rsquo;re not feeling ready for that just yet, it\u0026rsquo;s no worries! Contunie working your way through the series and you\u0026rsquo;ll soon be building Flask apps of your own.\nWrapping up A Flask application can be as simple or as complex as you want it to be.\nYou can put all of your views into a single file or break them up into separate logical files, likewise with templates, you can keep them all together of split them up into corresponding directories.\nThe beauty of Flask is that it\u0026rsquo;s all up to you.\nIn the next part of this series, you\u0026rsquo;ll be learning how to serve static files including images, CSS and Javascript.\nLast modified · 28 Feb 2019\n Source : pythonise.com.\n "});index.add({'id':45,'href':'/library/tutorials/docs/python/pandas/1_io/excel/','title':"Excel files",'content':" Excel files The read_excel() method can read Excel 2003 (.xls) files using the xlrd Python module. Excel 2007+ (.xlsx) files can be read using either xlrd or openpyxl. Binary Excel (.xlsb) files can be read using pyxlsb. The to_excel() instance method is used for saving a DataFrame to Excel. Generally the semantics are similar to working with csv data. See the cookbook for some advanced strategies.\nReading Excel files In the most basic use-case, read_excel takes a path to an Excel file, and the sheet_name indicating which sheet to parse.\n# Returns a DataFrame pd.read_excel('path_to_file.xls', sheet_name='Sheet1')  ExcelFile class To facilitate working with multiple sheets from the same file, the ExcelFile class can be used to wrap the file and can be passed into read_excel There will be a performance benefit for reading multiple sheets as the file is read into memory only once.\nxlsx = pd.ExcelFile('path_to_file.xls') df = pd.read_excel(xlsx, 'Sheet1')  The ExcelFile class can also be used as a context manager.\nwith pd.ExcelFile('path_to_file.xls') as xls: df1 = pd.read_excel(xls, 'Sheet1') df2 = pd.read_excel(xls, 'Sheet2')  The sheet_names property will generate a list of the sheet names in the file.\nThe primary use-case for an ExcelFile is parsing multiple sheets with different parameters:\ndata = {} # For when Sheet1's format differs from Sheet2 with pd.ExcelFile('path_to_file.xls') as xls: data['Sheet1'] = pd.read_excel(xls, 'Sheet1', index_col=None, na_values=['NA']) data['Sheet2'] = pd.read_excel(xls, 'Sheet2', index_col=1)  Note that if the same parsing parameters are used for all sheets, a list of sheet names can simply be passed to read_excel with no loss in performance.\n# using the ExcelFile class data = {} with pd.ExcelFile('path_to_file.xls') as xls: data['Sheet1'] = pd.read_excel(xls, 'Sheet1', index_col=None, na_values=['NA']) data['Sheet2'] = pd.read_excel(xls, 'Sheet2', index_col=None, na_values=['NA']) # equivalent using the read_excel function data = pd.read_excel('path_to_file.xls', ['Sheet1', 'Sheet2'], index_col=None, na_values=['NA'])  ExcelFile can also be called with a xlrd.book.Book object as a parameter. This allows the user to control how the excel file is read. For example, sheets can be loaded on demand by calling xlrd.open_workbook() with on_demand=True.\nimport xlrd xlrd_book = xlrd.open_workbook('path_to_file.xls', on_demand=True) with pd.ExcelFile(xlrd_book) as xls: df1 = pd.read_excel(xls, 'Sheet1') df2 = pd.read_excel(xls, 'Sheet2')  Specifying sheets  Note The second argument is sheet_name, not to be confused with ExcelFile.sheet_names.\nNote An ExcelFile’s attribute sheet_names provides access to a list of sheets.\n  The arguments sheet_name allows specifying the sheet or sheets to read.\n The default value for sheet_name is 0, indicating to read the first sheet\n Pass a string to refer to the name of a particular sheet in the workbook.\n Pass an integer to refer to the index of a sheet. Indices follow Python convention, beginning at 0.\n Pass a list of either strings or integers, to return a dictionary of specified sheets.\n Pass a None to return a dictionary of all available sheets.\n# Returns a DataFrame pd.read_excel('path_to_file.xls', 'Sheet1', index_col=None, na_values=['NA'])   Using the sheet index:\n# Returns a DataFrame pd.read_excel('path_to_file.xls', 0, index_col=None, na_values=['NA'])  Using all default values:\n# Returns a DataFrame pd.read_excel('path_to_file.xls')  Using None to get all sheets:\n# Returns a dictionary of DataFrames pd.read_excel('path_to_file.xls', sheet_name=None)  Using a list to get multiple sheets:\n# Returns the 1st and 4th sheet, as a dictionary of DataFrames. pd.read_excel('path_to_file.xls', sheet_name=['Sheet1', 3])  read_excel can read more than one sheet, by setting sheet_name to either a list of sheet names, a list of sheet positions, or None to read all sheets. Sheets can be specified by sheet index or sheet name, using an integer or string, respectively.\nReading a MultiIndex read_excel can read a MultiIndex index, by passing a list of columns to index_col and a MultiIndex column by passing a list of rows to header. If either the index or columns have serialized level names those will be read in as well by specifying the rows/columns that make up the levels.\nFor example, to read in a MultiIndex index without names:\nIn [316]: df = pd.DataFrame({'a': [1, 2, 3, 4], 'b': [5, 6, 7, 8]}, .....: index=pd.MultiIndex.from_product([['a', 'b'], ['c', 'd']])) In [317]: df.to_excel('path_to_file.xlsx') In [318]: df = pd.read_excel('path_to_file.xlsx', index_col=[0, 1]) In [319]: df  Out[319]: a b a c 1 5 d 2 6 b c 3 7 d 4 8  If the index has level names, they will parsed as well, using the same parameters.\nIn [320]: df.index = df.index.set_names(['lvl1', 'lvl2']) In [321]: df.to_excel('path_to_file.xlsx') In [322]: df = pd.read_excel('path_to_file.xlsx', index_col=[0, 1]) In [323]: df  Out[323]: a b lvl1 lvl2 a c 1 5 d 2 6 b c 3 7 d 4 8  If the source file has both MultiIndex index and columns, lists specifying each should be passed to index_col and header:\nIn [324]: df.columns = pd.MultiIndex.from_product([['a'], ['b', 'd']], .....: names=['c1', 'c2']) In [325]: df.to_excel('path_to_file.xlsx') In [326]: df = pd.read_excel('path_to_file.xlsx', index_col=[0, 1], header=[0, 1]) In [327]: df  Out[327]: c1 a c2 b d lvl1 lvl2 a c 1 5 d 2 6 b c 3 7 d 4 8  Parsing specific columns It is often the case that users will insert columns to do temporary computations in Excel and you may not want to read in those columns. read_excel takes a usecols keyword to allow you to specify a subset of columns to parse.\nDeprecated since version 0.24.0.\nPassing in an integer for usecols has been deprecated. Please pass in a list of ints from 0 to usecols inclusive instead.\nIf usecols is an integer, then it is assumed to indicate the last column to be parsed.\npd.read_excel('path_to_file.xls', 'Sheet1', usecols=2)  You can also specify a comma-delimited set of Excel columns and ranges as a string:\npd.read_excel('path_to_file.xls', 'Sheet1', usecols='A,C:E')  If usecols is a list of integers, then it is assumed to be the file column indices to be parsed.\npd.read_excel('path_to_file.xls', 'Sheet1', usecols=[0, 2, 3])  Element order is ignored, so usecols=[0, 1] is the same as [1, 0].\nNew in version 0.24.\nIf usecols is a list of strings, it is assumed that each string corresponds to a column name provided either by the user in names or inferred from the document header row(s). Those strings define which columns will be parsed:\npd.read_excel('path_to_file.xls', 'Sheet1', usecols=['foo', 'bar'])  Element order is ignored, so usecols=['baz', 'joe'] is the same as ['joe', 'baz'].\nNew in version 0.24.\nIf usecols is callable, the callable function will be evaluated against the column names, returning names where the callable function evaluates to True.\npd.read_excel('path_to_file.xls', 'Sheet1', usecols=lambda x: x.isalpha())  Parsing dates Datetime-like values are normally automatically converted to the appropriate dtype when reading the excel file. But if you have a column of strings that look like dates (but are not actually formatted as dates in excel), you can use the parse_dates keyword to parse those strings to datetimes:\npd.read_excel(\u0026lsquo;path_to_file.xls\u0026rsquo;, \u0026lsquo;Sheet1\u0026rsquo;, parse_dates=[\u0026lsquo;date_strings\u0026rsquo;])\nCell converters It is possible to transform the contents of Excel cells via the converters option. For instance, to convert a column to boolean:\npd.read_excel('path_to_file.xls', 'Sheet1', converters={'MyBools': bool})  This options handles missing values and treats exceptions in the converters as missing data. Transformations are applied cell by cell rather than to the column as a whole, so the array dtype is not guaranteed. For instance, a column of integers with missing values cannot be transformed to an array with integer dtype, because NaN is strictly a float. You can manually mask missing data to recover integer dtype:\ndef cfun(x): return int(x) if x else -1 pd.read_excel('path_to_file.xls', 'Sheet1', converters={'MyInts': cfun})  Dtype specifications As an alternative to converters, the type for an entire column can be specified using the dtype keyword, which takes a dictionary mapping column names to types. To interpret data with no type inference, use the type str or object.\npd.read_excel('path_to_file.xls', dtype={'MyInts': 'int64', 'MyText': str})  Writing Excel files Writing Excel files to disk To write a DataFrame object to a sheet of an Excel file, you can use the to_excel instance method. The arguments are largely the same as to_csv described above, the first argument being the name of the excel file, and the optional second argument the name of the sheet to which the DataFrame should be written. For example:\ndf.to_excel('path_to_file.xlsx', sheet_name='Sheet1')  Files with a .xls extension will be written using xlwt and those with a .xlsx extension will be written using xlsxwriter (if available) or openpyxl.\nThe DataFrame will be written in a way that tries to mimic the REPL output. The index_label will be placed in the second row instead of the first. You can place it in the first row by setting the merge_cells option in to_excel() to False:\ndf.to_excel('path_to_file.xlsx', index_label='label', merge_cells=False)  In order to write separate DataFrames to separate sheets in a single Excel file, one can pass an ExcelWriter.\nwith pd.ExcelWriter('path_to_file.xlsx') as writer: df1.to_excel(writer, sheet_name='Sheet1') df2.to_excel(writer, sheet_name='Sheet2')   Note Wringing a little more performance out of read_excel Internally, Excel stores all numeric data as floats. Because this can produce unexpected behavior when reading in data, pandas defaults to trying to convert integers to floats if it doesn’t lose information (1.0 --\u0026gt; 1). You can pass convert_float=False to disable this behavior, which may give a slight performance improvement.\n Writing Excel files to memory Pandas supports writing Excel files to buffer-like objects such as StringIO or BytesIO using ExcelWriter.\n# Safe import for either Python 2.x or 3.x try: from io import BytesIO except ImportError: from cStringIO import StringIO as BytesIO bio = BytesIO() # By setting the 'engine' in the ExcelWriter constructor. writer = pd.ExcelWriter(bio, engine='xlsxwriter') df.to_excel(writer, sheet_name='Sheet1') # Save the workbook writer.save() # Seek to the beginning and read to copy the workbook to a variable in memory bio.seek(0) workbook = bio.read()   Note engine is optional but recommended. Setting the engine determines the version of workbook produced. Setting engine='xlrd' will produce an Excel 2003-format workbook (xls). Using either 'openpyxl' or 'xlsxwriter' will produce an Excel 2007-format workbook (xlsx). If omitted, an Excel 2007-formatted workbook is produced.\n Excel writer engines Pandas chooses an Excel writer via two methods:\n the engine keyword argument\n the filename extension (via the default specified in config options)\n  By default, pandas uses the XlsxWriter for .xlsx, openpyxl for .xlsm, and xlwt for .xls files. If you have multiple engines installed, you can set the default engine through setting the config options io.excel.xlsx.writer and io.excel.xls.writer. pandas will fall back on openpyxl for .xlsx files if Xlsxwriter is not available.\nTo specify which writer you want to use, you can pass an engine keyword argument to to_excel and to ExcelWriter. The built-in engines are:\n openpyxl: version 2.4 or higher is required\n xlsxwriter\n xlwt\n# By setting the 'engine' in the DataFrame 'to_excel()' methods. df.to_excel('path_to_file.xlsx', sheet_name='Sheet1', engine='xlsxwriter') # By setting the 'engine' in the ExcelWriter constructor. writer = pd.ExcelWriter('path_to_file.xlsx', engine='xlsxwriter') # Or via pandas configuration. from pandas import options # noqa: E402 options.io.excel.xlsx.writer = 'xlsxwriter' df.to_excel('path_to_file.xlsx', sheet_name='Sheet1')   Style and formatting The look and feel of Excel worksheets created from pandas can be modified using the following parameters on the DataFrame’s to_excel method.\n float_format : Format string for floating point numbers (default None).\n freeze_panes : A tuple of two integers representing the bottommost row and rightmost column to freeze. Each of these parameters is one-based, so (1, 1) will freeze the first row and first column (default None).\n  Using the Xlsxwriter engine provides many options for controlling the format of an Excel worksheet created with the to_excel method. Excellent examples can be found in the Xlsxwriter documentation here: https://xlsxwriter.readthedocs.io/working_with_pandas.html\n Source : .\n "});index.add({'id':46,'href':'/library/tutorials/docs/articles/webapp/falsk/build-a-crud-web-app/part-3/','title':"Part. III",'content':" Python Flask for Beginners: Build a CRUD Web App with Python and Flask Part. III This is the last part of a three-part tutorial to build an employee management web app, named Project Dream Team. In Part Two of the tutorial, we built out the CRUD functionality of the app.\nWe created forms, views, and templates to list, add, edit and delete departments and roles. By the end of Part Two, we could assign (and re-assign) departments and roles to employees.\nIn Part Three, we will cover:\n Custom error pages Unit tests Deployment on PythonAnywhere  Custom Error Pages Web applications make use of HTTP errors to let users know that something has gone wrong. Default error pages are usually quite plain, so we will create our own custom ones for the following common HTTP errors:\n Custom error pages Unit tests Deployment on PythonAnywhere  We\u0026rsquo;ll start by writing the views for the custom error pages. In your app/__init__.py file, add the following code:\n# app/__init__.py # update imports from flask import Flask, render_template # existing code remains def create_app(config_name): # existing code remains @app.errorhandler(403) def forbidden(error): return render_template(\u0026amp;apos;errors/403.html\u0026amp;apos;, title=\u0026amp;apos;Forbidden\u0026amp;apos;), 403 @app.errorhandler(404) def page_not_found(error): return render_template(\u0026amp;apos;errors/404.html\u0026amp;apos;, title=\u0026amp;apos;Page Not Found\u0026amp;apos;), 404 @app.errorhandler(500) def internal_server_error(error): return render_template(\u0026amp;apos;errors/500.html\u0026amp;apos;, title=\u0026amp;apos;Server Error\u0026amp;apos;), 500 return app  We make use of Flask\u0026rsquo;s @app.errorhandler decorator to define the error page views, where we pass in the status code as a parameter.\nNext, we\u0026rsquo;ll create the template files. Create a app/templates/errors directory, and in it, create 403.html, 404.html, and 500.html.\n\u0026lt;!-- app/templates/errors/403.html --\u0026gt; {% extends \u0026quot;base.html\u0026quot; %} {% block title %}Forbidden{% endblock %} {% block body %} \u0026lt;div class=\u0026quot;content-section\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;outer\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;middle\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;inner\u0026quot;\u0026gt; \u0026lt;div style=\u0026quot;text-align: center\u0026quot;\u0026gt; \u0026lt;h1\u0026gt; 403 Error \u0026lt;/h1\u0026gt; \u0026lt;h3\u0026gt; You do not have sufficient permissions to access this page. \u0026lt;/h3\u0026gt; \u0026lt;hr class=\u0026quot;intro-divider\u0026quot;\u0026gt; \u0026lt;a href=\u0026quot;{{ url_for(\u0026amp;apos;home.homepage\u0026amp;apos;) }}\u0026quot; class=\u0026quot;btn btn-default btn-lg\u0026quot;\u0026gt; \u0026lt;i class=\u0026quot;fa fa-home\u0026quot;\u0026gt;\u0026lt;/i\u0026gt; Home \u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {% endblock %} \u0026lt;!-- app/templates/errors/404.html --\u0026gt; {% extends \u0026quot;base.html\u0026quot; %} {% block title %}Page Not Found{% endblock %} {% block body %} \u0026lt;div class=\u0026quot;content-section\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;outer\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;middle\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;inner\u0026quot;\u0026gt; \u0026lt;div style=\u0026quot;text-align: center\u0026quot;\u0026gt; \u0026lt;h1\u0026gt; 404 Error \u0026lt;/h1\u0026gt; \u0026lt;h3\u0026gt; The page you\u0026amp;apos;re looking for doesn\u0026amp;apos;t exist. \u0026lt;/h3\u0026gt; \u0026lt;hr class=\u0026quot;intro-divider\u0026quot;\u0026gt; \u0026lt;a href=\u0026quot;{{ url_for(\u0026amp;apos;home.homepage\u0026amp;apos;) }}\u0026quot; class=\u0026quot;btn btn-default btn-lg\u0026quot;\u0026gt; \u0026lt;i class=\u0026quot;fa fa-home\u0026quot;\u0026gt;\u0026lt;/i\u0026gt; Home \u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {% endblock %} \u0026lt;!-- app/templates/errors/500.html --\u0026gt; {% extends \u0026quot;base.html\u0026quot; %} {% block title %}Internal Server Error{% endblock %} {% block body %} \u0026lt;div class=\u0026quot;content-section\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;outer\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;middle\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;inner\u0026quot;\u0026gt; \u0026lt;div style=\u0026quot;text-align: center\u0026quot;\u0026gt; \u0026lt;h1\u0026gt; 500 Error \u0026lt;/h1\u0026gt; \u0026lt;h3\u0026gt; The server encountered an internal error. That\u0026amp;apos;s all we know. \u0026lt;/h3\u0026gt; \u0026lt;hr class=\u0026quot;intro-divider\u0026quot;\u0026gt; \u0026lt;a href=\u0026quot;{{ url_for(\u0026amp;apos;home.homepage\u0026amp;apos;) }}\u0026quot; class=\u0026quot;btn btn-default btn-lg\u0026quot;\u0026gt; \u0026lt;i class=\u0026quot;fa fa-home\u0026quot;\u0026gt;\u0026lt;/i\u0026gt; Home \u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {% endblock %}  All the templates give a brief description of the error, and a button that links to the homepage.\nRun the app and log in as a non-admin user, then attempt to access \u0026lt;a href=\u0026quot;http://127.0.0.1:5000/admin/departments\u0026quot; target=\u0026quot;_blank\u0026quot;\u0026gt;http://127.0.0.1:5000/admin/departments\u0026lt;/a\u0026gt;. You should get the following page:\nNow attempt to access this non-existent page: \u0026lt;a href=\u0026quot;http://127.0.0.1:5000/nothinghere\u0026quot; target=\u0026quot;_blank\u0026quot;\u0026gt;http://127.0.0.1:5000/nothinghere\u0026lt;/a\u0026gt;. You should see:\nTo view the internal server error page, we\u0026rsquo;ll create a temporary route where we\u0026rsquo;ll use Flask\u0026rsquo;s abort() function to raise a 500 error. In the app/__init__.py file, add the following:\n# app/__init__.py # update imports from flask import abort, Flask, render_template # existing code remains def create_app(config_name): # existing code remains @app.route(\u0026amp;apos;/500\u0026amp;apos;) def error(): abort(500) return app  Go to \u0026lt;a href=\u0026quot;http://127.0.0.1:5000/500\u0026quot; target=\u0026quot;_blank\u0026quot;\u0026gt;http://127.0.0.1:5000/500\u0026lt;/a\u0026gt;; you should see the following page:\nNow you can remove the temporary route we just created for the internal server error.\nTests Now, let\u0026rsquo;s write some tests for the app. The importance of testing software can\u0026rsquo;t be overstated. Tests help ensure that your app is working as expected, without the need for you to manually test all of your app\u0026rsquo;s functionality.\nWe’ll begin by creating a test database, and give the database user we created in Part One all privileges on it:\n$ mysql -u root mysql\u0026gt; CREATE DATABASE dreamteam_test; Query OK, 1 row affected (0.00 sec) mysql\u0026gt; GRANT ALL PRIVILEGES ON dreamteam_test . * TO \u0026amp;apos;dt_admin\u0026amp;apos;@\u0026amp;apos;localhost\u0026amp;apos;; Query OK, 0 rows affected (0.00 sec)  Now we need to edit the config.py file to add configurations for testing. Delete the current contents and replace them with the following code:\n# config.py class Config(object): \u0026quot;\u0026quot;\u0026quot; Common configurations \u0026quot;\u0026quot;\u0026quot; DEBUG = True class DevelopmentConfig(Config): \u0026quot;\u0026quot;\u0026quot; Development configurations \u0026quot;\u0026quot;\u0026quot; SQLALCHEMY_ECHO = True class ProductionConfig(Config): \u0026quot;\u0026quot;\u0026quot; Production configurations \u0026quot;\u0026quot;\u0026quot; DEBUG = False class TestingConfig(Config): \u0026quot;\u0026quot;\u0026quot; Testing configurations \u0026quot;\u0026quot;\u0026quot; TESTING = True app_config = { \u0026amp;apos;development\u0026amp;apos;: DevelopmentConfig, \u0026amp;apos;production\u0026amp;apos;: ProductionConfig, \u0026amp;apos;testing\u0026amp;apos;: TestingConfig }  We have put DEBUG = True in the base class, Config, so that it is the default setting. We override this in the ProductionConfig class. In the TestingConfig class, we set the TESTING configuration variable to True.\nWe will be writing unit tests. Unit tests are written to test small, individual, and fairly isolated units of code, such as functions. We will make use of Flask-Testing, an extension that provides unit testing utilities for Flask.\n$ pip install Flask-Testing  Next, create a tests.py file in the root directory of your app. In it, add the following code:\n# tests.py import unittest from flask_testing import TestCase from app import create_app, db from app.models import Employee class TestBase(TestCase): def create_app(self): # pass in test configurations config_name = \u0026amp;apos;testing\u0026amp;apos; app = create_app(config_name) app.config.update( SQLALCHEMY_DATABASE_URI=\u0026amp;apos;mysql://dt_admin:dt2016@localhost/dreamteam_test\u0026amp;apos; ) return app def setUp(self): \u0026quot;\u0026quot;\u0026quot; Will be called before every test \u0026quot;\u0026quot;\u0026quot; db.create_all() # create test admin user admin = Employee(username=\u0026quot;admin\u0026quot;, password=\u0026quot;admin2016\u0026quot;, is_admin=True) # create test non-admin user employee = Employee(username=\u0026quot;test_user\u0026quot;, password=\u0026quot;test2016\u0026quot;) # save users to database db.session.add(admin) db.session.add(employee) db.session.commit() def tearDown(self): \u0026quot;\u0026quot;\u0026quot; Will be called after every test \u0026quot;\u0026quot;\u0026quot; db.session.remove() db.drop_all() if __name__ == \u0026amp;apos;__main__\u0026amp;apos;: unittest.main()  In the base class above, TestBase, we have a create_app method, where we pass in the configurations for testing.\nWe also have two other methods: setUp and tearDown. The setUp method will be called automatically before every test we run. In it, we create two test users, one admin and one non-admin, and save them to the database. The tearDown method will be called automatically after every test. In it, we remove the database session and drop all database tables.\nTo run the tests, we will run the tests.py file:\n$ python tests.py ---------------------------------------------------------------------- Ran 0 tests in 0.000s OK  The output above lets us know that our test setup is OK. Now let\u0026rsquo;s write some tests.\n# tests.py # update imports import os from flask import abort, url_for from app.models import Department, Employee, Role # add the following after the TestBase class class TestModels(TestBase): def test_employee_model(self): \u0026quot;\u0026quot;\u0026quot; Test number of records in Employee table \u0026quot;\u0026quot;\u0026quot; self.assertEqual(Employee.query.count(), 2) def test_department_model(self): \u0026quot;\u0026quot;\u0026quot; Test number of records in Department table \u0026quot;\u0026quot;\u0026quot; # create test department department = Department(name=\u0026quot;IT\u0026quot;, description=\u0026quot;The IT Department\u0026quot;) # save department to database db.session.add(department) db.session.commit() self.assertEqual(Department.query.count(), 1) def test_role_model(self): \u0026quot;\u0026quot;\u0026quot; Test number of records in Role table \u0026quot;\u0026quot;\u0026quot; # create test role role = Role(name=\u0026quot;CEO\u0026quot;, description=\u0026quot;Run the whole company\u0026quot;) # save role to database db.session.add(role) db.session.commit() self.assertEqual(Role.query.count(), 1) class TestViews(TestBase): def test_homepage_view(self): \u0026quot;\u0026quot;\u0026quot; Test that homepage is accessible without login \u0026quot;\u0026quot;\u0026quot; response = self.client.get(url_for(\u0026amp;apos;home.homepage\u0026amp;apos;)) self.assertEqual(response.status_code, 200) def test_login_view(self): \u0026quot;\u0026quot;\u0026quot; Test that login page is accessible without login \u0026quot;\u0026quot;\u0026quot; response = self.client.get(url_for(\u0026amp;apos;auth.login\u0026amp;apos;)) self.assertEqual(response.status_code, 200) def test_logout_view(self): \u0026quot;\u0026quot;\u0026quot; Test that logout link is inaccessible without login and redirects to login page then to logout \u0026quot;\u0026quot;\u0026quot; target_url = url_for(\u0026amp;apos;auth.logout\u0026amp;apos;) redirect_url = url_for(\u0026amp;apos;auth.login\u0026amp;apos;, next=target_url) response = self.client.get(target_url) self.assertEqual(response.status_code, 302) self.assertRedirects(response, redirect_url) def test_dashboard_view(self): \u0026quot;\u0026quot;\u0026quot; Test that dashboard is inaccessible without login and redirects to login page then to dashboard \u0026quot;\u0026quot;\u0026quot; target_url = url_for(\u0026amp;apos;home.dashboard\u0026amp;apos;) redirect_url = url_for(\u0026amp;apos;auth.login\u0026amp;apos;, next=target_url) response = self.client.get(target_url) self.assertEqual(response.status_code, 302) self.assertRedirects(response, redirect_url) def test_admin_dashboard_view(self): \u0026quot;\u0026quot;\u0026quot; Test that dashboard is inaccessible without login and redirects to login page then to dashboard \u0026quot;\u0026quot;\u0026quot; target_url = url_for(\u0026amp;apos;home.admin_dashboard\u0026amp;apos;) redirect_url = url_for(\u0026amp;apos;auth.login\u0026amp;apos;, next=target_url) response = self.client.get(target_url) self.assertEqual(response.status_code, 302) self.assertRedirects(response, redirect_url) def test_departments_view(self): \u0026quot;\u0026quot;\u0026quot; Test that departments page is inaccessible without login and redirects to login page then to departments page \u0026quot;\u0026quot;\u0026quot; target_url = url_for(\u0026amp;apos;admin.list_departments\u0026amp;apos;) redirect_url = url_for(\u0026amp;apos;auth.login\u0026amp;apos;, next=target_url) response = self.client.get(target_url) self.assertEqual(response.status_code, 302) self.assertRedirects(response, redirect_url) def test_roles_view(self): \u0026quot;\u0026quot;\u0026quot; Test that roles page is inaccessible without login and redirects to login page then to roles page \u0026quot;\u0026quot;\u0026quot; target_url = url_for(\u0026amp;apos;admin.list_roles\u0026amp;apos;) redirect_url = url_for(\u0026amp;apos;auth.login\u0026amp;apos;, next=target_url) response = self.client.get(target_url) self.assertEqual(response.status_code, 302) self.assertRedirects(response, redirect_url) def test_employees_view(self): \u0026quot;\u0026quot;\u0026quot; Test that employees page is inaccessible without login and redirects to login page then to employees page \u0026quot;\u0026quot;\u0026quot; target_url = url_for(\u0026amp;apos;admin.list_employees\u0026amp;apos;) redirect_url = url_for(\u0026amp;apos;auth.login\u0026amp;apos;, next=target_url) response = self.client.get(target_url) self.assertEqual(response.status_code, 302) self.assertRedirects(response, redirect_url) class TestErrorPages(TestBase): def test_403_forbidden(self): # create route to abort the request with the 403 Error @self.app.route(\u0026amp;apos;/403\u0026amp;apos;) def forbidden_error(): abort(403) response = self.client.get(\u0026amp;apos;/403\u0026amp;apos;) self.assertEqual(response.status_code, 403) self.assertTrue(\u0026quot;403 Error\u0026quot; in response.data) def test_404_not_found(self): response = self.client.get(\u0026amp;apos;/nothinghere\u0026amp;apos;) self.assertEqual(response.status_code, 404) self.assertTrue(\u0026quot;404 Error\u0026quot; in response.data) def test_500_internal_server_error(self): # create route to abort the request with the 500 Error @self.app.route(\u0026amp;apos;/500\u0026amp;apos;) def internal_server_error(): abort(500) response = self.client.get(\u0026amp;apos;/500\u0026amp;apos;) self.assertEqual(response.status_code, 500) self.assertTrue(\u0026quot;500 Error\u0026quot; in response.data) if __name__ == \u0026amp;apos;__main__\u0026amp;apos;: unittest.main()  We\u0026rsquo;ve added three classes: TestModels, TestViews and TestErrorPages.\nThe first class has methods to test that each of the models in the app are working as expected. This is done by querying the database to check that the correct number of records exist in each table.\nThe second class has methods that test the views in the app to ensure the expected status code is returned. For non-restricted views, such as the homepage and the login page, the 200 OK code should be returned; this means that everything is OK and the request has succeeded. For restricted views that require authenticated access, a 302 Found code is returned. This means that the page is redirected to an existing resource, in this case, the login page. We test both that the 302 Found code is returned and that the page redirects to the login page.\nThe third class has methods to ensure that the error pages we created earlier are shown when the respective error occurs.\nNote that each test method begins with test. This is deliberate, because unittest, the Python unit testing framework, uses the test prefix to automatically identify test methods. Also note that we have not written tests for the front-end to ensure users can register and login, and to ensure administrators can create departments and roles and assign them to employees. This can be done using a tool like Selenium Webdriver; however this is outside the scope of this tutorial.\nRun the tests again:\n$ python tests.py .............. ---------------------------------------------------------------------- Ran 14 tests in 2.313s OK  Success! The tests are passing.\nDeploy! Now for the final part of the tutorial: deployment. So far, we’ve been running the app locally. In this stage, we will publish the application on the internet so that other people can use it. We will use PythonAnywhere, a Platform as a Service (PaaS) that is easy to set up, secure, and scalable, not to mention free for basic accounts!\nPythonAnywhere Set-Up Create a free PythonAnywhere account here if you don’t already have one. Be sure to select your username carefully since the app will be accessible at your-username.pythonanywhere.com.\nOnce you\u0026rsquo;ve signed up, your-username.pythonanywhere.com should show this page:\nWe will use git to upload the app to PythonAnywhere. If you’ve been pushing your code to cloud repository management systems like Bitbucket, Gitlab or Github, that’s great! If not, now’s the time to do it. Remember that we won’t be pushing the instance directory, so be sure to include it in your .gitignore file, like so:\n# .gitignore *.pyc instance/  Also, ensure that your requirements.txt file is up to date using the pip freeze command before pushing your code:\n$ pip freeze \u0026gt; requirements.txt  Now, log in to your PythonAnywhere account. In your dashboard, there\u0026rsquo;s a Consoles tab; use it to start a new Bash console.\nIn the PythonAnywhere Bash console, clone your repository.\n$ git clone https://github.com/andela-mnzomo/project-dream-team-three  Next we will create a virtualenv, then install the dependencies from the requirements.txt file. Because PythonAnywhere installs virtualenvwrapper for all users by default, we can use its commands:\n$ mkvirtualenv dream-team $ cd project-dream-team-three $ pip install -r requirements.txt  We\u0026rsquo;ve created a virtualenv called dream-team. The virtualenv is automatically activated. We then entered the project directory and installed the dependencies.\nNow, in the Web tab on your dashboard, create a new web app.\nSelect the Manual Configuration option (not the Flask option), and choose Python 2.7 as your Python version. Once the web app is created, its configurations will be loaded. Scroll down to the Virtualenv section, and enter the name of the virtualenv you just created:\nDatabase Configuration Next, we will set up the MySQL production database. In the Databases tab of your PythonAnywhere dashboard, set a new password and then initialize a MySQL server:\nThe password above will be your database user password. Next, create a new database if you wish. PythonAnywhere already has a default database which you can use.\nBy default, the database user is your username, and has all privileges granted on any databases created. Now, we need to migrate the database and populate it with the tables. In a Bash console on PythonAnywhere, we will run the flask db upgrade command, since we already have the migrations directory that we created locally. Before running the commands, ensure you are in your virtualenv as well as in the project directory.\n$ export FLASK_CONFIG=production $ export FLASK_APP=run.py $ export SQLALCHEMY_DATABASE_URI=\u0026amp;apos;mysql://your-username:your-password@your-host-address/your-database-name\u0026amp;apos; $ flask db upgrade  When setting the SQLALCHEMY_DATABASE_URI environment variable, remember to replace your-username, your-password, your-host-address and your-database-name with their correct values. The username, host address and database name can be found in the MySQL settings in the Databases tab on your dashboard. For example, using the information below, my database URI is: mysql://projectdreamteam:password@projectdreamteam.mysql.pythonanywhere-services.com/projectdreamteam$dreamteam_db\nWSGI File Now we will edit the WSGI file, which PythonAnywhere uses to serve the app. Remember that we are not pushing the instance directory to version control. We therefore need to configure the environment variables for production, which we will do in the WSGI file.\nIn the Code section of the Web tab on your dashboard, click on the link to the WSGI configuration file.\nDelete all the current contents of the file, and replace them with the following:\nimport os import sys path = \u0026amp;apos;/home/your-username/your-project-directory-name\u0026amp;apos; if path not in sys.path: sys.path.append(path) os.environ[\u0026amp;apos;FLASK_CONFIG\u0026amp;apos;] = \u0026amp;apos;production\u0026amp;apos; os.environ[\u0026amp;apos;SECRET_KEY\u0026amp;apos;] = \u0026amp;apos;p9Bv\u0026lt;3Eid9%$i01\u0026amp;apos; os.environ[\u0026amp;apos;SQLALCHEMY_DATABASE_URI\u0026amp;apos;] = \u0026amp;apos;mysql://your-username:your-password@your-host-address/your-database-name\u0026amp;apos; from run import app as application  In the file above, we tell PythonAnywhere to get the variable app from the run.py file, and serve it as the application. We also set the FLASK_CONFIG, SECRET_KEY and SQLALCHEMY_DATABASE_URI environment variables. Feel free to alter the secret key. Note that the path variable should contain your username and project directory name, so be sure to replace it with the correct values. The same applies for the database URI environment variable.\nWe also need to edit our local app/__init__py file to prevent it from loading the instance/config.py file in production, as well as to load the configuration variables we\u0026rsquo;ve set:\n# app/__init__.py # update imports import os # existing code remains def create_app(config_name): if os.getenv(\u0026amp;apos;FLASK_CONFIG\u0026amp;apos;) == \u0026quot;production\u0026quot;: app = Flask(__name__) app.config.update( SECRET_KEY=os.getenv(\u0026amp;apos;SECRET_KEY\u0026amp;apos;), SQLALCHEMY_DATABASE_URI=os.getenv(\u0026amp;apos;SQLALCHEMY_DATABASE_URI\u0026amp;apos;) ) else: app = Flask(__name__, instance_relative_config=True) app.config.from_object(app_config[config_name]) app.config.from_pyfile(\u0026amp;apos;config.py\u0026amp;apos;) # existing code remains  Push your changes to version control, and pull them on the PythonAnywhere Bash console:\n$ git pull origin master  Now let\u0026rsquo;s try loading the app on PythonAnywhere. First, we need to reload the app on the Web tab in the dashboard:\nNow go to your app URL:\nGreat, it works! Try registering a new user and logging in. This should work just as it did locally.\nAdmin User We will now create an admin user the same way we did locally. Open the Bash console, and run the following commands:\n$ flask shell \u0026gt;\u0026gt;\u0026gt; from app.models import Employee \u0026gt;\u0026gt;\u0026gt; from app import db \u0026gt;\u0026gt;\u0026gt; admin = Employee(email=\u0026quot;admin@admin.com\u0026quot;,username=\u0026quot;admin\u0026quot;,password=\u0026quot;admin2016\u0026quot;,is_admin=True) \u0026gt;\u0026gt;\u0026gt; db.session.add(admin) \u0026gt;\u0026gt;\u0026gt; db.session.commit()  Now you can login as an admin user and add departments and roles, and assign them to employees.\nConclusion Congratulations on successfully deploying your first Flask CRUD web app! From setting up a MySQL database, to creating models, blueprints (with forms and views), templates, custom error pages, tests, and finally deploying the app on PythonAnywhere, you now have a strong foundation in web development with Flask. I hope this has been as fun and educational for you as it has for me! I\u0026rsquo;m looking forward to hearing about your experiences in the comments below.\n Source : .\n "});index.add({'id':47,'href':'/library/tutorials/docs/python/cheat-sheet/','title':"Python Cheat sheet",'content':" Python Cheat sheet Useful tricks # Terminate a Python script early. quit() # For 1 statement on multiple lines, # use line continuation character (\\). # Good for blog post. def __str__(self): return \u0026quot;Name={}, Title={}, Hourly rate={}.\u0026quot;\\ .format( self.name, self.title, self.__hourly_rate )  String # Concatenation s1 = 'Open' s2 = 'Writings.net' print( s1+s2 ) # Output: OpenWritings.net # Object to string: Use str() function import datetime now_str = \u0026quot;Today is \u0026quot; + str(datetime.datetime.now()) print(now_str) # Find and replace string.replace(old_str, new_str, maxreplace) # maxreplace: Replace N occurrences matched. # Replace using regular expression import re str=\u0026quot;Example regex\u0026quot; test = re.sub(r\u0026quot;[Ee]\u0026quot;, \u0026quot;a\u0026quot;, str) # axampla ragax # Join: string.join(iterable); iterable = list, string \u0026amp; tuple my_list = ['1', '3', '4', '5'] separator = ',' print( separator.join(my_list) ) # 1,3,4,5  If statement # Conditions # Comparison operators # == : Values are equal. # != : Values are NOT equal. # \u0026lt;\u0026gt; : Values are NOT equal. # \u0026gt;= : Value is greater or equal. # \u0026lt;= : Value is less or equal. # is : Is the same object. if True and b \u0026gt; a: print(\u0026quot;b is greater than a\u0026quot;) elif a == b and b is not None: print(\u0026quot;a and b are equal\u0026quot;) # Modulo if i%2==0: print('even') else: print('odd')  List my_list=[] # Empty list. my_list=[1,2,3] # Create a list with some values. print( len(my_list) ) # Size of my_list. my_list[2] # Access the third element(Index starts at 0) my_list[-1] # Get last element. my_list.append('a') # Append a new value to my_list my_list.insert(0, 'first') # Insert 'first' at position 0 del my_list[1] # Delete element at position 1. my_list.remove('a') # Remove first element with value 'a'. # Loop through a list. for item in my_list: print(item) # Loop through a list using range. for i in range(0, len(my_list)): print(my_list[i]) # Loop through a list and at the same time, get the index too. my_list = [1,3,5] for (i, item) in enumerate(my_list): print(i, item) # Slicing first_two = my_list[:2] # Get the first two items. last_two = my_list[-2:] # Get the last two items. portion_of_list= my_list[2:4] # Get items from position 2 to 4. # For sorting, data type has to be the same. Can't mix int and string. my_list=[1,2,3] my_list.sort() # Sort list permanently in alphabetical order. my_list.sort(reverse=True) # Sort list permanently in reverse alphabetical order. my_list.reverse() # Reverse the order of the list.  Loop # Loop through a list \u0026amp; get index at the same time. my_list = [1,3,5] for (i, item) in enumerate(my_list): print(i, item)  Date \u0026amp; Time import datetime today = datetime.date.today() print(today) # 2018-12-31 print(\u0026quot;{}-{}-{}\u0026quot;.format(today.year, today.month, today.day)) print(datetime.date(2011, 4, 13)) # 2011-04-13 print(datetime.date.fromtimestamp(1326244364)) # 2012-01-10 a_datetime = datetime.datetime(2011, 4, 13, 23, 33, 59) print(\u0026quot;{}-{}-{}\u0026quot;.format(a_datetime.year, a_datetime.month, a_datetime.day)) print(\u0026quot;{}:{}:{}\u0026quot;.format(a_datetime.hour, a_datetime.minute, a_datetime.second)) print(a_datetime.timestamp()) # Convert date to string. now = datetime.datetime.now() print(now.strftime(\u0026quot;%m/%d/%Y, %H:%M:%S\u0026quot;)) # 04/04/2019, 12:45:08 # Convert string to date: string should match date representation. # All directives(%): https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior a_date = datetime.datetime.strptime(\u0026quot;21 June, 2018\u0026quot;, \u0026quot;%d %B, %Y\u0026quot;) print(a_date) # 2018-06-21 00:00:00 a_date = datetime.datetime.strptime(\u0026quot;12/11/2018 09:15:32\u0026quot;, \u0026quot;%d/%m/%Y %H:%M:%S\u0026quot;) print(a_date) # 2018-11-12 09:15:32 # Add / Substract date # timedelta(days=0, seconds=0, microseconds=0, milliseconds=0, minutes=0, hours=0, weeks=0) today = datetime.datetime.now() days_ago_delta = datetime.timedelta(days = 5) days_ago_5 = today - days_ago_delta print(days_ago_5)  Function def sum(a,b): return (a, b, a+b) print( sum(3,4) ) # Output: (3, 4, 7)  ที่มาบทความ : https://openwritings.net/pg/python/python-cheat-sheet\n"});index.add({'id':48,'href':'/library/tutorials/docs/articles/data-science/web-scraping/','title':"Web Scraping",'content':" Web Scraping "});index.add({'id':49,'href':'/library/tutorials/docs/python/pandas/1_io/clipboard/','title':"Clipboard",'content':" Clipboard A handy way to grab data is to use the read_clipboard() method, which takes the contents of the clipboard buffer and passes them to the read_csv method. For instance, you can copy the following text to the clipboard (CTRL-C on many operating systems):\n   A B C     1 4 p   2 5 q   3 6 r    And then import the data directly to a DataFrame by calling:\nclipdf = pd.read_clipboard() clipdf     A B C     1 4 p   2 5 q   3 6 r    The to_clipboard method can be used to write the contents of a DataFrame to the clipboard. Following which you can paste the clipboard contents into other applications (CTRL-V on many operating systems). Here we illustrate writing a DataFrame into clipboard and reading it back.\ndf = pd.DataFrame({'A': [1, 2, 3], ... 'B': [4, 5, 6], ... 'C': ['p', 'q', 'r']}, ... index=['x', 'y', 'z']) df     A B C     1 4 p   2 5 q   3 6 r    df.to_clipboard() pd.read_clipboard()     A B C     1 4 p   2 5 q   3 6 r    We can see that we got the same content back, which we had earlier written to the clipboard.\n Note You may need to install xclip or xsel (with PyQt5, PyQt4 or qtpy) on Linux to use these methods.\nSource : .\n "});index.add({'id':50,'href':'/library/tutorials/docs/python/flask/learning-flask/ep-4/','title':"Ep.4 Serving static files",'content':" Serving static files | Learning Flask Ep. 4 Linking stylesheets, javascript files and serving images with Flask\nIn this episode of the Learning Flask series, we\u0026rsquo;ll be making our HTML look prettier with some images, CSS and JavaScript, along with a few extra tips on working with static files.\nFlask provides a few useful ways for working with static files so let\u0026rsquo;s get started.\nCreating stylesheets If you\u0026rsquo;ve worked with HTML and CSS before, you\u0026rsquo;ll know that we have to import a stylesheet in the \u0026lt;head\u0026gt; tag of our HTML.\nIt\u0026rsquo;s no dirrefent in Flask, however we need to cover a few bases before we try and import and stylesheets into our HTML files.\nFlask requires a static directory. Just like the templates directory we created in the last episode.\nLet\u0026rsquo;s go ahead and create a static directory, a css directory and a stylesheet.\nWe\u0026rsquo;ll create the static directory next to our templates directory. From the root app directory, enter the following:\ncd app mkdir static cd static mkdir css cd css touch style.css  Your application filestructure should now look loike this:\napp ├── app │ ├── __init__.py │ ├── admin_views.py │ ├── static │ │ └── css │ │ └── style.css │ ├── templates │ │ ├── admin │ │ │ └── dashboard.html │ │ └── public │ │ └── index.html │ └── views.py ├── requirements.txt └── run.py  Open up style.css in your editor and add the following:\napp/app/static/css/style.css\nbody { background-color: #f1f1f1; }  Save and close the file for now.\nNext up, we\u0026rsquo;ll import our new stylesheet into our index.html file in the public directory.\nTypically you would provide a relative path to your stylesheet in the \u0026lt;head\u0026gt;, for example:\n\u0026lt;head\u0026gt; \u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;path/to/your/stylesheet.css\u0026quot;\u0026gt; \u0026lt;/head\u0026gt;  You can use relative paths in Flask, but it\u0026rsquo;ll get complicated real fast as we\u0026rsquo;ve split our HTML templates up into sub-directories.\nThankfully, there\u0026rsquo;s a better way!\nLinking stylesheets Flask has a function called url_for which can be used in our HTML to provide a path to any static files we want to fetch.\nGo ahead and open up index.html in your editor and in the \u0026lt;head\u0026gt; tag, add the following:\napp/app/templates/public/index.html\n\u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;{{ url_for('static', filename='css/style.css') }}\u0026quot;\u0026gt;   Notice the double curly braces {{ }}\n These double curly braces are part of the Jinja templating engine that Flask uses to render our HTML templates.\nYou\u0026rsquo;ll learn all about Jinja in the next couple of episodes in this series! Just know for now, that before any of our HTML files are rendered in the browser, Flask will pass our HTML files through the Jinja templating engine and parse anything we provide in between the sets of curly braces.\nIn this case, Jinja will replace {{ url_for('static', filename='css/style.css') }} with the path to the CSS file.\nThe url_for function takes 2 arguments, and endpoint and some values. In this case, we\u0026rsquo;ve providing static as the endpoint and css/style.css as the filename value.\nIn this case, Flask will render the stylesheet we just created at static/css/style.css.\nSave the file and reload your browser to see the subtle changes to the background color.\nNext up, you\u0026rsquo;ll learn how to do something very similar with JavaScript files.\nJavascript files We\u0026rsquo;re going to create a Javascript directory and a JavaScript file and link them to our HTML templates in the exact same way as we did with the CSS.\nWe\u0026rsquo;ll create a js directory inside our static directory, along with creating a new file called app.js in the js folder.\nOur new app file structure will look like this:\napp ├── app │ ├── __init__.py │ ├── admin_views.py │ ├── static │ │ ├── css │ │ │ └── style.css │ │ └── js │ │ └── app.js │ ├── templates │ │ ├── admin │ │ │ └── dashboard.html │ │ └── public │ │ └── index.html │ └── views.py ├── requirements.txt └── run.py  From the app root directory, we\u0026rsquo;ll run the following:\ncd app cd static mkdir js cd js touch app.js  Open up the app.js file and add the following:\nconsole.log(\u0026quot;Hello from app.js!\u0026quot;);  Let\u0026rsquo;s link our js file to our HTML template.\nOpen up index.htmlin your editor, and at the bottom of the page, just before the closing \u0026lt;/body\u0026gt; tag, add the following:\n\u0026lt;script src=\u0026quot;{{ url_for('static', filename='js/app.js') }}\u0026quot;\u0026gt;\u0026lt;/script\u0026gt;  Your index.html file should now look something like this:\napp/app/templates/public/index.html\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;UTF-8\u0026quot;\u0026gt; \u0026lt;meta name=\u0026quot;viewport\u0026quot; content=\u0026quot;width=device-width, initial-scale=1.0\u0026quot;\u0026gt; \u0026lt;meta http-equiv=\u0026quot;X-UA-Compatible\u0026quot; content=\u0026quot;ie=edge\u0026quot;\u0026gt; \u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;{{ url_for('static', filename='css/style.css') }}\u0026quot;\u0026gt; \u0026lt;title\u0026gt;Index\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1 style=\u0026quot;color: blue\u0026quot;\u0026gt;Index\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;This is an HTML file served up by Flask\u0026lt;/p\u0026gt; \u0026lt;script src=\u0026quot;{{ url_for('static', filename='js/app.js') }}\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  Just like we did with the stylesheet, we use url_for to provide a directory and a path to our filename.\nSave the file, make sure your app is running with the flask run command and reload your browser.\n Tip - You must run the flask run command from the root directory of your application, in the same directory as run.py\n Open up the developer tools and click on the console tab to see the message from your JavaScript file.\nHello from app.js!\nPerfect! We\u0026rsquo;ve linked our stylesheet and our Javascript file. Let\u0026rsquo;s talk about serving images in Flask.\nServing images Any guesses on how we\u0026rsquo;re going to serve images?\nWe\u0026rsquo;re going to do exactly what we did with our CSS and JavaScript files and create a new img directory in our static directory and place all of our pictures in there.\nOur new app file structure will look like this:\napp ├── app │ ├── __init__.py │ ├── admin_views.py │ ├── static │ │ ├── css │ │ │ └── style.css │ │ ├── img │ │ │ └── my-image.png │ │ └── js │ │ └── app.js │ ├── templates │ │ ├── admin │ │ │ └── dashboard.html │ │ └── public │ │ └── index.html │ └── views.py ├── requirements.txt └── run.py  From the root app directory, we\u0026rsquo;ll create our new directories with the following commands:\ncd app cd static mkdir img  Go ahead and drop any image into the img directory.\nNext up, let\u0026rsquo;s put an \u0026lt;img\u0026gt; tag in our index.html file and render an image to the browser.\nopen up index.html and add the following just under the \u0026lt;p\u0026gt; tag in the \u0026lt;body\u0026gt;:\napp/app/templates/public/index.html\n\u0026lt;img src=\u0026quot;{{ url_for('static', filename='img/TEST-IMG.png') }}\u0026quot; alt=\u0026quot;\u0026quot;\u0026gt;  Your index.html should now look like this:\napp/app/templates/public/index.html\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;UTF-8\u0026quot;\u0026gt; \u0026lt;meta name=\u0026quot;viewport\u0026quot; content=\u0026quot;width=device-width, initial-scale=1.0\u0026quot;\u0026gt; \u0026lt;meta http-equiv=\u0026quot;X-UA-Compatible\u0026quot; content=\u0026quot;ie=edge\u0026quot;\u0026gt; \u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;{{ url_for('static', filename='css/style.css') }}\u0026quot;\u0026gt; \u0026lt;title\u0026gt;Index\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1 style=\u0026quot;color: blue\u0026quot;\u0026gt;Index\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;This is an HTML file served up by Flask\u0026lt;/p\u0026gt; \u0026lt;img src=\u0026quot;{{ url_for('static', filename='img/TEST-IMG.png') }}\u0026quot; alt=\u0026quot;\u0026quot;\u0026gt; \u0026lt;script src=\u0026quot;{{ url_for('static', filename='js/app.js') }}\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  We\u0026rsquo;re using the exact same url_for function to point to the path of our image.\nSave the file, make sure your app is running and reload the browser windows to see your image rendered!\nWrapping up You\u0026rsquo;ve learned how to create the static directory, CSS, JavaScript and image directories and link static files to HTML templates, along with rendering images using the url_for function.\nurl_for provides some other powerful uses that you\u0026rsquo;ll learn about very soon.\nAt this point, your armed with the tools to be able to create a simple static website! If you\u0026rsquo;re feeling confident, go ahead and create a few more pages, add some CSS and JavaScript and have some fun.\nIn the next part of this series, you\u0026rsquo;ll be learning more about the Jinja templating engine, along with passing variables and objects into your HTML from Flask views.\nLast modified · 28 Feb 2019\n Source : pythonise.com.\n "});index.add({'id':51,'href':'/library/tutorials/docs/python/list-python-basics/','title':"List for Tutorial",'content':" List Python Tutorial Python is one of the most popular programming languages. In the last few years, it has gained a lot of popularity due to the increasing interest in Data Science, Deep Learning, Machine Learning, and Artificial Intelligence.\nJust have a look at the Google Trends chart for interest in Python programming language. It’s increasing continuously and it will keep on increasing over time.\nPython Interest Over Time\nWhy to learn Python Programming?  Python programming is very simple, elegant, and English like. So it’s very easy to learn and a good programming language to start your IT career. Python is open source and you are free to extend it and make something beautiful out of it. Python has vast community support. There are over a million questions on StackOverflow in Python category. There are tons of free modules and packages to help you in every area of development. Most of the Machine Learning, Data Science, Graphs, Artificial Intelligence APIs are built on top of Python. So if you want to work in the area of cutting-edge technologies then it’s a great choice for you. Python is used by almost every major company in the world. So the chances of getting a job are much better if you know Python programming. If you are applying for any Python job, please go through Python Interview Questions. There are no limitations to Python programming, you can use it in IoT, web applications, game development, cryptography, blockchain, scientific calculations, graphs and many other areas.  Python Tutorial Python Tutorial can be broadly divided into the following categories.\n Python Basics – syntax, data types, variables, loops, functions, numbers, strings, classes, objects etc. Python Built-in Functions – format(), len(), super(), range(), slice(), tuple(), list() etc. Python Modules – collections, json, xml, io, os, sys, time, datetime etc. Web Applications Frameworks – Django, Flask Advanced Topics – Graphs, AI, ML modules such as Matplotlib, NumPy, TensorFlow, SciKit, Pandas etc.  Python Tutorial Important Points  If you are completely new to Python, spend enough time to go through basics. If your basics in Python won’t be strong then your code won’t be pythonic in nature. Python has two running major versions – Python-2 and Python-3. Python-3 is not backward compatible with Python-2. However, Python 3 is the recommended version to use. That’s why all the Python tutorials here are based on Python 3. While reading through the Python tutorials, please follow the examples and run them in your IDE for better understanding. PyCharm from JetBrains is the perfect IDE for Python programming. Its community edition is free to use. Most of our examples are present in our GitHub Repository. You can download them and look at the examples. I would recommend you to fork the project and then play around with the code. We have covered extensively on Python if you think we have missed some important topic. Please feel free to comment here and I will include them too.  Python Basics    Topic Description     Python Tutorial for Beginners Brief information about Python programming language and its advantages. Learn how to install Python on Windows, Linux/Ubuntu and Mac OS operating systems.   Python Keywords \u0026amp; Identifiers An article about keywords, identifiers and variables in Python. Learn about the rules for writing valid identifiers.   Python comments and statements Quick introduction to different types of comments and statements with example code.   Python Data Types Numeric, String, List, Tuple and Dict data types introduction.   Python Operators Arithmetic, Comparison, Bitwise, Logical, and Assignment Operators. Learn about the operator precedence in Python programming.   Python for loop Python for loop examples. Also, learn about nested for loops in Python.   Python while loop Python while loop, nested while loop and infinite while loop examples.   Python break continue A brief tutorial on Python break keyword and continue statement.   Python pass statement Learn about pass statement and the best practices to use them in your code.   Python loop Learn how to loop over a sequence, reverse looping, traversing through multiple sequences at once.   Python functions Learn how to define a function in Python, different types of arguments   Python Recursion How to implement recursion in Python, printing Fibonacci series using recursion.   Python Modules Understand what is a module in Python. Difference between module and package and how to import a module in your program.   Python Package Quick introduction to Python packages and how to use them.   Python Numbers Different types of numbers, type conversion and complex numbers in Python   Python List Python List functions – create, update, delete, append and iterate through elements.   Python Tuple Learn about accessing tuple elements, update and delete tuple, important tuple functions.   Python String A brief introduction of String in Python and important Python string functions.   Python set Learn how to work with Set in Python.   Python Dictionary Python dictionary operations, accessing key-value pairs, deleting dict elements.   Python File Python file operations – read, open, write, delete and copy file.   Python Directory How to create, rename and delete a directory in Python.    Python sort list\nLearn how to sort a List elements in Python, sort in decending order and with custom logic.\nPython List Comprehension\nLearn about Python List Comprehension to create list from some source sequence, string or list.\nPython try except\nLearn how to perform exception handling in Python using try-except block.\nPython Custom Exception\nHow to create custom exception in Python.\nPython namespace\nPython namespace and variable scope\nPython Class\nEverything about Python Classes, how to define them with variables, constructors, and functions.\nPython Inheritance\nLearn about inheritance in Python, method overloading, super class and sub class.\nPython Multiple Inheritance\nPython Multiple Inheritance Example. What is the difference between Multiple Inheritance and Multi-level Inheritance, Method Resolution Order (MRO) and logic to resolve the Conflicts with python multiple inheritance.\nPython Operator Overloading\nPython allows us to overload operators to work with custom object. Learn how to use operator overloading in Python.\nPython Iterator\nPython Iterator protocol, iterable elements, creating custom iterator example program.\nPython Generator\nLearn about yield keyword in Python to create generator functions that returns a series of arguments and work as an iterator.\nPython Closure\nA slightly complex topic with nested functions where outer function returns the nested function and nested function does some work on the enclosed function arguments.\nPython Decorator\nPython decorator is a function that helps to add some additional functionalities to an already defined function.\nPython Array\nPython Array contains a sequence of data. In python programming, there is no exclusive array object because we can perform all the array operations using list.\nPython list append\nShort example for using list append() function in Python.\nPython string to int\nLearn about different ways to convert string to int and vice versa in Python.\nPython variables\nA look into Python variable declaration and their scope.\nPython lambda\nA brief introduction to Python lambda keyword to create anonymous functions.\nPython metaclass\nPyton metaclass introduction and how to create a metaclass.\nPython switch case\nUnlike many other famous programming languages, Python doesn’t have switch-case statement. However, we can write code using dictionary to simulate the same behavior.\nPython modulo\nPython modulo operation is used to get the reminder of a division. The basic syntax of Python Modulo is a % b. Here a is divided by b and the remainder of that division is returned.\nPython assert statement\nPython assert statement takes a condition, the condition needs to be true. If the condition is true, then the program will run smoothly and the next statements will be executed. But, if the condition is false then it raises an exception.\nPython yield\nPython yield has almost same purpose as return keyword except that it returns the values one by one. This is very useful keyword when you need to return a huge number of values.\nPython Stack\nPython doesn’t provide any implementation of Stack data structure. This example shows how to implement stack data structure in Python.\nPython PIP\nPIP is a package management system used to install and manage software packages written in Python.\nPython self\nA brief article on the ‘self’ argument present in Python class constructors.\nPython ternary operator\nLearn how to effectively use Python ternary operator to reduce boiler plate code.\nPython print format\nIn this lesson, we will study about various ways for Python print format, through which we can print our data on the console and interpolate it.\nPython Command Line Arguments\nPython Command line arguments are input parameters passed to the script when executing them. Learn how to effectively read and parse command line parameters in Python.\nPython main function\nLearn the special technique to define main method in python program, so that it gets executed only when the program is run directly and not executed when imported as a module.\nPython Garbage Collection\nPython garbage collection is the memory management mechanism in python.\nPython XML Parser\nPython ElementTree XML API provides us easy way to read XML file and extract useful data.\nPython Join List to String\nWe can use String join() function to concatenate a list of string with specified delimiter to create a new string.\nPython init() function\nA complete tutorial for Python class init() function.\nPython print to file\nLearn how to route Python print() function output to a file.\nPython static method\nIn this Python tutorial, we will learn how to create Python static method. We will also look at advantages and disadvantages of static methods and comparison with the instance methods.\nPython Calculator Program\nIn this Python tutorial, we will learn how to create a very simple python calculator program. We will take input from the user about the operation he wants to perform and show the result on its basis.\nPython classmethod\nLearn how to use @classmethod annotation to create Python class methods.\nPython counter\nPython Counter class is part of Collections module. Counter is a subclass of Dictionary and used to keep track of elements and their count.\nPython OrderedDict\nPython OrderedDict is a dict subclass that maintains the items insertion order. When we iterate over an OrderedDict, items are returned in the order they were inserted.\nPython namedtuple\nPython namedtuple object is part of collections module. Python namedtuple is an extension of tuple.\nPython Catch Multiple Exceptions\nSometimes we call a function that may throw multiple types of exceptions depending on the arguments, processing logic etc. In this tutorial, we will learn how to catch multiple exceptions in python.\nPython add to dictionary\nThere is no explicitly defined method to add a new key to the dictionary. If you want to add a new key to the dictionary, then you can use assignment operator with dictionary key.\nPython Current Date Time\nWe can use Python datetime module to get the current date and time of the local system. Python pytz is one of the popular module to get the timezone aware date time objects.\nPython strftime()\nPython strftime() function is present in datetime and time modules to create a string representation based on the specified format string.\nPython timedelta\nPython timedelta object is used to perform datetime manipulations in an easy way. The timedelta class is part of datetime module.\nPython date\nPython date class is part of datetime module.\nPython wait for specific time\nSometimes we want our python program to wait for a specific time before executing the next steps. We can use time module sleep() function to pause our program for specified seconds.\nPython string to datetime – strptime()\nWe can convert a string to datetime using strptime() function. This function is available in datetime and time modules to parse a string to datetime and time objects respectively.\nPython Complex Numbers\nA complex number is created from two real numbers. Python complex number can be created using complex() function as well as using direct assignment statement.\nPython Set Intersection\nPython Set Difference\nPython Set Union\nPython Set to List\nPython Reverse List\nPython Set Environment Variable\nPython *args and **kwargs\nPython Division\nPython Not Equal Operator\nPython Return statement\nPython and operator\nPython logical operators\nPython Bitwise Operators\nPython Comparison Operators\nPython Built-In Functions Topic\nDescription\nPython input()\nPython input() function is used to get the user input from the console.\nPython zip()\nPython zip function takes iterable elements as input, and returns iterator.\nPython super()\nPython super() function allows us to refer to the parent class explicitly. It’s useful in case of inheritance where we want to call super class functions.\nPython getattr()\nPython getattr() function is used to get the value of an object’s attribute and if no attribute of that object is found, default value is returned.\nPython type\nPython type() function example to determine the type of the object.\nPython range()\nPython range() function examples to generate list of numbers.\nPython enumerate()\nPython enumerate takes a sequence, and then make each element of the sequence into a tuple.\nPython float()\nThis built-in function is used to create a floating point number. We can convert a string to floating point number using this function.\nPython print()\nOne of the most widely used Python function to print the values to a stream, or to sys.stdout by default.\nPython hash()\nPython hash() function returns the hash value of the object, which is a fixed size integer which identifies a particular value.\nPython str() and repr()\nPython str() function returns the string representation of the object. This method is called when print() or str() function is invoked on an object. Python repr() function returns the object representation. It could be any valid python expression such as tuple, dictionary, string etc.\nPython eval() function\nPython eval() function is used to parse an expression string as python expression and then execute it.\nPython exec()\nPython exec() function provides support for dynamic code execution.\nPython import\nPython abs()\nPython all()\nPython any()\nPython ascii()\nPython bin()\nPython bool()\nPython breakpoint()\nPython bytearray()\nPython bytes()\nPython callable()\nPython chr(), ord()\nPython classmethod()\nPython compile()\nPython complex()\nPython delattr()\nPython dir()\nPython divmod()\nPython filter()\nPython format()\nPython frozenset()\nPython globals()\nPython hasattr()\nPython help()\nPython hex()\nPython id()\nPython int()\nPython isinstance()\nPython issubclass()\nPython iter()\nPython len()\nPython locals()\nPython map()\nPython max()\nPython min()\nPython object()\nPython oct()\nPython open()\nPython pow()\nPython property()\nPython reversed()\nPython round()\nPython set()\nPython setattr()\nPython slice()\nPython sorted()\nPython staticmethod()\nPython sum()\nPython vars()\nPython String Functions Topic\nDescription\nPython String join()\nPython string join() function is used to concatenate a sequence of strings to create a new string.\nPython string to Uppercase – str.upper()\nWe can convert a string to uppercase in Python using str.upper() function.\nPython String to Lowercase – str.lower()\nWe can convert a string to lowercase in Python using str.lower() function. In this short tutorial, we will learn how to convert python string to lowercase.\nPython String contains\nPython String class has contains() function that we can use to check if it contains another string or not.\nPython String split\nPython string split() function is used to split a string into the list of strings based on a delimiter.\nPython String replace()\nPython string replace() function is used to create a string by replacing some parts of another string.\nPython String format()\nPython String format() function is used to create a formatted string from the template string and the supplied values.\nPython String Template\nPython String Template class is used to create a simple template string, where fields can be replaced later on to create a string object.\nPython String to bytes\nLearn how to convert String to bytes and then bytes to String in Python.\nPython Check Variable is String\nWe can use isinstance() function to verify that a variable is string or not.\nPython String Comparison\nPython String comparison can be performed using equality (==) and comparison (\u0026lt;, \u0026gt;, !=, \u0026lt;=, \u0026gt;=) operators.\nPython String join()\nPython String join() function returns a string that is the concatenation of the strings in iterable with string object as a delimiter.\nPython String Concatenation\nLearn about five different ways to concatenate Strings in Python.\nPython slice string\nPython string supports slicing to create substring. Note that Python string is immutable, slicing creates a new substring from the source string and original string remains unchanged.\nf-strings in Python\nPython f-strings or formatted strings are the new way to format strings. This feature was introduced in Python 3.6 under PEP-498. It’s also called literal string interpolation.\nPython Raw String\nPython raw string is created by prefixing a string literal with ‘r’ or ‘R’. Python raw string treats backslash () as a literal character.\nPython String equals\nPython strings equality can be checked using == operator or eq() function. Python strings are case sensitive, so these equality check methods are also case sensitive.\nPython String encode() decode()\nPython string encode() function is used to encode the string using the provided encoding. This function returns the bytes object. Python bytes decode() function is used to convert bytes to string object.\nPython Trim String\nPython provides three methods that can be used to trim whitespaces from the string object.\nPython String Length\nPython String length can be determined by using built-in len() function.\nPython Concatenate String and int\nLearn about different ways to concatenate String and int to create a new string.\nPython Reverse String\nPython String doesn’t have a built-in reverse() function. However, there are various ways to reverse a string in Python.\nPython List to String\nLearn how to convert a list to string in a Python program.\nPython String find()\nPython String find() method is used to find the index of a substring in a string.\nPython Remove Character from String\nLearn how to remove character from a string using replace() and translate() functions.\nPython String Append\nLearn the best way to append multiple strings to create a new string.\nPython String translate()\nPython String translate() function returns a new string with each character in the string replaced using the given translation table.\nPython String to float\nWe can convert a string to float in Python using float() function.\nPython String to List\nWe can convert a string to list in Python using split() function.\nPython String count()\nPython String count() function returns the number of occurrences of a substring in the given string.\nPython Find String in List\nWe can use Python in operator to check if a string is present in the list or not. There is also a not in operator to check if a string is not present in the list.\nPython Remove Spaces from String\nLearn about the five ways to remove spaces from a string in Python.\nPython Substring\nPython string provides various methods to create a substring, check if it contains a substring, index of substring etc. In this tutorial, we will look into various operations related to substrings.\nPython Generate Random String\nSometimes we want to generate a random string for unique identifiers, session id or to suggest a password. Learn how to generate a random string in Python.\nPython String Module\nPython String module contains some constants, utility function, and classes for string manipulation.\nString contains substring?\nPython provides two common ways to check if a string contains another string.\nPython String startswith()\nPython string startswith() function returns True if the string starts with the given prefix, otherwise it returns False.\nPython String endswith()\nPython string endswith() function returns True if the string ends with the given suffix, otherwise it returns False.\nPython Multiline String\nSometimes we have a very long string and we want to write it into multiple lines for better code readability. Python provides various ways to create multiline strings.\nPython String capitalize()\nPython String capitalize() function returns the capitalized version of the string. The first character of the returned string is converted to uppercase and rest of the characters are changed to lowercase.\nPython String center()\nPython string center() function returns a centered string of specified size.\nPython String casefold()\nPython string casefold() function returns a casefolded copy of the string. This function is used to perform case-insensitive string comparison.\nPython String expandtabs()\nPython string expandtabs() function returns a new string with tab characters (\\t) replaced with one or more whitespaces.\nPython String index()\nPython String index() function returns the lowest index where the specified substring is found. If the substring is not found then ValueError is raised.\nPython String format_map()\nPython string format_map() function returns a formatted version of the string using substitutions from the mapping provided.\nPython String isalnum()\nPython String isalpha()\nPython String isdecimal()\nPython String isdigit()\nPython String isidentifier()\nPython String islower()\nPython String isnumeric()\nPython String isprintable()\nPython String isspace()\nPython String istitle()\nPython String isupper()\nPython String ljust(), rjust()\nPython String swapcase()\nPython String partition()\nPython String splitlines()\nPython String title()\nPython String zfill()\nPython String Functions\nPython Modules Topic\nDescription\nPython os module\nPython OS module provides easy functions that allow us to interact and get Operating System related information and even control processes up to a limit.\nPython sys module\nPython sys module provides easy functions that allow us to interact with the interpreter directly.\nPython time\nPython time module helps us in working with local system date and time. The article also covers calendar module to get data in the calendar format.\nPython MySQL\nPython pymysql module is used to connect to MySQL database and execute database queries.\nPython CSV\nPython csv module allows us to easily read and write CSV files.\nPython multiprocessing\nPython multiprocessing module allows us to write code for parallel processing across multiple CPU. Process, Queue, and Lock are the most important classes in the multiprocessing module.\nPython pickle\nPython pickle module is used to serialize and deserialize a python object structure. Any object on python can be pickled so that it can be saved on disk.\nPython time sleep\nPython time sleep() function is used to add delay in the execution of a program. We can use python sleep function to halt the execution of the program for given time in seconds.\nPython queue\nPython queue module provides the implementation of different kinds of Queue data structures such as Queue, LifoQueue, and Priority Queue.\nPython unittest\nPython unittest module is used to test a unit of source code.\nPython socket\nPython socket module helps us in implementing socket server and client programs in Python code.\nPython SimpleHTTPServer\nPython SimpleHTTPServer module is a very handy tool. You can use Python SimpleHTTPServer to turn any directory into a simple HTTP web server.\nPython json\nPython json module is used to convert object to JSON data and vice versa.\nPython signal\nPython signal module is required for almost all the basic signal handling operations in python.\nPython random\nPython random module is used to generate random numbers.\nPython System Command\nWe can use os.system() function or subprocess.call() function to run shell commands from Python programs.\nPython Daemon Thread\nLearn how to create daemon thread using Python threading module.\nPython Copy\nPython copy module allows us to perform shallow and deep copy of objects.\nPython threading module\nPython threading module is used to implement multithreading in python programs.\nPython struct\nPython struct module is capable of performing the conversions between the Python values and C structs, which are represented as Python Strings.\nPython logging\nPython logging module defines functions and classes that provide a flexible event logging system for python applications.\nPython subprocess\nPython subprocess module provides easy functions that allow us to spawn a new process and get their return codes.\nPython argparse\nPython argparse module is the preferred way to parse command line arguments.\nPython functools\nPython functools module provides us various tools which allows and encourages us to write reusable code.\nPython itertools\nPython itertools module provide us various ways to manipulate the sequence while we are traversing it.\nPython getopt\nPython getopt module is one of the option to parse python command line arguments.\nPython ftp\nPython ftp module helps us in connecting to a FTP server, upload, and download files.\nPython tarfile\nPython tarfile module is used to read and write tar archives.\nPython lxml\nPython lxml is the most feature-rich and easy-to-use library for processing XML and HTML data.\nPython ConfigParser\nTo provide a quick summary, using configparser module, we can keep the configuration related to our application in a configuration file, anywhere in the system and access it inside our application.\nPython datetime\nPython datetime module manipulating dates and times. We can also format date and create naive or timezone aware date and time objects.\nPython decimal module\nPython decimal module helps us in division with proper precision and rounding of numbers.\nPython collections\nPython collections module comes with with a number of container data types such as OrderedDict, defaultdict, counter, namedtuple, and deque.\nPython zipfile\nPython zipfile module helps us in working with zip files. In this article, we will learn how to read zip archive details, create and extract zip files using zipfile module.\nPython pdb\nPython pdb module provides an interactive debugging environment for Developers to debug Python programs.\nPython io\nPython io module allows us to manage the file-related input and output operations. The advantage of using IO module is that the classes and functions available allows us to extend the functionality to enable writing to the Unicode data.\nPython fractions\nPython fractions module allows us to manage fractions in our Python programs.\nPython AST\nAbstract Syntax Tree is a very strong features in Python. Python AST module allows us to interact with Python code itself and modify it.\nPython HTTP\nPython HTTP module defines the classes which provide the client-side of the HTTP and HTTPS protocols. In this article, we will learn how to use a Python HTTP client to fire HTTP request and then parse response status and get response body data.\nPython xmltodict\nWe can use python xmltodict module to read XML file and convert it to Dict or JSON data. We can also stream over large xml files and convert them to Dictionary.\nPython gzip\nPython gzip module provides a very simple way to compress and decompress files and work in a similar manner to GNU programs gzip and gunzip.\nPython HTML Parser\nPython html.parser module provides us with the HTMLParser class, which can be sub-classed to parse HTML-formatted text files.\nPython inspect module\nPython inspect module is a very useful module which is used to introspect live objects in a program and look at the source code of modules, classes and functions which are used throughout a program.\nPython Send Email\nSending email is a very common task in any software program, we can use python smtplib module for sending email in the python program.\nPython tempfile\nPython tempfile module provides easy functions through which we can make temporary files and directories and access them easily as well.\nPython SQLite\nPython sqlite3 is an excellent module with which you can perform all possible DB operations with in-memory and persistent database in your applications.\nPython shutil\nPython shutil module enables us to operate with file objects easily and without diving into file objects a lot. It takes care of low-level semantics like creating file objects, closing the files once they are copied and allows us to focus on the business logic of our program.\nPython timeit\nPython timeit module helps us in measuring the time of execution for a piece of Python code. The timeit module runs a piece of code 1 million times (default value) and takes into account the minimum amount of time it took to run that piece of code.\nPython getpass module\nPython getpass module is the perfect choice when we want user to enter secret keys, pass-phrases or password through terminal.\nPython urllib\nPython urllib module allows us to access URL data programmatically. Some of the common usage are calling REST web services and making HTTP requests and read response data.\nPython pytz\nPython pytz module allows us to create timezone aware datetime instances.\nPython pendulum\nPython Pendulum module is a drop-in replacement for the built-in datetime module. Python pendulum module supports timezones and provides useful methods to format, parse and date time manipulations.\nPython arrow module\nPython Arrow module is a replacement library for datetime. It’s a simple module with a human-friendly approach to creating, manipulating, formatting and converting dates, times, and timestamps.\nPython Web Application Frameworks Topic\nDescription\nPython Flask\nPython flask module allows us to create web applications in Python.\nPython Django Tutorial\nLearn how to get started with Django framework to create a simple web application.\nDjango Templates\nDjango Models\nDjango Forms\nDjango ModelForms\nPython Advanced Topics Topic\nDescription\nPython NumPy\nPython NumPy is the core library for scientific computing in Python. NumPy provides a high-performance multidimensional array object and tools for working with these arrays.\nPython Matrix\nMatrix are used a lot in scientific and mathematical equations. Python NumPy module provides support for matrix creation, addition, multiplication, inverse, and transpose operations.\nPython math\nPython math module provides access to the mathematical functions defined by the C standard. So, we can do many complex mathematical operations with the help of the Python Math functions.\nPython hashlib\nWe can use python hashlib module to generate message digest or secure hash from the source message. Python hashlib hashing function takes variable length of bytes and converts it into a fixed length sequence. This is a one way function.\nPython Plotly\nPlotly’s Python graphing library makes interactive graphs online and allows us to save them offline if need be.\nPython Matplotlib\nPython matplotlib library helps us to plot data on graphs in its simplest terms. If you are familiar with MATLAB plotting, then Matplotlib will be easy to use for basic plotting.\nPython SciPy\nPython SciPy library is a set of convenience functions built on NumPy and mathematical algorithms.\nPython TensorFlow\nTensorFlow is a library for dataflow programming. It’s a symbolic math library and is also used for application of machine learning such as neural network.\nKeras Deep Learning\nKeras is a high-level neural networks API. It is written in Python and can run on top of Theano, TensorFlow or CNTK.\nPython SciKit-learn\nScikit-learn is a machine learning library for Python. It features several regression, classification and clustering algorithms including SVMs, gradient boosting, k-means, random forests and DBSCAN.\nPython Seaborn\nSeaborn is a library for making statistical infographics in Python. It is built on top of matplotlib and also supports numpy and pandas data structures. It also supports statistical units from SciPy.\nPython StatsModels\nPython StatsModels allows users to explore data, perform statistical tests and estimate statistical models. It is supposed to complement to SciPy’s stats module.\nPython Gensim Word2Vec\nGensim is an open-source vector space and topic modelling toolkit. It is implemented in Python and uses NumPy \u0026amp; SciPy. It also uses Cython for performance.\nNetworkX – Python Graph Library\nNetworkX is a Python package that allows us to create, manipulate, and study structure, functions and dynamics of complex networks.\nBokeh Python Data Visualization\nBokeh is an interactive Python data visualization library which targets modern web browsers for presentation.\nReferences:\n Python Built-In Functions Python Built-in Types Python 3 Official Documentation Python Wikipedia Page Python GitHub Source Code Python Package Index (PyPI) Python Reddit Community   Source journaldev.com.\n "});index.add({'id':52,'href':'/library/tutorials/docs/python/flask/learning-flask/ep-5/','title':"Ep.5 Jinja template inheritance",'content':" Jinja template inheritance | Learning Flask Ep. 5 Creating reusable base HTML templates and extending them throughout your Flask app\nIn this firth part of the Learning Flask series, you\u0026rsquo;ll learn how to use the powerful Jinja templating engine to make working with our HTML files much more efficient.\nTemplate inheritance works by creating a series of \u0026ldquo;base templates\u0026rdquo; and importing them into \u0026ldquo;child templates\u0026rdquo;, minimising the amount of repetitive code we need to write and allowing us to reuse elements effectively and reliably.\nJinja templating can be a bit confusing at first but quickly becomes fun to work with and a joy to use!\nWe\u0026rsquo;ll pick up where we left off from the last episode.\nLet\u0026rsquo;s get coding!\nCreating base templates If you\u0026rsquo;ve been following along with this series, you\u0026rsquo;ll be familiar enough with the concept of breaking up our Flask app into sub-directories and seperate files to maintain good readibility and create a clear separation of the different elements of our app.\nLet\u0026rsquo;s take a quick at our application structure:\n`app ├── app │ ├── __init__.py │ ├── admin_views.py │ ├── static │ │ ├── css │ │ │ └── style.css │ │ ├── img │ │ │ └── flask.png │ │ └── js │ │ └── app.js │ ├── templates │ │ ├── admin │ │ │ └── dashboard.html │ │ └── public │ │ └── index.html │ └── views.py ├── requirements.txt └── run.py`   Tip - I\u0026rsquo;m generating these directory maps using the tree command in my terminal\n We\u0026rsquo;re going to create 2 new templates directories.\n One at templates/admin/templates One at templates/public/templates  Let\u0026rsquo;s create them now from the root app directory:\nmkdir /app/templates/admin/templates mkdir app/templates/public/templates\nLet\u0026rsquo;s also create some HTML templates in those directories:\ntouch app/templates/admin/templates/admin_template.html touch app/templates/public/templates/admin_template.html\nNow let\u0026rsquo;s take a quick glance at our file structure:\n`app ├── app │ ├── __init__.py │ ├── admin_views.py │ ├── static │ │ ├── css │ │ │ └── style.css │ │ ├── img │ │ │ └── flask.png │ │ └── js │ │ └── app.js │ ├── templates │ │ ├── admin │ │ │ ├── dashboard.html │ │ │ └── templates │ │ │ └── admin_template.html │ │ └── public │ │ ├── index.html │ │ └── templates │ │ └── public_template.html │ └── views.py ├── requirements.txt └── run.py`  We\u0026rsquo;ve added our 2 base HTML template files to the 2 directories.\n Note - To make things a little more interesting, we\u0026rsquo;re going to use the Bootstrap CSS \u0026amp; JS library. Head over to the the Bootstrap webside to download the source files or feel free to use the Bootstrap CDN (Recommended).\n If you\u0026rsquo;re using the Bootstrap starter template found here. You don\u0026rsquo;t need to download any of the source files, otherwise, go ahead and download the Bootstrap library and jQuery library and do the following:\nYou can get the jQuery source code here. Just copy and paste it into a file called jquery.slim.min.js\n Place bootstrap.min.css in the static/css directory Place bootstrap.bundle.min.js in the static/js directory place jquery.slim.min.js in the static/js directory  Go ahead and open up public_template.html in your editor and add the following:\napp/app/templates/public/templates/public_template.html\n`\u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;!-- Required meta tags --\u0026gt; \u0026lt;meta charset=\u0026quot;utf-8\u0026quot;\u0026gt; \u0026lt;meta name=\u0026quot;viewport\u0026quot; content=\u0026quot;width=device-width, initial-scale=1, shrink-to-fit=no\u0026quot;\u0026gt; \u0026lt;!-- Import the Bootstrap stylesheet --\u0026gt; \u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;{{ url_for('static', filename='css/bootstrap.min.css') }}\u0026quot;\u0026gt; \u0026lt;!-- Import our custom stylesheet --\u0026gt; \u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;{{ url_for('static', filename='css/style.css') }}\u0026quot;\u0026gt; \u0026lt;title\u0026gt;{% block title %}{% endblock %}\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;main\u0026gt; {% block main %}{% endblock %} \u0026lt;/main\u0026gt; \u0026lt;!-- Import jquery 3.3.1 slim min --\u0026gt; \u0026lt;script src=\u0026quot;{{ url_for('static', filename='js/jquery.slim.min.js') }}\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;!-- Import Bootstrap bundle --\u0026gt; \u0026lt;script src=\u0026quot;{{ url_for('static', filename='js/bootstrap.bundle.min.js') }}\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;!-- Import our custom JavaScript --\u0026gt; \u0026lt;script src=\u0026quot;{{ url_for('static', filename='js/app.js') }}\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; {% block script %}{% endblock %} \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;`  Ok so we\u0026rsquo;ve added quite a lot of new code to this HTML file. Let\u0026rsquo;s step through what we\u0026rsquo;ve done:\n Tip - If you used the Bootstrap starter template, don\u0026rsquo;t worry about importing any of the Bootstrap or jQuery CSS or JS files as they\u0026rsquo;ll be delivered through the CDN\n  We import the bootstrap.min.css file in the \u0026lt;head\u0026gt; We then import our custom stylesheet as we did in the last episode We added the {% block title %} and {% endblock %} tags between the \u0026lt;title\u0026gt; \u0026lt;/title\u0026gt; tags We added the {% block main %} and {% endblock %} tags between the \u0026lt;main\u0026gt; \u0026lt;/main\u0026gt; tags We imported the jquery.slim.min library We imported the bootstrap.bundle.min.js library We imported out custom JavaScript file down at the bottom just like in the last part of the series Finally, we added the {% block script %} and {% endblock %} tags just before the closing \u0026lt;/body\u0026gt; tag  You\u0026rsquo;ll notice we use the syntax {% block something %} {% endblock %} to declare our blocks.\nWe\u0026rsquo;ll later fill in these blocks when we import this template into our child templates.\nYou can name a block whatever you like, however you can only use a block name once.\nWe should add a navigation bar to our public_template.html template. Add the following just below the opening \u0026lt;body\u0026gt; tag:\napp/app/templates/public/templates/public_template.html\n`\u0026lt;nav class=\u0026quot;navbar navbar-expand-lg navbar-light bg-light mb-3\u0026quot;\u0026gt; \u0026lt;a class=\u0026quot;navbar-brand\u0026quot; href=\u0026quot;#\u0026quot;\u0026gt;Flask\u0026lt;/a\u0026gt; \u0026lt;button class=\u0026quot;navbar-toggler\u0026quot; type=\u0026quot;button\u0026quot; data-toggle=\u0026quot;collapse\u0026quot; data-target=\u0026quot;#navbarNav\u0026quot; aria-controls=\u0026quot;navbarNav\u0026quot; aria-expanded=\u0026quot;false\u0026quot; aria-label=\u0026quot;Toggle navigation\u0026quot;\u0026gt; \u0026lt;span class=\u0026quot;navbar-toggler-icon\u0026quot;\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;/button\u0026gt; \u0026lt;div class=\u0026quot;collapse navbar-collapse\u0026quot; id=\u0026quot;navbarNav\u0026quot;\u0026gt; \u0026lt;ul class=\u0026quot;navbar-nav\u0026quot;\u0026gt; \u0026lt;li class=\u0026quot;nav-item\u0026quot;\u0026gt; \u0026lt;a class=\u0026quot;nav-link\u0026quot; href=\u0026quot;/\u0026quot;\u0026gt;Home\u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;nav-item\u0026quot;\u0026gt; \u0026lt;a class=\u0026quot;nav-link\u0026quot; href=\u0026quot;/about\u0026quot;\u0026gt;About\u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;collapse navbar-collapse\u0026quot; id=\u0026quot;navbarNav\u0026quot;\u0026gt; \u0026lt;ul class=\u0026quot;navbar-nav ml-auto\u0026quot;\u0026gt; \u0026lt;li class=\u0026quot;nav-item\u0026quot;\u0026gt; \u0026lt;a class=\u0026quot;nav-link\u0026quot; href=\u0026quot;/admin/dashboard\u0026quot;\u0026gt;Admin\u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/nav\u0026gt;`  Ok great, now we\u0026rsquo;ve got a nice navbar! Let\u0026rsquo;s create a child template and put our blocks to use.\nChild templates A child template will inherit all of the HTML from the base template and fill in the areas where we declared our blocks.\nLet\u0026rsquo;s refactor index.html to be our first child template. Go ahead and open it up in an your editor and enter the following:\napp/app/templates/public/index.html\n`{% extends \u0026quot;public/templates/public_template.html\u0026quot; %} {% block title %}Home{% endblock %} {% block main %} \u0026lt;div class=\u0026quot;container\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col\u0026quot;\u0026gt; \u0026lt;h1\u0026gt;Home\u0026lt;/h1\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {% endblock %}`  Let\u0026rsquo;s look at what we\u0026rsquo;ve done.\n We use the {% extends \u0026quot;path/to/our/template.html\u0026quot; %} syntax to import a base template {% block title %}Home{% endblock %} will set the page title Then we fill in the blocks we declared in our base template by once again, using the {% block something %} {% endblock %} syntax  Anything inside our named blocks will be plugged into our base template!\nLet\u0026rsquo;s throw in some JavaScript into the {% block script %} tags and see what happens.\nAt the bottom of index.html add the following:\n`{% block script %} \u0026lt;script\u0026gt; alert(\u0026quot;Template inheritance is awesome\u0026quot;); \u0026lt;/script\u0026gt; {% endblock %}`  Save the file and reload your browser window.\nYou should see the JavaScript alert dialogue pop up! Go ahead and close it and remove the {% block script %} and containing JavaScript we just added.\n Tip - Inspect the page HTML by hitting Ctrl + u to open up a new tab showing the source code to get a better understanding of what\u0026rsquo;s happening\n As you can see, our index.html file doesn\u0026rsquo;t contain any of the boilerplate HTML we added in our base template. That\u0026rsquo;s because index.html inherits all the contents of the base template, in our case it\u0026rsquo;s inheriting everything from public_template.html\nSo we\u0026rsquo;ve got our base template for our public views. Let\u0026rsquo;s do the same with our admin views by creating a new base template and refactoring our dashboard.html file to become a new child template.\nAdditional templates Open up admin_template.html and add the following:\napp/app/templates/admin/templates/admin_template.html\n\u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;!-- Required meta tags --\u0026gt; \u0026lt;meta charset=\u0026quot;utf-8\u0026quot;\u0026gt; \u0026lt;meta name=\u0026quot;viewport\u0026quot; content=\u0026quot;width=device-width, initial-scale=1, shrink-to-fit=no\u0026quot;\u0026gt; \u0026lt;!-- Import the Bootstrap stylesheet --\u0026gt; \u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;{{ url_for('static', filename='css/bootstrap.min.css') }}\u0026quot;\u0026gt; \u0026lt;!-- Import our custom stylesheet --\u0026gt; \u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;{{ url_for('static', filename='css/style.css') }}\u0026quot;\u0026gt; \u0026lt;title\u0026gt;{% block title %}{% endblock title %}\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;nav class=\u0026quot;navbar navbar-expand-lg navbar-light bg-light mb-3\u0026quot;\u0026gt; \u0026lt;a class=\u0026quot;navbar-brand\u0026quot; href=\u0026quot;#\u0026quot;\u0026gt;Admin\u0026lt;/a\u0026gt; \u0026lt;button class=\u0026quot;navbar-toggler\u0026quot; type=\u0026quot;button\u0026quot; data-toggle=\u0026quot;collapse\u0026quot; data-target=\u0026quot;#navbarNav\u0026quot; aria-controls=\u0026quot;navbarNav\u0026quot; aria-expanded=\u0026quot;false\u0026quot; aria-label=\u0026quot;Toggle navigation\u0026quot;\u0026gt; \u0026lt;span class=\u0026quot;navbar-toggler-icon\u0026quot;\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;/button\u0026gt; \u0026lt;div class=\u0026quot;collapse navbar-collapse\u0026quot; id=\u0026quot;navbarNav\u0026quot;\u0026gt; \u0026lt;ul class=\u0026quot;navbar-nav\u0026quot;\u0026gt; \u0026lt;li class=\u0026quot;nav-item\u0026quot;\u0026gt; \u0026lt;a class=\u0026quot;nav-link\u0026quot; href=\u0026quot;/admin/dashboard\u0026quot;\u0026gt;Dashboard\u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;nav-item\u0026quot;\u0026gt; \u0026lt;a class=\u0026quot;nav-link\u0026quot; href=\u0026quot;/admin/profile\u0026quot;\u0026gt;Profile\u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;collapse navbar-collapse\u0026quot; id=\u0026quot;navbarNav\u0026quot;\u0026gt; \u0026lt;ul class=\u0026quot;navbar-nav ml-auto\u0026quot;\u0026gt; \u0026lt;li class=\u0026quot;nav-item\u0026quot;\u0026gt; \u0026lt;a class=\u0026quot;nav-link\u0026quot; href=\u0026quot;/\u0026quot;\u0026gt;Return to site\u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/nav\u0026gt; \u0026lt;main\u0026gt; {% block main %}{% endblock main %} \u0026lt;/main\u0026gt; \u0026lt;!-- Import jquery 3.3.1 slim min --\u0026gt; \u0026lt;script src=\u0026quot;{{ url_for('static', filename='js/jquery.slim.min.js') }}\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;!-- Import Bootstrap bundle --\u0026gt; \u0026lt;script src=\u0026quot;{{ url_for('static', filename='js/bootstrap.bundle.min.js') }}\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;!-- Import our custom JavaScript --\u0026gt; \u0026lt;script src=\u0026quot;{{ url_for('static', filename='js/app.js') }}\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; {% block script %}{% endblock %} \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;`  We haven\u0026rsquo;t changed much here, just a few tweaks to the navbar.\nNow we need to refactor our dashboard.html file in the templates/admin directory to become a new child template.\nOpen up dashboard.html in your browser and change it to the following:\napp/app/templates/admin/templates/admin_template.html\n`{% extends \u0026quot;admin/templates/admin_template.html\u0026quot; %} {% block title %}Admin dashboard{% endblock %} {% block main %} \u0026lt;div class=\u0026quot;container\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col\u0026quot;\u0026gt; \u0026lt;h1\u0026gt;Admin dashboard\u0026lt;/h1\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {% endblock %}`  Save the file and head back to your browser window.\nIf you now click on the Admin link in the top right of the navbar, you\u0026rsquo;ll be taken to the admin dashboard page where you\u0026rsquo;ll see our new base and child templates in action!\nCode challenge If you\u0026rsquo;re feeling comfortable, go ahead and create the 2 new child templates and inherit from their corresponding base templates for the 2 routes:\n The about route in views.py The profile route in admin_views.py   Tip - You\u0026rsquo;ll need to create 2 new HTML files and modify the routes!\n Key takeaways Creating base templates and extending them in child templates is a great way to streamline your HTML files and create reusable code that\u0026rsquo;s repeatable and reliable.\nKeep the following procedure in mind:\n Your base templates should contain your reusable code Declare named block sections in your base templates using the {% block something %} {% endblock %} syntax Create child templates that extends your base templates and plug the blocks with the corresponding block names  There\u0026rsquo;s still lots more to cover on Jinja! You\u0026rsquo;ll learn more about working with Python, Flask and Jinja in the next part of this series.\nLast modified · 28 Feb 2019\n Source : pythonise.com.\n "});index.add({'id':53,'href':'/library/tutorials/docs/python/modules-list/','title':"Modules List",'content':" Python Modules List Python os module\nPython sys module\nPython time\nPython MySQL\nPython CSV\nPython multiprocessing\nPython pickle\nPython time sleep\nPython queue\nPython unittest\nPython socket\nPython SimpleHTTPServer\nPython json\nPython signal\nPython random\nPython System Command\nPython Daemon Thread\nPython Copy\nPython threading module\nPython struct\nPython logging\nPython subprocess\nPython argparse\nPython functools\nPython itertools\nPython getopt\nPython ftp\nPython tarfile\nPython lxml\nPython ConfigParser\nPython datetime\nPython decimal module\nPython collections\nPython zipfile\nPython pdb\nPython io\nPython fractions\nPython AST\nPython HTTP\nPython xmltodict\nPython gzip\nPython HTML Parser\nPython inspect module\nPython Send Email\nPython tempfile\nPython SQLite\nPython shutil\nPython timeit\nPython getpass module\nPython urllib\nPython pytz\nPython pendulum\nPython arrow module\nReferences:\n https://docs.python.org/3/tutorial/modules.html https://docs.python.org/3/py-modindex.html   ที่มาบทความ : journaldev.com.\n "});index.add({'id':54,'href':'/library/tutorials/docs/articles/webapp/','title':"WebApp",'content':" WebApp "});index.add({'id':55,'href':'/library/tutorials/docs/articles/webapp/django/','title':"Django",'content':" Django Framework "});index.add({'id':56,'href':'/library/tutorials/docs/python/flask/learning-flask/ep-6/','title':"Ep.6 Jinja template design",'content':" Jinja template design | Learning Flask Ep. 6 An brief introduction to the power of the Jinja templating engine\nIn this part of the Learning Flask series, we\u0026rsquo;re going to dive deeper into the Jinja templating engine and you\u0026rsquo;ll learn more of the advanced features of this powerful library!\nIn the last part of this series, you learned how to create base templates, child templates and how to extend them. In this part you\u0026rsquo;ll learn more about template design, working with Python objects in your HTML and a few more handy tips for writing efficient, reusable code.\nThere\u0026rsquo;s a lot to cover, in fact, too much for this article. Check out the Jinja documentation for a full list of the features available.\nLet\u0026rsquo;s get started!\nCreating a new view For this example we\u0026rsquo;ll create a new view called jinja. Open up views.py and add the following route:\n@app.route(\u0026quot;/jinja\u0026quot;) def jinja(): return render_template(\u0026quot;public/jinja.html\u0026quot;)  We\u0026rsquo;ll need to create a new child template for this view. Create a file called jinja.html in the templates/public, open it in your editor and add the following:\napp/app/templates/public/jinja.html\n{% extends \u0026quot;public/templates/public_template.html\u0026quot; %} {% block title %}Jinja{% endblock %} {% block main %} \u0026lt;div class=\u0026quot;container\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col\u0026quot;\u0026gt; \u0026lt;h1\u0026gt;Jinja\u0026lt;/h1\u0026gt; \u0026lt;hr\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {% endblock %}  We should also add a link in our navbar so we access this view quickly! Go ahead and open up public_template.html in your editor.\nLet\u0026rsquo;s switch the About link to our new Jinja view.\nChange this:\n\u0026lt;li class=\u0026quot;nav-item\u0026quot;\u0026gt; \u0026lt;a class=\u0026quot;nav-link\u0026quot; href=\u0026quot;/about\u0026quot;\u0026gt;About\u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt;  To this:\n\u0026lt;li class=\u0026quot;nav-item\u0026quot;\u0026gt; \u0026lt;a class=\u0026quot;nav-link\u0026quot; href=\u0026quot;/jinja\u0026quot;\u0026gt;Jinja\u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt;  Reload your browser and click on the Jinja link in the nav to see our new view in action.\nPassing objects to templates We can pass any Python object to a template by passing it to the render_template function as a key/value pair. For example, let\u0026rsquo;s create a simple variable called my_name and assign it a string value (Feel free to replace the value for your own!)\nOpen up views.py and create the new my_name variable inside the jinja view:\napp/app/views.py\n@app.route(\u0026quot;/jinja\u0026quot;) def jinja(): my_name = \u0026quot;Julian\u0026quot; return render_template(\u0026quot;public/jinja.html\u0026quot;)  We pass objects to views in the render_template function as key/value pairs, like so:\nreturn render_template(\u0026quot;public/jinja.html\u0026quot;, my_name=my_name)\nGo ahead and pass the my_name key/value pair into render_template\nYour view will now look like this:\napp/app/views.py\n@app.route(\u0026quot;/jinja\u0026quot;) def jinja(): my_name = \u0026quot;Julian\u0026quot; return render_template(\u0026quot;public/jinja.html\u0026quot;, my_name=my_name)  Let\u0026rsquo;s use this variable in our jinja.html template. We access objects in Jinja with the {{ object }} syntax.\nOpen up jinja.html and add the following just under the \u0026lt;hr\u0026gt; tag:\napp/app/templates/public/jinja.html\nh4\u0026gt;Accessing an objects value\u0026lt;/h4\u0026gt; \u0026lt;hr\u0026gt; \u0026lt;p\u0026gt;Hello {{ my_name }}!\u0026lt;/p\u0026gt;  Your jinja.html file should look like this:\napp/app/templates/public/jinja.html\n{% extends \u0026quot;public/templates/public_template.html\u0026quot; %} {% block title %}Jinja{% endblock %} {% block main %} \u0026lt;div class=\u0026quot;container\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col\u0026quot;\u0026gt; \u0026lt;h1\u0026gt;Jinja\u0026lt;/h1\u0026gt; \u0026lt;hr\u0026gt; \u0026lt;h4\u0026gt;Accessing an objects value\u0026lt;/h4\u0026gt; \u0026lt;hr\u0026gt; \u0026lt;p\u0026gt;Hello {{ my_name }}!\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {% endblock %}   Tip - Going forward, we\u0026rsquo;re going to separate all of the sections in our jinja.html with a heading, description and example\n Save the file and reload the page to see Hello and the value for my_name!\nWe access an objects value in Jinja by passing it in between a pair of curly braces {{ like_so }}\nLet\u0026rsquo;s create some more objects in our jinja view and pass them into our template. Replace the contents of the jinja function with the following:\napp/app/views.py\n# Strings my_name = \u0026quot;Julian\u0026quot; # Integers my_age = 30 # Lists langs = [\u0026quot;Python\u0026quot;, \u0026quot;JavaScript\u0026quot;, \u0026quot;Bash\u0026quot;, \u0026quot;Ruby\u0026quot;, \u0026quot;C\u0026quot;, \u0026quot;Rust\u0026quot;] # Dictionaries friends = { \u0026quot;Tony\u0026quot;: 43, \u0026quot;Cody\u0026quot;: 28, \u0026quot;Amy\u0026quot;: 26, \u0026quot;Clarissa\u0026quot;: 23, \u0026quot;Wendell\u0026quot;: 39 } # Tuples colors = (\u0026quot;Red\u0026quot;, \u0026quot;Blue\u0026quot;) # Booleans cool = True # Classes class GitRemote: def __init__(self, name, description, domain): self.name = name self.description = description self.domain = domain def clone(self, repo): return f\u0026quot;Cloning into {repo}\u0026quot; my_remote = GitRemote( name=\u0026quot;Learning Flask\u0026quot;, description=\u0026quot;Learn the Flask web framework for Python\u0026quot;, domain=\u0026quot;https://github.com/Julian-Nash/learning-flask.git\u0026quot; ) # Functions def repeat(x, qty=1): return x * qty  Now we need to pass our objects into our template using the render_template function. Pass them in as key/value pairs like the following:\napp/app/views.py\nreturn render_template( \u0026quot;public/jinja.html\u0026quot;, my_name=my_name, my_age=my_age, langs=langs, friends=friends, colors=colors, cool=cool, GitRemote=GitRemote, my_remote=my_remote, repeat=repeat )  Your jinja view should now look like this:\napp/app/views.py\n@app.route(\u0026quot;/jinja\u0026quot;) def jinja(): # Strings my_name = \u0026quot;Julian\u0026quot; # Integers my_age = 30 # Lists langs = [\u0026quot;Python\u0026quot;, \u0026quot;JavaScript\u0026quot;, \u0026quot;Bash\u0026quot;, \u0026quot;Ruby\u0026quot;, \u0026quot;C\u0026quot;, \u0026quot;Rust\u0026quot;] # Dictionaries friends = { \u0026quot;Tony\u0026quot;: 43, \u0026quot;Cody\u0026quot;: 28, \u0026quot;Amy\u0026quot;: 26, \u0026quot;Clarissa\u0026quot;: 23, \u0026quot;Wendell\u0026quot;: 39 } # Tuples colors = (\u0026quot;Red\u0026quot;, \u0026quot;Blue\u0026quot;) # Booleans cool = True # Classes class GitRemote: def __init__(self, name, description, domain): self.name = name self.description = description self.domain = domain def pull(self): return f\u0026quot;Pulling repo '{self.name}'\u0026quot; def clone(self, repo): return f\u0026quot;Cloning into {repo}\u0026quot; my_remote = GitRemote( name=\u0026quot;Learning Flask\u0026quot;, description=\u0026quot;Learn the Flask web framework for Python\u0026quot;, domain=\u0026quot;https://github.com/Julian-Nash/learning-flask.git\u0026quot; ) # Functions def repeat(x, qty=1): return x * qty return render_template( \u0026quot;public/jinja.html\u0026quot;, my_name=my_name, my_age=my_age, langs=langs, friends=friends, colors=colors, cool=cool, GitRemote=GitRemote, my_remote=my_remote, repeat=repeat )  Ok so we\u0026rsquo;ve added quite a lot of code to our view function, just some standard Python objects that most of which you should be fairly familiar with.\nWe then passed them as key/value pairs into our template using the render_template function.\nLet\u0026rsquo;s put them to use in jinja.html.\nAccessing objects in templates Our template now contains all of the objects we\u0026rsquo;ve passed into it. Let\u0026rsquo;s explore what we can do with them!\nLooping Looping in Jinja is done with the following syntax:\n{% for variable in iterable %} \u0026lt;!-- Do something with the variable --\u0026gt; {{ variable }} {% endfor %}  Just like a Python for loop, we use the for variable in iterable syntax, wrapped in a pair of {% %} braces.\nWe then access the variable using the double curly brace syntax {{ variable }}\nFor loops must always be closed with {% endfor %}\nLet\u0026rsquo;s put this into practice and loop through our langs list and create a HTML list with each of the values:\napp/app/templates/public/jinja.html\n\u0026lt;h4\u0026gt;Looping through an iterable\u0026lt;/h4\u0026gt; \u0026lt;hr\u0026gt; \u0026lt;strong class=\u0026quot;d-block mb-3\u0026quot;\u0026gt;Programming languages\u0026lt;/strong\u0026gt; \u0026lt;ul\u0026gt; {% for lang in langs %} \u0026lt;li\u0026gt;{{ lang }}\u0026lt;/li\u0026gt; {% endfor %} \u0026lt;/ul\u0026gt;  Reload your browser tab to see the changes.\nWe can also enumarate an iterable using {{ loop.index }}\napp/app/templates/public/jinja.html\n\u0026lt;h4\u0026gt;Looping and enumerating an iterable\u0026lt;/h4\u0026gt; \u0026lt;hr\u0026gt; \u0026lt;strong class=\u0026quot;d-block mb-3\u0026quot;\u0026gt;Programming languages\u0026lt;/strong\u0026gt; \u0026lt;ul\u0026gt; {% for lang in langs %} \u0026lt;li\u0026gt;{{ loop.index }} - {{ lang }}\u0026lt;/li\u0026gt; {% endfor %} \u0026lt;/ul\u0026gt;   Tip - loop.index starts at 1. To start enumerating at 0, use loop.index0\n Let\u0026rsquo;s loop though the key/value pairs of our friends dictionary:\napp/app/templates/public/jinja.html\n\u0026lt;h4\u0026gt;Looping key/value pairs in a dict\u0026lt;/h4\u0026gt; \u0026lt;hr\u0026gt; \u0026lt;strong class=\u0026quot;d-block mb-3\u0026quot;\u0026gt;Friends \u0026amp; ages\u0026lt;/strong\u0026gt; \u0026lt;ul\u0026gt; {% for name, age in friends.items() %} \u0026lt;li\u0026gt;{{ name }}: {{ age }}\u0026lt;/li\u0026gt; {% endfor %} \u0026lt;/ul\u0026gt;  Just like in Python, we can access the dictionary methods such as .keys(), .values() and .items().\nUsing the {% for variable in iterable %} and closing it with the {% endfor %} syntax, you can loop through any iterable, including lists, tuples, dictionaries, sets etc.. and access the variable value using {{ variable }}\nCalling functions We can call any functions we pass into our template simply by doing just that!\nLet\u0026rsquo;s call our repeat function and pass it some arguments:\napp/app/templates/public/jinja.html\n\u0026lt;h4\u0026gt;Calling functions\u0026lt;/h4\u0026gt; \u0026lt;hr\u0026gt; \u0026lt;p\u0026gt;{{ repeat(\u0026quot;Jinja is great! \u0026quot;, 10) }}\u0026lt;/p\u0026gt;  Save and refresh the page to see Jinja is great! printed 10 times.\nPassing and calling functions from templates is useful, but an even better way is to create custom filters which you\u0026rsquo;ll learn about shortly!\nAccessing object indexes, keys and attributes Just like in Python, we can access the indexes, keys and attributes of an object.\nAccessing a list index:\napp/app/templates/public/jinja.html\n\u0026lt;h4\u0026gt;List index\u0026lt;/h4\u0026gt; \u0026lt;hr\u0026gt; \u0026lt;p\u0026gt;{{ langs[0] }}\u0026lt;/p\u0026gt;  Accessing a dictionary value:\napp/app/templates/public/jinja.html\n\u0026lt;h4\u0026gt;Dictionary value\u0026lt;/h4\u0026gt; \u0026lt;hr\u0026gt; \u0026lt;p\u0026gt;{{ friends[\u0026quot;Tony\u0026quot;] }}\u0026lt;/p\u0026gt;  Accessing a class attribute:\napp/app/templates/public/jinja.html\n\u0026lt;h4\u0026gt;Class attributes\u0026lt;/h4\u0026gt; \u0026lt;hr\u0026gt; \u0026lt;p\u0026gt;{{ my_remote.description }}\u0026lt;/p\u0026gt;  As you can see, we just use the familiar Python syntax for accessing these values.\nClasses You\u0026rsquo;ve seen how to access class attributes using the class.attribute syntax. We can also call class methods from our Jinja template, just like in Python:\napp/app/templates/public/jinja.html\n\u0026lt;h4\u0026gt;Class methods\u0026lt;/h4\u0026gt; \u0026lt;hr\u0026gt; \u0026lt;p\u0026gt;{{ my_remote.pull() }}\u0026lt;/p\u0026gt;  Assignments Assigning new variables in Jinja is done using the {% set x = y %} syntax.\nLet\u0026rsquo;s create a new instance of our GitRemote class from within our template using the set tag:\napp/app/templates/public/jinja.html\n\u0026lt;h4\u0026gt;Create a class\u0026lt;/h4\u0026gt; \u0026lt;hr\u0026gt; {% set new_repo = GitRemote( name=\u0026quot;Learning Flask\u0026quot;, description=\u0026quot;Learn the Flask web framework for Python\u0026quot;, domain=\u0026quot;https://github.com/Julian-Nash/learning-flask.git\u0026quot;) %} \u0026lt;p\u0026gt;{{ new_repo.description }}\u0026lt;/p\u0026gt;`  We can also unpack and set variables directly in our template, for example:\n\u0026lt;h4\u0026gt;Unpack variables\u0026lt;/h4\u0026gt; \u0026lt;hr\u0026gt; {% set foo, bar = colors %} \u0026lt;p\u0026gt;{{ foo }}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;{{ bar }}\u0026lt;/p\u0026gt;  Conditionals \u0026amp; comparison operators Just like in Python, Jinja gives us acccess to many of the familiar conditional operators.\nif statement:\napp/app/templates/public/jinja.html\n\u0026lt;h4\u0026gt;Conditional if\u0026lt;/h4\u0026gt; \u0026lt;hr\u0026gt; {% if cool %} \u0026lt;p\u0026gt;Cool = {{ cool }}\u0026lt;/p\u0026gt; {% endif %}  We have to close any if conditionals with the {% endif %} syntax\nif, elif \u0026amp; else:\napp/app/templates/public/jinja.html\n\u0026lt;h4\u0026gt;Conditional if/elif\u0026lt;/h4\u0026gt; \u0026lt;hr\u0026gt; {% if my_age \u0026lt; 18 %} \u0026lt;p\u0026gt;No entry\u0026lt;/p\u0026gt; {% elif my_age \u0026lt;= 25 %} \u0026lt;p\u0026gt;You may enter\u0026lt;/p\u0026gt; {% else %} \u0026lt;p\u0026gt;Entry denied. You're not cool enough\u0026lt;/p\u0026gt; {% endif %}  As you\u0026rsquo;ll see we threw in some Python comparison operators. You have access to all of the standard operators including:\n- == Equality - != Inequality - \u0026gt; Greater than - \u0026gt;= Greater than or equal to - \u0026lt; Less than - \u0026lt;= Less than or equal to   Tip - You must always close an {% if x %} statement with {% endif %}\n Logic \u0026amp; other operators Just like in Python, you have full access to the logic operators:\n- and Return true if the left and the right operand are true - or Return true if the left or the right operand are true. - not Negate a statement (See tip below) - (exp) Group an expression   Tip - Read more about the not operator here at the official Jinja docs\n You\u0026rsquo;ll also have access to many other operators you\u0026rsquo;ll be familiar with including:\n in Containment test. For example {{ \u0026quot;a\u0026quot; in [\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;] }} will return true is Performs a test. {% foo is bar %} / {{ foo is not bar }}  Special Jinja operators Jinja features some special operators you may not be familiar with and we\u0026rsquo;ll be using later in this guide:\n | Applies a filter (Continue reading) For example {{ langs|length }} will return 6 ~ Converts all operands to strings and concatenates them, for example {{ \u0026quot;cool\u0026quot; ~ \u0026quot;==\u0026quot; ~ cool }} returns \u0026ldquo;cool==True\u0026rdquo; (**args, **kwargs) Callable. You\u0026rsquo;ve seen this used when we called class method  Math You\u0026rsquo;ll have full access to all of the Python math operators in Jinja. Not particularly useful but there if you need them.\nTemplate filters Jinja comes with a bunch of useful template filters which can be compared to funtions that take an argument or aguments and return a value or set of values.\nWe\u0026rsquo;re only going to show a few in this example, but a full list of built in filters can be found here\nThe syntax for using filters is {{ object|filter }}\nWe\u0026rsquo;ll use the length filter to return the length of a list:\napp/app/templates/public/jinja.html\n\u0026lt;h4\u0026gt;Built in filters (length)\u0026lt;/h4\u0026gt; \u0026lt;hr\u0026gt; \u0026lt;p\u0026gt;{{ langs|length }}\u0026lt;/p\u0026gt;  We can also use filters in conjunction with conditionals, for example:\napp/app/templates/public/jinja.html\n\u0026lt;h4\u0026gt;Filters \u0026amp; conditionals\u0026lt;/h4\u0026gt; \u0026lt;hr\u0026gt; {% if langs|length \u0026gt; 2 %} {% for lang in langs %} {% if lang == \u0026quot;Python\u0026quot; %} \u0026lt;p\u0026gt;{{ lang|upper }}\u0026lt;/p\u0026gt; {% else %} \u0026lt;p\u0026gt;{{ lang|reverse }}\u0026lt;/p\u0026gt; {% endif %} {% endfor %} {% endif %}   Tip - You can nest loops and conditionals just like in Python. Be sure to close the conditional or loop with an {% endif %} or {% endfor %} respectively\n The upper filter will capitalize the string we pass to it whilst the reverse filter will return a reversed string.\nBe sure to read the Jinja docs for a full list of built in filters, they\u0026rsquo;re incredibly useful\nOne of the filters I find myself using a lot is the join filter. Let\u0026rsquo;s join our langs list into a single string:\napp/app/templates/public/jinja.html\n\u0026lt;h4\u0026gt;Join filter\u0026lt;/h4\u0026gt; \u0026lt;hr\u0026gt; \u0026lt;p\u0026gt;Unjoined: {{ langs }}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;Joined: {{ langs|join(\u0026quot;, \u0026quot;) }}\u0026lt;/p\u0026gt;  Custom filters Flask provides us a convenient way to build our own custom template filters.\nLet\u0026rsquo;s create a filter that takes a datetime object and returns a nicely formatted string.\nOpen up views.py and add follow along.\nFirst, we need to import the datetime library\napp/app/views.py\nfrom datetime import datetime\nLet\u0026rsquo;s create a datetime variable in our jinja view and pass it to render_template:\napp/app/views.py\ndate = datetime.utcnow() return render_template( \u0026quot;public/jinja.html\u0026quot;, my_name=my_name, my_age=my_age, langs=langs, friends=friends, colors=colors, cool=cool, GitRemote=GitRemote, my_remote=my_remote, repeat=repeat, date=date)  Let\u0026rsquo;s drop our date variable into our jinja.html file and see how it looks without formatting:\napp/app/templates/public/jinja.html\n\u0026lt;h4\u0026gt;Custom filters\u0026lt;/h4\u0026gt; \u0026lt;hr\u0026gt; \u0026lt;p\u0026gt;{{ date }}\u0026lt;/p\u0026gt;  Save and refresh your browser to see the raw datetime object:\n2019-02-06 17:40:58.374084\nLet\u0026rsquo;s create a custom filter and pass our date variable to it. Back in views.py, add the following:\napp/app/views.py\n@app.template_filter(\u0026quot;clean_date\u0026quot;) def clean_date(dt): return dt.strftime(\u0026quot;%d %b %Y\u0026quot;)  We create custom filters by registering them on our app using the @app.template_filter syntax and passing it the name of the filter we want to create.\nWe then pass our object into the function defined below it. It\u0026rsquo;s here we can modify the object and return it back to the template.\nThe great thing about custom template filters is that once defined, we can access them from any template in our app! In this case, we\u0026rsquo;re just formatting the datetime object and returning it as a nicely formatted string.\nGo ahead and save the file and reload the browser to see the changes take effect.\nEscaping Escaping strings is vital in any web application as we simply cannot rely on our users (or ourselves!) to ensure we\u0026rsquo;re not passing in any malicious strings that may get executed by the browser.\nIn Flask, auto escaping IS enabled by default for all templates ending in .html, .htm, .xml and .xhtml when using the render_template function.\nLet\u0026rsquo;s start by looking at when we want to insert some HTML or JavaScript into our template to be executed by the browser. This is not uncommon, in fact, you\u0026rsquo;re looking at it right now!\nLet\u0026rsquo;s create a variable in our jinja route and assign it an HTML string:\napp/app/views.py\nmy_html = \u0026quot;\u0026lt;h1\u0026gt;This is some HTML\u0026lt;/h1\u0026gt;\u0026quot;\nBe sure to pass it to render_template as my_html=my_html\nLet\u0026rsquo;s dump my_html into our jinja.html template:\napp/app/templates/public/jinja.html\n\u0026lt;h4\u0026gt;Escaped\u0026lt;/h4\u0026gt; \u0026lt;hr\u0026gt; {{ my_html }}  Save and reload the page.\nInstinct tell us that the browser is going to parse the HTML and render it as part of our page. However, as Flask enables Jinja escaping by default, we just see a string containing the HTML, rather than the H1 heading we defined.\nLet\u0026rsquo;s escape our my_html variable and make it part of the page with the safe filter:\napp/app/templates/public/jinja.html\n\u0026lt;h4\u0026gt;Marked as safe\u0026lt;/h4\u0026gt; \u0026lt;hr\u0026gt; {{ my_html|safe }}  You\u0026rsquo;ll see a big H1 heading which is now part of our pages actual HTML.\n Tip - Use with caution. Never pipe any values through the safe filter from untrusted sources. Especially from users!\n To illustrate this, let\u0026rsquo;s create a suspicious variables in our jinja view:\napp/app/views.py\nsuspicious = \u0026quot;\u0026lt;script\u0026gt;alert('NEVER TRUST USER INPUT!')\u0026lt;/script\u0026gt;\u0026quot;\nPass the suspicious variable to render_template and add the following to jinja.html:\napp/app/templates/public/jinja.html\n\u0026lt;h4\u0026gt;Suspicious script\u0026lt;/h4\u0026gt; \u0026lt;hr\u0026gt; {{ suspicious|safe }}  Save and refresh your browser to see why cautious use of the safe filter is required! (Don\u0026rsquo;t worry it\u0026rsquo;s safe\u0026hellip; Get it?)\nGo ahead and comment out the last part otherwise you\u0026rsquo;ll have an annoying alert dialogue every time you reload your browser!\nLet\u0026rsquo;s move on to macros.\nmacros Jinja macros are an extremely convenient and useful way to create reusable code within your templates. They\u0026rsquo;re a bit like functions as in we can reuse them over and over again and supply arguments.\nWe define a macro with the following syntax:\n{% macro macro_name(**args, **kwargs) -%} \u0026lt;!-- We then define the code we want as part of our macro --\u0026gt; \u0026lt;!-- We have access to any args \u0026amp; kwargs passed into the macro --\u0026gt; \u0026lt;!-- We access the args and kwargs with the familiar `{{ variable }}` syntax --\u0026gt; {%- endmacro %}   Tip - Pay attention to the dashes in the opening and closing {% macro -%} \u0026amp; {%- endmacro %} tags\n A demonstration is in order!\nSay you\u0026rsquo;ve got a page with lots of input fields, we can create an input macro and pass it arguments which then get rendered within the macro.\nOpen up jinja.html and add the following:\napp/app/templates/public/jinja.html\n{% macro input(label=\u0026quot;\u0026quot;, type=\u0026quot;text\u0026quot;, id=\u0026quot;\u0026quot;, name=\u0026quot;\u0026quot;, placeholder=\u0026quot;\u0026quot;) -%} \u0026lt;div class=\u0026quot;form-group\u0026quot;\u0026gt; \u0026lt;label\u0026gt;{{ label }}\u0026lt;/label\u0026gt; \u0026lt;input type=\u0026quot;{{ type }}\u0026quot; class=\u0026quot;form-control\u0026quot; id=\u0026quot;{{ id }}\u0026quot; name=\u0026quot;{{ name }}\u0026quot; placeholder=\u0026quot;{{ placeholder }}\u0026quot;\u0026gt; \u0026lt;/div\u0026gt; {%- endmacro %}  We\u0026rsquo;ve created an HTML input elemt inside our macro which we can pass arguments to and reuse throughout our template.\n Tip - Notice the default arguments? You can do that with macros!\n Here\u0026rsquo;s the syntax to use a macro in your templates:\n{{ macro_name(**args, **kwargs) }}\nLet\u0026rsquo;s go ahead and use our macro a few times in jinja.html. We\u0026rsquo;ll wrap our macros in a \u0026lt;form\u0026gt; tag:\napp/app/templates/public/jinja.html\n\u0026lt;h4\u0026gt;Macros\u0026lt;/h4\u0026gt; \u0026lt;hr\u0026gt; {% macro input(label=\u0026quot;\u0026quot;, type=\u0026quot;text\u0026quot;, id=\u0026quot;\u0026quot;, name=\u0026quot;\u0026quot;, placeholder=\u0026quot;\u0026quot;) -%} \u0026lt;div class=\u0026quot;form-group\u0026quot;\u0026gt; \u0026lt;label\u0026gt;{{ label }}\u0026lt;/label\u0026gt; \u0026lt;input type=\u0026quot;{{ type }}\u0026quot; class=\u0026quot;form-control\u0026quot; id=\u0026quot;{{ id }}\u0026quot; name=\u0026quot;{{ name }}\u0026quot; placeholder=\u0026quot;{{ placeholder }}\u0026quot;\u0026gt; \u0026lt;/div\u0026gt; {%- endmacro %} \u0026lt;form action=\u0026quot;#\u0026quot; method=\u0026quot;POST\u0026quot;\u0026gt; {{ input(label=\u0026quot;Name\u0026quot;, id=\u0026quot;name\u0026quot;, name=\u0026quot;name\u0026quot;, placeholder=\u0026quot;Enter your name\u0026quot;) }} {{ input(label=\u0026quot;Email\u0026quot;, type=\u0026quot;email\u0026quot;, id=\u0026quot;email\u0026quot;, name=\u0026quot;email\u0026quot;, placeholder=\u0026quot;Enter your email\u0026quot;) }} {{ input(label=\u0026quot;Password\u0026quot;, id=\u0026quot;password\u0026quot;, name=\u0026quot;password\u0026quot;, placeholder=\u0026quot;Enter your password\u0026quot;) }} \u0026lt;/form\u0026gt;  Save and refresh your browser.\nAwesome, we\u0026rsquo;ve got 3 \u0026lt;input\u0026gt; fields all with different labels, types, names, ids and placeholders. Notice how little code we had to white to produce these 3 input fields? That\u0026rsquo;s the power of macros!\nAnother key feature of macros, is being able to import them from other templates, similarly to how you import a Python library.\nLet\u0026rsquo;s create a macros directory at the root of our templates directory and create a new file in there called input_macros.html.\nOpen up input_macros.html and copy and paste the macro we just created:\napp/app/templates/macros/input_macros.html\n{% macro input(label=\u0026quot;\u0026quot;, type=\u0026quot;text\u0026quot;, id=\u0026quot;\u0026quot;, name=\u0026quot;\u0026quot;, placeholder=\u0026quot;\u0026quot;) -%} \u0026lt;div class=\u0026quot;form-group\u0026quot;\u0026gt; \u0026lt;label\u0026gt;{{ label }}\u0026lt;/label\u0026gt; \u0026lt;input type=\u0026quot;{{ type }}\u0026quot; class=\u0026quot;form-control\u0026quot; id=\u0026quot;{{ id }}\u0026quot; name=\u0026quot;{{ name }}\u0026quot; placeholder=\u0026quot;{{ placeholder }}\u0026quot;\u0026gt; \u0026lt;/div\u0026gt; {%- endmacro %}  Save and close the file.\nNow back in jinja.html, we\u0026rsquo;re going to refactor our code to import and use the macro from input_macros.html.\nFirst up, we need to import the template. At the top of jinja.html, just under the {% extends %} tag, add the following:\n{% import \u0026quot;macros/input_macros.html\u0026quot; as im %}\nWe now have full access to any of the macros defined in input_macros.html! Pretty cool right.\nWe just need to refactor our existing macros and get rid of the macro we created in jinja.html just now. Go ahead and delete the macro and change the following:\nfrom this:\napp/app/templates/public/jinja.html\n\u0026lt;form action=\u0026quot;#\u0026quot; method=\u0026quot;POST\u0026quot;\u0026gt; {{ input(label=\u0026quot;Name\u0026quot;, id=\u0026quot;name\u0026quot;, name=\u0026quot;name\u0026quot;, placeholder=\u0026quot;Enter your name\u0026quot;) }} {{ input(label=\u0026quot;Email\u0026quot;, type=\u0026quot;email\u0026quot;, id=\u0026quot;email\u0026quot;, name=\u0026quot;email\u0026quot;, placeholder=\u0026quot;Enter your email\u0026quot;) }} {{ input(label=\u0026quot;Password\u0026quot;, id=\u0026quot;password\u0026quot;, name=\u0026quot;password\u0026quot;, placeholder=\u0026quot;Enter your password\u0026quot;) }} \u0026lt;/form\u0026gt;  To this:\napp/app/templates/public/jinja.html\n\u0026lt;form action=\u0026quot;#\u0026quot; method=\u0026quot;POST\u0026quot;\u0026gt; {{ im.input(label=\u0026quot;Name\u0026quot;, id=\u0026quot;name\u0026quot;, name=\u0026quot;name\u0026quot;, placeholder=\u0026quot;Enter your name\u0026quot;) }} {{ im.input(label=\u0026quot;Email\u0026quot;, type=\u0026quot;email\u0026quot;, id=\u0026quot;email\u0026quot;, name=\u0026quot;email\u0026quot;, placeholder=\u0026quot;Enter your email\u0026quot;) }} {{ im.input(label=\u0026quot;Password\u0026quot;, id=\u0026quot;password\u0026quot;, name=\u0026quot;password\u0026quot;, placeholder=\u0026quot;Enter your password\u0026quot;) }} \u0026lt;/form\u0026gt;  We\u0026rsquo;ve just prepend our macro calls with im after adding {% import \u0026quot;macros/input_macros.html\u0026quot; as im %} at the top of the file.\nWrapping up As you can see, Jinja provides us with some pretty useful tools for creating smart templates in our Flask application (And I can\u0026rsquo;t help but feel I\u0026rsquo;ve only touched the surface!)\nI highly suggest you have a look through the Jinja documentation to grasp even more knowledge of this awesome templating language.\nGetting to grips with Jinja early on can really make a difference. You\u0026rsquo;ll be way more efficient and reduce the amount of boilerplate code you\u0026rsquo;re writing.\nDrop a comment below if you found this guide useful or if you think I missed anything critical. This wasn\u0026rsquo;t designed to be an exhaustive or in depth guide (That\u0026rsquo;s what the docs are for!) But it should give you enough ammo to start designing smarter templates of your own!\nLast modified · 28 Feb 2019\n Source : pythonise.com\n "});index.add({'id':57,'href':'/library/tutorials/docs/python/flask/learning-flask/ep-7/','title':"Ep.7 Working with forms in Flask",'content':" Working with forms in Flask | Learning Flask Ep. 7 Creating forms, posting data to views and working with form data in Flask\nIn this part of the Learning Flask series, You\u0026rsquo;ll learn how to post forms to a Flask view and work with the incoming data.\nForms (or input data in general) play a critical role in any kind of website or web allication as we need a way for the user to communicate with our app!\nIn this example, we\u0026rsquo;ll start with a simple account sign-up form.\nCreating a new route Let\u0026rsquo;s get started by creating a new route in views.py. We\u0026rsquo;ll give it the URL sign-up.\napp/app/views.py\n@app.route(\u0026quot;/sign-up\u0026quot;) def sign_up(): return render_template(\u0026quot;public/sign_up.html\u0026quot;)  We\u0026rsquo;re going to be accepting POST requests on this route so we need to pass another argument to @app.route\nWe do this by passing the methods argument, along with a list of methods as the value.\nFlask supports all of the common HTTP methods including:\n GET POST PUT DELETE  Let\u0026rsquo;s privide our route with the methods argument and a list of methods we want the route to handle:\napp/app/views.py\n@app.route(\u0026quot;/sign-up\u0026quot;, methods=[\u0026quot;GET\u0026quot;, \u0026quot;POST\u0026quot;]) def sign_up(): return render_template(\u0026quot;public/sign_up.html\u0026quot;)   Tip - Flask routes support GET requests by default, however must be declared if the methods argument is provided\n We need to create a new template so go ahead and create a new file called sign_up.html and place it in the templates/public directory.\nOpen up sign_up.html in your editor and add the following:\napp/app/templates/public/sign_up.html\n{% extends \u0026quot;public/templates/public_template.html\u0026quot; %} {% block title %}Sign up{% endblock %} {% block main %} \u0026lt;div class=\u0026quot;container\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col\u0026quot;\u0026gt; \u0026lt;h1\u0026gt;Sign up\u0026lt;/h1\u0026gt; \u0026lt;hr\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {% endblock %}  Save the file and open go to the /sign-up route in your browser. You should see the new page render.\nLet\u0026rsquo;s create a form and add some input fields to our template. We\u0026rsquo;re going to add fields for username, email and pasword. Go ahead and enter the following just under the \u0026lt;hr\u0026gt; tag:\napp/app/templates/public/sign_up.html\n\u0026lt;form action=\u0026quot;/sign-up\u0026quot; method=\u0026quot;POST\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;form-group\u0026quot;\u0026gt; \u0026lt;label\u0026gt;Username\u0026lt;/label\u0026gt; \u0026lt;input type=\u0026quot;text\u0026quot; class=\u0026quot;form-control\u0026quot; id=\u0026quot;username\u0026quot; name=\u0026quot;username\u0026quot; placeholder=\u0026quot;Select a username\u0026quot;\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;form-group\u0026quot;\u0026gt; \u0026lt;label\u0026gt;Email\u0026lt;/label\u0026gt; \u0026lt;input type=\u0026quot;email\u0026quot; class=\u0026quot;form-control\u0026quot; id=\u0026quot;email\u0026quot; name=\u0026quot;email\u0026quot; placeholder=\u0026quot;Enter your email\u0026quot;\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;form-group\u0026quot;\u0026gt; \u0026lt;label\u0026gt;Password\u0026lt;/label\u0026gt; \u0026lt;input type=\u0026quot;password\u0026quot; class=\u0026quot;form-control\u0026quot; id=\u0026quot;password\u0026quot; name=\u0026quot;password\u0026quot; placeholder=\u0026quot;Create a password\u0026quot;\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/form\u0026gt;  Lastly, we need to add a submit button. Add it just befor the closing \u0026lt;/form\u0026gt; tag:\napp/app/templates/public/sign_up.html\n\u0026lt;button type=\u0026quot;submit\u0026quot; class=\u0026quot;btn btn-primary\u0026quot;\u0026gt;Sign up\u0026lt;/button\u0026gt;\nYour template should now look something like this:\napp/app/templates/public/sign_up.html\n{% extends \u0026quot;public/templates/public_template.html\u0026quot; %} {% block title %}Sign up{% endblock %} {% block main %} \u0026lt;div class=\u0026quot;container\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col\u0026quot;\u0026gt; \u0026lt;h1\u0026gt;Sign up\u0026lt;/h1\u0026gt; \u0026lt;hr\u0026gt; \u0026lt;form action=\u0026quot;/sign-up\u0026quot; method=\u0026quot;POST\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;form-group\u0026quot;\u0026gt; \u0026lt;label\u0026gt;Username\u0026lt;/label\u0026gt; \u0026lt;input type=\u0026quot;text\u0026quot; class=\u0026quot;form-control\u0026quot; id=\u0026quot;username\u0026quot; name=\u0026quot;username\u0026quot; placeholder=\u0026quot;Select a username\u0026quot;\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;form-group\u0026quot;\u0026gt; \u0026lt;label\u0026gt;Email\u0026lt;/label\u0026gt; \u0026lt;input type=\u0026quot;email\u0026quot; class=\u0026quot;form-control\u0026quot; id=\u0026quot;email\u0026quot; name=\u0026quot;email\u0026quot; placeholder=\u0026quot;Enter your email\u0026quot;\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;form-group\u0026quot;\u0026gt; \u0026lt;label\u0026gt;Password\u0026lt;/label\u0026gt; \u0026lt;input type=\u0026quot;password\u0026quot; class=\u0026quot;form-control\u0026quot; id=\u0026quot;password\u0026quot; name=\u0026quot;password\u0026quot; placeholder=\u0026quot;Create a password\u0026quot;\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;button type=\u0026quot;submit\u0026quot; class=\u0026quot;btn btn-primary\u0026quot;\u0026gt;Sign up\u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {% endblock %}`   Tip - To access form data in Flask, you must provide the name attribute in each of the forms input tags\n Pay attention to the opening \u0026lt;form\u0026gt; tag.\nWe pass the URL of the route we want to post the form data to in the action attribute of the form. In our case action=\u0026quot;/sign-up\u0026quot;.\nYou\u0026rsquo;ll also need to pass the request method to the method attribute in the opening \u0026lt;form\u0026gt; tag. We\u0026rsquo;ve added method=\u0026quot;POST\u0026quot; because we\u0026rsquo;re POSTing data to the server.\nSave the file and refresh the page to see your form.\nPosting form data to a route Go ahead and hit the submit button and pay attention to your terminal or console. You\u0026rsquo;ll see:\n127.0.0.1 - - [06/Feb/2019 22:00:25] \u0026quot;POST /sign-up HTTP/1.1\u0026quot; 200 -\nPerfect, our form is posting to the sign-up route on our server!\nLet\u0026rsquo;s jump back into views.py and start working with our form data.\nHandling form data Before we can access any of the request data, we need to import request from flask.\nAt the top of views.py, go ahead and import request from flask. We\u0026rsquo;ll also import redirect\napp/app/views.py\nfrom flask import request, redirect`  To access form data in our route, we use request.form.\nLet\u0026rsquo;s capture our incoming form data to a variable called req, but first, we should add a conditional to validate we\u0026rsquo;re receiving POST data.\nWe can do so by testing request.method for the \u0026quot;POST\u0026quot; method:\napp/app/views.py\n@app.route(\u0026quot;/sign-up\u0026quot;, methods=[\u0026quot;GET\u0026quot;, \u0026quot;POST\u0026quot;]) def sign_up(): if request.method == \u0026quot;POST\u0026quot;: req = request.form return redirect(request.url) return render_template(\u0026quot;public/sign_up.html\u0026quot;)`  The redirect function, amongst many other things allows us to redirect the client to different parts our app. We\u0026rsquo;ll be exploring redirect in more detail in a future part of this series.\nIn this case, we\u0026rsquo;re instructing redirect to redirect the client to the URL of the request.\nIf you were to print(type(req)) you\u0026rsquo;ll see that the request.form object a special type called werkzeug.datastructures.ImmutableMultiDict which we can essentially treat it like a dictionary.\nLet\u0026rsquo;s just print(req) and inspect the results.\napp/app/views.py\n@app.route(\u0026quot;/sign-up\u0026quot;, methods=[\u0026quot;GET\u0026quot;, \u0026quot;POST\u0026quot;]) def sign_up(): if request.method == \u0026quot;POST\u0026quot;: req = request.form print(req) return redirect(request.url) return render_template(\u0026quot;public/sign_up.html\u0026quot;)  Depending on whether you supplied any input, you\u0026rsquo;ll see:\nImmutableMultiDict([('username', ''), ('email', ''), ('password', '')])\nWe can treat our req object just like a normal Python dictionary, for example, to access the individual inputs from the form, we can use any of the following:\napp/app/views.py\n@app.route(\u0026quot;/sign-up\u0026quot;, methods=[\u0026quot;GET\u0026quot;, \u0026quot;POST\u0026quot;]) def sign_up(): if request.method == \u0026quot;POST\u0026quot;: req = request.form username = req.get(\u0026quot;username\u0026quot;) email = req[\u0026quot;email\u0026quot;] password = request.form[\u0026quot;password\u0026quot;] # You could also use password = request.form.get(\u0026quot;password\u0026quot;) return redirect(request.url) return render_template(\u0026quot;public/sign_up.html\u0026quot;)`  You could bypass capturing and storing the form data as a variable with the following:\napp/app/views.py\n@app.route(\u0026quot;/sign-up\u0026quot;, methods=[\u0026quot;GET\u0026quot;, \u0026quot;POST\u0026quot;]) def sign_up(): if request.method == \u0026quot;POST\u0026quot;: username = request.form.get(\u0026quot;username\u0026quot;) email = request.form.get(\u0026quot;email\u0026quot;) password = request.form.get(\u0026quot;password\u0026quot;) # Alternatively username = request.form[\u0026quot;username\u0026quot;] email = request.form[\u0026quot;email\u0026quot;] password = request.form[\u0026quot;password\u0026quot;] return redirect(request.url) return render_template(\u0026quot;public/sign_up.html\u0026quot;)  We\u0026rsquo;ve now got each of the form values stored as a Python variable to do as we please.\nValidating form data There\u0026rsquo;s lots of things we could do to validate, however they\u0026rsquo;re very much application specific. Let\u0026rsquo;s keep it simple and just validate that we\u0026rsquo;ve got some data for all 3 fields. We\u0026rsquo;ll cover validating a sign up form later in this series.\nLet\u0026rsquo;s iterate through the keys and values of our req object and look for missing fields, then return a response and message to the user:\napp/app/views.py\n@app.route(\u0026quot;/sign-up\u0026quot;, methods=[\u0026quot;GET\u0026quot;, \u0026quot;POST\u0026quot;]) def sign_up(): if request.method == \u0026quot;POST\u0026quot;: req = request.form missing = list() for k, v in req.items(): if v == \u0026quot;\u0026quot;: missing.append(k) if missing: feedback = f\u0026quot;Missing fields for {', '.join(missing)}\u0026quot; return render_template(\u0026quot;public/sign_up.html\u0026quot;, feedback=feedback) return redirect(request.url) return render_template(\u0026quot;public/sign_up.html\u0026quot;)`  We\u0026rsquo;ll add a message in sign_up.html to give some feedback to the user. Open up sign_up.html and add the following just under the \u0026lt;button\u0026gt; tag inside the form:\napp/app/templates/public/sign_up.html\n{% if feedback %} \u0026lt;p class=\u0026quot;text-danger float-right\u0026quot;\u0026gt;{{ feedback }}\u0026lt;/p\u0026gt; {% endif %}`  Save and close the file.\nRefresh your browser and submit an empty form. You should see the error message appear to the bottom right of the form. When you submit values for all 3 fields, the feedback message doesn\u0026rsquo;t appear.\nWe could use the required attribute in the HTML form and let the browser do the validation for us but that\u0026rsquo;s not much fun is it. And besides, this series is about Flask!\nIn the next part, you\u0026rsquo;ll be learning about dynamic URL\u0026rsquo;s\nLast modified · 28 Feb 2019\n Written with StackEdit.\n "});index.add({'id':58,'href':'/library/tutorials/docs/python/flask/learning-flask/ep-8/','title':"Ep.8 Generating dynamic URLs in Flask",'content':" Generating dynamic URLs in Flask | Learning Flask Ep. 8 Learn how to create and work with dynamic URLs and dynamic data in Flask\nDynamic URL\u0026rsquo;s in Flask play an important role in the ability to create unique URL\u0026rsquo;s that aren\u0026rsquo;t hard-coded into our application.\nFor example, let\u0026rsquo;s say our application allows users to create an account and log into their profile, we\u0026rsquo;ll need a way to dynamically generate a route for that specific user.\nCan you imagine hard coding a unique URL for each and every user of your application?!\nLet\u0026rsquo;s dive in and learn how we can generate dynamic URL\u0026rsquo;s in Flask.\ncreating a dynamic route First up, let\u0026rsquo;s create a new route in out app. We\u0026rsquo;re going to give it the URL /profile:\napp/app/views.py\n@app.route(\u0026quot;/profile\u0026quot;) def profile(): return render_template(\u0026quot;public/profile.html\u0026quot;)  We\u0026rsquo;ll also create a new template for this route. Go ahead and create a file named profile.html in the templates/public directory (Or whatever directory contains your HTML files)\nLet\u0026rsquo;s just create a simple page for now:\napp/app/templates/public/dynamic.html\n{% extends \u0026quot;public/templates/public_template.html\u0026quot; %} {% block title %}Profile{% endblock %} {% block main %} \u0026lt;div class=\u0026quot;container\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col\u0026quot;\u0026gt; \u0026lt;h1\u0026gt;Profile\u0026lt;/h1\u0026gt; \u0026lt;hr\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {% endblock %}   Tip - We\u0026rsquo;re using the Bootstrap CSS library but feel free to use your own or leave it out completely\n As it is, our new route isn\u0026rsquo;t dynamic. We need to make some tweaks to the URL we\u0026rsquo;ve provided in out @app.route decorator.\nGo ahead and make the following changes to the @app.route URL:\napp/app/views.py\n@app.route(\u0026quot;/profile/\u0026lt;username\u0026gt;\u0026quot;)   We\u0026rsquo;ve added trailing slash to /profile/ We\u0026rsquo;ve provided a variable in the URL path and wrapped in with two opposing arrows \u0026lt;\u0026gt; as shown.  Essentially, we\u0026rsquo;re expecting some sort of value to be passed into the URL after /profile/. We\u0026rsquo;re then capturing that data as a variable called username.\nJust remember, to catch a a value in the URL and store it as a variable it must look \u0026lt;like_this\u0026gt; and follow a trailing slash.\nBefore we can work with the username data, we need to pass it into the routes function as an argument:\napp/app/views.py\ndef profile(username):\nWe now have access to the username variable and its data.\nFor clarity, our route now looks like this:\napp/app/views.py\n@app.route(\u0026quot;/profile/\u0026lt;username\u0026gt;\u0026quot;) def profile(username): return render_template(\u0026quot;public/profile.html\u0026quot;)  At this point, if you try to access the /profile route in your browser, Flask will throw an error because the profile function is expecting an value!\n Tip - Trailing slashes matter in Flask. If you try to access a route that\u0026rsquo;s not defined with a trailing slash in the URL, you\u0026rsquo;ll get an error.\n Capturing URL variables Go to /profile/x in your browser. You\u0026rsquo;ll see Flask returns our new profile.html page and displays /profile/x in the browser URL address bar.\nWe can now work with data that comes into our app from the URL! Let\u0026rsquo;s create a dictionary containing a few usernames and some information about our users.\nWe\u0026rsquo;ll search the dictonary for the username variable and return some basic information about that user. Let\u0026rsquo;s create our users dictionary:\napp/app/views.py\nusers = { \u0026quot;mitsuhiko\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;Armin Ronacher\u0026quot;, \u0026quot;bio\u0026quot;: \u0026quot;Creatof of the Flask framework\u0026quot;, \u0026quot;twitter_handle\u0026quot;: \u0026quot;@mitsuhiko\u0026quot; }, \u0026quot;gvanrossum\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;Guido Van Rossum\u0026quot;, \u0026quot;bio\u0026quot;: \u0026quot;Creator of the Python programming language\u0026quot;, \u0026quot;twitter_handle\u0026quot;: \u0026quot;@gvanrossum\u0026quot; }, \u0026quot;elonmusk\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;Elon Musk\u0026quot;, \u0026quot;bio\u0026quot;: \u0026quot;technology entrepreneur, investor, and engineer\u0026quot;, \u0026quot;twitter_handle\u0026quot;: \u0026quot;@elonmusk\u0026quot; } }  We\u0026rsquo;ll add some logic to our profile route to look up the user and return their information:\napp/app/views.py\n@app.route(\u0026quot;/profile/\u0026lt;username\u0026gt;\u0026quot;) def profile(username): user = None if username in users: user = users[username] return render_template(\u0026quot;public/profile.html\u0026quot;, username=username, user=user)  Lastly, let\u0026rsquo;s refactor our profile.html to display our user information:\napp/app/templates/public/dynamic.html\n{% extends \u0026quot;public/templates/public_template.html\u0026quot; %} {% block title %}Profile{% endblock %} {% block main %} \u0026lt;div class=\u0026quot;container\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col\u0026quot;\u0026gt; \u0026lt;h1\u0026gt;Profile\u0026lt;/h1\u0026gt; \u0026lt;hr\u0026gt; \u0026lt;div class=\u0026quot;card\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;card-body\u0026quot;\u0026gt; {% if user %} \u0026lt;h5 class=\u0026quot;card-title\u0026quot;\u0026gt;{{ username }}\u0026lt;/h5\u0026gt; \u0026lt;hr\u0026gt; \u0026lt;p\u0026gt;\u0026lt;strong\u0026gt;{{ user[\u0026quot;name\u0026quot;] }}\u0026lt;/strong\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;p style=\u0026quot;color: blue\u0026quot;\u0026gt;{{ user[\u0026quot;twitter_handle\u0026quot;] }}\u0026lt;/p\u0026gt; \u0026lt;p class=\u0026quot;text-muted\u0026quot;\u0026gt;{{ user[\u0026quot;bio\u0026quot;] }}\u0026lt;/p\u0026gt; {% else %} \u0026lt;p\u0026gt;User {{ username }} not found\u0026lt;/p\u0026gt; {% endif %} \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {% endblock %}  Requesting a dynamic route Save the files and head to /profile/mitsuhiko or any of the other usernames in your browser to see their profile!\nAlso, try a name that\u0026rsquo;s not in our dictionary to see how we\u0026rsquo;ve handled that with a simple {% if user %} statement in our template.\nDynamic URL\u0026rsquo;s aren\u0026rsquo;t just limited to one variable. Let\u0026rsquo;s stack some more veriables to capture in our URL string.\nMultiple URL variables In our first example, we created the profile route to expect only one variable in the URL. However, we can add as many as we like.\nLet\u0026rsquo;s create a new route with multiple variables that just prints the variables and returns a simple string to the client:\napp/app/views.py\n@app.route(\u0026quot;/multiple/\u0026lt;foo\u0026gt;/\u0026lt;bar\u0026gt;/\u0026lt;baz\u0026gt;\u0026quot;) def multiple(foo, bar, baz): print(f\u0026quot;foo is {foo}\u0026quot;) print(f\u0026quot;bar is {bar}\u0026quot;) print(f\u0026quot;baz is {baz}\u0026quot;) return f\u0026quot;foo is {foo}, bar is {bar}, baz is {baz}\u0026quot;  Go to /multiple/foo/bar/baz in your browser, you\u0026rsquo;ll see:\nfoo is foo, bar is bar, baz is baz\nAs you can see, we have full access to the variables captured in the URL and passed into our function!\nIn the next part of this series, we\u0026rsquo;ll be covering how to work with query strings in Flask.\nLast modified · 28 Feb 2019\n Written with StackEdit.\n "});index.add({'id':59,'href':'/library/tutorials/docs/python/flask/learning-flask/ep-9/','title':"Ep.9 Working with JSON data",'content':" Working with JSON data | Learning Flask Ep. 9 Handle incoming, parsing and returning JSON data with Flask!\nIn this part of the \u0026ldquo;Learning Flask\u0026rdquo; series, we\u0026rsquo;re going to be working with JSON data.\nJSON is an extremely popular format for sending and receiving data over the web. Flask provides us with some great tools to make light work of handling JSON data.\nIn this guide, we\u0026rsquo;re going to quickly cover how to handle incoming JSON data and return JSON data to the client.\nHandling JSON Let\u0026rsquo;s start out with a new route. This route will receive some JSON, parse the data, do some validation and return a new JSON response.\napp/app/views.py\n@app.route(\u0026quot;/json\u0026quot;) def json_example(): return \u0026quot;Thanks!\u0026quot;  We\u0026rsquo;re going to be POSTing data to the server so we need to pass the methods argument to the @app.route() decorator, along with the HTTP methods we want to allow for this route:\napp/app/views.py\n@app.route(\u0026quot;/json\u0026quot;, methods=[\u0026quot;POST\u0026quot;]) def json_example(): return \u0026quot;Thanks!\u0026quot;  Working with any kind of request in Flask requires importing the request object. Go ahead and import it:\napp/app/views.py\nfrom flask import request  Now we need a method to handle the incoming JSON. Flask provides the handy request.get_json() method, which parses any incoming JSON data into a Python dictionary.\nLet\u0026rsquo;s store our incoming JSON data in a variable called req and print it out to the terminal:\napp/app/views.py\n@app.route(\u0026quot;/json\u0026quot;, methods=[\u0026quot;POST\u0026quot;]) def json_example(): req = request.get_json() print(req) return \u0026quot;Thanks!\u0026quot;  Whilst we\u0026rsquo;re here, let\u0026rsquo;s explicitly set an HTTP response by passing it to return:\napp/app/views.py\n@app.route(\u0026quot;/json\u0026quot;, methods=[\u0026quot;POST\u0026quot;]) def json_example(): req = request.get_json() print(req) return \u0026quot;Thanks!\u0026quot;, 200  POSTing JSON Let\u0026rsquo;s post some data to our route!\n Tip - We\u0026rsquo;re going to use the free Postman app to make our requests, however, feel free to use an alternative such as curl or write a JavaScript function and call it from the browser (You\u0026rsquo;ll learn how to do this in the next episode!)\n Go ahead and create a new POST request to the following URL:\nPostman URL\nhttp://127.0.0.1:5000/json\nWe need to create some JSON data in the body of our request. Go ahead and click the raw tab and select JSON (application/json) from the dropdown list on the right.\nLet\u0026rsquo;s just create a simple JSON object with 2 fields for now:\nPostman body\n{ \u0026quot;name\u0026quot;: \u0026quot;Julian\u0026quot;, \u0026quot;message\u0026quot;: \u0026quot;Posting JSON data to Flask!\u0026quot; }\nIf you\u0026rsquo;re using cURL:\ncURL request\ncurl --header \u0026quot;Content-Type: application/json\u0026quot; --request POST --data '{\u0026quot;name\u0026quot;:\u0026quot;Julian\u0026quot;,\u0026quot;message\u0026quot;:\u0026quot;Posting JSON data to Flask!\u0026quot;}' http://127.0.0.1:5000/json\nGo ahead and click the Send button and look at the bottom of the app for the response body.\nYou\u0026rsquo;ll see:\nPostman response body\nThanks!\nNow take a look in your terminal, you\u0026rsquo;ll see:\nTerminal\n{'name': 'Julian', 'message': 'Posting JSON data to Flask!'}\nAwesome, We\u0026rsquo;ve posted some JSON data to Flask and received a response. You\u0026rsquo;ll also notice the response status at the bottom of the Postman app with 200 OK. Just as we told our route to do!\nParsing incoming JSON We know using the get_json() method on the request object will return a Python dictionary with our JSON fields serielized into key/value pairs.\nWe can also validate and perform some conditional testing on our incoming request to determine if the body contains JSON data or not using the is_json check provided by Flask.\nLet\u0026rsquo;s check that our response is JSON and return a response depending on what we receive:\napp/app/views.py\n@app.route(\u0026quot;/json\u0026quot;, methods=[\u0026quot;POST\u0026quot;]) def json_example(): # Validate the request body contains JSON if request.is_json: # Parse the JSON into a Python dictionary req = request.get_json() # Print the dictionary print(req) # Return a string along with an HTTP status code return \u0026quot;JSON received!\u0026quot;, 200 else: # The request body wasn't JSON so return a 400 HTTP status code return \u0026quot;Request was not JSON\u0026quot;, 400  We perform a conditional check using the if statement on the incoming request object to determine if the request body contains JSON or not.\nIf the request contains JSON, we\u0026rsquo;re printing it and returning the JSON received! string along with a 200 status code to indicate a successful transaction.\nIf the request body doesn\u0026rsquo;t contain JSON, we\u0026rsquo;re returning Request was not JSON along with a 400 HTTP status code to let the client know there was a bad request.\nGo ahead and make another POST request in the Postman app to see the updates JSON received! response.\nPostman response body\nJSON received!\nNow, change the dropdown menu in the Postman app from JSON (applicationjson) to text and click send to see the Request was not JSON message in the response, along with the 400 BAD REQUEST error.\nPostman response body\nRequest was not JSON\nAlright! So now you know how to handle incoming JSON. Let\u0026rsquo;s go ahead and return some!\nReturning JSON Again, Flask makes returning JSON a breeze using the the built in jsonify and make_response functions.\nLet\u0026rsquo;s go ahead and import them:\napp/app/views.py\nfrom flask import jsonify, make_response\nLet\u0026rsquo;s refactor our /json route to use jsonify and make_response. We\u0026rsquo;ll discuss them after:\napp/app/views.py\n@app.route(\u0026quot;/json\u0026quot;, methods=[\u0026quot;POST\u0026quot;]) def json_example(): if request.is_json: req = request.get_json() response_body = { \u0026quot;message\u0026quot;: \u0026quot;JSON received!\u0026quot;, \u0026quot;sender\u0026quot;: req.get(\u0026quot;name\u0026quot;) } res = make_response(jsonify(response_body), 200) return res else: return make_response(jsonify({\u0026quot;message\u0026quot;: \u0026quot;Request body must be JSON\u0026quot;}), 400)  We\u0026rsquo;ve created a new response_body object using a dictionary and passed it some values.\nWe then use the make_response() function to prepare a response, to which we\u0026rsquo;ve provided 2 arguments:\n jsonify(*args, **kwargs) wraps Python\u0026rsquo;s own json.dumps() method and will serialize Python strings, lists or dicts as a JSON string. 200 is the HTTP status code we want to return.   Tip - jsonify(1, 2, 3) and jsonify([1, 2, 3]) will both serialize to [1, 2, 3]\n By passing both of these arguments to the make_response() function, we can create our response ahead of returning it by storing it as a variable. In our case, the res variable.\nWe\u0026rsquo;ve also done the same under the else conditional, just with it all on one line to save some space.\nGo ahead and repeat the same process in the Postman app or cURL to see the newly formatted responses.\nPosting JSON (application/json) will return:\nPostman response body\n{ \u0026quot;message\u0026quot;: \u0026quot;JSON received!\u0026quot;, \u0026quot;sender\u0026quot;: \u0026quot;Julian\u0026quot; }  Changing the dropdown to Text and posting will return:\nPostman response body\n{ \u0026quot;message\u0026quot;: \u0026quot;Request body must be JSON\u0026quot; }  Wrapping up Flask makes working with JSON easy, providing many useful functions and methods such as is_json, get_json() and jsonify(), along with helpful functions such as make_response(). Creating API\u0026rsquo;s, webhooks and handling JSON is only a few lines of code away!\nLast modified · 28 Feb 2019\n Written with StackEdit.\n "});index.add({'id':60,'href':'/library/tutorials/posts/creating-a-new-theme/','title':"Creating a New Theme",'content':" Introduction This tutorial will show you how to create a simple theme in Hugo. I assume that you are familiar with HTML, the bash command line, and that you are comfortable using Markdown to format content. I\u0026rsquo;ll explain how Hugo uses templates and how you can organize your templates to create a theme. I won\u0026rsquo;t cover using CSS to style your theme.\nWe\u0026rsquo;ll start with creating a new site with a very basic template. Then we\u0026rsquo;ll add in a few pages and posts. With small variations on that, you will be able to create many different types of web sites.\nIn this tutorial, commands that you enter will start with the \u0026ldquo;$\u0026rdquo; prompt. The output will follow. Lines that start with \u0026ldquo;#\u0026rdquo; are comments that I\u0026rsquo;ve added to explain a point. When I show updates to a file, the \u0026ldquo;:wq\u0026rdquo; on the last line means to save the file.\nHere\u0026rsquo;s an example:\n## this is a comment $ echo this is a command this is a command ## edit the file $ vi foo.md +++ date = \u0026quot;2014-09-28\u0026quot; title = \u0026quot;creating a new theme\u0026quot; +++ bah and humbug :wq ## show it $ cat foo.md +++ date = \u0026quot;2014-09-28\u0026quot; title = \u0026quot;creating a new theme\u0026quot; +++ bah and humbug $  Some Definitions There are a few concepts that you need to understand before creating a theme.\nSkins Skins are the files responsible for the look and feel of your site. It’s the CSS that controls colors and fonts, it’s the Javascript that determines actions and reactions. It’s also the rules that Hugo uses to transform your content into the HTML that the site will serve to visitors.\nYou have two ways to create a skin. The simplest way is to create it in the layouts/ directory. If you do, then you don’t have to worry about configuring Hugo to recognize it. The first place that Hugo will look for rules and files is in the layouts/ directory so it will always find the skin.\nYour second choice is to create it in a sub-directory of the themes/ directory. If you do, then you must always tell Hugo where to search for the skin. It’s extra work, though, so why bother with it?\nThe difference between creating a skin in layouts/ and creating it in themes/ is very subtle. A skin in layouts/ can’t be customized without updating the templates and static files that it is built from. A skin created in themes/, on the other hand, can be and that makes it easier for other people to use it.\nThe rest of this tutorial will call a skin created in the themes/ directory a theme.\nNote that you can use this tutorial to create a skin in the layouts/ directory if you wish to. The main difference will be that you won’t need to update the site’s configuration file to use a theme.\nThe Home Page The home page, or landing page, is the first page that many visitors to a site see. It is the index.html file in the root directory of the web site. Since Hugo writes files to the public/ directory, our home page is public/index.html.\nSite Configuration File When Hugo runs, it looks for a configuration file that contains settings that override default values for the entire site. The file can use TOML, YAML, or JSON. I prefer to use TOML for my configuration files. If you prefer to use JSON or YAML, you’ll need to translate my examples. You’ll also need to change the name of the file since Hugo uses the extension to determine how to process it.\nHugo translates Markdown files into HTML. By default, Hugo expects to find Markdown files in your content/ directory and template files in your themes/ directory. It will create HTML files in your public/ directory. You can change this by specifying alternate locations in the configuration file.\nContent Content is stored in text files that contain two sections. The first section is the “front matter,” which is the meta-information on the content. The second section contains Markdown that will be converted to HTML.\nFront Matter The front matter is information about the content. Like the configuration file, it can be written in TOML, YAML, or JSON. Unlike the configuration file, Hugo doesn’t use the file’s extension to know the format. It looks for markers to signal the type. TOML is surrounded by “+++”, YAML by “---”, and JSON is enclosed in curly braces. I prefer to use TOML, so you’ll need to translate my examples if you prefer YAML or JSON.\nThe information in the front matter is passed into the template before the content is rendered into HTML.\nMarkdown Content is written in Markdown which makes it easier to create the content. Hugo runs the content through a Markdown engine to create the HTML which will be written to the output file.\nTemplate Files Hugo uses template files to render content into HTML. Template files are a bridge between the content and presentation. Rules in the template define what content is published, where it\u0026rsquo;s published to, and how it will rendered to the HTML file. The template guides the presentation by specifying the style to use.\nThere are three types of templates: single, list, and partial. Each type takes a bit of content as input and transforms it based on the commands in the template.\nHugo uses its knowledge of the content to find the template file used to render the content. If it can’t find a template that is an exact match for the content, it will shift up a level and search from there. It will continue to do so until it finds a matching template or runs out of templates to try. If it can’t find a template, it will use the default template for the site.\nPlease note that you can use the front matter to influence Hugo’s choice of templates.\nSingle Template A single template is used to render a single piece of content. For example, an article or post would be a single piece of content and use a single template.\nList Template A list template renders a group of related content. That could be a summary of recent postings or all articles in a category. List templates can contain multiple groups.\nThe homepage template is a special type of list template. Hugo assumes that the home page of your site will act as the portal for the rest of the content in the site.\nPartial Template A partial template is a template that can be included in other templates. Partial templates must be called using the “partial” template command. They are very handy for rolling up common behavior. For example, your site may have a banner that all pages use. Instead of copying the text of the banner into every single and list template, you could create a partial with the banner in it. That way if you decide to change the banner, you only have to change the partial template.\nCreate a New Site Let\u0026rsquo;s use Hugo to create a new web site. I\u0026rsquo;m a Mac user, so I\u0026rsquo;ll create mine in my home directory, in the Sites folder. If you\u0026rsquo;re using Linux, you might have to create the folder first.\nThe \u0026ldquo;new site\u0026rdquo; command will create a skeleton of a site. It will give you the basic directory structure and a useable configuration file.\n$ hugo new site ~/Sites/zafta $ cd ~/Sites/zafta $ ls -l total 8 drwxr-xr-x 7 quoha staff 238 Sep 29 16:49 . drwxr-xr-x 3 quoha staff 102 Sep 29 16:49 .. drwxr-xr-x 2 quoha staff 68 Sep 29 16:49 archetypes -rw-r--r-- 1 quoha staff 82 Sep 29 16:49 config.toml drwxr-xr-x 2 quoha staff 68 Sep 29 16:49 content drwxr-xr-x 2 quoha staff 68 Sep 29 16:49 layouts drwxr-xr-x 2 quoha staff 68 Sep 29 16:49 static $  Take a look in the content/ directory to confirm that it is empty.\nThe other directories (archetypes/, layouts/, and static/) are used when customizing a theme. That\u0026rsquo;s a topic for a different tutorial, so please ignore them for now.\nGenerate the HTML For the New Site Running the hugo command with no options will read all the available content and generate the HTML files. It will also copy all static files (that\u0026rsquo;s everything that\u0026rsquo;s not content). Since we have an empty site, it won\u0026rsquo;t do much, but it will do it very quickly.\n$ hugo --verbose INFO: 2014/09/29 Using config file: config.toml INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/static/ to /Users/quoha/Sites/zafta/public/ WARN: 2014/09/29 Unable to locate layout: [index.html _default/list.html _default/single.html] WARN: 2014/09/29 Unable to locate layout: [404.html] 0 draft content 0 future content 0 pages created 0 tags created 0 categories created in 2 ms $  The \u0026ldquo;--verbose\u0026rdquo; flag gives extra information that will be helpful when we build the template. Every line of the output that starts with \u0026ldquo;INFO:\u0026rdquo; or \u0026ldquo;WARN:\u0026rdquo; is present because we used that flag. The lines that start with \u0026ldquo;WARN:\u0026rdquo; are warning messages. We\u0026rsquo;ll go over them later.\nWe can verify that the command worked by looking at the directory again.\n$ ls -l total 8 drwxr-xr-x 2 quoha staff 68 Sep 29 16:49 archetypes -rw-r--r-- 1 quoha staff 82 Sep 29 16:49 config.toml drwxr-xr-x 2 quoha staff 68 Sep 29 16:49 content drwxr-xr-x 2 quoha staff 68 Sep 29 16:49 layouts drwxr-xr-x 4 quoha staff 136 Sep 29 17:02 public drwxr-xr-x 2 quoha staff 68 Sep 29 16:49 static $  See that new public/ directory? Hugo placed all generated content there. When you\u0026rsquo;re ready to publish your web site, that\u0026rsquo;s the place to start. For now, though, let\u0026rsquo;s just confirm that we have what we\u0026rsquo;d expect from a site with no content.\n$ ls -l public total 16 -rw-r--r-- 1 quoha staff 416 Sep 29 17:02 index.xml -rw-r--r-- 1 quoha staff 262 Sep 29 17:02 sitemap.xml $  Hugo created two XML files, which is standard, but there are no HTML files.\nTest the New Site Verify that you can run the built-in web server. It will dramatically shorten your development cycle if you do. Start it by running the \u0026ldquo;server\u0026rdquo; command. If it is successful, you will see output similar to the following:\n$ hugo server --verbose INFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/static/ to /Users/quoha/Sites/zafta/public/ WARN: 2014/09/29 Unable to locate layout: [index.html _default/list.html _default/single.html] WARN: 2014/09/29 Unable to locate layout: [404.html] 0 draft content 0 future content 0 pages created 0 tags created 0 categories created in 2 ms Serving pages from /Users/quoha/Sites/zafta/public Web Server is available at http://localhost:1313 Press Ctrl+C to stop  Connect to the listed URL (it\u0026rsquo;s on the line that starts with \u0026ldquo;Web Server\u0026rdquo;). If everything is working correctly, you should get a page that shows the following:\nindex.xml sitemap.xml  That\u0026rsquo;s a listing of your public/ directory. Hugo didn\u0026rsquo;t create a home page because our site has no content. When there\u0026rsquo;s no index.html file in a directory, the server lists the files in the directory, which is what you should see in your browser.\nLet’s go back and look at those warnings again.\nWARN: 2014/09/29 Unable to locate layout: [index.html _default/list.html _default/single.html] WARN: 2014/09/29 Unable to locate layout: [404.html]  That second warning is easier to explain. We haven’t created a template to be used to generate “page not found errors.” The 404 message is a topic for a separate tutorial.\nNow for the first warning. It is for the home page. You can tell because the first layout that it looked for was “index.html.” That’s only used by the home page.\nI like that the verbose flag causes Hugo to list the files that it\u0026rsquo;s searching for. For the home page, they are index.html, _default/list.html, and _default/single.html. There are some rules that we\u0026rsquo;ll cover later that explain the names and paths. For now, just remember that Hugo couldn\u0026rsquo;t find a template for the home page and it told you so.\nAt this point, you\u0026rsquo;ve got a working installation and site that we can build upon. All that’s left is to add some content and a theme to display it.\nCreate a New Theme Hugo doesn\u0026rsquo;t ship with a default theme. There are a few available (I counted a dozen when I first installed Hugo) and Hugo comes with a command to create new themes.\nWe\u0026rsquo;re going to create a new theme called \u0026ldquo;zafta.\u0026rdquo; Since the goal of this tutorial is to show you how to fill out the files to pull in your content, the theme will not contain any CSS. In other words, ugly but functional.\nAll themes have opinions on content and layout. For example, Zafta uses \u0026ldquo;post\u0026rdquo; over \u0026ldquo;blog\u0026rdquo;. Strong opinions make for simpler templates but differing opinions make it tougher to use themes. When you build a theme, consider using the terms that other themes do.\nCreate a Skeleton Use the hugo \u0026ldquo;new\u0026rdquo; command to create the skeleton of a theme. This creates the directory structure and places empty files for you to fill out.\n$ hugo new theme zafta $ ls -l total 8 drwxr-xr-x 2 quoha staff 68 Sep 29 16:49 archetypes -rw-r--r-- 1 quoha staff 82 Sep 29 16:49 config.toml drwxr-xr-x 2 quoha staff 68 Sep 29 16:49 content drwxr-xr-x 2 quoha staff 68 Sep 29 16:49 layouts drwxr-xr-x 4 quoha staff 136 Sep 29 17:02 public drwxr-xr-x 2 quoha staff 68 Sep 29 16:49 static drwxr-xr-x 3 quoha staff 102 Sep 29 17:31 themes $ find themes -type f | xargs ls -l -rw-r--r-- 1 quoha staff 1081 Sep 29 17:31 themes/zafta/LICENSE.md -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/archetypes/default.md -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/_default/list.html -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/_default/single.html -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/index.html -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/partials/footer.html -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/partials/header.html -rw-r--r-- 1 quoha staff 93 Sep 29 17:31 themes/zafta/theme.toml $  The skeleton includes templates (the files ending in .html), license file, a description of your theme (the theme.toml file), and an empty archetype.\nPlease take a minute to fill out the theme.toml and LICENSE.md files. They\u0026rsquo;re optional, but if you\u0026rsquo;re going to be distributing your theme, it tells the world who to praise (or blame). It\u0026rsquo;s also nice to declare the license so that people will know how they can use the theme.\n$ vi themes/zafta/theme.toml author = \u0026quot;michael d henderson\u0026quot; description = \u0026quot;a minimal working template\u0026quot; license = \u0026quot;MIT\u0026quot; name = \u0026quot;zafta\u0026quot; source_repo = \u0026quot;\u0026quot; tags = [\u0026quot;tags\u0026quot;, \u0026quot;categories\u0026quot;] :wq ## also edit themes/zafta/LICENSE.md and change ## the bit that says \u0026quot;YOUR_NAME_HERE\u0026quot;  Note that the the skeleton\u0026rsquo;s template files are empty. Don\u0026rsquo;t worry, we\u0026rsquo;ll be changing that shortly.\n$ find themes/zafta -name '*.html' | xargs ls -l -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/_default/list.html -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/_default/single.html -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/index.html -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/partials/footer.html -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/partials/header.html $  Update the Configuration File to Use the Theme Now that we\u0026rsquo;ve got a theme to work with, it\u0026rsquo;s a good idea to add the theme name to the configuration file. This is optional, because you can always add \u0026ldquo;-t zafta\u0026rdquo; on all your commands. I like to put it the configuration file because I like shorter command lines. If you don\u0026rsquo;t put it in the configuration file or specify it on the command line, you won\u0026rsquo;t use the template that you\u0026rsquo;re expecting to.\nEdit the file to add the theme, add a title for the site, and specify that all of our content will use the TOML format.\n$ vi config.toml theme = \u0026quot;zafta\u0026quot; baseurl = \u0026quot;\u0026quot; languageCode = \u0026quot;en-us\u0026quot; title = \u0026quot;zafta - totally refreshing\u0026quot; MetaDataFormat = \u0026quot;toml\u0026quot; :wq $  Generate the Site Now that we have an empty theme, let\u0026rsquo;s generate the site again.\n$ hugo --verbose INFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/themes/zafta/static/ to /Users/quoha/Sites/zafta/public/ INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/static/ to /Users/quoha/Sites/zafta/public/ WARN: 2014/09/29 Unable to locate layout: [404.html theme/404.html] 0 draft content 0 future content 0 pages created 0 tags created 0 categories created in 2 ms $  Did you notice that the output is different? The warning message for the home page has disappeared and we have an additional information line saying that Hugo is syncing from the theme\u0026rsquo;s directory.\nLet\u0026rsquo;s check the public/ directory to see what Hugo\u0026rsquo;s created.\n$ ls -l public total 16 drwxr-xr-x 2 quoha staff 68 Sep 29 17:56 css -rw-r--r-- 1 quoha staff 0 Sep 29 17:56 index.html -rw-r--r-- 1 quoha staff 407 Sep 29 17:56 index.xml drwxr-xr-x 2 quoha staff 68 Sep 29 17:56 js -rw-r--r-- 1 quoha staff 243 Sep 29 17:56 sitemap.xml $  Notice four things:\n Hugo created a home page. This is the file public/index.html. Hugo created a css/ directory. Hugo created a js/ directory. Hugo claimed that it created 0 pages. It created a file and copied over static files, but didn\u0026rsquo;t create any pages. That\u0026rsquo;s because it considers a \u0026ldquo;page\u0026rdquo; to be a file created directly from a content file. It doesn\u0026rsquo;t count things like the index.html files that it creates automatically.  The Home Page Hugo supports many different types of templates. The home page is special because it gets its own type of template and its own template file. The file, layouts/index.html, is used to generate the HTML for the home page. The Hugo documentation says that this is the only required template, but that depends. Hugo\u0026rsquo;s warning message shows that it looks for three different templates:\nWARN: 2014/09/29 Unable to locate layout: [index.html _default/list.html _default/single.html]  If it can\u0026rsquo;t find any of these, it completely skips creating the home page. We noticed that when we built the site without having a theme installed.\nWhen Hugo created our theme, it created an empty home page template. Now, when we build the site, Hugo finds the template and uses it to generate the HTML for the home page. Since the template file is empty, the HTML file is empty, too. If the template had any rules in it, then Hugo would have used them to generate the home page.\n$ find . -name index.html | xargs ls -l -rw-r--r-- 1 quoha staff 0 Sep 29 20:21 ./public/index.html -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 ./themes/zafta/layouts/index.html $  The Magic of Static Hugo does two things when generating the site. It uses templates to transform content into HTML and it copies static files into the site. Unlike content, static files are not transformed. They are copied exactly as they are.\nHugo assumes that your site will use both CSS and JavaScript, so it creates directories in your theme to hold them. Remember opinions? Well, Hugo\u0026rsquo;s opinion is that you\u0026rsquo;ll store your CSS in a directory named css/ and your JavaScript in a directory named js/. If you don\u0026rsquo;t like that, you can change the directory names in your theme directory or even delete them completely. Hugo\u0026rsquo;s nice enough to offer its opinion, then behave nicely if you disagree.\n$ find themes/zafta -type d | xargs ls -ld drwxr-xr-x 7 quoha staff 238 Sep 29 17:38 themes/zafta drwxr-xr-x 3 quoha staff 102 Sep 29 17:31 themes/zafta/archetypes drwxr-xr-x 5 quoha staff 170 Sep 29 17:31 themes/zafta/layouts drwxr-xr-x 4 quoha staff 136 Sep 29 17:31 themes/zafta/layouts/_default drwxr-xr-x 4 quoha staff 136 Sep 29 17:31 themes/zafta/layouts/partials drwxr-xr-x 4 quoha staff 136 Sep 29 17:31 themes/zafta/static drwxr-xr-x 2 quoha staff 68 Sep 29 17:31 themes/zafta/static/css drwxr-xr-x 2 quoha staff 68 Sep 29 17:31 themes/zafta/static/js $  The Theme Development Cycle When you\u0026rsquo;re working on a theme, you will make changes in the theme\u0026rsquo;s directory, rebuild the site, and check your changes in the browser. Hugo makes this very easy:\n Purge the public/ directory. Run the built in web server in watch mode. Open your site in a browser. Update the theme. Glance at your browser window to see changes. Return to step 4.  I’ll throw in one more opinion: never work on a theme on a live site. Always work on a copy of your site. Make changes to your theme, test them, then copy them up to your site. For added safety, use a tool like Git to keep a revision history of your content and your theme. Believe me when I say that it is too easy to lose both your mind and your changes.\nCheck the main Hugo site for information on using Git with Hugo.\nPurge the public/ Directory When generating the site, Hugo will create new files and update existing ones in the public/ directory. It will not delete files that are no longer used. For example, files that were created in the wrong directory or with the wrong title will remain. If you leave them, you might get confused by them later. I recommend cleaning out your site prior to generating it.\nNote: If you\u0026rsquo;re building on an SSD, you should ignore this. Churning on a SSD can be costly.\nHugo\u0026rsquo;s Watch Option Hugo\u0026rsquo;s \u0026ldquo;--watch\u0026rdquo; option will monitor the content/ and your theme directories for changes and rebuild the site automatically.\nLive Reload Hugo\u0026rsquo;s built in web server supports live reload. As pages are saved on the server, the browser is told to refresh the page. Usually, this happens faster than you can say, \u0026ldquo;Wow, that\u0026rsquo;s totally amazing.\u0026rdquo;\nDevelopment Commands Use the following commands as the basis for your workflow.\n## purge old files. hugo will recreate the public directory. ## $ rm -rf public ## ## run hugo in watch mode ## $ hugo server --watch --verbose  Here\u0026rsquo;s sample output showing Hugo detecting a change to the template for the home page. Once generated, the web browser automatically reloaded the page. I\u0026rsquo;ve said this before, it\u0026rsquo;s amazing.\n$ rm -rf public $ hugo server --watch --verbose INFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/themes/zafta/static/ to /Users/quoha/Sites/zafta/public/ INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/static/ to /Users/quoha/Sites/zafta/public/ WARN: 2014/09/29 Unable to locate layout: [404.html theme/404.html] 0 draft content 0 future content 0 pages created 0 tags created 0 categories created in 2 ms Watching for changes in /Users/quoha/Sites/zafta/content Serving pages from /Users/quoha/Sites/zafta/public Web Server is available at http://localhost:1313 Press Ctrl+C to stop INFO: 2014/09/29 File System Event: [\u0026quot;/Users/quoha/Sites/zafta/themes/zafta/layouts/index.html\u0026quot;: MODIFY|ATTRIB] Change detected, rebuilding site WARN: 2014/09/29 Unable to locate layout: [404.html theme/404.html] 0 draft content 0 future content 0 pages created 0 tags created 0 categories created in 1 ms  Update the Home Page Template The home page is one of a few special pages that Hugo creates automatically. As mentioned earlier, it looks for one of three files in the theme\u0026rsquo;s layout/ directory:\n index.html _default/list.html _default/single.html  We could update one of the default templates, but a good design decision is to update the most specific template available. That\u0026rsquo;s not a hard and fast rule (in fact, we\u0026rsquo;ll break it a few times in this tutorial), but it is a good generalization.\nMake a Static Home Page Right now, that page is empty because we don\u0026rsquo;t have any content and we don\u0026rsquo;t have any logic in the template. Let\u0026rsquo;s change that by adding some text to the template.\n$ vi themes/zafta/layouts/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;hugo says hello!\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; :wq $  Build the web site and then verify the results.\n$ hugo --verbose INFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/themes/zafta/static/ to /Users/quoha/Sites/zafta/public/ INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/static/ to /Users/quoha/Sites/zafta/public/ WARN: 2014/09/29 Unable to locate layout: [404.html theme/404.html] 0 draft content 0 future content 0 pages created 0 tags created 0 categories created in 2 ms $ find public -type f -name '*.html' | xargs ls -l -rw-r--r-- 1 quoha staff 78 Sep 29 21:26 public/index.html $ cat public/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;hugo says hello!\u0026lt;/p\u0026gt; \u0026lt;/html\u0026gt;  Live Reload Note: If you\u0026rsquo;re running the server with the --watch option, you\u0026rsquo;ll see different content in the file:\n$ cat public/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;hugo says hello!\u0026lt;/p\u0026gt; \u0026lt;script\u0026gt;document.write('\u0026lt;script src=\u0026quot;http://' + (location.host || 'localhost').split(':')[0] + ':1313/livereload.js?mindelay=10\u0026quot;\u0026gt;\u0026lt;/' + 'script\u0026gt;')\u0026lt;/script\u0026gt;\u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  When you use --watch, the Live Reload script is added by Hugo. Look for live reload in the documentation to see what it does and how to disable it.\nBuild a \u0026ldquo;Dynamic\u0026rdquo; Home Page \u0026ldquo;Dynamic home page?\u0026rdquo; Hugo\u0026rsquo;s a static web site generator, so this seems an odd thing to say. I mean let\u0026rsquo;s have the home page automatically reflect the content in the site every time Hugo builds it. We\u0026rsquo;ll use iteration in the template to do that.\nCreate New Posts Now that we have the home page generating static content, let\u0026rsquo;s add some content to the site. We\u0026rsquo;ll display these posts as a list on the home page and on their own page, too.\nHugo has a command to generate a skeleton post, just like it does for sites and themes.\n$ hugo --verbose new post/first.md INFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml INFO: 2014/09/29 attempting to create post/first.md of post INFO: 2014/09/29 curpath: /Users/quoha/Sites/zafta/themes/zafta/archetypes/default.md ERROR: 2014/09/29 Unable to Cast \u0026lt;nil\u0026gt; to map[string]interface{} $  That wasn\u0026rsquo;t very nice, was it?\nThe \u0026ldquo;new\u0026rdquo; command uses an archetype to create the post file. Hugo created an empty default archetype file, but that causes an error when there\u0026rsquo;s a theme. For me, the workaround was to create an archetypes file specifically for the post type.\n$ vi themes/zafta/archetypes/post.md +++ Description = \u0026quot;\u0026quot; Tags = [] Categories = [] +++ :wq $ find themes/zafta/archetypes -type f | xargs ls -l -rw-r--r-- 1 quoha staff 0 Sep 29 21:53 themes/zafta/archetypes/default.md -rw-r--r-- 1 quoha staff 51 Sep 29 21:54 themes/zafta/archetypes/post.md $ hugo --verbose new post/first.md INFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml INFO: 2014/09/29 attempting to create post/first.md of post INFO: 2014/09/29 curpath: /Users/quoha/Sites/zafta/themes/zafta/archetypes/post.md INFO: 2014/09/29 creating /Users/quoha/Sites/zafta/content/post/first.md /Users/quoha/Sites/zafta/content/post/first.md created $ hugo --verbose new post/second.md INFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml INFO: 2014/09/29 attempting to create post/second.md of post INFO: 2014/09/29 curpath: /Users/quoha/Sites/zafta/themes/zafta/archetypes/post.md INFO: 2014/09/29 creating /Users/quoha/Sites/zafta/content/post/second.md /Users/quoha/Sites/zafta/content/post/second.md created $ ls -l content/post total 16 -rw-r--r-- 1 quoha staff 104 Sep 29 21:54 first.md -rw-r--r-- 1 quoha staff 105 Sep 29 21:57 second.md $ cat content/post/first.md +++ Categories = [] Description = \u0026quot;\u0026quot; Tags = [] date = \u0026quot;2014-09-29T21:54:53-05:00\u0026quot; title = \u0026quot;first\u0026quot; +++ my first post $ cat content/post/second.md +++ Categories = [] Description = \u0026quot;\u0026quot; Tags = [] date = \u0026quot;2014-09-29T21:57:09-05:00\u0026quot; title = \u0026quot;second\u0026quot; +++ my second post $  Build the web site and then verify the results.\n$ rm -rf public $ hugo --verbose INFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/themes/zafta/static/ to /Users/quoha/Sites/zafta/public/ INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/static/ to /Users/quoha/Sites/zafta/public/ INFO: 2014/09/29 found taxonomies: map[string]string{\u0026quot;category\u0026quot;:\u0026quot;categories\u0026quot;, \u0026quot;tag\u0026quot;:\u0026quot;tags\u0026quot;} WARN: 2014/09/29 Unable to locate layout: [404.html theme/404.html] 0 draft content 0 future content 2 pages created 0 tags created 0 categories created in 4 ms $  The output says that it created 2 pages. Those are our new posts:\n$ find public -type f -name '*.html' | xargs ls -l -rw-r--r-- 1 quoha staff 78 Sep 29 22:13 public/index.html -rw-r--r-- 1 quoha staff 0 Sep 29 22:13 public/post/first/index.html -rw-r--r-- 1 quoha staff 0 Sep 29 22:13 public/post/index.html -rw-r--r-- 1 quoha staff 0 Sep 29 22:13 public/post/second/index.html $  The new files are empty because because the templates used to generate the content are empty. The homepage doesn\u0026rsquo;t show the new content, either. We have to update the templates to add the posts.\nList and Single Templates In Hugo, we have three major kinds of templates. There\u0026rsquo;s the home page template that we updated previously. It is used only by the home page. We also have \u0026ldquo;single\u0026rdquo; templates which are used to generate output for a single content file. We also have \u0026ldquo;list\u0026rdquo; templates that are used to group multiple pieces of content before generating output.\nGenerally speaking, list templates are named \u0026ldquo;list.html\u0026rdquo; and single templates are named \u0026ldquo;single.html.\u0026rdquo;\nThere are three other types of templates: partials, content views, and terms. We will not go into much detail on these.\nAdd Content to the Homepage The home page will contain a list of posts. Let\u0026rsquo;s update its template to add the posts that we just created. The logic in the template will run every time we build the site.\n$ vi themes/zafta/layouts/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; {{ range first 10 .Data.Pages }} \u0026lt;h1\u0026gt;{{ .Title }}\u0026lt;/h1\u0026gt; {{ end }} \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; :wq $  Hugo uses the Go template engine. That engine scans the template files for commands which are enclosed between \u0026ldquo;{{\u0026rdquo; and \u0026ldquo;}}\u0026rdquo;. In our template, the commands are:\n range .Title end  The \u0026ldquo;range\u0026rdquo; command is an iterator. We\u0026rsquo;re going to use it to go through the first ten pages. Every HTML file that Hugo creates is treated as a page, so looping through the list of pages will look at every file that will be created.\nThe \u0026ldquo;.Title\u0026rdquo; command prints the value of the \u0026ldquo;title\u0026rdquo; variable. Hugo pulls it from the front matter in the Markdown file.\nThe \u0026ldquo;end\u0026rdquo; command signals the end of the range iterator. The engine loops back to the top of the iteration when it finds \u0026ldquo;end.\u0026rdquo; Everything between the \u0026ldquo;range\u0026rdquo; and \u0026ldquo;end\u0026rdquo; is evaluated every time the engine goes through the iteration. In this file, that would cause the title from the first ten pages to be output as heading level one.\nIt\u0026rsquo;s helpful to remember that some variables, like .Data, are created before any output files. Hugo loads every content file into the variable and then gives the template a chance to process before creating the HTML files.\nBuild the web site and then verify the results.\n$ rm -rf public $ hugo --verbose INFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/themes/zafta/static/ to /Users/quoha/Sites/zafta/public/ INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/static/ to /Users/quoha/Sites/zafta/public/ INFO: 2014/09/29 found taxonomies: map[string]string{\u0026quot;tag\u0026quot;:\u0026quot;tags\u0026quot;, \u0026quot;category\u0026quot;:\u0026quot;categories\u0026quot;} WARN: 2014/09/29 Unable to locate layout: [404.html theme/404.html] 0 draft content 0 future content 2 pages created 0 tags created 0 categories created in 4 ms $ find public -type f -name '*.html' | xargs ls -l -rw-r--r-- 1 quoha staff 94 Sep 29 22:23 public/index.html -rw-r--r-- 1 quoha staff 0 Sep 29 22:23 public/post/first/index.html -rw-r--r-- 1 quoha staff 0 Sep 29 22:23 public/post/index.html -rw-r--r-- 1 quoha staff 0 Sep 29 22:23 public/post/second/index.html $ cat public/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;second\u0026lt;/h1\u0026gt; \u0026lt;h1\u0026gt;first\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; $  Congratulations, the home page shows the title of the two posts. The posts themselves are still empty, but let\u0026rsquo;s take a moment to appreciate what we\u0026rsquo;ve done. Your template now generates output dynamically. Believe it or not, by inserting the range command inside of those curly braces, you\u0026rsquo;ve learned everything you need to know to build a theme. All that\u0026rsquo;s really left is understanding which template will be used to generate each content file and becoming familiar with the commands for the template engine.\nAnd, if that were entirely true, this tutorial would be much shorter. There are a few things to know that will make creating a new template much easier. Don\u0026rsquo;t worry, though, that\u0026rsquo;s all to come.\nAdd Content to the Posts We\u0026rsquo;re working with posts, which are in the content/post/ directory. That means that their section is \u0026ldquo;post\u0026rdquo; (and if we don\u0026rsquo;t do something weird, their type is also \u0026ldquo;post\u0026rdquo;).\nHugo uses the section and type to find the template file for every piece of content. Hugo will first look for a template file that matches the section or type name. If it can\u0026rsquo;t find one, then it will look in the _default/ directory. There are some twists that we\u0026rsquo;ll cover when we get to categories and tags, but for now we can assume that Hugo will try post/single.html, then _default/single.html.\nNow that we know the search rule, let\u0026rsquo;s see what we actually have available:\n$ find themes/zafta -name single.html | xargs ls -l -rw-r--r-- 1 quoha staff 132 Sep 29 17:31 themes/zafta/layouts/_default/single.html  We could create a new template, post/single.html, or change the default. Since we don\u0026rsquo;t know of any other content types, let\u0026rsquo;s start with updating the default.\nRemember, any content that we haven\u0026rsquo;t created a template for will end up using this template. That can be good or bad. Bad because I know that we\u0026rsquo;re going to be adding different types of content and we\u0026rsquo;re going to end up undoing some of the changes we\u0026rsquo;ve made. It\u0026rsquo;s good because we\u0026rsquo;ll be able to see immediate results. It\u0026rsquo;s also good to start here because we can start to build the basic layout for the site. As we add more content types, we\u0026rsquo;ll refactor this file and move logic around. Hugo makes that fairly painless, so we\u0026rsquo;ll accept the cost and proceed.\nPlease see the Hugo documentation on template rendering for all the details on determining which template to use. And, as the docs mention, if you\u0026rsquo;re building a single page application (SPA) web site, you can delete all of the other templates and work with just the default single page. That\u0026rsquo;s a refreshing amount of joy right there.\nUpdate the Template File $ vi themes/zafta/layouts/_default/single.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;{{ .Title }}\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;{{ .Title }}\u0026lt;/h1\u0026gt; {{ .Content }} \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; :wq $  Build the web site and verify the results.\n$ rm -rf public $ hugo --verbose INFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/themes/zafta/static/ to /Users/quoha/Sites/zafta/public/ INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/static/ to /Users/quoha/Sites/zafta/public/ INFO: 2014/09/29 found taxonomies: map[string]string{\u0026quot;tag\u0026quot;:\u0026quot;tags\u0026quot;, \u0026quot;category\u0026quot;:\u0026quot;categories\u0026quot;} WARN: 2014/09/29 Unable to locate layout: [404.html theme/404.html] 0 draft content 0 future content 2 pages created 0 tags created 0 categories created in 4 ms $ find public -type f -name '*.html' | xargs ls -l -rw-r--r-- 1 quoha staff 94 Sep 29 22:40 public/index.html -rw-r--r-- 1 quoha staff 125 Sep 29 22:40 public/post/first/index.html -rw-r--r-- 1 quoha staff 0 Sep 29 22:40 public/post/index.html -rw-r--r-- 1 quoha staff 128 Sep 29 22:40 public/post/second/index.html $ cat public/post/first/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;first\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;first\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;my first post\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; $ cat public/post/second/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;second\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;second\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;my second post\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; $  Notice that the posts now have content. You can go to localhost:1313/post/first to verify.\nLinking to Content The posts are on the home page. Let\u0026rsquo;s add a link from there to the post. Since this is the home page, we\u0026rsquo;ll update its template.\n$ vi themes/zafta/layouts/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; {{ range first 10 .Data.Pages }} \u0026lt;h1\u0026gt;\u0026lt;a href=\u0026quot;{{ .Permalink }}\u0026quot;\u0026gt;{{ .Title }}\u0026lt;/a\u0026gt;\u0026lt;/h1\u0026gt; {{ end }} \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  Build the web site and verify the results.\n$ rm -rf public $ hugo --verbose INFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/themes/zafta/static/ to /Users/quoha/Sites/zafta/public/ INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/static/ to /Users/quoha/Sites/zafta/public/ INFO: 2014/09/29 found taxonomies: map[string]string{\u0026quot;tag\u0026quot;:\u0026quot;tags\u0026quot;, \u0026quot;category\u0026quot;:\u0026quot;categories\u0026quot;} WARN: 2014/09/29 Unable to locate layout: [404.html theme/404.html] 0 draft content 0 future content 2 pages created 0 tags created 0 categories created in 4 ms $ find public -type f -name '*.html' | xargs ls -l -rw-r--r-- 1 quoha staff 149 Sep 29 22:44 public/index.html -rw-r--r-- 1 quoha staff 125 Sep 29 22:44 public/post/first/index.html -rw-r--r-- 1 quoha staff 0 Sep 29 22:44 public/post/index.html -rw-r--r-- 1 quoha staff 128 Sep 29 22:44 public/post/second/index.html $ cat public/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;\u0026lt;a href=\u0026quot;/post/second/\u0026quot;\u0026gt;second\u0026lt;/a\u0026gt;\u0026lt;/h1\u0026gt; \u0026lt;h1\u0026gt;\u0026lt;a href=\u0026quot;/post/first/\u0026quot;\u0026gt;first\u0026lt;/a\u0026gt;\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; $  Create a Post Listing We have the posts displaying on the home page and on their own page. We also have a file public/post/index.html that is empty. Let\u0026rsquo;s make it show a list of all posts (not just the first ten).\nWe need to decide which template to update. This will be a listing, so it should be a list template. Let\u0026rsquo;s take a quick look and see which list templates are available.\n$ find themes/zafta -name list.html | xargs ls -l -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/_default/list.html  As with the single post, we have to decide to update _default/list.html or create post/list.html. We still don\u0026rsquo;t have multiple content types, so let\u0026rsquo;s stay consistent and update the default list template.\nCreating Top Level Pages Let\u0026rsquo;s add an \u0026ldquo;about\u0026rdquo; page and display it at the top level (as opposed to a sub-level like we did with posts).\nThe default in Hugo is to use the directory structure of the content/ directory to guide the location of the generated html in the public/ directory. Let\u0026rsquo;s verify that by creating an \u0026ldquo;about\u0026rdquo; page at the top level:\n$ vi content/about.md +++ title = \u0026quot;about\u0026quot; description = \u0026quot;about this site\u0026quot; date = \u0026quot;2014-09-27\u0026quot; slug = \u0026quot;about time\u0026quot; +++ ## about us i'm speechless :wq  Generate the web site and verify the results.\n$ find public -name '*.html' | xargs ls -l -rw-rw-r-- 1 mdhender staff 334 Sep 27 15:08 public/about-time/index.html -rw-rw-r-- 1 mdhender staff 527 Sep 27 15:08 public/index.html -rw-rw-r-- 1 mdhender staff 358 Sep 27 15:08 public/post/first-post/index.html -rw-rw-r-- 1 mdhender staff 0 Sep 27 15:08 public/post/index.html -rw-rw-r-- 1 mdhender staff 342 Sep 27 15:08 public/post/second-post/index.html  Notice that the page wasn\u0026rsquo;t created at the top level. It was created in a sub-directory named \u0026lsquo;about-time/\u0026rsquo;. That name came from our slug. Hugo will use the slug to name the generated content. It\u0026rsquo;s a reasonable default, by the way, but we can learn a few things by fighting it for this file.\nOne other thing. Take a look at the home page.\n$ cat public/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;\u0026lt;a href=\u0026quot;http://localhost:1313/post/theme/\u0026quot;\u0026gt;creating a new theme\u0026lt;/a\u0026gt;\u0026lt;/h1\u0026gt; \u0026lt;h1\u0026gt;\u0026lt;a href=\u0026quot;http://localhost:1313/about-time/\u0026quot;\u0026gt;about\u0026lt;/a\u0026gt;\u0026lt;/h1\u0026gt; \u0026lt;h1\u0026gt;\u0026lt;a href=\u0026quot;http://localhost:1313/post/second-post/\u0026quot;\u0026gt;second\u0026lt;/a\u0026gt;\u0026lt;/h1\u0026gt; \u0026lt;h1\u0026gt;\u0026lt;a href=\u0026quot;http://localhost:1313/post/first-post/\u0026quot;\u0026gt;first\u0026lt;/a\u0026gt;\u0026lt;/h1\u0026gt; \u0026lt;script\u0026gt;document.write('\u0026lt;script src=\u0026quot;http://' + (location.host || 'localhost').split(':')[0] + ':1313/livereload.js?mindelay=10\u0026quot;\u0026gt;\u0026lt;/' + 'script\u0026gt;')\u0026lt;/script\u0026gt;\u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  Notice that the \u0026ldquo;about\u0026rdquo; link is listed with the posts? That\u0026rsquo;s not desirable, so let\u0026rsquo;s change that first.\n$ vi themes/zafta/layouts/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;posts\u0026lt;/h1\u0026gt; {{ range first 10 .Data.Pages }} {{ if eq .Type \u0026quot;post\u0026quot;}} \u0026lt;h2\u0026gt;\u0026lt;a href=\u0026quot;{{ .Permalink }}\u0026quot;\u0026gt;{{ .Title }}\u0026lt;/a\u0026gt;\u0026lt;/h2\u0026gt; {{ end }} {{ end }} \u0026lt;h1\u0026gt;pages\u0026lt;/h1\u0026gt; {{ range .Data.Pages }} {{ if eq .Type \u0026quot;page\u0026quot; }} \u0026lt;h2\u0026gt;\u0026lt;a href=\u0026quot;{{ .Permalink }}\u0026quot;\u0026gt;{{ .Title }}\u0026lt;/a\u0026gt;\u0026lt;/h2\u0026gt; {{ end }} {{ end }} \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; :wq  Generate the web site and verify the results. The home page has two sections, posts and pages, and each section has the right set of headings and links in it.\nBut, that about page still renders to about-time/index.html.\n$ find public -name '*.html' | xargs ls -l -rw-rw-r-- 1 mdhender staff 334 Sep 27 15:33 public/about-time/index.html -rw-rw-r-- 1 mdhender staff 645 Sep 27 15:33 public/index.html -rw-rw-r-- 1 mdhender staff 358 Sep 27 15:33 public/post/first-post/index.html -rw-rw-r-- 1 mdhender staff 0 Sep 27 15:33 public/post/index.html -rw-rw-r-- 1 mdhender staff 342 Sep 27 15:33 public/post/second-post/index.html  Knowing that hugo is using the slug to generate the file name, the simplest solution is to change the slug. Let\u0026rsquo;s do it the hard way and change the permalink in the configuration file.\n$ vi config.toml [permalinks] page = \u0026quot;/:title/\u0026quot; about = \u0026quot;/:filename/\u0026quot;  Generate the web site and verify that this didn\u0026rsquo;t work. Hugo lets \u0026ldquo;slug\u0026rdquo; or \u0026ldquo;URL\u0026rdquo; override the permalinks setting in the configuration file. Go ahead and comment out the slug in content/about.md, then generate the web site to get it to be created in the right place.\nSharing Templates If you\u0026rsquo;ve been following along, you probably noticed that posts have titles in the browser and the home page doesn\u0026rsquo;t. That\u0026rsquo;s because we didn\u0026rsquo;t put the title in the home page\u0026rsquo;s template (layouts/index.html). That\u0026rsquo;s an easy thing to do, but let\u0026rsquo;s look at a different option.\nWe can put the common bits into a shared template that\u0026rsquo;s stored in the themes/zafta/layouts/partials/ directory.\nCreate the Header and Footer Partials In Hugo, a partial is a sugar-coated template. Normally a template reference has a path specified. Partials are different. Hugo searches for them along a TODO defined search path. This makes it easier for end-users to override the theme\u0026rsquo;s presentation.\n$ vi themes/zafta/layouts/partials/header.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;{{ .Title }}\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; :wq $ vi themes/zafta/layouts/partials/footer.html \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; :wq  Update the Home Page Template to Use the Partials The most noticeable difference between a template call and a partials call is the lack of path:\n{{ template \u0026quot;theme/partials/header.html\u0026quot; . }}  versus\n{{ partial \u0026quot;header.html\u0026quot; . }}  Both pass in the context.\nLet\u0026rsquo;s change the home page template to use these new partials.\n$ vi themes/zafta/layouts/index.html {{ partial \u0026quot;header.html\u0026quot; . }} \u0026lt;h1\u0026gt;posts\u0026lt;/h1\u0026gt; {{ range first 10 .Data.Pages }} {{ if eq .Type \u0026quot;post\u0026quot;}} \u0026lt;h2\u0026gt;\u0026lt;a href=\u0026quot;{{ .Permalink }}\u0026quot;\u0026gt;{{ .Title }}\u0026lt;/a\u0026gt;\u0026lt;/h2\u0026gt; {{ end }} {{ end }} \u0026lt;h1\u0026gt;pages\u0026lt;/h1\u0026gt; {{ range .Data.Pages }} {{ if or (eq .Type \u0026quot;page\u0026quot;) (eq .Type \u0026quot;about\u0026quot;) }} \u0026lt;h2\u0026gt;\u0026lt;a href=\u0026quot;{{ .Permalink }}\u0026quot;\u0026gt;{{ .Type }} - {{ .Title }} - {{ .RelPermalink }}\u0026lt;/a\u0026gt;\u0026lt;/h2\u0026gt; {{ end }} {{ end }} {{ partial \u0026quot;footer.html\u0026quot; . }} :wq  Generate the web site and verify the results. The title on the home page is now \u0026ldquo;your title here\u0026rdquo;, which comes from the \u0026ldquo;title\u0026rdquo; variable in the config.toml file.\nUpdate the Default Single Template to Use the Partials $ vi themes/zafta/layouts/_default/single.html {{ partial \u0026quot;header.html\u0026quot; . }} \u0026lt;h1\u0026gt;{{ .Title }}\u0026lt;/h1\u0026gt; {{ .Content }} {{ partial \u0026quot;footer.html\u0026quot; . }} :wq  Generate the web site and verify the results. The title on the posts and the about page should both reflect the value in the markdown file.\nAdd “Date Published” to Posts It\u0026rsquo;s common to have posts display the date that they were written or published, so let\u0026rsquo;s add that. The front matter of our posts has a variable named \u0026ldquo;date.\u0026rdquo; It\u0026rsquo;s usually the date the content was created, but let\u0026rsquo;s pretend that\u0026rsquo;s the value we want to display.\nAdd “Date Published” to the Template We\u0026rsquo;ll start by updating the template used to render the posts. The template code will look like:\n{{ .Date.Format \u0026quot;Mon, Jan 2, 2006\u0026quot; }}  Posts use the default single template, so we\u0026rsquo;ll change that file.\n$ vi themes/zafta/layouts/_default/single.html {{ partial \u0026quot;header.html\u0026quot; . }} \u0026lt;h1\u0026gt;{{ .Title }}\u0026lt;/h1\u0026gt; \u0026lt;h2\u0026gt;{{ .Date.Format \u0026quot;Mon, Jan 2, 2006\u0026quot; }}\u0026lt;/h2\u0026gt; {{ .Content }} {{ partial \u0026quot;footer.html\u0026quot; . }} :wq  Generate the web site and verify the results. The posts now have the date displayed in them. There\u0026rsquo;s a problem, though. The \u0026ldquo;about\u0026rdquo; page also has the date displayed.\nAs usual, there are a couple of ways to make the date display only on posts. We could do an \u0026ldquo;if\u0026rdquo; statement like we did on the home page. Another way would be to create a separate template for posts.\nThe \u0026ldquo;if\u0026rdquo; solution works for sites that have just a couple of content types. It aligns with the principle of \u0026ldquo;code for today,\u0026rdquo; too.\nLet\u0026rsquo;s assume, though, that we\u0026rsquo;ve made our site so complex that we feel we have to create a new template type. In Hugo-speak, we\u0026rsquo;re going to create a section template.\nLet\u0026rsquo;s restore the default single template before we forget.\n$ mkdir themes/zafta/layouts/post $ vi themes/zafta/layouts/_default/single.html {{ partial \u0026quot;header.html\u0026quot; . }} \u0026lt;h1\u0026gt;{{ .Title }}\u0026lt;/h1\u0026gt; {{ .Content }} {{ partial \u0026quot;footer.html\u0026quot; . }} :wq  Now we\u0026rsquo;ll update the post\u0026rsquo;s version of the single template. If you remember Hugo\u0026rsquo;s rules, the template engine will use this version over the default.\n$ vi themes/zafta/layouts/post/single.html {{ partial \u0026quot;header.html\u0026quot; . }} \u0026lt;h1\u0026gt;{{ .Title }}\u0026lt;/h1\u0026gt; \u0026lt;h2\u0026gt;{{ .Date.Format \u0026quot;Mon, Jan 2, 2006\u0026quot; }}\u0026lt;/h2\u0026gt; {{ .Content }} {{ partial \u0026quot;footer.html\u0026quot; . }} :wq  Note that we removed the date logic from the default template and put it in the post template. Generate the web site and verify the results. Posts have dates and the about page doesn\u0026rsquo;t.\nDon\u0026rsquo;t Repeat Yourself DRY is a good design goal and Hugo does a great job supporting it. Part of the art of a good template is knowing when to add a new template and when to update an existing one. While you\u0026rsquo;re figuring that out, accept that you\u0026rsquo;ll be doing some refactoring. Hugo makes that easy and fast, so it\u0026rsquo;s okay to delay splitting up a template.\n"});index.add({'id':61,'href':'/library/tutorials/posts/migrate-from-jekyll/','title':"Migrate to Hugo from Jekyll",'content':" Move static content to static Jekyll has a rule that any directory not starting with _ will be copied as-is to the _site output. Hugo keeps all static content under static. You should therefore move it all there. With Jekyll, something that looked like\n▾ \u0026lt;root\u0026gt;/ ▾ images/ logo.png  should become\n▾ \u0026lt;root\u0026gt;/ ▾ static/ ▾ images/ logo.png  Additionally, you\u0026rsquo;ll want any files that should reside at the root (such as CNAME) to be moved to static.\nCreate your Hugo configuration file Hugo can read your configuration as JSON, YAML or TOML. Hugo supports parameters custom configuration too. Refer to the Hugo configuration documentation for details.\nSet your configuration publish folder to _site The default is for Jekyll to publish to _site and for Hugo to publish to public. If, like me, you have _site mapped to a git submodule on the gh-pages branch, you\u0026rsquo;ll want to do one of two alternatives:\n Change your submodule to point to map gh-pages to public instead of _site (recommended).\ngit submodule deinit _site git rm _site git submodule add -b gh-pages git@github.com:your-username/your-repo.git public  Or, change the Hugo configuration to use _site instead of public.\n{ .. \u0026quot;publishdir\u0026quot;: \u0026quot;_site\u0026quot;, .. }   Convert Jekyll templates to Hugo templates That\u0026rsquo;s the bulk of the work right here. The documentation is your friend. You should refer to Jekyll\u0026rsquo;s template documentation if you need to refresh your memory on how you built your blog and Hugo\u0026rsquo;s template to learn Hugo\u0026rsquo;s way.\nAs a single reference data point, converting my templates for heyitsalex.net took me no more than a few hours.\nConvert Jekyll plugins to Hugo shortcodes Jekyll has plugins; Hugo has shortcodes. It\u0026rsquo;s fairly trivial to do a port.\nImplementation As an example, I was using a custom image_tag plugin to generate figures with caption when running Jekyll. As I read about shortcodes, I found Hugo had a nice built-in shortcode that does exactly the same thing.\nJekyll\u0026rsquo;s plugin:\nmodule Jekyll class ImageTag \u0026lt; Liquid::Tag @url = nil @caption = nil @class = nil @link = nil // Patterns IMAGE_URL_WITH_CLASS_AND_CAPTION = IMAGE_URL_WITH_CLASS_AND_CAPTION_AND_LINK = /(\\w+)(\\s+)((https?:\\/\\/|\\/)(\\S+))(\\s+)\u0026quot;(.*?)\u0026quot;(\\s+)-\u0026gt;((https?:\\/\\/|\\/)(\\S+))(\\s*)/i IMAGE_URL_WITH_CAPTION = /((https?:\\/\\/|\\/)(\\S+))(\\s+)\u0026quot;(.*?)\u0026quot;/i IMAGE_URL_WITH_CLASS = /(\\w+)(\\s+)((https?:\\/\\/|\\/)(\\S+))/i IMAGE_URL = /((https?:\\/\\/|\\/)(\\S+))/i def initialize(tag_name, markup, tokens) super if markup =~ IMAGE_URL_WITH_CLASS_AND_CAPTION_AND_LINK @class = $1 @url = $3 @caption = $7 @link = $9 elsif markup =~ IMAGE_URL_WITH_CLASS_AND_CAPTION @class = $1 @url = $3 @caption = $7 elsif markup =~ IMAGE_URL_WITH_CAPTION @url = $1 @caption = $5 elsif markup =~ IMAGE_URL_WITH_CLASS @class = $1 @url = $3 elsif markup =~ IMAGE_URL @url = $1 end end def render(context) if @class source = \u0026quot;\u0026lt;figure class='#{@class}'\u0026gt;\u0026quot; else source = \u0026quot;\u0026lt;figure\u0026gt;\u0026quot; end if @link source += \u0026quot;\u0026lt;a href=\\\u0026quot;#{@link}\\\u0026quot;\u0026gt;\u0026quot; end source += \u0026quot;\u0026lt;img src=\\\u0026quot;#{@url}\\\u0026quot;\u0026gt;\u0026quot; if @link source += \u0026quot;\u0026lt;/a\u0026gt;\u0026quot; end source += \u0026quot;\u0026lt;figcaption\u0026gt;#{@caption}\u0026lt;/figcaption\u0026gt;\u0026quot; if @caption source += \u0026quot;\u0026lt;/figure\u0026gt;\u0026quot; source end end end Liquid::Template.register_tag('image', Jekyll::ImageTag)  is written as this Hugo shortcode:\n\u0026lt;!-- image --\u0026gt; \u0026lt;figure {{ with .Get \u0026quot;class\u0026quot; }}class=\u0026quot;{{.}}\u0026quot;{{ end }}\u0026gt; {{ with .Get \u0026quot;link\u0026quot;}}\u0026lt;a href=\u0026quot;{{.}}\u0026quot;\u0026gt;{{ end }} \u0026lt;img src=\u0026quot;{{ .Get \u0026quot;src\u0026quot; }}\u0026quot; {{ if or (.Get \u0026quot;alt\u0026quot;) (.Get \u0026quot;caption\u0026quot;) }}alt=\u0026quot;{{ with .Get \u0026quot;alt\u0026quot;}}{{.}}{{else}}{{ .Get \u0026quot;caption\u0026quot; }}{{ end }}\u0026quot;{{ end }} /\u0026gt; {{ if .Get \u0026quot;link\u0026quot;}}\u0026lt;/a\u0026gt;{{ end }} {{ if or (or (.Get \u0026quot;title\u0026quot;) (.Get \u0026quot;caption\u0026quot;)) (.Get \u0026quot;attr\u0026quot;)}} \u0026lt;figcaption\u0026gt;{{ if isset .Params \u0026quot;title\u0026quot; }} {{ .Get \u0026quot;title\u0026quot; }}{{ end }} {{ if or (.Get \u0026quot;caption\u0026quot;) (.Get \u0026quot;attr\u0026quot;)}}\u0026lt;p\u0026gt; {{ .Get \u0026quot;caption\u0026quot; }} {{ with .Get \u0026quot;attrlink\u0026quot;}}\u0026lt;a href=\u0026quot;{{.}}\u0026quot;\u0026gt; {{ end }} {{ .Get \u0026quot;attr\u0026quot; }} {{ if .Get \u0026quot;attrlink\u0026quot;}}\u0026lt;/a\u0026gt; {{ end }} \u0026lt;/p\u0026gt; {{ end }} \u0026lt;/figcaption\u0026gt; {{ end }} \u0026lt;/figure\u0026gt; \u0026lt;!-- image --\u0026gt;  Usage I simply changed:\n{% image full http://farm5.staticflickr.com/4136/4829260124_57712e570a_o_d.jpg \u0026quot;One of my favorite touristy-type photos. I secretly waited for the good light while we were \u0026quot;having fun\u0026quot; and took this. Only regret: a stupid pole in the top-left corner of the frame I had to clumsily get rid of at post-processing.\u0026quot; -\u0026gt;http://www.flickr.com/photos/alexnormand/4829260124/in/set-72157624547713078/ %}  to this (this example uses a slightly extended version named fig, different than the built-in figure):\n{{% fig class=\u0026quot;full\u0026quot; src=\u0026quot;http://farm5.staticflickr.com/4136/4829260124_57712e570a_o_d.jpg\u0026quot; title=\u0026quot;One of my favorite touristy-type photos. I secretly waited for the good light while we were having fun and took this. Only regret: a stupid pole in the top-left corner of the frame I had to clumsily get rid of at post-processing.\u0026quot; link=\u0026quot;http://www.flickr.com/photos/alexnormand/4829260124/in/set-72157624547713078/\u0026quot; %}}  As a bonus, the shortcode named parameters are, arguably, more readable.\nFinishing touches Fix content Depending on the amount of customization that was done with each post with Jekyll, this step will require more or less effort. There are no hard and fast rules here except that hugo server --watch is your friend. Test your changes and fix errors as needed.\nClean up You\u0026rsquo;ll want to remove the Jekyll configuration at this point. If you have anything else that isn\u0026rsquo;t used, delete it.\nA practical example in a diff Hey, it\u0026rsquo;s Alex was migrated in less than a father-with-kids day from Jekyll to Hugo. You can see all the changes (and screw-ups) by looking at this diff.\n"});index.add({'id':62,'href':'/library/tutorials/docs/backup/example/table-of-contents/','title':"Docs\\backup\\example\\table of Contents\\",'content':" Ubi loqui Mentem genus facietque salire tempus bracchia Lorem markdownum partu paterno Achillem. Habent amne generosi aderant ad pellem nec erat sustinet merces columque haec et, dixit minus nutrit accipiam subibis subdidit. Temeraria servatum agros qui sed fulva facta. Primum ultima, dedit, suo quisque linguae medentes fixo: tum petis.\nRapit vocant si hunc siste adspice Ora precari Patraeque Neptunia, dixit Danae Cithaeron armaque maxima in nati Coniugis templis fluidove. Effugit usus nec ingreditur agmen ac manus conlato. Nullis vagis nequiquam vultibus aliquos altera suum venis teneas fretum. Armos remotis hoc sine ferrea iuncta quam!\nLocus fuit caecis Nefas discordemque domino montes numen tum humili nexilibusque exit, Iove. Quae miror esse, scelerisque Melaneus viribus. Miseri laurus. Hoc est proposita me ante aliquid, aura inponere candidioribus quidque accendit bella, sumpta. Intravit quam erat figentem hunc, motus de fontes parvo tempestate.\niscsi_virus = pitch(json_in_on(eupViral), northbridge_services_troubleshooting, personal( firmware_rw.trash_rw_crm.device(interactive_gopher_personal, software, -1), megabit, ergonomicsSoftware(cmyk_usb_panel, mips_whitelist_duplex, cpa))); if (5) { managementNetwork += dma - boolean; kilohertz_token = 2; honeypot_affiliate_ergonomics = fiber; } mouseNorthbridge = byte(nybble_xmp_modem.horse_subnet( analogThroughputService * graphicPoint, drop(daw_bit, dnsIntranet), gateway_ospf), repository.domain_key.mouse(serverData(fileNetwork, trim_duplex_file), cellTapeDirect, token_tooltip_mashup( ripcordingMashup))); module_it = honeypot_driver(client_cold_dvr(593902, ripping_frequency) + coreLog.joystick(componentUdpLink), windows_expansion_touchscreen); bashGigabit.external.reality(2, server_hardware_codec.flops.ebookSampling( ciscNavigationBacklink, table + cleanDriver), indexProtocolIsp);  Placabilis coactis nega ingemuit ignoscat nimia non Frontis turba. Oculi gravis est Delphice; inque praedaque sanguine manu non.\nif (ad_api) { zif += usb.tiffAvatarRate(subnet, digital_rt) + exploitDrive; gigaflops(2 - bluetooth, edi_asp_memory.gopher(queryCursor, laptop), panel_point_firmware); spyware_bash.statePopApplet = express_netbios_digital( insertion_troubleshooting.brouter(recordFolderUs), 65); } recursionCoreRay = -5; if (hub == non) { portBoxVirus = soundWeb(recursive_card(rwTechnologyLeopard), font_radcab, guidCmsScalable + reciprocalMatrixPim); left.bug = screenshot; } else { tooltipOpacity = raw_process_permalink(webcamFontUser, -1); executable_router += tape; } if (tft) { bandwidthWeb *= social_page; } else { regular += 611883; thumbnail /= system_lag_keyboard; }  Caesorum illa tu sentit micat vestes papyriferi Inde aderam facti; Theseus vis de tauri illa peream. Oculos uberaque non regisque vobis cursuque, opus venit quam vulnera. Et maiora necemque, lege modo; gestanda nitidi, vero? Dum ne pectoraque testantur.\nVenasque repulsa Samos qui, exspectatum eram animosque hinc, aut manes, Assyrii. Cupiens auctoribus pariter rubet, profana magni super nocens. Vos ius sibilat inpar turba visae iusto! Sedes ante dum superest extrema.\n"});index.add({'id':63,'href':'/library/tutorials/docs/python/flask/learning-flask/ep-10/','title':"Ep.10 Flask and the Fetch API",'content':" Flask and the Fetch API | Learning Flask Ep. 10 Asynchronous requests from the client to the server using the JavaScript Fetch API\nMaking asynchronus requests from the client to the server is a common feature of most modern web applications, allowing a more fluid user experience.\nIn this episode of the \u0026ldquo;Learning Flask\u0026rdquo; series, you\u0026rsquo;ll learn how to make asynchronus requests from the client to your application using some basic vanilla JavaScript and the Fetch API.\nThe Fetch API supersedes XML AJAX requests, allowing a relitively clean and simple promise based way to post and fetch data to and from the server, with a simple yet powerful feature set for catching errors and bad requests.\nCreate a new route For this example, we\u0026rsquo;re going to be building a simple guestbook, allowing our users to post their name and message along with reading other previous entries.\nWe\u0026rsquo;ll use the Fetch API to post a new entry and a JavaScript function to render the entries to our template.\nLet\u0026rsquo;s start with a new route called /guestbook:\napp/app/views.py\n@app.route(\u0026quot;/guestbook\u0026quot;) def guestbook(): return render_template(\u0026quot;public/guestbook.html\u0026quot;)  We\u0026rsquo;ll need to create a new template too. Go ahead and create guestbook.html in the public directory and add the following:\napp/app/templates/public/guestbook.html\n{% extends \u0026quot;public/templates/public_template.html\u0026quot; %} {% block title %}Guestbook{% endblock %} {% block main %} \u0026lt;div class=\u0026quot;container\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col\u0026quot;\u0026gt; \u0026lt;h1\u0026gt;Guestbook\u0026lt;/h1\u0026gt; \u0026lt;hr\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {% endblock %}  Save the files and head to /guestbook in the browser to see the new template.\n Note - We\u0026rsquo;re using the Bootstrap 4 library for CSS\n We\u0026rsquo;ll need some input fields for our users to fill out the guestbook.\nWe\u0026rsquo;ll add an input field for name and a textarea for message along with a button to submit their entry:\napp/app/templates/public/guestbook.html\n{% extends \u0026quot;public/templates/public_template.html\u0026quot; %} {% block title %}Guestbook{% endblock %} {% block main %} \u0026lt;div class=\u0026quot;container\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col\u0026quot;\u0026gt; \u0026lt;h1\u0026gt;Guestbook\u0026lt;/h1\u0026gt; \u0026lt;hr\u0026gt; \u0026lt;div class=\u0026quot;mb-3\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;form-group\u0026quot;\u0026gt; \u0026lt;label\u0026gt;Name\u0026lt;/label\u0026gt; \u0026lt;input type=\u0026quot;text\u0026quot; class=\u0026quot;form-control\u0026quot; id=\u0026quot;name\u0026quot; placeholder=\u0026quot;Your name\u0026quot;\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;form-group\u0026quot;\u0026gt; \u0026lt;label\u0026gt;Message\u0026lt;/label\u0026gt; \u0026lt;textarea class=\u0026quot;form-control\u0026quot; id=\u0026quot;message\u0026quot; cols=\u0026quot;30\u0026quot; rows=\u0026quot;3\u0026quot; placeholder=\u0026quot;Your message\u0026quot;\u0026gt;\u0026lt;/textarea\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;button class=\u0026quot;btn btn-primary\u0026quot; id=\u0026quot;submit\u0026quot; onclick=\u0026quot;submit_message();\u0026quot;\u0026gt;Submit message\u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;h3\u0026gt;Messages\u0026lt;/h3\u0026gt; \u0026lt;hr\u0026gt; \u0026lt;div class=\u0026quot;mb-3\u0026quot; id=\u0026quot;messages\u0026quot;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {% endblock %} {% block script %}  Notice we\u0026rsquo;ve set an id attribute on the input elements and the button. We\u0026rsquo;ll create a function to submit the data when the button is clicked, collecting the values from the input fields and posting it to our Flask app.\nWe\u0026rsquo;ve also added a new heading and a \u0026lt;div\u0026gt; element with the id messages. We\u0026rsquo;ll use this div to display the entries of our guestbook later.\nCollecting JSON We\u0026rsquo;re going to wrap all of our JavaScript in a set of {% block script %} {% endblock %} tags with corresponding {% block script %} {% endblock %} tags in our base template.\nLet\u0026rsquo;s create a function to collect the input values and create a new JSON object when the button is clicked:\napp/app/templates/public/guestbook.html\n{% block script %} \u0026lt;script\u0026gt; function submit_message() { var name = document.getElementById(\u0026quot;name\u0026quot;); var message = document.getElementById(\u0026quot;message\u0026quot;); var entry = { name: name.value, message: message.value }; } \u0026lt;/script\u0026gt; {% endblock %}  We need to attach this function to the submit button. Go ahead and refactor the \u0026lt;button\u0026gt; element to the following:\n\u0026lt;button class=\u0026quot;btn btn-primary\u0026quot; id=\u0026quot;submit\u0026quot; onclick=\u0026quot;submit_message();\u0026quot;\u0026gt;Submit message\u0026lt;/button\u0026gt;  We\u0026rsquo;re calling the submit_message() function when someone clicks the button, fetching the input values and storing them in a JSON object called entry.\nCreating a JSON handler in Flask Before we attempt to post any data to our app, we need to create a handler for it.\nWe\u0026rsquo;re submitting data to our app so we\u0026rsquo;ll need to import request from flask.\nWe\u0026rsquo;re also going to be creating a JSON response so go ahead and import jsonify from flask too.\nWe will also create a response object, so go ahead and import make_response from flask.\napp/app/views.py\nfrom flask import request, jsonify, make_response`  Go ahead and create the following route in your Flask app:\napp/app/views.py\n@app.route(\u0026quot;/guestbook/create-entry\u0026quot;, methods=[\u0026quot;POST\u0026quot;]) def create_entry(): req = request.get_json() print(req) res = make_response(jsonify({\u0026quot;message\u0026quot;: \u0026quot;OK\u0026quot;}), 200) return res  For now, we\u0026rsquo;ll just use the print() function to print our request data to the terminal and return a simple JSON response.\nFetch setup Let\u0026rsquo;s go back to guestbook.html and work on the submit_message() function to post some data to our app.\nOur fetch function is initially going to look like this:\nfetch(${window.origin}/guestbook/create-entry, { method: \u0026quot;POST\u0026quot;, credentials: \u0026quot;include\u0026quot;, body: JSON.stringify(entry), cache: \u0026quot;no-cache\u0026quot;, headers: new Headers({ \u0026quot;content-type\u0026quot;: \u0026quot;application/json\u0026quot; }) }) .then(function(response) { if (response.status !== 200) { console.log(`Looks like there was a problem. Status code: ${response.status}`); return; } response.json().then(function(data) { console.log(data); }); }) .catch(function(error) { console.log(\u0026quot;Fetch error: \u0026quot; + error); });  Let\u0026rsquo;s take a look at our JavaScript so far and take a quick look at what we\u0026rsquo;re doing:\n{% block script %} \u0026lt;script\u0026gt; function submit_message() { var name = document.getElementById(\u0026quot;name\u0026quot;); var message = document.getElementById(\u0026quot;message\u0026quot;); var entry = { name: name.value, message: message.value }; fetch(`${window.origin}/guestbook/create-entry`, { method: \u0026quot;POST\u0026quot;, credentials: \u0026quot;include\u0026quot;, body: JSON.stringify(entry), cache: \u0026quot;no-cache\u0026quot;, headers: new Headers({ \u0026quot;content-type\u0026quot;: \u0026quot;application/json\u0026quot; }) }) .then(function (response) { if (response.status !== 200) { console.log(`Looks like there was a problem. Status code: ${response.status}`); return; } response.json().then(function (data) { console.log(data); }); }) .catch(function (error) { console.log(\u0026quot;Fetch error: \u0026quot; + error); }); } \u0026lt;/script\u0026gt; {% endblock %}  Fetch explained fetch() takes 2 arguments, a URL or input and a set of options or init as descibed in the fetch documentation.\nWe\u0026rsquo;ve provided the URL to our Flask JSON handler using ${window.origin} followed by our URL, along with an init object containing several keys and values to setup the type of request we want to make. In our case:\n method: \u0026quot;POST\u0026quot; As we\u0026rsquo;re posting data to the server credentials: \u0026quot;include\u0026quot; To send any cookies from the current domain/client to the server body: JSON.stringify(entry) Converts our JSON object into a string cache: \u0026quot;no-cache\u0026quot; We\u0026rsquo;re not interested in any cached data headers: new Headers({\u0026quot;content-type\u0026quot;: \u0026quot;application/json\u0026quot;}) Adds a header to tell the server we\u0026rsquo;re sending JSON  You\u0026rsquo;ll then see we\u0026rsquo;ve got .then() chained to our fetch() request which does some error handling for us, depending on what status code the server responds with. We\u0026rsquo;re going to leave that as is for now.\nresponse.json() parses returned JSON from a string to a JSON object which we can access with the data variable passed into the callback function chained to it using .then()! 😅\nThe final block is a .catch() containing a callback function to catch and handle any errors with our fetch request.\n Tip - The more you use fetch the more it starts to make sense!\n Let\u0026rsquo;s post some data to our route.\nPosting with Fetch Save the file, reload the browser, fill out the name and message fields and submit the form. You should see a dictionary printed in your terminal along with a JSON response printed to the browser console.\nLet\u0026rsquo;s refactor the code in our view to return the same object send to us from the client:\napp/app/views.py\n@app.route(\u0026quot;/guestbook/create-entry\u0026quot;, methods=[\u0026quot;POST\u0026quot;]) def create_entry(): req = request.get_json() print(req) res = make_response(jsonify(req), 200) return res  All we do it pass the req variable to jsonify(), which will serialize the Python dictionary into a JSON string.\nIf you now fill out the form and send another request to the app, you\u0026rsquo;ll see down in the developer tools console our route is now just bouncing back what was sent to it!\nTakeaways The main takeaway from this episode is that asynchronously sending and receiving data betwen the client and the server is relitively simple using the Fetch API.\nIn the next part of this series, we\u0026rsquo;ll complete our guestbook app where you\u0026rsquo;ll see more of the Fetch API in action! We\u0026rsquo;ll be saving entries and reloading new entries in the background without having to reload the page.\nLast modified · 28 Feb 2019\n Written with StackEdit.\n "});index.add({'id':64,'href':'/library/tutorials/docs/articles/git/','title':"Git",'content':" Git "});index.add({'id':65,'href':'/library/tutorials/docs/articles/webapp/vue/','title':"Vue",'content':" Vue.js "});index.add({'id':66,'href':'/library/tutorials/docs/front-end/bootstrap/basic-bootstap/','title':"Bootstrap 4 แบบพื้นฐาน",'content':" สรุปการใช้งาน Bootstrap 4 แบบพื้นฐาน "});index.add({'id':67,'href':'/library/tutorials/docs/python/flask/learning-flask/ep-11/','title':"Ep.11 Query strings in Flask",'content':" Query strings in Flask | Learning Flask Ep. 11 Creating, serializing and working with query string data in Flask\nIn this part of the \u0026ldquo;Learning Flask\u0026rdquo; series, we\u0026rsquo;re going to working with query strings. A query string is part of the URL as a string of parameters and values and are used ubiquitously across the web.\nQuery strings are essentially a string of key/value pairs sent by the client to the server.\nHere\u0026rsquo;s an example of a query string in the URL from a quick Google search for query string:\nhttps://www.google.com/search?q=query+string\nLet\u0026rsquo;s break down the URL:\n https is the protocol www.google.com is the domain /search is the path ?q=query+string is the query string  Anatomy of a query string Focusing on the query string element of the URL, we see the following components:\n ? starts the query string q is the first parameter = separates/assigns a value to the parameter query+string is the value assigned to the q parameter  You\u0026rsquo;ll notice the + substitution between \u0026ldquo;query string\u0026rdquo;. This is because the space charactes is not allowed in a URL so must be replaced with something else.\nSpaces in query strings are replaced with + or %20\nLet\u0026rsquo;s take a look at a slightly more complex query string, again from a Google search for \u0026ldquo;flask\u0026rdquo;:\nhttps://www.google.com/search?q=flask\u0026amp;oq=flask\u0026amp;sourceid=chrome\u0026amp;ie=UTF-8\nIf you take a closer look at the query string, you\u0026rsquo;ll see multiple parameters and values, separated by the \u0026amp; symbol.\nWe use \u0026amp; to separate parameters and values in the query string. Let\u0026rsquo;s create a query string below with a few sets of params \u0026amp; values:\nhttp://127.0.0.1:5000/query?foo=foo\u0026amp;bar=bar\u0026amp;baz=baz\u0026amp;title=query+strings+with+flask\nLet\u0026rsquo;s use this query string in our Flask application and learn how to work with it!\nFlask query strings First up, let\u0026rsquo;s create a new route with the URL /query:\napp/app/views.py\n@app.route(\u0026quot;/query\u0026quot;) def query(): return \u0026quot;No query string received\u0026quot;, 200  If you got to /query in your browser, you\u0026rsquo;ll see No query string received in your window.\nGo ahead and paste the query string we just created above into your browser URL bar and see what happens.\nYou\u0026rsquo;ll notice we don\u0026rsquo;t get any errors, however we\u0026rsquo;re not yet doing anything with our query string. Let\u0026rsquo;s go ahead and serialize it!\nSerializing query strings To work with any kind of request object or data, we need to import request from flask:\napp/app/views.py\nfrom flask import request  Just like we\u0026rsquo;ve used request.form for serializing form data and request.get_json() to serialize incoming JSON data, we use request.args to parse and serialize the query string into a Python object.\nLet\u0026rsquo;s store our query string object as a variable called args and print them:\napp/app/views.py\n@app.route(\u0026quot;/query\u0026quot;) def query(): args = request.args print(args) return \u0026quot;No query string received\u0026quot;, 200  Save and reload that same URL with the query string, you\u0026rsquo;ll see the following in your terminal:\nImmutableMultiDict([('foo', 'foo'), ('bar', 'bar'), ('baz', 'baz'), ('title', 'query strings with flask')])\nrequest.args has parsed our query string and conveniently converted it into an ImmutableMultiDict which we can treat just like a Python dictionary, for example, change print(args) for the following:\napp/app/views.py\nfor k, v in args.items(): print(f\u0026quot;{k}: {v}\u0026quot;)`  You\u0026rsquo;ll see our keys and values printed out to the console:\nfoo: foo bar: bar baz: baz title: query strings with flask`  Just like a dictionary, we can now pluck out values by their key:\n@app.route(\u0026quot;/query\u0026quot;) def query(): args = request.args if \u0026quot;foo\u0026quot; in args: foo = args[\u0026quot;foo\u0026quot;] if \u0026quot;bar\u0026quot; in args: bar = args.get(\u0026quot;bar\u0026quot;) if \u0026quot;baz\u0026quot; in args: baz = args[\u0026quot;baz\u0026quot;] if \u0026quot;title\u0026quot; in request.args: title = request.args.get(\u0026quot;title\u0026quot;) print(foo, bar, baz, title) return \u0026quot;No query string received\u0026quot;, 200  However at this point we\u0026rsquo;ll get an error if we don\u0026rsquo;t send a query string with values for foo, bar, baz and title.\nLet\u0026rsquo;s refactor our code to mitigate any potantial errors and return a formatted query string to the client:\n@app.route(\u0026quot;/query\u0026quot;) def query(): if request.args: # We have our query string nicely serialized as a Python dictionary args = request.args # We'll create a string to display the parameters \u0026amp; values serialized = \u0026quot;, \u0026quot;.join(f\u0026quot;{k}: {v}\u0026quot; for k, v in request.args.items()) # Display the query string to the client in a different format return f\u0026quot;(Query) {serialized}\u0026quot;, 200 else: return \u0026quot;No query string received\u0026quot;, 200  If you re-submit the URL, you\u0026rsquo;ll see:\n(Query) foo: foo, bar: bar, baz: baz, title: query strings with flask\nAnd that pretty much wraps things up for query strings with Flask!\nExtras Although I\u0026rsquo;ve not found much use for them in the past, the request object also provides us with a few more features for working with query strings.\nrequest.query_string will return the query string, for example:\n@app.route(\u0026quot;/query\u0026quot;) def query(): print(request.query_string) return \u0026quot;Thanks\u0026quot;, 200  Will return:\nb'foo=foo\u0026amp;bar=bar\u0026amp;baz=baz\u0026amp;title=query+strings+with+flask'\nrequest.values will return a CombinedMultiDict which comines args with form, for example:\n@app.route(\u0026quot;/query\u0026quot;) def query(): print(request.values) return \u0026quot;Thanks\u0026quot;, 200`  Returns:\nCombinedMultiDict([ImmutableMultiDict([('foo', 'foo'), ('bar', 'bar'), ('baz', 'baz'), ('title', 'query strings with flask')]), ImmutableMultiDict([])])  Not something I\u0026rsquo;ve used in the past but can imagine it would be useful to submit a form with query string parameters in the URL.\nWrapping up Query strings are a convenient way to pass arguments to your application and Flask makes light work of quickly parsing them into something we can work with.\nPOST requests don\u0026rsquo;t typically include a query string as they tend to include data that you want to keep within the request body, so you\u0026rsquo;ll mostly be using them with GET requests.\nLast modified · 28 Feb 2019\n Written with StackEdit.\n "});index.add({'id':68,'href':'/library/tutorials/docs/front-end/javascript/','title':"JavaScript",'content':" JavaScript Learning Python: From Zero to Hero First of all, what is Python? According to its creator, Guido van Rossum, Python is a:\n “high-level programming language, and its core design philosophy is all about code readability and a syntax which allows programmers to express concepts in a few lines of code.”\n For me, the first reason to learn Python was that it is, in fact, a beautiful programming language. It was really natural to code in it and express my thoughts.\nAnother reason was that we can use coding in Python in multiple ways: data science, web development, and machine learning all shine here. Quora, Pinterest and Spotify all use Python for their backend web development. So let’s learn a bit about it.\nThe Basics 1. Variables You can think about variables as words that store a value. Simple as that.\nIn Python, it is really easy to define a variable and set a value to it. Imagine you want to store number 1 in a variable called “one.” Let’s do it:\none = 1  How simple was that? You just assigned the value 1 to the variable “one.”\ntwo = 2 some_number = 10000  And you can assign any other value to whatever other variables you want. As you see in the table above, the variable “two” stores the integer 2, and “some_number” stores 10,000.\nBesides integers, we can also use booleans (True / False), strings, float, and so many other data types.\n# booleans true_boolean = True false_boolean = False # string my_name = \u0026quot;Leandro Tk\u0026quot; # float book_price = 15.80  2. Control Flow: conditional statements “If” uses an expression to evaluate whether a statement is True or False. If it is True, it executes what is inside the “if” statement. For example:\nif True: print(\u0026quot;Hello Python If\u0026quot;) if 2 \u0026gt; 1: print(\u0026quot;2 is greater than 1\u0026quot;)  2 is greater than 1, so the “print” code is executed.\nThe “else” statement will be executed if the “if” expression is false.\nif 1 \u0026gt; 2: print(\u0026quot;1 is greater than 2\u0026quot;) else: print(\u0026quot;1 is not greater than 2\u0026quot;)  1 is not greater than 2, so the code inside the “else” statement will be executed.\nYou can also use an “elif” statement:\nif 1 \u0026gt; 2: print(\u0026quot;1 is greater than 2\u0026quot;) elif 2 \u0026gt; 1: print(\u0026quot;1 is not greater than 2\u0026quot;) else: print(\u0026quot;1 is equal to 2\u0026quot;)  3. Looping / Iterator In Python, we can iterate in different forms. I’ll talk about two: while and for.\nWhile Looping: while the statement is True, the code inside the block will be executed. So, this code will print the number from 1 to 10.\nnum = 1 while num \u0026lt;= 10: print(num) num += 1  The while loop needs a “loop condition.” If it stays True, it continues iterating. In this example, when num is 11 the loop condition equals False.\nAnother basic bit of code to better understand it:\nloop_condition = True while loop_condition: print(\u0026quot;Loop Condition keeps: %s\u0026quot; %(loop_condition)) loop_condition = False  The loop condition is True so it keeps iterating — until we set it to False.\nFor Looping: you apply the variable “num” to the block, and the “for” statement will iterate it for you. This code will print the same as while code: from 1 to 10.\nfor i in range(1, 11): print(i)  See? It is so simple. The range starts with 1 and goes until the 11th element (10 is the 10th element).\nList: Collection | Array | Data Structure Imagine you want to store the integer 1 in a variable. But maybe now you want to store 2. And 3, 4, 5 …\nDo I have another way to store all the integers that I want, but not in millions of variables? You guessed it — there is indeed another way to store them.\nList is a collection that can be used to store a list of values (like these integers that you want). So let’s use it:\nmy_integers = [1, 2, 3, 4, 5]  It is really simple. We created an array and stored it on my_integer.\nBut maybe you are asking: “How can I get a value from this array?”\nGreat question. List has a concept called index. The first element gets the index 0 (zero). The second gets 1, and so on. You get the idea.\nTo make it clearer, we can represent the array and each element with its index. I can draw it:\nUsing the Python syntax, it’s also simple to understand:\nmy_integers = [5, 7, 1, 3, 4] print(my_integers[0]) # 5 print(my_integers[1]) # 7 print(my_integers[4]) # 4  Imagine that you don’t want to store integers. You just want to store strings, like a list of your relatives’ names. Mine would look something like this:\nrelatives_names = [ \u0026quot;Toshiaki\u0026quot;, \u0026quot;Juliana\u0026quot;, \u0026quot;Yuji\u0026quot;, \u0026quot;Bruno\u0026quot;, \u0026quot;Kaio\u0026quot; ] print(relatives_names[4]) # Kaio  It works the same way as integers. Nice.\nWe just learned how Lists indices work. But I still need to show you how we can add an element to the List data structure (an item to a list).\nThe most common method to add a new value to a List is append. Let’s see how it works:\nbookshelf = [] bookshelf.append(\u0026quot;The Effective Engineer\u0026quot;) bookshelf.append(\u0026quot;The 4 Hour Work Week\u0026quot;) print(bookshelf[0]) # The Effective Engineer print(bookshelf[1]) # The 4 Hour Work Week  append is super simple. You just need to apply the element (eg. “The Effective Engineer”) as the append parameter.\nWell, enough about Lists. Let’s talk about another data structure.\nDictionary: Key-Value Data Structure Now we know that Lists are indexed with integer numbers. But what if we don’t want to use integer numbers as indices? Some data structures that we can use are numeric, string, or other types of indices.\nLet’s learn about the Dictionary data structure. Dictionary is a collection of key-value pairs. Here’s what it looks like:\ndictionary_example = { \u0026quot;key1\u0026quot;: \u0026quot;value1\u0026quot;, \u0026quot;key2\u0026quot;: \u0026quot;value2\u0026quot;, \u0026quot;key3\u0026quot;: \u0026quot;value3\u0026quot; }  The key is the index pointing to the value. How do we access the Dictionary value? You guessed it — using the key. Let’s try it:\ndictionary_tk = { \u0026quot;name\u0026quot;: \u0026quot;Leandro\u0026quot;, \u0026quot;nickname\u0026quot;: \u0026quot;Tk\u0026quot;, \u0026quot;nationality\u0026quot;: \u0026quot;Brazilian\u0026quot; } print(\u0026quot;My name is %s\u0026quot; %(dictionary_tk[\u0026quot;name\u0026quot;])) # My name is Leandro print(\u0026quot;But you can call me %s\u0026quot; %(dictionary_tk[\u0026quot;nickname\u0026quot;])) # But you can call me Tk print(\u0026quot;And by the way I'm %s\u0026quot; %(dictionary_tk[\u0026quot;nationality\u0026quot;])) # And by the way I'm Brazilian  I created a Dictionary about me. My name, nickname, and nationality. Those attributes are the Dictionary keys.\nAs we learned how to access the List using index, we also use indices (keys in the Dictionary context) to access the value stored in the Dictionary.\nIn the example, I printed a phrase about me using all the values stored in the Dictionary. Pretty simple, right?\nAnother cool thing about Dictionary is that we can use anything as the value. In the Dictionary I created, I want to add the key “age” and my real integer age in it:\ndictionary_tk = { \u0026quot;name\u0026quot;: \u0026quot;Leandro\u0026quot;, \u0026quot;nickname\u0026quot;: \u0026quot;Tk\u0026quot;, \u0026quot;nationality\u0026quot;: \u0026quot;Brazilian\u0026quot;, \u0026quot;age\u0026quot;: 24 } print(\u0026quot;My name is %s\u0026quot; %(dictionary_tk[\u0026quot;name\u0026quot;])) # My name is Leandro print(\u0026quot;But you can call me %s\u0026quot; %(dictionary_tk[\u0026quot;nickname\u0026quot;])) # But you can call me Tk print(\u0026quot;And by the way I'm %i and %s\u0026quot; %(dictionary_tk[\u0026quot;age\u0026quot;], dictionary_tk[\u0026quot;nationality\u0026quot;])) # And by the way I'm Brazilian  Here we have a key (age) value (24) pair using string as the key and integer as the value.\nAs we did with Lists, let’s learn how to add elements to a Dictionary. The key pointing to a value is a big part of what Dictionary is. This is also true when we are talking about adding elements to it:\ndictionary_tk = { \u0026quot;name\u0026quot;: \u0026quot;Leandro\u0026quot;, \u0026quot;nickname\u0026quot;: \u0026quot;Tk\u0026quot;, \u0026quot;nationality\u0026quot;: \u0026quot;Brazilian\u0026quot; } dictionary_tk['age'] = 24 print(dictionary_tk) # {'nationality': 'Brazilian', 'age': 24, 'nickname': 'Tk', 'name': 'Leandro'}  We just need to assign a value to a Dictionary key. Nothing complicated here, right?\nIteration: Looping Through Data Structures As we learned in the Python Basics, the List iteration is very simple. We Python developers commonly use For looping. Let’s do it:\nbookshelf = [ \u0026quot;The Effective Engineer\u0026quot;, \u0026quot;The 4-hour Workweek\u0026quot;, \u0026quot;Zero to One\u0026quot;, \u0026quot;Lean Startup\u0026quot;, \u0026quot;Hooked\u0026quot; ] for book in bookshelf: print(book)  So for each book in the bookshelf, we (can do everything with it) print it. Pretty simple and intuitive. That’s Python.\nFor a hash data structure, we can also use the for loop, but we apply the key :\ndictionary = { \u0026quot;some_key\u0026quot;: \u0026quot;some_value\u0026quot; } for key in dictionary: print(\u0026quot;%s --\u0026gt; %s\u0026quot; %(key, dictionary[key])) # some_key --\u0026gt; some_value  This is an example how to use it. For each key in the dictionary , we print the key and its corresponding value.\nAnother way to do it is to use the iteritems method.\ndictionary = { \u0026quot;some_key\u0026quot;: \u0026quot;some_value\u0026quot; } for key, value in dictionary.items(): print(\u0026quot;%s --\u0026gt; %s\u0026quot; %(key, value)) # some_key --\u0026gt; some_value  We did name the two parameters as key and value, but it is not necessary. We can name them anything. Let’s see it:\ndictionary_tk = { \u0026quot;name\u0026quot;: \u0026quot;Leandro\u0026quot;, \u0026quot;nickname\u0026quot;: \u0026quot;Tk\u0026quot;, \u0026quot;nationality\u0026quot;: \u0026quot;Brazilian\u0026quot;, \u0026quot;age\u0026quot;: 24 } for attribute, value in dictionary_tk.items(): print(\u0026quot;My %s is %s\u0026quot; %(attribute, value)) # My name is Leandro # My nickname is Tk # My nationality is Brazilian # My age is 24  We can see we used attribute as a parameter for the Dictionary key, and it works properly. Great!\nClasses \u0026amp; Objects A little bit of theory: Objects are a representation of real world objects like cars, dogs, or bikes. The objects share two main characteristics: data and behavior.\nCars have data, like number of wheels, number of doors, and seating capacity They also exhibit behavior: they can accelerate, stop, show how much fuel is left, and so many other things.\nWe identify data as attributes and behavior as methods in object-oriented programming. Again:\nData → Attributes and Behavior → Methods\nAnd a Class is the blueprint from which individual objects are created. In the real world, we often find many objects with the same type. Like cars. All the same make and model (and all have an engine, wheels, doors, and so on). Each car was built from the same set of blueprints and has the same components.\nPython Object-Oriented Programming mode: ON Python, as an Object-Oriented programming language, has these concepts: class and object.\nA class is a blueprint, a model for its objects.\nSo again, a class it is just a model, or a way to define attributes and behavior (as we talked about in the theory section). As an example, a vehicle class has its own attributes that define what objects are vehicles. The number of wheels, type of tank, seating capacity, and maximum velocity are all attributes of a vehicle.\nWith this in mind, let’s look at Python syntax for classes:\nclass Vehicle: pass  We define classes with a class statement — and that’s it. Easy, isn’t it?\nObjects are instances of a class. We create an instance by naming the class.\ncar = Vehicle() print(car) # \u0026lt;__main__.Vehicle instance at 0x7fb1de6c2638\u0026gt;  Here car is an object (or instance) of the class Vehicle.\nRemember that our vehicle class has four attributes: number of wheels, type of tank, seating capacity, and maximum velocity. We set all these attributes when creating a vehicle object. So here, we define our class to receive data when it initiates it:\nclass Vehicle: def __init__(self, number_of_wheels, type_of_tank, seating_capacity, maximum_velocity): self.number_of_wheels = number_of_wheels self.type_of_tank = type_of_tank self.seating_capacity = seating_capacity self.maximum_velocity = maximum_velocity  We use the init method. We call it a constructor method. So when we create the vehicle object, we can define these attributes. Imagine that we love the Tesla Model S, and we want to create this kind of object. It has four wheels, runs on electric energy, has space for five seats, and the maximum velocity is 250km/hour (155 mph). Let’s create this object:\ntesla_model_s = Vehicle(4, 'electric', 5, 250)  Four wheels + electric “tank type” + five seats + 250km/hour maximum speed.\nAll attributes are set. But how can we access these attributes’ values? We send a message to the object asking about them. We call it a method. It’s the object’s behavior. Let’s implement it:\nclass Vehicle: def __init__(self, number_of_wheels, type_of_tank, seating_capacity, maximum_velocity): self.number_of_wheels = number_of_wheels self.type_of_tank = type_of_tank self.seating_capacity = seating_capacity self.maximum_velocity = maximum_velocity def number_of_wheels(self): return self.number_of_wheels def set_number_of_wheels(self, number): self.number_of_wheels = number  This is an implementation of two methods: number_of_wheels and set_number_of_wheels. We call it getter \u0026amp; setter. Because the first gets the attribute value, and the second sets a new value for the attribute.\nIn Python, we can do that using @property (decorators) to define getters and setters. Let’s see it with code:\nclass Vehicle: def __init__(self, number_of_wheels, type_of_tank, seating_capacity, maximum_velocity): self.number_of_wheels = number_of_wheels self.type_of_tank = type_of_tank self.seating_capacity = seating_capacity self.maximum_velocity = maximum_velocity @property def number_of_wheels(self): return self.__number_of_wheels @number_of_wheels.setter def number_of_wheels(self, number): self.__number_of_wheels = number  And we can use these methods as attributes:\ntesla_model_s = Vehicle(4, 'electric', 5, 250) print(tesla_model_s.number_of_wheels) # 4 tesla_model_s.number_of_wheels = 2 # setting number of wheels to 2 print(tesla_model_s.number_of_wheels) # 2  This is slightly different than defining methods. The methods work as attributes. For example, when we set the new number of wheels, we don’t apply two as a parameter, but set the value 2 to number_of_wheels. This is one way to write pythonic getter and setter code.\nBut we can also use methods for other things, like the “make_noise” method. Let’s see it:\nclass Vehicle: def __init__(self, number_of_wheels, type_of_tank, seating_capacity, maximum_velocity): self.number_of_wheels = number_of_wheels self.type_of_tank = type_of_tank self.seating_capacity = seating_capacity self.maximum_velocity = maximum_velocity def make_noise(self): print('VRUUUUUUUM')  When we call this method, it just returns a string _“_VRRRRUUUUM.”\ntesla_model_s = Vehicle(4, 'electric', 5, 250) tesla_model_s.make_noise() # VRUUUUUUUM  Encapsulation: Hiding Information Encapsulation is a mechanism that restricts direct access to objects’ data and methods. But at the same time, it facilitates operation on that data (objects’ methods).\n “Encapsulation can be used to hide data members and members function. Under this definition, encapsulation means that the internal representation of an object is generally hidden from view outside of the object’s definition.” — Wikipedia\n All internal representation of an object is hidden from the outside. Only the object can interact with its internal data.\nFirst, we need to understand how public and non-public instance variables and methods work.\nPublic Instance Variables For a Python class, we can initialize a public instance variable within our constructor method. Let’s see this:\nWithin the constructor method:\nclass Person: def __init__(self, first_name): self.first_name = first_name  Here we apply the first_name value as an argument to the public instance variable.\ntk = Person('TK') print(tk.first_name) # =\u0026gt; TK  Within the class:\nclass Person: first_name = 'TK'  Here, we do not need to apply the first_name as an argument, and all instance objects will have a class attribute initialized with TK.\ntk = Person() print(tk.first_name) # =\u0026gt; TK  Cool. We have now learned that we can use public instance variables and class attributes. Another interesting thing about the public part is that we can manage the variable value. What do I mean by that? Our object can manage its variable value: Get and Set variable values.\nKeeping the Person class in mind, we want to set another value to its first_name variable:\ntk = Person('TK') tk.first_name = 'Kaio' print(tk.first_name) # =\u0026gt; Kaio  There we go. We just set another value (kaio) to the first_name instance variable and it updated the value. Simple as that. Since it’s a public variable, we can do that.\nNon-public Instance Variable  We don’t use the term “private” here, since no attribute is really private in Python (without a generally unnecessary amount of work). — PEP 8\n As the public instance variable , we can define the non-public instance variable both within the constructor method or within the class. The syntax difference is: for non-public instance variables , use an underscore (_) before the variable name.\n “‘Private’ instance variables that cannot be accessed except from inside an object don’t exist in Python. However, there is a convention that is followed by most Python code: a name prefixed with an underscore (e.g. _spam) should be treated as a non-public part of the API (whether it is a function, a method or a data member)” — Python Software Foundation\n Here’s an example:\nclass Person: def __init__(self, first_name, email): self.first_name = first_name self._email = email  Did you see the email variable? This is how we define a non-public variable :\ntk = Person('TK', 'tk@mail.com') print(tk._email) # tk@mail.com   We can access and update it. Non-public variables are just a convention and should be treated as a non-public part of the API.\n So we use a method that allows us to do it inside our class definition. Let’s implement two methods (email and update_email) to understand it:\nclass Person: def __init__(self, first_name, email): self.first_name = first_name self._email = email def update_email(self, new_email): self._email = new_email def email(self): return self._email  Now we can update and access non-public variables using those methods. Let’s see:\ntk = Person('TK', 'tk@mail.com') print(tk.email()) # =\u0026gt; tk@mail.com # tk._email = 'new_tk@mail.com' -- treat as a non-public part of the class API print(tk.email()) # =\u0026gt; tk@mail.com tk.update_email('new_tk@mail.com') print(tk.email()) # =\u0026gt; new_tk@mail.com   We initiated a new object with first_name TK and email tk@mail.com Printed the email by accessing the non-public variable with a method Tried to set a new email out of our class We need to treat non-public variable as non-public part of the API Updated the non-public variable with our instance method Success! We can update it inside our class with the helper method  Public Method With public methods, we can also use them out of our class:\nclass Person: def __init__(self, first_name, age): self.first_name = first_name self._age = age def show_age(self): return self._age  Let’s test it:\ntk = Person('TK', 25) print(tk.show_age()) # =\u0026gt; 25  Great — we can use it without any problem.\nNon-public Method But with non-public methods we aren’t able to do it. Let’s implement the same Person class, but now with a show_age non-public method using an underscore (_).\nclass Person: def __init__(self, first_name, age): self.first_name = first_name self._age = age def _show_age(self): return self._age  And now, we’ll try to call this non-public method with our object:\ntk = Person('TK', 25) print(tk._show_age()) # =\u0026gt; 25   We can access and update it. Non-public methods are just a convention and should be treated as a non-public part of the API.\n Here’s an example for how we can use it:\nclass Person: def __init__(self, first_name, age): self.first_name = first_name self._age = age def show_age(self): return self._get_age() def _get_age(self): return self._age tk = Person('TK', 25) print(tk.show_age()) # =\u0026gt; 25  Here we have a _get_age non-public method and a show_age public method. The show_age can be used by our object (out of our class) and the _get_age only used inside our class definition (inside show_age method). But again: as a matter of convention.\nEncapsulation Summary With encapsulation we can ensure that the internal representation of the object is hidden from the outside.\nInheritance: behaviors and characteristics Certain objects have some things in common: their behavior and characteristics.\nFor example, I inherited some characteristics and behaviors from my father. I inherited his eyes and hair as characteristics, and his impatience and introversion as behaviors.\nIn object-oriented programming, classes can inherit common characteristics (data) and behavior (methods) from another class.\nLet’s see another example and implement it in Python.\nImagine a car. Number of wheels, seating capacity and maximum velocity are all attributes of a car. We can say that an ElectricCar class inherits these same attributes from the regular Car class.\nclass Car: def __init__(self, number_of_wheels, seating_capacity, maximum_velocity): self.number_of_wheels = number_of_wheels self.seating_capacity = seating_capacity self.maximum_velocity = maximum_velocity  Our Car class implemented:\nmy_car = Car(4, 5, 250) print(my_car.number_of_wheels) print(my_car.seating_capacity) print(my_car.maximum_velocity)  Once initiated, we can use all instance variables created. Nice.\nIn Python, we apply a parent class to the child class as a parameter. An ElectricCar class can inherit from our Car class.\nclass ElectricCar(Car): def __init__(self, number_of_wheels, seating_capacity, maximum_velocity): Car.__init__(self, number_of_wheels, seating_capacity, maximum_velocity)  Simple as that. We don’t need to implement any other method, because this class already has it (inherited from Car class). Let’s prove it:\nmy_electric_car = ElectricCar(4, 5, 250) print(my_electric_car.number_of_wheels) # =\u0026gt; 4 print(my_electric_car.seating_capacity) # =\u0026gt; 5 print(my_electric_car.maximum_velocity) # =\u0026gt; 250  Beautiful.\nThat’s it! We learned a lot of things about Python basics:\n How Python variables work How Python conditional statements work How Python looping (while \u0026amp; for) works How to use Lists: Collection | Array Dictionary Key-Value Collection How we can iterate through these data structures Objects and Classes Attributes as objects’ data Methods as objects’ behavior Using Python getters and setters \u0026amp; property decorator Encapsulation: hiding information Inheritance: behaviors and characteristics  Ref : FreeCodeCamp\n"});index.add({'id':69,'href':'/library/tutorials/docs/python/flask/learning-flask/ep-12/','title':"Ep.12 Flask configuration files",'content':" Flask configuration files | Learning Flask Ep. 12 Configuring Flask applications using a config file and classes\nConfiguration is an important part of any appliction and Flask provides several different methods for us to configure our app.\nIn this part of the \u0026ldquo;Learning Flask\u0026rdquo; series, we\u0026rsquo;re going to cover our preferred app configuration method, using a config file with classes.\nLet\u0026rsquo;s get started.\nConfig basics Every Flask application has a global config object which can be accessed via app.config.\nFlask\u0026rsquo;s config object allows us to assign values to configuration variables, which we\u0026rsquo;ll then have access to throughout our application.\nThe global config object can be treated just like a Python dictionary, which we can access and modify.\nThe best way to visually see the config object it to simply print it in one of your routes. Go ahead and add the following to any route:\nprint(app.config)\nYou\u0026rsquo;ll see:\n{'APPLICATION_ROOT': '/', 'DEBUG': True, 'ENV': 'development', 'EXPLAIN_TEMPLATE_LOADING': False, 'JSONIFY_MIMETYPE': 'application/json', 'JSONIFY_PRETTYPRINT_REGULAR': False, 'JSON_AS_ASCII': True, 'JSON_SORT_KEYS': True, 'MAX_CONTENT_LENGTH': None, 'MAX_COOKIE_SIZE': 4093, 'PERMANENT_SESSION_LIFETIME': datetime.timedelta(days=31), 'PREFERRED_URL_SCHEME': 'http', 'PRESERVE_CONTEXT_ON_EXCEPTION': None, 'PROPAGATE_EXCEPTIONS': None, 'SECRET_KEY': None, 'SEND_FILE_MAX_AGE_DEFAULT': datetime.timedelta(seconds=43200), 'SERVER_NAME': None, 'SESSION_COOKIE_DOMAIN': None, 'SESSION_COOKIE_HTTPONLY': True, 'SESSION_COOKIE_NAME': 'session', 'SESSION_COOKIE_PATH': None, 'SESSION_COOKIE_SAMESITE': None, 'SESSION_COOKIE_SECURE': False, 'SESSION_REFRESH_EACH_REQUEST': True, 'TEMPLATES_AUTO_RELOAD': None, 'TESTING': False, 'TRAP_BAD_REQUEST_ERRORS': None, 'TRAP_HTTP_EXCEPTIONS': False, 'USE_X_SENDFILE': False}  These are the default built-in configuration variables, which we can modify and change.\nTo modify any of these variables, we can just assign a new value to the key:\napp.config[\u0026quot;KEY\u0026quot;] = \u0026quot;value\nFor example, let\u0026rsquo;s update the configuration SECRET_KEY variable with the following:\napp.config[\u0026quot;SECRET_KEY\u0026quot;] = \u0026quot;iuhto743yto34iuho287gh78\u0026quot; print(app.config[\u0026quot;SECRET_KEY\u0026quot;])\nYou\u0026rsquo;ll see the following in your terminal:\niuhto743yto34iuho287gh78\nThe SECRET_KEY value will now be permanently modified with the new value.\nThis method of updating config values works well for small applications which don\u0026rsquo;t require many configuration variables.\nHowever it\u0026rsquo;s not very practical when you need to work across multiple environments and set several unique config values which you\u0026rsquo;ll need to access all across your app. Thankfully there\u0026rsquo;s a better way.\nApp Configuration file Flask allows us to create a configuration file, where we can place all of our config values, overwrite the default values and alse create our own.\nThere are a few option for this, however we\u0026rsquo;re just going to cover our preferred method of creating a Python file and creating a Config class.\nGo ahead and create a new file called config.py and place it in the same directory as your application entry point (Where you call app.run())\nHere\u0026rsquo;s the barebones of the config.py file:\nconfig.py\nclass Config(object): DEBUG = False TESTING = False class ProductionConfig(Config): pass class DevelopmentConfig(Config): DEBUG = True class TestingConfig(Config): TESTING = True  We first create the Config class and set some default attributes. In this case, we\u0026rsquo;ve set DEBUG and TESTING to False.\nWe then create 3 more classes, each of which inherits the Config class and attributes.\n ProductionConfig - Is the config class we\u0026rsquo;ll use for running in production DevelopmentConfig - Is the config class we\u0026rsquo;ll use for development TestingConfig - Is the class we\u0026rsquo;ll use for testing  By the nature of class inheritance, all of our 3 subclasses have access to the Config class attributes and can be overwritten in any of the subclasses.\nLet\u0026rsquo;s populate our config file with some attributes:\nclass Config(object): DEBUG = False TESTING = False SECRET_KEY = \u0026quot;B\\xb2?.\\xdf\\x9f\\xa7m\\xf8\\x8a%,\\xf7\\xc4\\xfa\\x91\u0026quot; DB_NAME = \u0026quot;production-db\u0026quot; DB_USERNAME = \u0026quot;admin\u0026quot; DB_PASSWORD = \u0026quot;example\u0026quot; IMAGE_UPLOADS = \u0026quot;/home/username/app/app/static/images/uploads\u0026quot; SESSION_COOKIE_SECURE = True class ProductionConfig(Config): pass class DevelopmentConfig(Config): DEBUG = True DB_NAME = \u0026quot;development-db\u0026quot; DB_USERNAME = \u0026quot;admin\u0026quot; DB_PASSWORD = \u0026quot;example\u0026quot; IMAGE_UPLOADS = \u0026quot;/home/username/projects/my_app/app/static/images/uploads\u0026quot; SESSION_COOKIE_SECURE = False class TestingConfig(Config): TESTING = True DB_NAME = \u0026quot;development-db\u0026quot; DB_USERNAME = \u0026quot;admin\u0026quot; DB_PASSWORD = \u0026quot;example\u0026quot; SESSION_COOKIE_SECURE = False  We\u0026rsquo;ve assigned new values to some of the built-in config variables and created some of our own.\nProduction level attributes have been placed in the parent Config class which will be inherited by the ProductionConfig class, hence the pass.\nNow that we\u0026rsquo;ve created our config file, we\u0026rsquo;ll need to instruct Flask to load it.\nLoading a config file Loading a config file is a simple one liner and should be placed as close to wherever you\u0026rsquo;ve created your app object.\nIt\u0026rsquo;s best practice to load the config as soon as possible, just after your app object is created so any other extension has access to your configuration variables.\nWe load a config file with the from_object() method, for example:\napp.config.from_object(\u0026quot;config_filename.ConfigClass\u0026quot;)\nFor example, if we want to load the DevelopmentConfig class, we would do the following:\napp.config.from_object(\u0026quot;config.DevelopmentConfig\u0026quot;)  For ProductionConfig:\napp.config.from_object(\u0026quot;config.ProductionConfig\u0026quot;)  In our case, we\u0026rsquo;ve placed this line in our __init__.py file, just underneath creating our app object:\napp = Flask(__name__) app.config.from_object(\u0026quot;config.DevelopmentConfig\u0026quot;)  The config has now been registered on the app and is now accessible from any part of your application.\nFor example, you may want to connect to a local database using the DevelopmentConfig settings in a different part or file in your app:\nconnect( name=app.config[\u0026quot;DB_NAME\u0026quot;], username=app.config[\u0026quot;DB_USERNAME\u0026quot;], password=app.config[\u0026quot;DB_PASSWORD\u0026quot;] )  Flask ENV The ENV built-in configuration variable is extremely important and should always be set outside of your application, which we set with FLASK_ENV from the terminal.\nIf you\u0026rsquo;ve been following this series, you\u0026rsquo;ll know that we set this as an environment variable in the terminal before running the flask run command.\nBy default, ENV is set to production which disables DEBUG mode and avoids displaying the interactive debugger to the world, meaning if you just ran your application without explicitly setting FLASK_ENV, it would run in production mode.\nSetting FLASK_ENV=development enables the debugger, which should never, ever be done in production!\nI\u0026rsquo;ve found a nice pattern is to load a config based on the ENV environment variable. We can do so with the following:\napp = Flask(__name__) if app.config[\u0026quot;ENV\u0026quot;] == \u0026quot;production\u0026quot;: app.config.from_object(\u0026quot;config.ProductionConfig\u0026quot;) else: app.config.from_object(\u0026quot;config.DevelopmentConfig\u0026quot;)  This pattern allows us to leave our code alone and control the config environment outside the application by setting the FLASK_ENV environment variable in the terminal.\nTo illustrate this, we\u0026rsquo;ll change our FLASK_ENV and print it after loading the config:\nif app.config[\u0026quot;ENV\u0026quot;] == \u0026quot;production\u0026quot;: app.config.from_object(\u0026quot;config.ProductionConfig\u0026quot;) else: app.config.from_object(\u0026quot;config.DevelopmentConfig\u0026quot;) print(f'ENV is set to: {app.config[\u0026quot;ENV\u0026quot;]}')  In the terminal, run the following to set FLASK_ENV to development\nexport FLASK_ENV=development\nRun flask run and watch your terminal, you\u0026rsquo;ll see:\n$ flask run * Serving Flask app \u0026quot;run.py\u0026quot; (lazy loading) * Environment: development * Debug mode: on ENV is set to: development  Now repeat the process, changing FLASK_ENV to production:\nexport FLASK_ENV=production\nRun flask run again and you\u0026rsquo;ll see:\n$ flask run * Serving Flask app \u0026quot;run.py\u0026quot; * Environment: production WARNING: Do not use the development server in a production environment. Use a production WSGI server instead. * Debug mode: off ENV is set to: production  Flask gives us a big red warning when the environment is set to production, just to drill home the importance of not running the development server in a production environment.\nAlternative config methods Flask is a very flexible framework and provides many ways to configure our application.\nTake a look at the Flask configuration documentation for some alternative options and feel free to experiment with some alternative methods!\nLast modified · 28 Feb 2019\n Written with StackEdit.\n "});index.add({'id':70,'href':'/library/tutorials/docs/python/flask/learning-flask/ep-13/','title':"Ep.13 Uploading files with Flask",'content':" Uploading files with Flask | Learning Flask Ep. 13 Posting, checking and validating file uploads with Flask\nUploading files to the server is often a requirement of a website or web application. Thankfully, Flask makes this relitively simple for us with a few useful functions.\nWe\u0026rsquo;re using Bootstrap 4 CSS in this example but feel free to use any other CSS library, use your own or skip the styling completely.\nLet\u0026rsquo;s get started.\nCreate a new route We\u0026rsquo;ll start by creating a new route which we\u0026rsquo;ll use to render a template containing a form, which users can use to upload an image.\n Tip - You\u0026rsquo;ll need to import render_template from flask if you haven\u0026rsquo;t already\n We\u0026rsquo;ll give the route the URL of /upload-image:\napp/app/views.py\n@app.route(\u0026quot;/upload-image\u0026quot;, methods=[\u0026quot;GET\u0026quot;, \u0026quot;POST\u0026quot;]) def upload_image(): return render_template(\u0026quot;public/upload_image.html\u0026quot;)  We\u0026rsquo;ll be making a POST request to the server, so we\u0026rsquo;ve added methods=[\u0026quot;GET\u0026quot;, \u0026quot;POST\u0026quot;] to the route.\nUpload form Now we need to create our HTML template. We\u0026rsquo;ll call it upload_image.html and place it in the templates/public directory.\nGo ahead and add the following:\napp/app/templates/public/upload_image.html\n{% extends \u0026quot;public/templates/public_template.html\u0026quot; %} {% block title %}Upload{% endblock %} {% block main %} \u0026lt;div class=\u0026quot;container\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col\u0026quot;\u0026gt; \u0026lt;h1\u0026gt;Upload an image\u0026lt;/h1\u0026gt; \u0026lt;hr\u0026gt; \u0026lt;form action=\u0026quot;/upload-image\u0026quot; method=\u0026quot;POST\u0026quot; enctype=\u0026quot;multipart/form-data\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;form-group\u0026quot;\u0026gt; \u0026lt;label\u0026gt;Select image\u0026lt;/label\u0026gt; \u0026lt;div class=\u0026quot;custom-file\u0026quot;\u0026gt; \u0026lt;input type=\u0026quot;file\u0026quot; class=\u0026quot;custom-file-input\u0026quot; name=\u0026quot;image\u0026quot; id=\u0026quot;image\u0026quot;\u0026gt; \u0026lt;label class=\u0026quot;custom-file-label\u0026quot; for=\u0026quot;image\u0026quot;\u0026gt;Select image...\u0026lt;/label\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;button type=\u0026quot;submit\u0026quot; class=\u0026quot;btn btn-primary\u0026quot;\u0026gt;Upload\u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {% endblock %}  We\u0026rsquo;ve created a new child template containing a form with a single input, a file browser.\n Tip - When uploading images via a form with Flask, you must add the enctype attribute to the form with the value multipart/form-data\n Now that we have our form and file browser, we can move on to handling the upload in our route.\nAccessing files in a route To access a file being posted by a fowm, we use request.files provided by the request object. We need to import request from flask. We\u0026rsquo;ll also go ahead and import redirect too. from flask import request, redirect Go ahead and refactor the /upload-image route to the following:\napp/app/views.py\n@app.route(\u0026quot;/upload-image\u0026quot;, methods=[\u0026quot;GET\u0026quot;, \u0026quot;POST\u0026quot;]) def upload_image(): if request.method == \u0026quot;POST\u0026quot;: if request.files: image = request.files[\u0026quot;image\u0026quot;] print(image) return redirect(request.url) return render_template(\u0026quot;public/upload_image.html\u0026quot;)   We\u0026rsquo;re veryfying the request method is POST with if request.method == \u0026quot;POST\u0026quot;: We then veryfy if the request contains files with if request.files: We then store the file as a variable called image using image = request.files[\u0026quot;image\u0026quot;]  Using request.files[\u0026quot;image\u0026quot;], we\u0026rsquo;re able to access the file from the form with the attribute name=\u0026quot;image\u0026quot;\nAdding another file input is as simple as creating another file input field in the HTML form and providing a different value in the name attribute.\nFor example, creating another file input with the attribute name=\u0026quot;image_2\u0026quot; could then be accessed in Flask with request.files[\u0026quot;image_2\u0026quot;]\nPrinting the image variable you\u0026rsquo;ll see:\n\u0026lt;FileStorage: 'example.png' ('image/png')\u0026gt;\nYou\u0026rsquo;ll notice the FileStorage class, followed by the filename and the type of file.\nFileStroage is a wrapper class around incoming files provided by Werkzeug, Flask\u0026rsquo;s underlying HTTP library which handles incoming request data.\nFlask stores incoming file uploads in the webservers memory (If the files are small), otherwise it will store them in a temporary location.\nSaving files We\u0026rsquo;ll start with the quickest and easiest way to save a file.\nYou\u0026rsquo;ll need the os library. Go ahead and import it:\napp/app/views.py\nimport os\nWe should specify a directory to save our uploaded images which we\u0026rsquo;ll add to our app.config object. You don\u0026rsquo;t have to do this but it\u0026rsquo;s best practice.\nEither create a variable in your config file with IMAGE_UPLOADS = /path/to/uploads/folder or asssign it directly to app.config[\u0026quot;IMAGE_UPLOADS\u0026quot;].\n TIp - You should provide a complete path, making sure any directories in the path exist\n In this example, we\u0026rsquo;re going to assign the IMAGE_UPLOADS config attribute in our app but I\u0026rsquo;d recommend you create it in your app config file.\napp/app/views.py\napp.config[\u0026quot;IMAGE_UPLOADS\u0026quot;] = \u0026quot;/mnt/c/wsl/projects/pythonise/tutorials/flask_series/app/app/static/img/uploads\u0026quot;`  As you can see, we have a long but complete path!\nTo save the file, we simply call image.save() and join the path to the uploads folder with the filename using os.join():\napp/app/views.py\nimage.save(os.path.join(app.config[\u0026quot;IMAGE_UPLOADS\u0026quot;], image))  Our route now looks like this:\napp/app/views.py\nfrom flask import request, redirect import os app.config[\u0026quot;IMAGE_UPLOADS\u0026quot;] = \u0026quot;/mnt/c/wsl/projects/pythonise/tutorials/flask_series/app/app/static/img/uploads\u0026quot; @app.route(\u0026quot;/upload-image\u0026quot;, methods=[\u0026quot;GET\u0026quot;, \u0026quot;POST\u0026quot;]) def upload_image(): if request.method == \u0026quot;POST\u0026quot;: if request.files: image = request.files[\u0026quot;image\u0026quot;] image.save(os.path.join(app.config[\u0026quot;IMAGE_UPLOADS\u0026quot;], image.filename)) print(\u0026quot;Image saved\u0026quot;) return redirect(request.url) return render_template(\u0026quot;public/upload_image.html\u0026quot;)  We use image.filename to access the filename of the image and join that with the path to the uploads folder with os.join().\nSave the file and upload an image to see it in action.\nSecuring file uploads At this point, a user could upload any kind of file of any filesize, which is dangerous..\n Tip - NEVER TRUST USER INPUT\n To mitigate any damage our application might receive from a malicius actor or user error, we should consider the following:\n Ensuring the file has a name Ensuring the file type is allowed Ensuring the filename is allowed Ensuring the filesize is allowed  Let\u0026rsquo;s start with the filename.\nEnsuring the file has a filename is a simple fix:\napp/app/views.py\nif image.filename == \u0026quot;\u0026quot;: print(\u0026quot;No filename\u0026quot;) return redirect(request.url)  To ensure the type of file is allowed, we should create a set of allowed extensions in our app.config.\nWe\u0026rsquo;ll just stick to image extensions for now but you\u0026rsquo;ll need to modify this to allow other file types.\nGo ahead and add the following:\napp/app/views.py\napp.config[\u0026quot;ALLOWED_IMAGE_EXTENSIONS\u0026quot;] = [\u0026quot;JPEG\u0026quot;, \u0026quot;JPG\u0026quot;, \u0026quot;PNG\u0026quot;, \u0026quot;GIF\u0026quot;]  This declares we\u0026rsquo;re only going to accept 4 file extensions for image uploads.\nWe should create a function that we can call to confirm this:\napp/app/views.py\ndef allowed_image(filename): # We only want files with a . in the filename if not \u0026quot;.\u0026quot; in filename: return False # Split the extension from the filename ext = filename.rsplit(\u0026quot;.\u0026quot;, 1)[1] # Check if the extension is in ALLOWED_IMAGE_EXTENSIONS if ext.upper() in app.config[\u0026quot;ALLOWED_IMAGE_EXTENSIONS\u0026quot;]: return True else: return False  Ensuring the filename itself isn\u0026rsquo;t dangerous is probably even more important. Luckily for us, Werkzeug provides a handy function called secure_filename that we can call to return a secure filename.\nFirst of all we need to import it:\napp/app/views.py\nfrom werkzeug.utils import secure_filename\nWe can now call it to return a secure filename of our file:\napp/app/views.py\nfilename = secure_filename(image.filename)`  Lastly, we need to modify image.save() to include the safe filename:\napp/app/views.py\nimage.save(os.path.join(app.config[\u0026quot;IMAGE_UPLOADS\u0026quot;], filename))\nPutting everything together, our app now looks like this:\napp/app/views.py\nfrom flask import request, redirect from werkzeug.utils import secure_filename import os app.config[\u0026quot;IMAGE_UPLOADS\u0026quot;] = \u0026quot;/mnt/c/wsl/projects/pythonise/tutorials/flask_series/app/app/static/img/uploads\u0026quot; app.config[\u0026quot;ALLOWED_IMAGE_EXTENSIONS\u0026quot;] = [\u0026quot;JPEG\u0026quot;, \u0026quot;JPG\u0026quot;, \u0026quot;PNG\u0026quot;, \u0026quot;GIF\u0026quot;] def allowed_image(filename): if not \u0026quot;.\u0026quot; in filename: return False ext = filename.rsplit(\u0026quot;.\u0026quot;, 1)[1] if ext.upper() in app.config[\u0026quot;ALLOWED_IMAGE_EXTENSIONS\u0026quot;]: return True else: return False @app.route(\u0026quot;/upload-image\u0026quot;, methods=[\u0026quot;GET\u0026quot;, \u0026quot;POST\u0026quot;]) def upload_image(): if request.method == \u0026quot;POST\u0026quot;: if request.files: image = request.files[\u0026quot;image\u0026quot;] if image.filename == \u0026quot;\u0026quot;: print(\u0026quot;No filename\u0026quot;) return redirect(request.url) if allowed_image(image.filename): filename = secure_filename(image.filename) image.save(os.path.join(app.config[\u0026quot;IMAGE_UPLOADS\u0026quot;], filename)) print(\u0026quot;Image saved\u0026quot;) return redirect(request.url) else: print(\u0026quot;That file extension is not allowed\u0026quot;) return redirect(request.url) return render_template(\u0026quot;public/upload_image.html\u0026quot;)  Lastly, we should ensure the file is of an acceptable filesize.\nJust like we did with specifying the allowed image extensions in the app config. We can do the same with the maximum filesize using the default MAX_CONTENT_LENGTH config variable.\nLet\u0026rsquo;s set our maximum filesize at around 50 megabytes:\napp/app/views.py\napp.config['MAX_CONTENT_LENGTH'] = 50 * 1024 * 1024  This setting will apply globally to all uploads sent to your application, which may or may not be ideal.\nLimiting file upload size I\u0026rsquo;ve been unable to find a way to read the filesize using the Flask or Werkzeug utilities, so had to find another creative way.\nThere may be instances where you need users to upload different file types, all with different filesize restrictions.\nAn alternative to using MAX_CONTENT_LENGTH is to send the filesize as a cookie along with the file, validate the filesize and then decide whether to save the file of not.\nIn order to achieve this, we\u0026rsquo;re going to do the following:\n Create a JavaScript function that saves the filesize as a cookie Set a maximum filesize limit for images in the app config Create a function to validate the image filesize  Let\u0026rsquo;s create the JavaScript function to listen for an oninput event and attach it to the file input field:\n\u0026lt;script\u0026gt; function filesize(elem){ document.cookie = `filesize=${elem.files[0].size}` } \u0026lt;/script\u0026gt;`  We also need to attach the oninput event to the input field and call the function:\n\u0026lt;input type=\u0026quot;file\u0026quot; class=\u0026quot;custom-file-input\u0026quot; name=\u0026quot;image\u0026quot; id=\u0026quot;image\u0026quot; oninput=\u0026quot;filesize(this);\u0026quot;\u0026gt;\nNow, when the user changes the input value, a cookie is saved and send to our app when the form is submitted.\nLet\u0026rsquo;s set a MAX_IMAGE_FILESIZE in our app config:\napp/app/views.py\napp.config[\u0026quot;MAX_IMAGE_FILESIZE\u0026quot;] = 0.5 * 1024 * 1024  We\u0026rsquo;ve set it at around 500,00 bytes for testing purposes.\nNext up, we\u0026rsquo;ll need to create a function to validate the filesize:\napp/app/views.py\ndef allowed_image_filesize(filesize): if int(filesize) \u0026lt;= app.config[\u0026quot;MAX_IMAGE_FILESIZE\u0026quot;]: return True else: return False  Cookies come in as strings, so we pass the filesize cookie to the int() function to convert it.\nWe access cookies using request.cookies, a dictionary like object which we can extract values by key.\nFinally, let\u0026rsquo;s grab the cookie and call the allowed_image_filesize function, passing the value to it:\napp/app/views.py\nif \u0026quot;filesize\u0026quot; in request.cookies: if not allowed_image_filesize(request.cookies[\u0026quot;filesize\u0026quot;]): print(\u0026quot;Filesize exceeded maximum limit\u0026quot;) return redirect(request.url)  Our finished app now looks like this:\napp/app/views.py\nfrom flask import request, redirect from werkzeug.utils import secure_filename import os app.config[\u0026quot;IMAGE_UPLOADS\u0026quot;] = \u0026quot;/mnt/c/wsl/projects/pythonise/tutorials/flask_series/app/app/static/img/uploads\u0026quot; app.config[\u0026quot;ALLOWED_IMAGE_EXTENSIONS\u0026quot;] = [\u0026quot;JPEG\u0026quot;, \u0026quot;JPG\u0026quot;, \u0026quot;PNG\u0026quot;, \u0026quot;GIF\u0026quot;] app.config[\u0026quot;MAX_IMAGE_FILESIZE\u0026quot;] = 0.5 * 1024 * 1024 def allowed_image(filename): if not \u0026quot;.\u0026quot; in filename: return False ext = filename.rsplit(\u0026quot;.\u0026quot;, 1)[1] if ext.upper() in app.config[\u0026quot;ALLOWED_IMAGE_EXTENSIONS\u0026quot;]: return True else: return False def allowed_image_filesize(filesize): if int(filesize) \u0026lt;= app.config[\u0026quot;MAX_IMAGE_FILESIZE\u0026quot;]: return True else: return False @app.route(\u0026quot;/upload-image\u0026quot;, methods=[\u0026quot;GET\u0026quot;, \u0026quot;POST\u0026quot;]) def upload_image(): if request.method == \u0026quot;POST\u0026quot;: if request.files: if \u0026quot;filesize\u0026quot; in request.cookies: if not allowed_image_filesize(request.cookies[\u0026quot;filesize\u0026quot;]): print(\u0026quot;Filesize exceeded maximum limit\u0026quot;) return redirect(request.url) image = request.files[\u0026quot;image\u0026quot;] if image.filename == \u0026quot;\u0026quot;: print(\u0026quot;No filename\u0026quot;) return redirect(request.url) if allowed_image(image.filename): filename = secure_filename(image.filename) image.save(os.path.join(app.config[\u0026quot;IMAGE_UPLOADS\u0026quot;], filename)) print(\u0026quot;Image saved\u0026quot;) return redirect(request.url) else: print(\u0026quot;That file extension is not allowed\u0026quot;) return redirect(request.url) return render_template(\u0026quot;public/upload_image.html\u0026quot;)  Go ahead and try to upload an image over 500,000 bytes. It should print \u0026quot;Filesize exceeded maximum limit\u0026quot;\nLast modified · 28 Feb 2019\n Written with StackEdit.\n "});index.add({'id':71,'href':'/library/tutorials/docs/python/flask/learning-flask/ep-14/','title':"Ep.14 Sending files with Flask",'content':" Sending files with Flask | Learning Flask Ep. 14 How to send and allow users to download files with Flask\nAllowing users to download files from your website of application is an often required feature of any website or application and Flask provides us with some useful function to do so.\nIn this example, we\u0026rsquo;re going to allow our users to download 3 types of files, images, CSV\u0026rsquo;s and PDF\u0026rsquo;s simply by accessing a route and providing a unique id to the resource.\nLet\u0026rsquo;s get started.\nFlask imports First up, we\u0026rsquo;re going to need some imports from flask. Go ahead and import the following:\nfrom flask import send_file, send_from_directory, safe_join, abort\n send_file allows us to send the contents of a file to the client send_from_directory allows us to send a specific file from a directory (Recommended) safe_join allows us to safely join a filename with a file/directory path abort allows us to abort a request and return an HTTP status code of our choosing  Variable rules Before we jump in and create any routes, I want to quickly discuss variable rules which we\u0026rsquo;ve touched on before.\nVariable rules allow values to be passed into the URL using \u0026lt;this_syntax\u0026gt; and allows us to work with variable data coming in via the URL.\nAlthough not a necessity, Flask provides us with some useful converters to add an additional layer of validation to any values soming in via the URL.\nWe an use converters in our URL routes like so:\n@app.route(\u0026quot;/get-image/\u0026lt;image_name\u0026gt;\u0026quot;) # No converter (defaults to string) @app.route(\u0026quot;/get-image/\u0026lt;int:image_number\u0026gt;\u0026quot;) # Integer @app.route(\u0026quot;/get-image/\u0026lt;uuid:image_uuid\u0026gt;\u0026quot;) # uuid  Full list of variable rules: Converter\nFunction\nstring\nAccepts any text without a slash (Default)\nint\nAccepts positive integers\nfloat\nAccepts positive floating point values\npath\nLike string but also accepts slashes\nuuid\nAccepts UUID strings (Universally unique identifier) (e.g 118bc9c3-1af4-4d46-87a1-266db2e64e7a)\nUsing any of the converters listed above will convert the incoming variable into it\u0026rsquo;s related type.\nFor example, if you define a url with \u0026lt;int:some_integer\u0026gt;, Flask will try to convert it into an integer, \u0026lt;path:path_to_some_file\u0026gt; will allow a path like string, including slashes etc..\nDirectory structure Like many other important application configuration variables, we\u0026rsquo;re going to add 3 new entries to our app.config object, each with a path to the directories we\u0026rsquo;ve created to hold the files we want to make available for our users.\nBut before we do so, we\u0026rsquo;re going to create some new directories and add some files for our users to download:\n We\u0026rsquo;re first going to create a new directory inside our static directory called client Inside of the client directory, we\u0026rsquo;ll create 3 more directories, img, csv and pdf We\u0026rsquo;ll then place 2 of each file type in their parent folders.   Note - Feel free to use dirrefent file \u0026amp; directory names, just be sure to update the examples in this guide with your own names\n Our applications directory/file structure now looks like this (pay attention to the client directory in the static directory):\napp ├── app │ ├── __init__.py │ ├── admin_views.py │ ├── static │ │ ├── client │ │ │ ├── csv │ │ │ │ ├── sales_report.csv │ │ │ │ └── users.csv │ │ │ ├── img │ │ │ │ ├── 001.jpg │ │ │ │ └── 002.jpg │ │ │ └── pdf │ │ │ ├── 202de685-1dcb-4272-9aff-3dc10b65ef77.pdf │ │ │ └── 7471eaf0-f85a-48b9-8450-4ccb5d493210.pdf │ │ ├── css │ │ │ └── style.css │ │ ├── img │ │ │ ├── flask.png │ │ │ └── uploads │ │ │ ├── YT-THUMB.png │ │ │ ├── post-img.png │ │ │ └── pythonise_favicon.png │ │ └── js │ │ └── app.js │ ├── templates │ │ ├── admin │ │ │ ├── dashboard.html │ │ │ └── templates │ │ │ └── admin_template.html │ │ ├── macros │ │ │ └── input_macros.html │ │ └── public │ │ ├── guestbook.html │ │ ├── index.html │ │ ├── jinja.html │ │ ├── profile.html │ │ ├── sign_up.html │ │ ├── templates │ │ │ └── public_template.html │ │ └── upload_image.html │ └── views.py ├── config.py ├── requirements.txt └── run.py  Now that we\u0026rsquo;ve got our directories and files in place, let\u0026rsquo;s update our app.config.\nApp config We\u0026rsquo;re going to create 3 new entries in our app.config object, each containing an absolute path to their corresponding directories:\n# The absolute path of the directory containing images for users to download app.config[\u0026quot;CLIENT_IMAGES\u0026quot;] = \u0026quot;/mnt/c/wsl/projects/pythonise/tutorials/flask_series/app/app/static/client/img\u0026quot; # The absolute path of the directory containing CSV files for users to download app.config[\u0026quot;CLIENT_CSV\u0026quot;] = \u0026quot;/mnt/c/wsl/projects/pythonise/tutorials/flask_series/app/app/static/client/csv\u0026quot; # The absolute path of the directory containing PDF files for users to download app.config[\u0026quot;CLIENT_PDF\u0026quot;] = \u0026quot;/mnt/c/wsl/projects/pythonise/tutorials/flask_series/app/app/static/client/pdf\u0026quot;  Now that we\u0026rsquo;ve updated our app config, let\u0026rsquo;s go ahead and create our routes (I\u0026rsquo;d recommend using a config file for this which you can read more about here).\nSend from directory The send_from_directory function is the recommended secure way to allow a user to download a file from our application.\nLet\u0026rsquo;s create our first route and discuss it after:\n@app.route(\u0026quot;/get-image/\u0026lt;image_name\u0026gt;\u0026quot;) def get_image(image_name): try: return send_from_directory(app.config[\u0026quot;CLIENT_IMAGES\u0026quot;], filename=image_name, as_attachment=True) except FileNotFoundError: abort(404)  Let\u0026rsquo;s step through what we\u0026rsquo;ve done:\nWe\u0026rsquo;re using \u0026lt;image_name\u0026gt; in the URL and expect to receive the filename of the image without any slashes. As we haven\u0026rsquo;t set a variable rule, Flask will default to string and not allow any slashes.\n@app.route(\u0026quot;/get-image/\u0026lt;image_name\u0026gt;\u0026quot;)  Tip - As a reminder, if you replaced \u0026lt;image_name\u0026gt; with \u0026lt;path:image_name\u0026gt; and a user went to /get-image/path/to/the/image.png, the my_image variable would be path/to/the/image.png, so use with caution.\nWe then pass the image_name string to the get_image() function.\ndef get_image(image_name):  We setup a try \u0026amp; except block to catch if the filename isn\u0026rsquo;t found on the server by using the FileNotFoundError handler.\ntry: return send_from_directory(app.config[\u0026quot;CLIENT_IMAGES\u0026quot;], filename=image_name, as_attachment=True) except FileNotFoundError: abort(404)  Inside the try: block, we call the send_from_directory function and pass it 3 arguments:\n app.config[\u0026quot;CLIENT_IMAGES\u0026quot;] - The path to the directory containing the images we\u0026rsquo;re allowing our users to download filename=image_name - The image_name variable passed in from the URL as_attachment=True - Allows the client to download the file as an attachment send_from_directory is then returned  Inside the except FileNotFoundError: block, we call abort() and pass it an HTTP status code, a 404 in the case that the file doesn\u0026rsquo;t exist.\nabort(404)\nIf you now go to either http://127.0.0.1:5000/get-image/001.png or http://127.0.0.1:5000/get-image/002.png, you\u0026rsquo;ll instantly download the file!\nIf you try a filename that doesn\u0026rsquo;t exist, you\u0026rsquo;ll get a Not Found error in your browser.\nLet\u0026rsquo;s setup our remaining 2 routes to serve CSV\u0026rsquo;s and PDF\u0026rsquo;s.\nYou\u0026rsquo;ll notice these 2 routes are very similar to the first, with the addition of the filename variable.\nCSV route:\n@app.route(\u0026quot;/get-csv/\u0026lt;csv_id\u0026gt;\u0026quot;) def get_csv(csv_id): filename = f\u0026quot;{csv_id}.csv\u0026quot; try: return send_from_directory(app.config[\u0026quot;CLIENT_CSV\u0026quot;], filename=filename, as_attachment=True) except FileNotFoundError: abort(404)  PDF route:\n@app.route(\u0026quot;/get-pdf/\u0026lt;pdf_id\u0026gt;\u0026quot;) def get_pdf(pdf_id): filename = f\u0026quot;{pdf_id}.csv\u0026quot; try: return send_from_directory(app.config[\u0026quot;CLIENT_PDF\u0026quot;], filename=filename, as_attachment=True) except FileNotFoundError: abort(404)  Both router are identical apart from the addition of their corresponding file extensions in the filename variable, where we\u0026rsquo;ve just used an f string to append the extension to the filename.\nWe\u0026rsquo;ve hard coded the extension this way as we\u0026rsquo;re only allowing that type of file extension from their given route. You could of course omit it and ask the user to provide the file extension too.\nFile path in the URL You may want a nested directory structure within your trusted base directory, where users can provide a path to a file in the URL to retrieve a file.\nLet\u0026rsquo;s say reports is our trusted base directory, containing several sub-directories and files, like so:\n├── app │ ├── __init__.py │ ├── admin_views.py │ ├── static │ │ ├── client │ │ │ └── reports │ │ │ ├── 2017 │ │ │ │ ├── feb │ │ │ │ │ └── sales │ │ │ │ │ └── sales_report.csv │ │ │ │ └── jan │ │ │ │ └── sales │ │ │ │ └── sales_report.csv │ │ │ ├── 2018 │ │ │ │ ├── feb │ │ │ │ │ └── sales │ │ │ │ │ └── sales_report.csv │ │ │ │ └── jan │ │ │ │ └── sales │ │ │ │ └── sales_report.csv │ │ │ └── 2019 │ │ │ ├── feb │ │ │ │ └── sales │ │ │ │ └── sales_report.csv │ │ │ └── jan │ │ │ └── sales │ │ │ └── sales_report.csv  Without using a database, we can create a dynamic system of URL\u0026rsquo;s and allow users to provide a path to a file.\nLet\u0026rsquo;s create a new route and put this into practice, allowing our user to download a report by providing a path in the URL.\nFirst up, we\u0026rsquo;ll add our reports directory to our app.config:\napp.config[\u0026quot;CLIENT_REPORTS\u0026quot;] = \u0026quot;/mnt/c/wsl/projects/pythonise/tutorials/flask_series/app/app/static/client/reports\u0026quot;  Now we\u0026rsquo;ll create the route:\n@app.route(\u0026quot;/get-report/\u0026lt;path:path\u0026gt;\u0026quot;) def get_report(path): try: return send_from_directory(app.config[\u0026quot;CLIENT_REPORTS\u0026quot;], filename=path, as_attachment=True) except FileNotFoundError: abort(404)  We\u0026rsquo;re doing exactly the same as above, with the exception of adding the path prefix to the URL variable.\n@app.route(\u0026quot;/get-report/\u0026lt;path:path\u0026gt;\u0026quot;)  The path should be relative from the reports directory saved in our app.config!\nIf you were to go to /get-report/2018/feb/sales/sales_report.csv, the file would be downloaded. Likewise any non-existent filenames would throw a 404 error.\nSend file and safe join The send_file function is another way to allow users to download and directly access files on your server, however it\u0026rsquo;s not recommended for any application that may take a filename from user sources.\n Tip - Always use send_from_directory where possible.\n The reason? send_file will happily return any file from a specified path! I\u0026rsquo;m sure you wouldn\u0026rsquo;t want users to be able to downlaod any file from your application at their own will. If you do intend on using send_file, make sure your input source is trusted.\nLet\u0026rsquo;s setup a route to show send_file in action, using Flask\u0026rsquo;s safe_join function:\n@app.route(\u0026quot;/get-csv/\u0026lt;path:filename\u0026gt;\u0026quot;) def get_csv(filename): safe_path = safe_join(app.config[\u0026quot;CLIENT_CSV\u0026quot;], filename) try: return send_file(safe_path, as_attachment=True) except FileNotFoundError: abort(404)  We use safe_join and pass it 2 arguments:\n The TRUSTED base directory The UNTRUSTED path to the file  This function will safely join the base directory and zero or more pathnames/filenames and return it to the safe_path variable.\nAgain, you can send files this way but it\u0026rsquo;s recommended to use send_from_directory\nWe then call send_files and pass it the safe_path along with as_attachment=True to allow the user to download the file.\nRead more about sending files in Flask over at the official documentation, linked here\nLast modified · 28 Feb 2019\n Written with StackEdit.\n "});index.add({'id':72,'href':'/library/tutorials/docs/python/flask/learning-flask/ep-15/','title':"Ep.15 Flask cookies",'content':" Flask cookies | Learning Flask Ep. 15 Setting, getting and working with cookies in Flask\nCookies play an important role in most modern websites and web applications, allowing us leave small strings of key/value pairs on the clients browser to help both developers and users by temporarily preserving inportant information such as preferences, unique identifiers, state etc..\nFortunately for us, Flask makes working with cookies very simple.\nLet\u0026rsquo;s get started.\nFlask imports Working with cookies requires a couple of imports from Flask.\n request To set and get cookies make_response - To build a response to attach cookies to  Go ahead and import them at the top of your Flask app:\nfrom flask import request, make_response  Create a new route For this example, we\u0026rsquo;re going to create a simple route with the URL /cookies:\n@app.route(\u0026quot;/cookies\u0026quot;) def cookies(): resp = make_response(\u0026quot;Cookies\u0026quot;) return resp  We\u0026rsquo;ve create a response by passing a simple string to the make_response function resp = make_response(\u0026quot;Cookies\u0026quot;) which is then returned.\nThe exact same thing would be achieved with:\n@app.route(\u0026quot;/cookies\u0026quot;) def cookies(): return \u0026quot;Cookies\u0026quot;  We\u0026rsquo;re not covering make_response in detail in this part, just know that you can build your response ahead of time and modify it before returning it!\nIf you wanted to return a template, you would do the following:\n@app.route(\u0026quot;/cookies\u0026quot;) def cookies(): resp = make_response(render_template(\u0026quot;cookies.html\u0026quot;)) return resp  It\u0026rsquo;s exactly the same as:\n@app.route(\u0026quot;/cookies\u0026quot;) def cookies(): return render_template(\u0026quot;cookies.html\u0026quot;)  The difference is that by using make_response we can build and modify our request ahead of sending it.\nSetting cookies Setting cookies is a simple affair. We simply attach them to our response object.\nThe syntax for setting a cookie is:\nresponse.set_cookie(\u0026quot;key\u0026quot;, \u0026quot;value\u0026quot;)  For example, let\u0026rsquo;s set a cookie with the key of flavor and the value of chocolate chip:\n@app.route(\u0026quot;/cookies\u0026quot;) def cookies(): resp = make_response(\u0026quot;Cookies\u0026quot;) resp.set_cookie(\u0026quot;flavor\u0026quot;, \u0026quot;chocolate chip\u0026quot;) return resp  If you open the developer tools in your browser, head to the storage tab and select cookies from the navigation on the left, you\u0026rsquo;ll see that the flavour cookie has been set!\nCookie parameters You might notice in the developer tools, cookies have several parameters including key, value, domain, path and more, all of which can be set using Flask.\nThe set_cookie function takes the following parameters:\nset_cookie( key, value='', max_age=None, expires=None, path='/', domain=None, secure=False, httponly=False, samesite=None )  See the table below for a breakdown of the cookie parameters available:\n   Parameter Default Description     key required The key (name) of the cookie   value \u0026rdquo;\u0026rdquo; The value of the cookie   max_age None Number of seconds or None (default)   expires None The date of then the cookie expires, must be a datetime object   path None Limits the cookie to a given path   domain None specify a domain able to read the cookie (default is the domain that set it)   secure False If True, the cookie will only be available over HTTPS   httponly False Disallow JavaScript to access the cookie (Limited browser support)   samesite False Limits the scope of where the cookie is accessible to the same site    These options give us a great deal of control of how our cookies work and provide plenty of ways to manage them.\nLet\u0026rsquo;s set the max_age and path keys with 30 seconds and the /cookies path:\nresp.set_cookie( \u0026quot;flavor\u0026quot;, value=\u0026quot;chocolate chip\u0026quot;, max_age=10, path=request.path )  We\u0026rsquo;ve used request.path to access the path of the current route\nIf you check your browsers developer tools console, you\u0026rsquo;ll see our flavor cookie now has an Expires on date along with a value for Path of /cookies.\nWe\u0026rsquo;re going to come back to max_age in a minute with another example, but now let\u0026rsquo;s talk through how to access cookies.\nAccessing cookies Just like we\u0026rsquo;ve used the request object to access many different request values including request.form, request.args, request.files and request.get_json()..\nWe use request.cookies to access the cookies with the following syntax:\ncookies = request.cookies  If you run print(request.cookies) you\u0026rsquo;ll see we get a nicely serialized Python disctionary:\nprint(request.cookies)  {'flavor': 'chocolate chip'}  As we\u0026rsquo;re now working with a dictionary, we can access the individual values by key:\nflavor = cookies.get(\u0026quot;flavor\u0026quot;)   Tip - Use cookies.get(\u0026quot;key\u0026quot;) to access keys in order to mute any key errors when trying to access the dictionary values by key\n Let\u0026rsquo;s set a few more cookies:\nresp.set_cookie(\u0026quot;chocolate type\u0026quot;, \u0026quot;dark\u0026quot;) resp.set_cookie(\u0026quot;chewy\u0026quot;, \u0026quot;yes\u0026quot;)  If we now print request.cookies, we see:\n{'flavor': 'chocolate chip', 'chocolate type': 'dark', 'chewy': 'yes'}  max age You may notice that even after setting max_age in our flavor cookie, it still hangs around in the developer tools.\nGo ahead and comment out the first cookie we set:\n@app.route(\u0026quot;/cookies\u0026quot;) def cookies(): resp = make_response(\u0026quot;Set cookies\u0026quot;) cookies = request.cookies print(cookies) # resp.set_cookie( # \u0026quot;flavor\u0026quot;, # value=\u0026quot;chocolate chip\u0026quot;, # max_age=10, # path=request.path # ) resp.set_cookie(\u0026quot;chocolate type\u0026quot;, \u0026quot;dark\u0026quot;) resp.set_cookie(\u0026quot;chewy\u0026quot;, \u0026quot;yes\u0026quot;) return resp  Refresh the page and give it 10 seconds or so. You\u0026rsquo;ll notice we get the following in the terminal output:\n{'chocolate type': 'dark', 'chewy': 'yes'}  Even though the flavor cookie persists in the browser, it\u0026rsquo;s not send to the server as we explicitly set the max_age variable in the cookie to 10 seconds. It will be deleted when the browser is closed.\n Tip - To delete cookies from your browser, right click on the domain in the cookies tab in the developer tools and click on delete\n Setting cookies from the client Setting cookies using JavaScript is also very simple.\ndocument.cookie = \u0026quot;key=value\u0026quot;;  This will set the most basic type of cookie with no other meta information.\nWe can also provide the cookie with some more parameters like so:\ndocument.cookie = \u0026quot;key=value; expires=DDD, DD MMM YYYY HH:MM:SS UTC\u0026quot;;  You can also add a path with the following:\ndocument.cookie = \u0026quot;key=value; expires=DDD, DD MMM YYYY HH:MM:SS UTC; path=/path\u0026quot;;  You\u0026rsquo;ll then be able to access any of the cookies set client-side using\nrequest.cookies  Sessions Sessions use a special type of signed cookie, but you\u0026rsquo;ll have to read the next episode in this series to learn more!\nLast modified · 28 Feb 2019\n Written with StackEdit.\n "});index.add({'id':73,'href':'/library/tutorials/docs/python/flask/learning-flask/ep-16/','title':"Ep.16 The Flask session object",'content':" The Flask session object | Learning Flask Ep. 16 Using, understanding and decoding the Flask session object, the globally available signed \u0026amp; encoded cookie\nSessions in Flask are a way to store information about a specific user from one request to the next. They work by storing a cryptographically signed cookie on the users browser and decoding it on every request.\nThe sesison object can be treated just like a dictionary that persists across requests, making it an ideal place to store non sensitive user data.\nImportant\n The session object is NOT a secure way to store data. It\u0026rsquo;s a base64 encoded string and can easily be decoded, thus not making it a secure way to save or access sensitive information.\n We\u0026rsquo;ll demonstrate decoding a session cookie shortly.\nIn this example, we\u0026rsquo;re going to create a very unsecure system to allow users to log in and view their profile.\nThe purpose is to demonstrate the session object, not a secure user management system! This guide doesn\u0026rsquo;t include any password hashing, user feedback or even a real database, it\u0026rsquo;s purely for the demonstration of working with sessions.\nLogin page Let\u0026rsquo;s start by creating a template allowing our user to login by providing a username and password:\n{% extends \u0026quot;public/templates/public_template.html\u0026quot; %} {% block title %}sign up{% endblock %} {% block main %} \u0026lt;div class=\u0026quot;container\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col\u0026quot;\u0026gt; \u0026lt;h1\u0026gt;Sign in\u0026lt;/h1\u0026gt; \u0026lt;hr\u0026gt; \u0026lt;form action=\u0026quot;/sign-in\u0026quot; method=\u0026quot;POST\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;form-group\u0026quot;\u0026gt; \u0026lt;label\u0026gt;Username\u0026lt;/label\u0026gt; \u0026lt;input class=\u0026quot;form-control\u0026quot; type=\u0026quot;text\u0026quot; name=\u0026quot;username\u0026quot;\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;form-group\u0026quot;\u0026gt; \u0026lt;label\u0026gt;Password\u0026lt;/label\u0026gt; \u0026lt;input class=\u0026quot;form-control\u0026quot; type=\u0026quot;password\u0026quot; name=\u0026quot;password\u0026quot;\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;button type=\u0026quot;submit\u0026quot; class=\u0026quot;btn btn-primary\u0026quot;\u0026gt;Sign in\u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {% endblock %}  Flask imports We need to import a few things from Flask for this example:\nfrom flask import render_template, request, session, redirect, url_for   render_template - Allows us to render a template to the browser request - To handle the incoming form data and URL session - The session object redirect - Allows us to redirect users to various parts of our app url_for - Constructs URL\u0026rsquo;s from arguments  Mock database We\u0026rsquo;ll also need a mock database containing a couple of users (Feel free to change the values to something more familiar!):\nusers = { \u0026quot;julian\u0026quot;: { \u0026quot;username\u0026quot;: \u0026quot;julian\u0026quot;, \u0026quot;email\u0026quot;: \u0026quot;julian@gmail.com\u0026quot;, \u0026quot;password\u0026quot;: \u0026quot;example\u0026quot;, \u0026quot;bio\u0026quot;: \u0026quot;Some guy from the internet\u0026quot; }, \u0026quot;clarissa\u0026quot;: { \u0026quot;username\u0026quot;: \u0026quot;clarissa\u0026quot;, \u0026quot;email\u0026quot;: \u0026quot;clarissa@icloud.com\u0026quot;, \u0026quot;password\u0026quot;: \u0026quot;sweetpotato22\u0026quot;, \u0026quot;bio\u0026quot;: \u0026quot;Sweet potato is life\u0026quot; } }  We\u0026rsquo;re just using a dictionary containing 2 dictionaries to represent our users database.\nSecret Key The session object requires your app to have a value set for the SECRET_KEY variable. You can either set it in your application config file or provide it somewhere in the file containing your views.\nWhatever decision you make, it\u0026rsquo;s best to declare it as soon as you assign the app variable.\nThe secret key is used to encode the session cookie, so it\u0026rsquo;s advised to use something relitively complex.\nA good place to generate a secret key is with secrets.token_urlsafe() and pass it an integer:\nimport secrets secrets.token_urlsafe(16) OCML3BRawWEUeaxcuKHLpw Go ahead and create the `SECRET_KEY`: app.config[\u0026quot;SECRET_KEY\u0026quot;] = \u0026quot;OCML3BRawWEUeaxcuKHLpw\u0026quot;  Now that we\u0026rsquo;ve got our imports, database and secret key, let\u0026rsquo;s go ahead and build our routes.\nSign in route We need a route to handle signing our users in and setting up the session object:\n@app.route(\u0026quot;/sign-in\u0026quot;, methods=[\u0026quot;GET\u0026quot;, \u0026quot;POST\u0026quot;]) def sign_in(): if request.method == \u0026quot;POST\u0026quot;: req = request.form username = req.get(\u0026quot;username\u0026quot;) password = req.get(\u0026quot;password\u0026quot;) if not username in users: print(\u0026quot;Username not found\u0026quot;) return redirect(request.url) else: user = users[username] if not password == user[\u0026quot;password\u0026quot;]: print(\u0026quot;Incorrect password\u0026quot;) return redirect(request.url) else: session[\u0026quot;USERNAME\u0026quot;] = user[\u0026quot;username\u0026quot;] print(\u0026quot;session username set\u0026quot;) return redirect(url_for(\u0026quot;profile\u0026quot;)) return render_template(\u0026quot;public/sign_in.html\u0026quot;)  As you can see, it\u0026rsquo;s a relitively simple route, just for demostration.\n We check if the username is in the database with if not username in users: If the user exists, we assign the user to user with user = users[username] We check the users password matches the password for the user in the database with if not password == user[\u0026quot;password\u0026quot;]: If either checks fail, we redirect back to the URL of the request using redirect(request.url)  If both checks pass, we assign the users username to the session key USERNAME.\nWe can treat the session object just like a Python dictionary.\nUpdating the session To set a key \u0026amp; value:\nsession[\u0026quot;KEY\u0026quot;] = \u0026quot;VALUE\u0026quot;  In this case, we\u0026rsquo;ve assigned the session USERNAME key to the users username:\nsession[\u0026quot;USERNAME\u0026quot;] = user[\u0026quot;username\u0026quot;]  If you were to print(session) just after we set the USERNAME key, you would see (Assuming the username of \u0026ldquo;julian\u0026rdquo;):\n\u0026lt;SecureCookieSession {'USERNAME': 'julian'}\u0026gt;  You\u0026rsquo;ll also notice the redirect to profile, using:\nreturn redirect(url_for(\u0026quot;profile\u0026quot;))  Redirect takes a URL and redirects the client to it. In this case we\u0026rsquo;ve passed it url_for(\u0026quot;profile\u0026quot;).\nurl_for takes arguments and builds an endpoint, in this case we\u0026rsquo;ve just passed the name of a function, \u0026quot;profile\u0026quot;, to which it builds a URL.\nWe havent\u0026rsquo;s created the profile route yet so let\u0026rsquo;s go ahead and do so:\n### Getting the session object @app.route(\u0026quot;/profile\u0026quot;) def profile(): if not session.get(\u0026quot;USERNAME\u0026quot;) is None: username = session.get(\u0026quot;USERNAME\u0026quot;) user = users[username] return render_template(\u0026quot;public/profile.html\u0026quot;, user=user) else: print(\u0026quot;No username found in session\u0026quot;) return redirect(url_for(\u0026quot;sign_in\u0026quot;))  The session object is global, meaning we can access it from any part of our application and treat it like a dictionary.\nIn the profile route, we do the following:\nif not session.get(\u0026quot;USERNAME\u0026quot;) is None:\n We use session.get(\u0026quot;KEY\u0026quot;) to check if the key exists in the session. If the key doesn\u0026rsquo;t exist, session.get(\u0026quot;KEY\u0026quot;) returns None\nuser = users[session.get(\u0026quot;USERNAME\u0026quot;)]  username = session.get(\u0026quot;USERNAME\u0026quot;) assigns the username variable to the value saved in the session USERNAME key\n We then assign the user from the users dictionary with user = users[username]\nreturn render_template(\u0026quot;public/profile.html\u0026quot;, user=user)`  If the user is found in the session, we call render_template and pass it the profile.html file, along with the user\nelse: print(\u0026quot;No username found in session\u0026quot;) return redirect(url_for(\u0026quot;sign_in\u0026quot;))  If the USERNAME key is not in the session, we redirect back to the sign in page\n  Now we need to create the profile page!\nProfile page Create a new file called profile.html and add the following:\n{% extends \u0026quot;public/templates/public_template.html\u0026quot; %} {% block title %}Profile{% endblock %} {% block main %} \u0026lt;div class=\u0026quot;container\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col\u0026quot;\u0026gt; \u0026lt;h1\u0026gt;Profile\u0026lt;/h1\u0026gt; \u0026lt;hr\u0026gt; \u0026lt;div class=\u0026quot;card\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;card-body\u0026quot;\u0026gt; \u0026lt;h4\u0026gt;{{ user[\u0026quot;username\u0026quot;] }}\u0026lt;/h4\u0026gt; \u0026lt;hr\u0026gt; \u0026lt;p\u0026gt;{{ user[\u0026quot;email\u0026quot;] }}\u0026lt;/p\u0026gt; \u0026lt;p class=\u0026quot;text-muted\u0026quot;\u0026gt;{{ user[\u0026quot;bio\u0026quot;] }}\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {% endblock %}  It\u0026rsquo;s a very simple page containing some of the users details pulled from the database.\nBefore we go ahead and test any of our code, let\u0026rsquo;s create a route to allow our user to logout.\nPopping sessions We need to create a route that clears the USERNAME from the session object.\nAs session is just a Python object, we can pop a key from it!\nLet\u0026rsquo;s create a simple sign out route:\n@app.route(\u0026quot;/sign-out\u0026quot;) def sign_out(): session.pop(\u0026quot;USERNAME\u0026quot;, None) return redirect(url_for(\u0026quot;sign_in\u0026quot;))  To pop a key from the session object:\nsession.pop(\u0026quot;KEY\u0026quot;, None)\nIf a user who\u0026rsquo;s been signed in visits this route, their USERNAME variable will be removed from the session and they\u0026rsquo;ll be redirected to the sign in page.\nWe pass None to session.pop to make sure if a user who isn\u0026rsquo;t signed in visits the sign out route, they will also be redirected to the sign in route without the application throwing an error.\nWithout None, the application throws a KeyError.\nLet\u0026rsquo;s test our app!\nTesting it out Before you sign in, open up the developer tools in your browser and head over to the session storage.\nFor Chrome users:\n Open the developer tools with Ctrl + Shift + i Select the Application tab along the top of the toolbar Select Cookies from the sidebar on the left  For Firefox users:\n Open the developer tools with Ctrl + Shift + i Select the Storage tab along the top of the toolbar Select Cookies from the sidebar on the left  Go to /sign-in, enter one of the usernames and passwords in the database and submit the form.\nYou should see a cookie appear with the name session and an encoded string in the value entry.\nIf all went as it should, you\u0026rsquo;ll be at the profile page for the user and see some of their details.\nNow go to /sign-out in the browser and you should be redirected to the sign in page. The session cookie should also be removed and you\u0026rsquo;ll no longer see it in the developer tools.\nSession best practices As mentioned before, the session object is NOT a secure place to store data as it can be easily decoded.\nSome examples of what you\u0026rsquo;d store in the session object:\n Unique user ID\u0026rsquo;s Publicly visible usernames Tracking ID\u0026rsquo;s User preferences  Ideally, you\u0026rsquo;d store as much as you can in a database or local cache, such as Redis.\nNEVER put passwords or ANY sensitive information in the session object! As we\u0026rsquo;ll now demonstrate why\u0026hellip;\nDecoding the session Log back into the application and open up the developer tools.\nIn the developer tools, head to the Network tab and look for the POST request to the /sign-in route. Click on it.\nUnder Response headers, you\u0026rsquo;ll see Set-Cookie: with a value similar to the following:\nsession=eyJVU0VSTkFNRSI6Imp1bGlhbiJ9.XGxnkw.0-dtOEX9rJYS9MqYgnM9reWr7dY; HttpOnly; Path=/  Copy this string and start an instance of the Python interpreter in your terminal or console.\npython\nImport base64:\nimport base64  We\u0026rsquo;re going to pass the session tookie to base64.b64decode() which requires the string to not be 1 more than a multiple of 4 in character length.\nYou may have to delete a character or 2 from the string until you get the right number of characters.\nDecode the string using base64.b64decode(\u0026quot;session_cookie\u0026quot;):\nbase64.b64decode(\u0026quot;eyJVU0VSTkFNRSI6Imp1bGlhbiJ9.XGxnkw.0-dtOEX9rJYS9MqYgnM9reWr7dY; HttpOnly; Path=\u0026quot;)  After stripping session= and the trailing / from the string, we got the following output:\nb'{\u0026quot;USERNAME\u0026quot;:\u0026quot;julian\u0026quot;}\\\\lg\\x93\\r\\x1d\\xb4\\xe1\\x17\\xf6\\xb2XK\\xd3*b\\t\\xcc\\xf6\\xb7\\x96\\xaf\\xb7X\\x1e\\xdbi:yr=\\xaba'  As you can clearly see, we\u0026rsquo;ve decoded the string and revealed the USERNAME value. The rest is just padding.\nI hope this illustrated why you should never store anything sensitive in the session!\nWrapping up The session object in Flask is an extremely useful tool for remembering and sharing state across an application and should be used with care.\nIt can be accessed globally across your application and in templates using the Jinja {{ session[\u0026quot;KEY\u0026quot;] }} syntax.\nJust remember to set a secret key and keep it safe. Ideally in an app config file and out of version control!\nviews.py\nfrom flask import render_template, request, session, redirect, url_for app.config[\u0026quot;SECRET_KEY\u0026quot;] = \u0026quot;OCML3BRawWEUeaxcuKHLpw\u0026quot; users = { \u0026quot;julian\u0026quot;: { \u0026quot;username\u0026quot;: \u0026quot;julian\u0026quot;, \u0026quot;email\u0026quot;: \u0026quot;julian@gmail.com\u0026quot;, \u0026quot;password\u0026quot;: \u0026quot;example\u0026quot;, \u0026quot;bio\u0026quot;: \u0026quot;Some guy from the internet\u0026quot; }, \u0026quot;clarissa\u0026quot;: { \u0026quot;username\u0026quot;: \u0026quot;clarissa\u0026quot;, \u0026quot;email\u0026quot;: \u0026quot;clarissa@icloud.com\u0026quot;, \u0026quot;password\u0026quot;: \u0026quot;sweetpotato22\u0026quot;, \u0026quot;bio\u0026quot;: \u0026quot;Sweet potato is life\u0026quot; } } @app.route(\u0026quot;/sign-in\u0026quot;, methods=[\u0026quot;GET\u0026quot;, \u0026quot;POST\u0026quot;]) def sign_in(): if request.method == \u0026quot;POST\u0026quot;: req = request.form username = req.get(\u0026quot;username\u0026quot;) password = req.get(\u0026quot;password\u0026quot;) if not username in users: print(\u0026quot;Username not found\u0026quot;) return redirect(request.url) else: user = users[username] if not password == user[\u0026quot;password\u0026quot;]: print(\u0026quot;Incorrect password\u0026quot;) return redirect(request.url) else: session[\u0026quot;USERNAME\u0026quot;] = user[\u0026quot;username\u0026quot;] print(session) print(\u0026quot;session username set\u0026quot;) return redirect(url_for(\u0026quot;profile\u0026quot;)) return render_template(\u0026quot;public/sign_in.html\u0026quot;) @app.route(\u0026quot;/profile\u0026quot;) def profile(): if not session.get(\u0026quot;USERNAME\u0026quot;) is None: username = session.get(\u0026quot;USERNAME\u0026quot;) user = users[username] return render_template(\u0026quot;public/profile.html\u0026quot;, user=user) else: print(\u0026quot;No username found in session\u0026quot;) return redirect(url_for(\u0026quot;sign_in\u0026quot;)) @app.route(\u0026quot;/sign-out\u0026quot;) def sign_out(): session.pop(\u0026quot;USERNAME\u0026quot;, None) return redirect(url_for(\u0026quot;sign_in\u0026quot;))  Last modified · 28 Feb 2019\n Written with StackEdit.\n "});index.add({'id':74,'href':'/library/tutorials/docs/python/flask/learning-flask/ep-17/','title':"Ep.17 Flask message flashing",'content':" Flask message flashing | Learning Flask Ep. 17 Providing feedback and notifications to users using Flask\u0026rsquo;s flash function\nProviding feedback to users of a web application is critical, from notifications and error messages to warnings and progress alerts.\nIf the application doesn\u0026rsquo;t the right level of feedback, chances are the user will become frustrated and end up having a bad experience.\nFortunately for us, Flask provides a simple way to send messages from the server to the client using flash.\nHigh level overview Flask\u0026rsquo;s message flashing system allows us to record a message at any point withing a request, then display it at the start of the next request (and only the next request).\nThis is ideal for cases when we want to provide the user with some feedback based on the actions of their current request, take this scenario for example:\n User attempts to create an account, submitting a form with a username and password The password must be at least 10 characters long, but the one submitted is only 8 Our application rejects the short password and we call flash, passing it a message to let the user know the password was too short We redirect the user back to the account creation page The message is flashed to the user, then destroyed. Provising them with feedback to let them know  Working with flash requires 2 main components:\n Calling the flash function and passing it a message from a route in our application Checking for flashed messages in a template  Now you know a little more about what flash does, it\u0026rsquo;s time for an example.\nUsing flash in a route To work with flash, we need to import it from Flask\nfrom flask import flash  We\u0026rsquo;ll go ahead and create a route which we described in the scenario earlier. An account creation page:\n@app.route(\u0026quot;/sign-up\u0026quot;, methods=[\u0026quot;GET\u0026quot;, \u0026quot;POST\u0026quot;]) def sign_up(): if request.method == \u0026quot;POST\u0026quot;: req = request.form username = req.get(\u0026quot;username\u0026quot;) email = req.get(\u0026quot;email\u0026quot;) password = req.get(\u0026quot;password\u0026quot;) if not len(password) \u0026gt;= 10: flash(\u0026quot;Password length must be at least 10 characters\u0026quot;) return redirect(request.url) flash(\u0026quot;Account created!\u0026quot;) return redirect(request.url) return render_template(\u0026quot;public/sign_up.html\u0026quot;)  This is obviously not a real account creation page! It\u0026rsquo;s just to demonstrate message flashing (We\u0026rsquo;re returning the user back to the sign up page, even on succcess)\nThe part to pay attention to here:\nif not len(password) \u0026gt;= 10: flash(\u0026quot;Password must be at least 10 characters\u0026quot;) return redirect(request.url)  We\u0026rsquo;re performing some basic validation on the length of the password that the user submitted. If it doesn\u0026rsquo;t pass, we call the flash function and pass it a message:\nflash(\u0026quot;Password length must be at least 10 characters\u0026quot;)  Now we need to add something to our template to check for flashed messages.\nIf you\u0026rsquo;re using a base template, it\u0026rsquo;s the ideal place to put it. We\u0026rsquo;re going to put the following in our public_template.html base template. If not, place it somewhere your users will notice and doesn\u0026rsquo;t interfere with the rest of your HTML.\nGetting flashed messages Here\u0026rsquo;s the basic Jinja syntax for getting flashed messages:\n{% with messages = get_flashed_messages() %} {% if messages %} {% for message in messages %} \u0026lt;!-- Do something with the message --\u0026gt; {{ message }} {% endfor %} {% endif %} {% endwith %}   We call with messages = get_flashed_messages() to register any flashed messages {% if messages %} then checkes to see if there are any messages in the queue {% for message in messages %} iterates over the messages (you can call flash more then once to register several messages) We can then do something with the contents of the message using {{ message }}  As it is, this code isn\u0026rsquo;t going to produce anything pretty or useful, so let\u0026rsquo;s go ahead and add some HTML to our flashed messages.\nStyling flashed messages  We\u0026rsquo;re using Bootstrap for styling but feel free to add your own CSS.\n Any code inside the {% for message in messages %} block will be repeated for the amount of flashed messages in the queue and will persist on the page until the next request.\nBootstrap comes with the alert class, featuring a dismissable button to clear the alert, so we\u0026rsquo;ll go ahead and use that. Place it above the main tag of your HTML or just above the form in the sign_up.html page:\n{% with messages = get_flashed_messages() %} {% if messages %} {% for message in messages %} \u0026lt;div class=\u0026quot;alert alert-primary alert-dismissible fade show\u0026quot; role=\u0026quot;alert\u0026quot;\u0026gt; \u0026lt;span\u0026gt;{{ message }}\u0026lt;/span\u0026gt; \u0026lt;button type=\u0026quot;button\u0026quot; class=\u0026quot;close\u0026quot; data-dismiss=\u0026quot;alert\u0026quot; aria-label=\u0026quot;Close\u0026quot;\u0026gt; \u0026lt;span aria-hidden=\u0026quot;true\u0026quot;\u0026gt;\u0026amp;times;\u0026lt;/span\u0026gt; \u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; {% endfor %} {% endif %} {% endwith %}  If you now submit the form with less that 10 characters in the password field, you\u0026rsquo;ll see a nice dismissable alert at the top of your page!\nBut what if we need even more control over the style of our flashed messages? The good news is there\u0026rsquo;s a simple solution.\nFlash categories Flask\u0026rsquo;s Flash function takes up to 2 arguments, a message and a category:\nflash(\u0026quot;message\u0026quot;, \u0026quot;category\u0026quot;)  Both values are not fixed and you\u0026rsquo;ve already seen us pass a message into flash, but what about category?\nWe can provide any value we like as the category argument and access it in our template, meaning we can style flashed messages using the category passed in and drop it into our HTML.\nConsider the following:\nYou have 3 levels of alerts you\u0026rsquo;d like to show to your user.\n Success (Green) Warning (Yellow) Danger (Red)  Using the category argument, we can design flashes depending on the control flow and what feedback we want the user to see.\nTo access the flash category, we need to refactor our previous flash:\n{% with messages = get_flashed_messages(with_categories=true) %} {% if messages %} {% for category, message in messages %} \u0026lt;div class=\u0026quot;alert alert-{{ category }} alert-dismissible fade show\u0026quot; role=\u0026quot;alert\u0026quot;\u0026gt; \u0026lt;span\u0026gt;{{ message }}\u0026lt;/span\u0026gt; \u0026lt;button type=\u0026quot;button\u0026quot; class=\u0026quot;close\u0026quot; data-dismiss=\u0026quot;alert\u0026quot; aria-label=\u0026quot;Close\u0026quot;\u0026gt; \u0026lt;span aria-hidden=\u0026quot;true\u0026quot;\u0026gt;\u0026amp;times;\u0026lt;/span\u0026gt; \u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; {% endfor %} {% endif %} {% endwith %}   Passing with_categories=true to get_flashed_messages(), we\u0026rsquo;re able to access the category of that flash {% for category, message in messages %} unpacks the message and category, which we can then access within the for loop  Depending on your CSS, you should use {{ category }} as a class in your alert. As you can see from our Bootstrap example, we\u0026rsquo;re using it to complete the alert-{{ category }}, which will trigger a different color of the alert.\n alert-success will trigger a green alert alert-warning will trigger an orange alert alert-danger will trigger a red alert  Let\u0026rsquo;s refactor our route to include a category in the flash:\n@app.route(\u0026quot;/sign-up\u0026quot;, methods=[\u0026quot;GET\u0026quot;, \u0026quot;POST\u0026quot;]) def sign_up(): if request.method == \u0026quot;POST\u0026quot;: req = request.form username = req.get(\u0026quot;username\u0026quot;) email = req.get(\u0026quot;email\u0026quot;) password = req.get(\u0026quot;password\u0026quot;) if not len(password) \u0026gt;= 10: flash(\u0026quot;Password must be at least 10 characters\u0026quot;, \u0026quot;warning\u0026quot;) return redirect(request.url) flash(\u0026quot;Account created!\u0026quot;, \u0026quot;success\u0026quot;) return redirect(request.url) return render_template(\u0026quot;public/sign_up.html\u0026quot;)  We haven\u0026rsquo;t changed much, just added the 2 classes to our flash functions:\nflash(\u0026quot;Password must be at least 10 characters\u0026quot;, \u0026quot;warning\u0026quot;) flash(\u0026quot;Account created!\u0026quot;, \u0026quot;success\u0026quot;)  If you now submit the sign up form with both less than and more than 10 characters, you\u0026rsquo;ll see the 2 different styles of flash.\nWarning:\nSuccess:\nFiltering flashes In many cases, you\u0026rsquo;ll want to have more than 1 style of alert. You may have a notification section, warning section and conformation alert in different parts of your templates and in varius styles.\nFiltering flashes allows us to only trigger a flash based on the category it receives! meaning you\u0026rsquo;re not fixed to one style of alert.\nSay you\u0026rsquo;d like to have success notifications show up on the top right of your app and error messages pop up as a modal in the middle of your app, you can create 2 separate flash triggers in your templates to handle each instance.\nThe syntax for filtering flashes is very similar, with only some minor tweaks:\n{% with success = get_flashed_messages(category_filter=[\u0026quot;success\u0026quot;]) %} {% if success %} {%- for message in success %} \u0026lt;div class=\u0026quot;alert alert-success alert-dismissible fade show\u0026quot; role=\u0026quot;alert\u0026quot;\u0026gt; \u0026lt;span\u0026gt;{{ message }}\u0026lt;/span\u0026gt; \u0026lt;button type=\u0026quot;button\u0026quot; class=\u0026quot;close\u0026quot; data-dismiss=\u0026quot;alert\u0026quot; aria-label=\u0026quot;Close\u0026quot;\u0026gt; \u0026lt;span aria-hidden=\u0026quot;true\u0026quot;\u0026gt;\u0026amp;times;\u0026lt;/span\u0026gt; \u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; {% endfor -%} {% endif %} {% endwith %}   By passing category_filter=[\u0026quot;success\u0026quot;] to get_flashed_messages(), we only trigger the flash when a given category is passed into the flash function.  Using filtering, we can create several flashes in our templates and we only need to pass in the actual message of the flash.\nIn this simple example, we\u0026rsquo;ll create 3 flash instances in our template, each with their own filter. One for success, one for warning and one for danger. We\u0026rsquo;ll space these 3 flashes over 3 columns.\n\u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col-sm-4\u0026quot;\u0026gt; {% with errors = get_flashed_messages(category_filter=[\u0026quot;success\u0026quot;]) %} {% if errors %} {%- for message in errors %} \u0026lt;div class=\u0026quot;alert alert-success alert-dismissible fade show\u0026quot; role=\u0026quot;alert\u0026quot;\u0026gt; \u0026lt;span\u0026gt;{{ message }}\u0026lt;/span\u0026gt; \u0026lt;button type=\u0026quot;button\u0026quot; class=\u0026quot;close\u0026quot; data-dismiss=\u0026quot;alert\u0026quot; aria-label=\u0026quot;Close\u0026quot;\u0026gt; \u0026lt;span aria-hidden=\u0026quot;true\u0026quot;\u0026gt;\u0026amp;times;\u0026lt;/span\u0026gt; \u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; {% endfor -%} {% endif %} {% endwith %} \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;col-sm-4\u0026quot;\u0026gt; {% with errors = get_flashed_messages(category_filter=[\u0026quot;warning\u0026quot;]) %} {% if errors %} {%- for message in errors %} \u0026lt;div class=\u0026quot;alert alert-warning alert-dismissible fade show\u0026quot; role=\u0026quot;alert\u0026quot;\u0026gt; \u0026lt;span\u0026gt;{{ message }}\u0026lt;/span\u0026gt; \u0026lt;button type=\u0026quot;button\u0026quot; class=\u0026quot;close\u0026quot; data-dismiss=\u0026quot;alert\u0026quot; aria-label=\u0026quot;Close\u0026quot;\u0026gt; \u0026lt;span aria-hidden=\u0026quot;true\u0026quot;\u0026gt;\u0026amp;times;\u0026lt;/span\u0026gt; \u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; {% endfor -%} {% endif %} {% endwith %} \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;col-sm-4\u0026quot;\u0026gt; {% with errors = get_flashed_messages(category_filter=[\u0026quot;danger\u0026quot;]) %} {% if errors %} {%- for message in errors %} \u0026lt;div class=\u0026quot;alert alert-danger alert-dismissible fade show\u0026quot; role=\u0026quot;alert\u0026quot;\u0026gt; \u0026lt;span\u0026gt;{{ message }}\u0026lt;/span\u0026gt; \u0026lt;button type=\u0026quot;button\u0026quot; class=\u0026quot;close\u0026quot; data-dismiss=\u0026quot;alert\u0026quot; aria-label=\u0026quot;Close\u0026quot;\u0026gt; \u0026lt;span aria-hidden=\u0026quot;true\u0026quot;\u0026gt;\u0026amp;times;\u0026lt;/span\u0026gt; \u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; {% endfor -%} {% endif %} {% endwith %} \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt;  You\u0026rsquo;ll see, we\u0026rsquo;re filtering the flashes using our 3 categories, with a specific flash for each category.\nCalling all 3 categories of flash in our route:\nflash(\u0026quot;Success!\u0026quot;, \u0026quot;success\u0026quot;) flash(\u0026quot;This is a warning\u0026quot;, \u0026quot;warning\u0026quot;) flash(\u0026quot;DANGER DANGER\u0026quot;, \u0026quot;danger\u0026quot;)  Produces the following:\nWrapping up Flashing provides us with a simple and flexible way to provide users with valuable feedback and can be styled freely.\nUsing filters allows us to customize flashes depending on the category passed to it, keeping users happy and notified!\n Last modified · 28 Feb 2019\nSource : .\n "});index.add({'id':75,'href':'/library/tutorials/docs/python/flask/learning-flask/ep-18/','title':"Ep.18 Flask error handling",'content':" Flask error handling | Learning Flask Ep. 18 Manually throwing errors, creating custom error handlers and rendering error templates\nIn a perfect world, our applications would never have errors and our users would use our application just as we intended, however it\u0026rsquo;s not a perfect world and there will be bugs in our code and users will always be unpredictable!\nCatching and handling errors ensures our users aren\u0026rsquo;t confused when something goes wrong, also giving them a way to get home or back to the content.\nFlask provides us with a simple way to throw and catch errors, along with displaying a custom HTML template for each error. When an HTTP error is raised, for example a 404 Not Found or 500 Internal Server Error, we can catch it, handle it and return something relevant to the exception.\nThrowing errors There may be times when you need to manually throw an error, for example if an unauthenticated user was trying to access a protected route or if a certain request method isn\u0026rsquo;t allowed.\nFlask provides us with the abort() function, to which we can supply the HTTP status code related to the error.\nWe need to import it from Flask:\nfrom flask import abort  To use abort, simply call it and pass in the HTTP status code:\nabort(404) # Not found abort(405) # Method Not allowed abort(500) # Internal Server Error  If a user encounters the abort function, the error will trigger and the browser will display its default page/text for that error (Which normally look quite ugly)\nA better solution is to setup an handler to let us decide what happens when one of these errors are encountered.\nCustom error handlers Just as we can throw errors on demand, we can handle them using the errorhandler() decorator and attaching it to our app instance.\nThe syntax for a custom error handler:\n@app.errorhandler(STATUS_CODE) def function_name(error): # Do something here.. # Log the error.. # Send en email.. # Etc .. return render_template(\u0026quot;handler.html\u0026quot;), STATUS_CODE  For example, an error handler for a 403 Forbidden status code:\n@app.errorhandler(403) def forbidden(e): return render_template(\u0026quot;error_handlers/forbidden.html\u0026quot;), 403  Not found 404:\nfrom flask import request @app.errorhandler(404) def page_not_found(e): app.logger.info(f\u0026quot;Page not found: {request.url}\u0026quot;) return render_template(\u0026quot;error_handlers/404.html\u0026quot;), 404  Server error 500:\nfrom flask import request @app.errorhandler(500) def server_error(e): email_admin(message=\u0026quot;Server error\u0026quot;, url=request.url, error=e) app.logger.error(f\u0026quot;Server error: {request.url}\u0026quot;) return render_template(\u0026quot;error_handlers/500.html\u0026quot;), 500  Error templates Default browser error pages aren\u0026rsquo;t pretty:\nA better looking example of a 404 page from the Mozilla developer site:\nJust as you would normally return a template in a route using render_template() and passing it an HTML file, we\u0026rsquo;ve done the same in our custom error handlers.\nWe\u0026rsquo;ve created our error HTML files and placed them in a directory called error_handlers, giving each HTML file the name corresponding to the error which we then call with render_template, passing it the path to the relevant handler file.\nWrapping up Throwing strategic errors is as simple as calling abort() and passing it an HTTP status code.\nHandling errors and creating custom error pages is also simple with @app.errorhandler(STATUS) and writing a function to handle the error and return a relevant response.\nLast modified · 28 Feb 2019\n Source : .\n "});index.add({'id':76,'href':'/library/tutorials/docs/python/flask/learning-flask/ep-19/','title':"Ep.19 Flask HTTP methods",'content':" Flask HTTP methods | Learning Flask Ep. 19 Understanding when and where to use GET, POST, PUT, PATCH, DELETE and a brief introduction to HTTP methods in Flask\nFlask supports the common HTTP methods, including GET, POST, PUT, PATCH, DELETE and working with them is extremely simple, allowing us to build URL\u0026rsquo;s and endpoints which only listen for certain HTTP methods.\nIn this part of the \u0026ldquo;Learning Flask\u0026rdquo; series, we\u0026rsquo;re going to build a simple application to demonstrate working with the 5 HTTP methods listed above, along with examples of when and how to use them.\nIf you\u0026rsquo;re new to programming or new to working on web, getting to know the HTTP methods and understanding the basics of HTTP is extremely valuable, so I\u0026rsquo;d suggest reading up on it after you\u0026rsquo;re done here.\nThis guide isn\u0026rsquo;t designed to be an in depth tutorial on HTTP, however it should give you enough information to use them in your Flask applications and hopefully you\u0026rsquo;ll learn something new!\nHTTP basics The \u0026ldquo;Hyper text transfer protocol\u0026rdquo; AKA HTTP is the world wide protocol for how we communicate and send/receive information on the web.\nIt works on a \u0026ldquo;Request/Response\u0026rdquo; protocol, where a client makes a request to a web server which then returns a response.\nFor example, when you clicked on this very URL, your browser (The client) made a request to the Pythonise web server, which internally triggered a series of events to return a response, which is the HTML you\u0026rsquo;re reading now.\nLike I said, this is a very basic introduction to HTTP and we\u0026rsquo;re not going to go into too much detail on it in this guide. For more information, the Wikipedia page is a good place to start.\nHTTP status codes When something goes well, it\u0026rsquo;s nice to get a pat on the back, likewise when something doesn\u0026rsquo;t go as planned, it helps to know why so you can put it right.\nFeedback is very important and it\u0026rsquo;s no different on the web!\nHTTP status codes are used as a feedback system, issued by the server in response to a request from the client to indicate the status of the request.\nIf the request went well, the server returns a status code to the client to indicate that everything is OK, likewise a bad request or error will result in a different code to tell the client that something didn\u0026rsquo;t go as expected.\nIf you\u0026rsquo;ve spend any time on the web, you\u0026rsquo;ve most likely come across these status codes yourself.\nEver clicked on a link and got a 404 NOT FOUND? That\u0026rsquo;s the web servers way of saying \u0026ldquo;I got your message, but whatever you\u0026rsquo;re looking for, I don\u0026rsquo;t have it\u0026rdquo;. However rather than saying that it simply returns a 404 status code (Which is much more friendly for machines to understand 🤖)\nHTTP status codes are made up of 3 digits that fall into 5 categories, with each category representing a certain class of code.\nThe first digit is the category and the 5 categories correspond to the following class:\n 1xx - Informational 2xx - Success 3xx - Redirection 4xx - Client errors 5xx - Server errors  The example of the 404 status code falls under the \u0026ldquo;client error\u0026rdquo; category, where the client tried to request something that doesn\u0026rsquo;t exist on the server.\nThe last 2 digits of the code don\u0026rsquo;t fall under any kind of class or category, but are used to provide more information and context.\nAgain to use the 404 example, the last 2 digits refer to NOT FOUND, giving more context to the type of client error.\nA full list of HTTP status codes can be found here at the Wiki.\nHTTP methods The method is the type of action you want the request to perform and is sent from the client to the server on every request.\nThere are several HTTP methods but we\u0026rsquo;re only going to cover 5 in this article:\n GET - Used to fetch the specified resource POST - Used to create new data at the specified resource PUT - Used to create new data or replace existing data at the specified resource PATCH - Used to create new data or update/modify existing data at the specified resource DELETE - Used to delele existing data at the specified resource  Requesting a URL is an example of a GET request, where your browser makes a request for resources at a specified location (the URL) and the server returns some HTML. GET requests are \u0026ldquo;safe\u0026rdquo; as they aren\u0026rsquo;t able to modify state or data on the server.\nAn example use case of a POST request would be creating a new account on a website or application, whereby the resource doesn\u0026rsquo;t already exist.\nFlask HTTP methods By default, routes created with @app.route(/example) only listen and respond to GET requests and have to be instructed to listen and respond to other methods using the methods keyword \u0026amp; passing it a list of request methods.\nLet\u0026rsquo;s explore some common use cases for GET requests.\nGET requests Ubiquitously used in Flask applications, the GET method is used to return data at a specified resource/location.\nReturning text Possible one of the most simple routes you can write in a flask app simply returns a string:\n@app.route(\u0026quot;/get-text\u0026quot;) def get_text(): return \u0026quot;some text\u0026quot;`  Rendering templates A very common use case for a GET request is to return some HTML:\nfrom flask import render template @app.route(\u0026quot;/\u0026quot;) def index(): return render_template(\u0026quot;index.html\u0026quot;)  Handlinq query strings No different from either of the 2 previous examples, with the addition of handling a query string in the URL and returning a formatted string to the client:\nfrom flask import request @app.route(\u0026quot;/qs\u0026quot;) def qs(): if request.args: req = request.args return \u0026quot; \u0026quot;.join(f\u0026quot;{k}: {v} \u0026quot; for k, v in req.items()) return \u0026quot;No query\u0026quot;  Requesting /qs?name=john\u0026amp;language=python returns the string name: john language: python.\nFetching resources Again, not really any different from the previous examples, just in this case fetching and returning a resource as a JSON string. We\u0026rsquo;ve also created a mock database called stock:\nfrom flask import make_response, jsonify stock = { \u0026quot;fruit\u0026quot;: { \u0026quot;apple\u0026quot;: 30, \u0026quot;banana\u0026quot;: 45, \u0026quot;cherry\u0026quot;: 1000 } } @app.route(\u0026quot;/stock\u0026quot;) def get_stock(): res = make_response(jsonify(stock), 200) return res  Extending the previous example with some URL variables, ding a lookup and returning a JSON response (Note the use of the 404 if the collection or member is not found):\n@app.route(\u0026quot;/stock/\u0026lt;collection\u0026gt;\u0026quot;) def get_collection(collection): \u0026quot;\u0026quot;\u0026quot; Returns a collection from stock \u0026quot;\u0026quot;\u0026quot; if collection in stock: res = make_response(jsonify(stock[collection]), 200) return res res = res = make_response(jsonify({\u0026quot;error\u0026quot;: \u0026quot;Not found\u0026quot;}), 404) return res @app.route(\u0026quot;/stock/\u0026lt;collection\u0026gt;/\u0026lt;member\u0026gt;\u0026quot;) def get_member(collection, member): \u0026quot;\u0026quot;\u0026quot; Returns the qty of the collection member \u0026quot;\u0026quot;\u0026quot; if collection in stock: member = stock[collection].get(member) if member: res = make_response(jsonify(member), 200) return res res = make_response(jsonify({\u0026quot;error\u0026quot;: \u0026quot;Not found\u0026quot;}), 404) return res res = res = make_response(jsonify({\u0026quot;error\u0026quot;: \u0026quot;Not found\u0026quot;}), 404) return res  In summary, use GET requests when you just need to return resources to the client and NOT make any changes to the state/data of your application.\nGET and POST In many cases such as rendering forms, you\u0026rsquo;ll need a route to handle more than just GET requests.\nMaking any request other than GET to a route without the methods argument and a list of methods will result in a 405 METHOD NOT ALLOWED HTTP status code, as methods must be declared for the route to respond to.\nAdding multiple request methods to a route is done with the following:\n@app.route(\u0026quot;/example\u0026quot;, methods=[\u0026quot;METHOD_A\u0026quot;, \u0026quot;METHOD_B\u0026quot;]) # GET POST PUT PATCH DELETE etc..  The route will now listen and respond to both methods provided which means we have to put in some control flow to handle each type of request.\nFortunately this is made easy using the request object, in particular the request.method attribute which returns the method for the current request.\nThis verbose and silly example illustrates the logic, assuming we want to listen for GET and POST requests:\n@app.route(\u0026quot;/log-in\u0026quot;, methods=[\u0026quot;GET\u0026quot;, \u0026quot;POST\u0026quot;]) def log_in(): if request.method == \u0026quot;POST\u0026quot;: # Attempt the login \u0026amp; do something else elif request.method == \u0026quot;GET\u0026quot;: return render_template(\u0026quot;log_in.html\u0026quot;)  As Flask routes default to GET requests, we can remove the elif statement and let Flask return the template:\n@app.route(\u0026quot;/log-in\u0026quot;, methods=[\u0026quot;GET\u0026quot;, \u0026quot;POST\u0026quot;]) def log_in(): if request.method == \u0026quot;POST\u0026quot;: # Only if the request method is POST # attempt the login \u0026amp; do something else # Otherwise default to this return render_template(\u0026quot;log_in.html\u0026quot;)`  A working example can be seen below where we\u0026rsquo;re rendering a template which a user can then use to add a new collection to our stock database:\n@app.route(\u0026quot;/add-collection\u0026quot;, methods=[\u0026quot;GET\u0026quot;, \u0026quot;POST\u0026quot;]) def add_collection(): \u0026quot;\u0026quot;\u0026quot; Renders a template if request method is GET. Creates a collection if request method is POST and if collection doesn't exist \u0026quot;\u0026quot;\u0026quot; if request.method == \u0026quot;POST\u0026quot;: req = request.form collection = req.get(\u0026quot;collection\u0026quot;) member = req.get(\u0026quot;member\u0026quot;) qty = req.get(\u0026quot;qty\u0026quot;) if collection in stock: message = \u0026quot;Collection already exists\u0026quot; return render_template(\u0026quot;add_collection.html\u0026quot;, stock=stock, message=message) stock[collection] = {member: qty} message = \u0026quot;Collection created\u0026quot; return render_template(\u0026quot;add_collection.html\u0026quot;, stock=stock, message=message) return render_template(\u0026quot;add_collection.html\u0026quot;, stock=stock)  POST requests Flask routes listen for GET requests by default, so we must implicitly instruct them to listen for anything other than GET.\nIn the example below, we\u0026rsquo;ve passed methods=[\u0026quot;POST\u0026quot;] to the @app.route() decorator, meaning this route will ONLY respond to POST requests:\n@app.route(\u0026quot;/stock/\u0026lt;collection\u0026gt;\u0026quot;, methods=[\u0026quot;POST\u0026quot;]) def create_collection(collection): \u0026quot;\u0026quot;\u0026quot; Creates a new collection if it doesn't exist \u0026quot;\u0026quot;\u0026quot; req = request.get_json() if collection in stock: res = make_response(jsonify({\u0026quot;error\u0026quot;: \u0026quot;Collection already exists\u0026quot;}), 400) return res stock.update({collection: req}) res = make_response(jsonify({\u0026quot;message\u0026quot;: \u0026quot;Collection created\u0026quot;}), 201) return res  We\u0026rsquo;re checking to see if the collection variable (passed in via the URL) is in our stock database and if not, create it, otherwise return a 400 BAD REQUEST to indicate the resource already exists.\nPOST requests should be used to create NEW resources (New users, devices, posts, articles, datasets etc..)\nAgain, if you tried to access this resource from the browser, you\u0026rsquo;d be greeted with a 405 METHOD NOT ALLOWED status as we\u0026rsquo;ve not provided GET as one of the available request methods to listen for.\nPUT requests PUT requests are similar to POST requests but serve a very different purpose.\nAs we explained earlier, PUT should be used to create or replace a resource, meaning if it doesn\u0026rsquo;t exist - create it, however if it does exist, replace it.\nCheck out the example below:\n@app.route(\u0026quot;/stock/\u0026lt;collection\u0026gt;\u0026quot;, methods=[\u0026quot;PUT\u0026quot;]) def put_collection(collection): \u0026quot;\u0026quot;\u0026quot; Replaces or creates a collection \u0026quot;\u0026quot;\u0026quot; req = request.get_json() if collection in stock: stock[collection] = req res = make_response(jsonify({\u0026quot;message\u0026quot;: \u0026quot;Collection replaced\u0026quot;}), 200) return res stock[collection] = req res = make_response(jsonify({\u0026quot;message\u0026quot;: \u0026quot;Collection created\u0026quot;}), 201) return res  Since PUT requests shouldn\u0026rsquo;t care about the existing data or resource, we\u0026rsquo;ve decided to go ahead and create the resource with no regard for any existing data. The only dirrerence in the logic is the HTTP status code.\nIf the collection DIDN\u0026rsquo;T exist, we\u0026rsquo;re returning a 201 CREATED status. Whereas if the collection DID exist, we\u0026rsquo;re returning a 200 OK to indicate that the collection has been replaced.\n It\u0026rsquo;s probably bad design to replace an entire collection using the PUT request, but for demonstrational purposes it\u0026rsquo;ll do. A better solution would be to use PUT to replace or create a value for one of the members in the collection.\n PATCH requests We\u0026rsquo;re using a PATCH request to update OR create a resource in our stock database:\n@app.route(\u0026quot;/stock/\u0026lt;collection\u0026gt;\u0026quot;, methods=[\u0026quot;PATCH\u0026quot;]) def patch_collection(collection): \u0026quot;\u0026quot;\u0026quot; Updates or creates a collection \u0026quot;\u0026quot;\u0026quot; req = request.get_json() if collection in stock: for k, v in req.items(): stock[collection][k] = v res = make_response(jsonify({\u0026quot;message\u0026quot;: \u0026quot;Collection updated\u0026quot;}), 200) return res stock[collection] = req res = make_response(jsonify({\u0026quot;message\u0026quot;: \u0026quot;Collection created\u0026quot;}), 201) return res  Rather than replace the collection entirely, we\u0026rsquo;re iterating over the keys and values in the request body and updating the values in the collection, only creating new members if they don\u0026rsquo;t exist.\nAnd just like in PUT, we\u0026rsquo;re returning a 200 if the collection was updated and a 201 if the collection was created.\nLet\u0026rsquo;s cover the last request method in this article, DELETE.\nDelete requests Just like it says on the tin, DELETE requests should be used to delete a resource.\nAs per the rest of the examples, we provide methods=[\u0026quot;DELETE\u0026quot;] in the @app.route() decorator, meaning this route will only listen for that specific method.\nIn the 2 examples below, you\u0026rsquo;ll see we\u0026rsquo;re deleting a collection and deleting individual members from a collection with 2 separate routes:\n@app.route(\u0026quot;/stock/\u0026lt;collection\u0026gt;\u0026quot;, methods=[\u0026quot;DELETE\u0026quot;]) def delete_collection(collection): \u0026quot;\u0026quot;\u0026quot; If the collection exists, delete it \u0026quot;\u0026quot;\u0026quot; if collection in stock: del stock[collection] res = make_response(jsonify({}), 204) return res res = make_response(jsonify({\u0026quot;error\u0026quot;: \u0026quot;Collection not found\u0026quot;}), 404) return res @app.route(\u0026quot;/stock/\u0026lt;collection\u0026gt;/\u0026lt;member\u0026gt;\u0026quot;, methods=[\u0026quot;DELETE\u0026quot;]) def delete_member(collection, member): \u0026quot;\u0026quot;\u0026quot; If the collection exists and the member exists, delete it \u0026quot;\u0026quot;\u0026quot; if collection in stock: if member in stock[collection]: del stock[collection][member] res = make_response(jsonify({}), 204) return res res = make_response(jsonify({\u0026quot;error\u0026quot;: \u0026quot;Member not found\u0026quot;}), 404) return res res = make_response(jsonify({\u0026quot;error\u0026quot;: \u0026quot;Collection not found\u0026quot;}), 404) return res  On deletion, we\u0026rsquo;re returning a 204 NO CONTENT status code to indicate a successful transaction and we have no content to return.\nIf the resource isn\u0026rsquo;t found, I/e the collection or member doesn\u0026rsquo;t exist, we\u0026rsquo;re returning a 404 NOT FOUND.\nWrapping up The code snippets shown here were designed to demonstrate how to work with some of the common request methods in Flask, rather than be examples of how to write a REST API, so take the examples with a pinch of salt.\nrestfulapi.net is a great place to learn more about API design and using the various request methods, along with the 2 Wikipedia links below.\nI hope you learned something new!\n https://en.wikipedia.org/wiki/List_of_HTTP_status_codes https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol  Last modified · 28 Feb 2019\n Source : .\n "});index.add({'id':77,'href':'/library/tutorials/docs/backup/example/2nd/','title':"Docs\\backup\\example\\2nd\\",'content':" 2nd Level of Menu Cognita laeva illo fracta Lorem markdownum pavent auras, surgit nunc cingentibus libet Laomedonque que est. Pastor An arbor filia foedat, ne fugit aliter, per. Helicona illas et callida neptem est Oresitrophos caput, dentibus est venit. Tenet reddite famuli praesentem fortibus, quaeque vis foret si frondes gelidos gravidae circumtulit inpulit armenta nativum.\n Te at cruciabere vides rubentis manebo Maturuit in praetemptat ruborem ignara postquam habitasse Subitarum supplevit quoque fontesque venabula spretis modo Montis tot est mali quasque gravis Quinquennem domus arsit ipse Pellem turis pugnabant locavit  "});index.add({'id':78,'href':'/library/tutorials/docs/python/flask/learning-flask/ep-20/','title':"Ep.20 The request object",'content':" The request object | Learning Flask Ep. 20 Exploring the Flask request object\nThe Flask request object gives us access to all of the incoming request data, nicely parsed and ready for us to work with.\nThe request object is available globally and can be accessed to get information about the current request, ensuring we only get data from the active thread.\nIf you\u0026rsquo;ve been following along with the \u0026ldquo;Learning Flask\u0026rdquo; series, you\u0026rsquo;ve seen the request object in action, from parsing incoming form data and handling the various request methods, however there\u0026rsquo;s much more to explore.\nIn this part, we\u0026rsquo;re going to create a couple of routes to take a look at some of the useful and interesting ways to work with the Flask request object.\nImporting request To work with it, you\u0026rsquo;ll first need to import it from Flask:\nfrom flask import request  The request object To take a look at the request object:\n@app.route(\u0026quot;/the/request/object\u0026quot;) def public_index(): print(request.__dict__.items()) return render_template(\u0026quot;index.html\u0026quot;)  dict_items([('environ', {'wsgi.version': (1, 0), 'wsgi.url_scheme': 'http', 'wsgi.input': \u0026lt;_io.BufferedReader name=6\u0026gt;, 'wsgi.errors': \u0026lt;_io.TextIOWrapper name='\u0026lt;stderr\u0026gt;' mode='w' encoding='UTF-8'\u0026gt;, 'wsgi.multithread': True, 'wsgi.multiprocess': False, 'wsgi.run_once': False, 'werkzeug.server.shutdown': \u0026lt;function WSGIRequestHandler.make_environ.\u0026lt;locals\u0026gt;.shutdown_server at 0x7f0740152e18\u0026gt;, 'SERVER_SOFTWARE': 'Werkzeug/0.14.1', 'REQUEST_METHOD': 'GET', 'SCRIPT_NAME': '', 'PATH_INFO': '/', 'QUERY_STRING': '', 'REMOTE_ADDR': '127.0.0.1', 'REMOTE_PORT': 52087, 'SERVER_NAME': '127.0.0.1', 'SERVER_PORT': '5000', 'SERVER_PROTOCOL': 'HTTP/1.1', 'HTTP_HOST': '127.0.0.1:5000', 'HTTP_USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:65.0) Gecko/20100101 Firefox/65.0', 'HTTP_ACCEPT': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8', 'HTTP_ACCEPT_LANGUAGE': 'en-GB,en;q=0.5', 'HTTP_ACCEPT_ENCODING': 'gzip, deflate', 'HTTP_REFERER': 'http://127.0.0.1:5000/', 'HTTP_DNT': '1', 'HTTP_CONNECTION': 'keep-alive', 'HTTP_UPGRADE_INSECURE_REQUESTS': '1', 'HTTP_PRAGMA': 'no-cache', 'HTTP_CACHE_CONTROL': 'no-cache', 'werkzeug.request': \u0026lt;Request 'http://127.0.0.1:5000/' [GET]\u0026gt;}), ('shallow', False), ('view_args', {}), ('url_rule', \u0026lt;Rule '/' (OPTIONS, HEAD, GET) -\u0026gt; public_index\u0026gt;), ('cookies', {})])  Thankfully for us, Flask provides a much cleaner way to work with the request object.\nRequest method request.method returns the method used in the current request - GET, POST, PUT, DELETE etc..\nFrequently used as a handler to trigger certain code blocks to run based on the type of incoming request, you\u0026rsquo;ll often see something similar to this:\n@app.route(\u0026quot;/log-in\u0026quot;, methods=[\u0026quot;GET\u0026quot;, \u0026quot;POST\u0026quot;]) def login(): if request.method == \u0026quot;POST\u0026quot;: # Get the form data # Do something else # Otherwise default to render_template return render_template(\u0026quot;log-in.html\u0026quot;)  Cookies request.cookies returns a dictionary with key-value pairs of any cookies sent in the request:\napp.py\n@app.route(\u0026quot;/\u0026quot;) def public_index(): cookies = request.cookies print(cookies) return render_template(\u0026quot;index.html\u0026quot;)  Terminal\n{'chocolate_chip': 'definitely'}  Query strings request.args returns a parsed dictionary of keys and values, representing the query string arguments.\nWe can access individual quary string values by calling request.args.get() and passing in a key:\n@app.route(\u0026quot;/args\u0026quot;) def args(): \u0026quot;\u0026quot;\u0026quot; Handling query string arguments \u0026quot;\u0026quot;\u0026quot; # request.args returns an ImmutableMultidict with the quesy string values args = request.args print(args) # Get an individual query string value q = request.args.get(\u0026quot;q\u0026quot;) print(q) return render_template(\u0026quot;index.html\u0026quot;)  If we access this route without a query string in the URL, we get:\nImmutableMultiDict([]) None\nIf we send a query string in the URL, including a value for the q parameter, we get:\nImmutableMultiDict([('q', 'hello'), ('w', 'world')]) # hello  Forms request.form returns an ImmutableMultiDict containing key value pairs, with the name attribute of the input elements of the form as keys.\nJust like request.args, we can access individual values from the form data using request.form.get() and passing in the key we want to fetch:\n@app.route(\u0026quot;/form\u0026quot;, methods=[\u0026quot;GET\u0026quot;, \u0026quot;POST\u0026quot;]) def form(): \u0026quot;\u0026quot;\u0026quot; Handling form data \u0026quot;\u0026quot;\u0026quot; # Use request.method to handle the request type if request.method == \u0026quot;POST\u0026quot;: # request.form returns an ImmutableMultiDict of keys and values req = request.form print(req) # Get individual form values based on the name attribute email = request.form.get(\u0026quot;email\u0026quot;) print(email) return render_template(\u0026quot;form.html\u0026quot;)  Our form has 2 input fields - email and password. If we submit the form, we get the following output:\nImmutableMultiDict([('email', 'foo@bar.com'), ('password', 'foobarred')]) # foo@bar.com  In addition to request.form, we can use request.values to return a CombinedMultiDict containing any query string paramaters and the form data, both parsed as ImmutableMultiDict.\nUsing the HTML tag action=\u0026quot;/form?h=hello\u0026quot; in our form, we get the following output:\nCombinedMultiDict([ImmutableMultiDict([('h', 'hello')]), ImmutableMultiDict([('email', 'foo@bar.com'), ('password', 'foobarred')])])  JSON Parsing JSON in flask is just as simple, with a few additional helper methods and attribites.\n request.is_json returns True if the request body contains JSON data. request.json parses the JSON and returns a dictionary of keys and values. request.get_json() also parses the JSON and returns a dictionary of keys and values. IT also accepts some arguments:  request.get_json(force=False, silent=False, cache=True)\n force - Ignores the mimetype and always tries to parse JSON silent - Silence any parsing arrors and return None cache- Store the parsed JSON to return for any subsequent calls  In this example, we have a route that renders a template containing a form for the user to submit some JSON to the server. We have another route below it where the data gets parsed and handled.\n@app.route(\u0026quot;/json\u0026quot;) def json(): \u0026quot;\u0026quot;\u0026quot; Returns an HTML template with an input to post some JSON \u0026quot;\u0026quot;\u0026quot; return render_template(\u0026quot;json.html\u0026quot;) @app.route(\u0026quot;/json/handler\u0026quot;, methods=[\u0026quot;POST\u0026quot;]) def json_handler(): \u0026quot;\u0026quot;\u0026quot; Handles the posted JSON data \u0026quot;\u0026quot;\u0026quot; # request.is_json returns True if the request body is JSON if request.is_json: # request.get_json returns a dictionary json_data = request.get_json() print(json_data) # request.json also returns a dictionary json_data = request.json # Get individual values from the JSON name = request.json.get(\u0026quot;name\u0026quot;) print(name) res = make_response(jsonify(json_data), 200) return res res = make_response(jsonify({}), 400) return res  We use request.is_json as a check before we attempt to parse the request body.\nPosting a JSON object with values for name and age gives us the following output:\n{'name': 'Foo', 'age': '29'} # Foo  Files request.files returns an ImmutableMultiDict containing the file as a FileStorage object, a special class from the Werkzeug library that sits underneath Flask and handles requests.\nrequest.files.get(\u0026quot;example\u0026quot;) returns a FileStorage object which has a few useful methods, including:\n filename - The name of the file name - The name of the form field save(destination) - Saves the file to the given destination  We\u0026rsquo;ll link at the bottom of this guide to the Werkzeug documentation on FileStorage.\nIn this example, we have a form containing a single file input browser, which the user can submit to the same route.\nYou\u0026rsquo;ll also notice a few more attributes of the request being called which we\u0026rsquo;ll discuss after:\n@app.route(\u0026quot;/file\u0026quot;, methods=[\u0026quot;GET\u0026quot;, \u0026quot;POST\u0026quot;]) def single_file(): \u0026quot;\u0026quot;\u0026quot; Handles a single file upload Note - Forms uploading files just have enctype=\u0026quot;multipart/form-data\u0026quot; in the form tag \u0026quot;\u0026quot;\u0026quot; # request.content_length returns the content length in bytes content_length = request.content_length print(f\u0026quot;Content length: {content_length}\u0026quot;) # content_type content_type = request.content_type print(f\u0026quot;Content type: {content_type}\u0026quot;) # request.mimetype returns the mimetype of the request mimetype = request.mimetype print(mimetype) # Get an ImmutableMultiDict of the files file = request.files print(file) # Get a specific file using the name attribute if request.files.get(\u0026quot;image\u0026quot;): image = request.files[\u0026quot;image\u0026quot;] print(f\u0026quot;Filename: {image.filename}\u0026quot;) print(f\u0026quot;Name: {image.name}\u0026quot;) print(image) # To save the image, call image.save() and provide a destination to save to # image.save(\u0026quot;/path/to/uploads/directory/filename\u0026quot;) return render_template(\u0026quot;file.html\u0026quot;)  Let\u0026rsquo;s take a look at the output. We\u0026rsquo;ve used f strings so you can see what\u0026rsquo;s what:\nContent length: 213671 Content type: multipart/form-data; boundary=----WebKitFormBoundaryB33O2yBRsBxnrIWr mimetype: multipart/form-data ImmutableMultiDict([('image', \u0026lt;FileStorage: 'flask.png' ('image/png')\u0026gt;)]) Filename: flask.png Name: image \u0026lt;FileStorage: 'flask.png' ('image/png')\u0026gt;   request.content_length returns the length of the request content in bytes request.content_type returns the content type of the request request.mimetype returns the mimetype of the request request.files returns the ImmutableMultiDict containing any files sent in the request\nif request.files.get(\u0026quot;image\u0026quot;): image = request.files[\u0026quot;image\u0026quot;]  We used if request.files.get(\u0026quot;image\u0026quot;): to check for a specific file where image is the name attribute of the form input, followed by image = request.files[\u0026quot;image\u0026quot;] to pull out the file.\n  Multiple files We can also use request.files.getlist(\u0026quot;name\u0026quot;) to return a list of files in the request, where name is the name attribute of the input element.\nTo upload multiple files from an HTML form, you\u0026rsquo;ll need to include the multiple attribute in the input element, for example:\n\u0026lt;form action=\u0026quot;/files\u0026quot; method=\u0026quot;POST\u0026quot; enctype=\u0026quot;multipart/form-data\u0026quot;\u0026gt; \u0026lt;input type=\u0026quot;file\u0026quot; name=\u0026quot;files\u0026quot; multiple\u0026gt; \u0026lt;button type=\u0026quot;submit\u0026quot;\u0026gt;Upload\u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt;  The route:\n@app.route(\u0026quot;/files\u0026quot;, methods=[\u0026quot;GET\u0026quot;, \u0026quot;POST\u0026quot;]) def files(): \u0026quot;\u0026quot;\u0026quot; Upload multiple files \u0026quot;\u0026quot;\u0026quot; # request.files.getlist returns a lift of files files = request.files.getlist(\u0026quot;files\u0026quot;) print(files) return render_template(\u0026quot;files.html\u0026quot;)  Uploading 3 files, produces the following output:\n`[\u0026lt;FileStorage: 'JavaScript-logo.png' ('image/png')\u0026gt;, \u0026lt;FileStorage: 'jinja.png' ('image/png')\u0026gt;, \u0026lt;FileStorage: 'linux_logo.png' ('image/png')\u0026gt;]  At this point, it\u0026rsquo;s easy to iterate over the list of files with a for loop and do something with each file, like save it.\nYou can read more about saving files here.\nView arguments request.view_args parses and returns a dictionary of any arguments passed into the route:\n@app.route(\u0026quot;/view/args/\u0026lt;foo\u0026gt;/\u0026lt;bar\u0026gt;\u0026quot;) def view_arguments(foo, bar): \u0026quot;\u0026quot;\u0026quot; Handles arguments coming in from the URL \u0026quot;\u0026quot;\u0026quot; # request.view_args returns a dict of any arguments passed to the view view_args = request.view_args print(view_args) return render_template(\u0026quot;index.html\u0026quot;)  Going to /view/args/hello/world returns the following:\n{'foo': 'hello', 'bar': 'world'}  URL info The request object also contains lots of useful data about the request URL.\nWe\u0026rsquo;ll use f strings so you can see the output for each of the request attributes:\n@app.route(\u0026quot;/url/info\u0026quot;) def url_info(): host = request.host print(f\u0026quot;host: {host}\u0026quot;) host_url = request.host_url print(f\u0026quot;host_url: {host_url}\u0026quot;) path = request.path print(f\u0026quot;path: {path}\u0026quot;) full_path = request.full_path print(f\u0026quot;full_path: {path}\u0026quot;) url = request.url print(f\u0026quot;url: {url}\u0026quot;) base_url = request.base_url print(f\u0026quot;base_url: {base_url}\u0026quot;) url_root = request.url_root print(f\u0026quot;url_root: {url_root}\u0026quot;) return render_template(\u0026quot;index.html\u0026quot;)  Going to /url/info?query=hello returns the following output:\nhost: 127.0.0.1:5000 host_url: http://127.0.0.1:5000/ path: /url/info full_path: /url/info url: http://127.0.0.1:5000/url/info?query=hello base_url: http://127.0.0.1:5000/url/info url_root: http://127.0.0.1:5000/  Headers \u0026amp; misc The request object contains useful information including the request headers, along with other various things.\nIn this example, we\u0026rsquo;ll create a route and run through some of the other request object attributes.\nrequest.headers returns the headers!:\n@app.route(\u0026quot;/the/request/object\u0026quot;) def the_request_object(): headers = request.headers print(headers) return render_template(\u0026quot;index.html\u0026quot;)  Host: 127.0.0.1:5000 User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:65.0) Gecko/20100101 Firefox/65.0 Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8 Accept-Language: en-GB,en;q=0.5 Accept-Encoding: gzip, deflate Dnt: 1 Connection: keep-alive Cookie: foo=bar Upgrade-Insecure-Requests: 1 Pragma: no-cache Cache-Control: no-cache  We can access individual headers with request.headers.get(\u0026quot;Example\u0026quot;), where Example is the header:\n@app.route(\u0026quot;/the/request/object\u0026quot;) def the_request_object(): accept_encoding = request.headers.get(\u0026quot;Accept-Encoding\u0026quot;) print(accept_encoding) return render_template(\u0026quot;index.html\u0026quot;)  gzip, deflate\nrequest.user_agent returns the user agent of the request:\n@app.route(\u0026quot;/the/request/object\u0026quot;) def the_request_object(): user_agent = request.user_agent print(user_agent) return render_template(\u0026quot;index.html\u0026quot;)  Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:65.0) Gecko/20100101 Firefox/65.0\nrequest.access_route is an interesting feature. If a forwarded header exists, it returns a list of all ip addresses from the client ip to the last proxy server:\n@app.route(\u0026quot;/the/request/object\u0026quot;) def the_request_object(): access_route = request.access_route print(access_route) return render_template(\u0026quot;index.html\u0026quot;)  ImmutableList(['127.0.0.1'])\nIf we expose our application using ngrok, we get the following:\nImmutableList(['82.2.172.100'])\nrequest.endpoint returns the name of the current function:\n@app.route(\u0026quot;/the/request/object\u0026quot;) def the_request_object(): endpoint = request.endpoint print(endpoint) return render_template(\u0026quot;index.html\u0026quot;)  the_request_object\nrequest.is_multiprocess returns True if the application is served by a WSGI server that spawns multiple processes:\n@app.route(\u0026quot;/the/request/object\u0026quot;) def the_request_object(): is_multiproc = request.is_multiprocess print(is_multiproc) return render_template(\u0026quot;index.html\u0026quot;) # False  request.is_multithread returns True if the application is served by a multithreaded WSGI server:\n@app.route(\u0026quot;/the/request/object\u0026quot;) def the_request_object(): is_multithread = request.is_multithread print(is_multithread) return render_template(\u0026quot;index.html\u0026quot;) # True  request.is_secure\nNote - I assumed this would return True if the application is served over https, however after some quick testing using ngrok to expose the application over https, it still returned False.\nI\u0026rsquo;ll do some more testing on a live Flask deployment served over https and update the article after, but please feel free to let me know if I\u0026rsquo;m \u0026ldquo;barking up he wrong tree\u0026rdquo; as they say. It might be something to do with running the app from the development server but I\u0026rsquo;m happy to be corrected!\n@app.route(\u0026quot;/the/request/object\u0026quot;) def the_request_object(): is_secure = request.is_secure print(is_secure) return render_template(\u0026quot;index.html\u0026quot;)  If we access the route from the development server:\nFalse\nProxying the application through ngrok over https also returns False, but we can see from the headers that the application is being served over https:\nX-Forwarded-Proto: https\nWe can also look at the scheme using request.scheme:\n@app.route(\u0026quot;/the/request/object\u0026quot;) def the_request_object(): scheme = request.scheme print(scheme) return render_template(\u0026quot;index.html\u0026quot;)  If we access the route from the development server:\nhttp\nAgain, exposing the app over https using ngrok also returned http so I must be missing something here! Will update the article after testing on a live application over https.\nrequest.remote_addr returns the remote address of the client:\n@app.route(\u0026quot;/the/request/object\u0026quot;) def the_request_object(): remote_addr = request.remote_addr print(remote_addr) return render_template(\u0026quot;index.html\u0026quot;)  If we access the route from the development server:\n127.0.0.1\nIf we access the route exposed over ngrok:\n127.0.0.1\nIf we want to see if the request has been proxied, we can check for the X-Forwarded-For and return a list of proxied IP\u0026rsquo;s:\nif request.headers.get(\u0026quot;X-Forwarded-For\u0026quot;): proxies = request.headers.getlist(\u0026quot;X-Forwarded-For\u0026quot;) print(proxies)  Making the same request over ngrok returns:\n['82.2.172.100']\nrequest.url_rule.methods returns a set of available request methods for the route:\n@app.route(\u0026quot;/the/request/object\u0026quot;) def the_request_object(): url_rule = request.url_rule.methods print(url_rule) return render_template(\u0026quot;index.html\u0026quot;)  As we haven\u0026rsquo;t provided the method argument or values, we get:\n{'HEAD', 'GET', 'OPTIONS'}  If we modify the route to include several request methods:\n@app.route(\u0026quot;/the/request/object\u0026quot;, methods=[\u0026quot;GET\u0026quot;, \u0026quot;POST\u0026quot;, \u0026quot;PUT\u0026quot;, \u0026quot;PATCH\u0026quot;, \u0026quot;DELETE\u0026quot;]) def the_request_object(): url_rule = request.url_rule.methods print(url_rule) return render_template(\u0026quot;index.html\u0026quot;)  We get the following:\n{'OPTIONS', 'GET', 'DELETE', 'POST', 'PUT', 'PATCH', 'HEAD'}  This is an exaggerated example to show the use of request.url_rule.methods.\nResources  Flask request data (Flask docs) HTTP headers (MDN)  Last modified · 07 Mar 2019\n Source : .\n "});index.add({'id':79,'href':'/library/tutorials/docs/python/flask/learning-flask/ep-21/','title':"Ep.21 Task queues with Flask",'content':" Task queues with Flask| Learning Flask Ep. 21 An introduction to task queues with Flask and RQ\nSometimes we need to run tasks in the background, outside of the HTTP request/response cycle. Long running tasks such as image, video or audio processing can take anywhere from minutes to hours, depending on the task at hand.\nPicture this scenario.\nYou have a web application that allows users to upload an image, to which you\u0026rsquo;re going to produce 5 copies, all with different sizes to match the various screen sizes used on modern devices, including a thumbnail.\nEven if this task only takes a few seconds to process, a few seconds of waiting on the web can feel like an eternity! And we want to keep our users using the application.\nThis is where task queues come in to play!\nTask queues allow us to offload jobs to another worker process, meaning we can return something to the user immidiately whilst the job gets placed in a queue and processed at a later time (depending on how many tasks are currently in the queue, it could start immidiately)\nThere\u0026rsquo;s many use cases for task queues, a few examples include:\n Image/video/audio processing Web scraping Analysis/complex calculation Sending emails  And much more!\nTask queues There are a handful of task queues available for Python, however for this introduction we\u0026rsquo;re going to use RQ, a simple yet powerful task queue that uses Redis as a message broker.\nTasks are handled by regular Python functions, which we can call, provide arguments and place in a queue.\nFor example, a very simple function can be used to handle a task:\ndef task_handler(args): # this function takes around 2 minutes to complete return True  When we want to add a task to a queue, we do something like the following:\nq.enqueue(task_handler, args)  Where..\n q is a reference to the queue itself enqueue adds a new task to the queue task_handler is the name of the function we want to call args any arguments to pass to the function  Any tasks in the queue will be executed sequentially until all tasks are complete.\nThe message broker is the middleman between our application and our workers, delivering messages when we want to schedule a task in thr queue.\nRedis is a fast, in memory database which we\u0026rsquo;ll use as our broker. So you\u0026rsquo;ll need to install it.\nInstalling Redis We\u0026rsquo;re not going to cover installing Redis in thie article. However some points to note:\n If you\u0026rsquo;re on Windows 10, consider using the Windows Subsystem for Linux or Docker If you\u0026rsquo;re on Mac, install Redis using Homebrew If you\u0026rsquo;re on Linux, build Redis from source or install it using your distro package manager  We\u0026rsquo;re using the Windows susbsystem for Linux running Ubuntu 18.04 and Redis is easily installed with:\nsudo apt install redis-server  Here\u0026rsquo;s a great link to an article on Digital Ocean for setting up Redis on Ubuntu 18.04 if you\u0026rsquo;d like it to run as a service:\nhttps://www.digitalocean.com/community/tutorials/how-to-install-and-secure-redis-on-ubuntu-18-04\nOtherwise just start Redis in a new terminal with the following command:\nredis-server\nNote - We haven\u0026rsquo;t set up any authentication on our installation of Redis as it\u0026rsquo;s only for local development. If you\u0026rsquo;re running in production, you\u0026rsquo;ll want to enable password auth.\nThe Flask app In this example, we\u0026rsquo;re going to build a simple application, allowing a user to submit a URL via a form.\nWe\u0026rsquo;ll create a task handler function which we\u0026rsquo;ll use to fetch the HTML of the URL and count the occurances of every word on the page.\nBut before we do that, let\u0026rsquo;s create a simple example first.\nTo get things going, we\u0026rsquo;re going to create a new virtual environment and install the dependencies:\npython -m venv env \u0026amp;\u0026amp; source env/bin/activate  We\u0026rsquo;re going to install flask, redis, beautifulsoup4 and rq with pip:\npip install flask redis rq beautifulsoup4  We\u0026rsquo;re going to create a simple, single file application in a file called app.py.\nFirst up, we need a few imports:\napp.py\nfrom flask import Flask, request import redis from rq import Queue import time  We\u0026rsquo;re importing time to simulate some delay in our background task.\nNext, we\u0026rsquo;ll create the flask app variable and setup our Redis instance and task queue object:\napp = Flask(__name__) r = redis.Redis() q = Queue(connection=r)  Lets create a very simple function that will handle a task. It takes an argument (n) and returns the length of it with a simulated delay.\nAs you can see, it\u0026rsquo;s just a normal Python function!\ndef background_task(n): \u0026quot;\u0026quot;\u0026quot; Function that returns len(n) and simulates a delay \u0026quot;\u0026quot;\u0026quot; delay = 2 print(\u0026quot;Task running\u0026quot;) print(f\u0026quot;Simulating a {delay} second delay\u0026quot;) time.sleep(delay) print(len(n)) print(\u0026quot;Task complete\u0026quot;) return len(n)  Finally, we\u0026rsquo;ll create a route which looks for a query string with n as the parameter.\n@app.route(\u0026quot;/task\u0026quot;) def index(): if request.args.get(\u0026quot;n\u0026quot;): job = q.enqueue(background_task, request.args.get(\u0026quot;n\u0026quot;)) return f\u0026quot;Task ({job.id}) added to queue at {job.enqueued_at}\u0026quot; return \u0026quot;No value for count provided\u0026quot; if __name__ == \u0026quot;__main__\u0026quot;: app.run()  If n is provided in the URL, it will add a task to the queue, with the value for n as the function argument.\nWe add a task to a queue with:\nq.enqueue(function_name, args)  In this case, we\u0026rsquo;ve stored this in a variable called job.\nWe now have access to the job object. You\u0026rsquo;ll notice we call job.id and job.enqueued_at which return a unique task id and the date when the task was enqueued.\nSome other interesting attributes of the job object include:\n job.status job.func_name job.args job.kwargs job.result job.enqueued_at job.started_at job.ended_at job.exc_info  Before you run the app, you need to start the rq worker.\nOpen a new terminal (In the same directory as run.py) and start the worker with:\nrq worker\nYou\u0026rsquo;ll see something like:\n20:55:23 RQ worker 'rq:worker:jnwt.4968' started, version 0.13.0 20:55:23 *** Listening on default... 20:55:23 Cleaning registries for queue: default  Start the Flask app with:\nexport FLASK_APP=run.py export FLASK_ENV = development flask run  Go to /task?n=100 in your browser and keep an eye on your terminal running the rq worker process.\nYou should see something similar to this in your browser:\nTask (7dc516bb-7720-446a-acce-cbb272d7f598) added to queue at 2019-03-08 22:03:15.936306  In your terminal, you should see:\n22:03:18 default: Job OK (86a8479a-e02d-4aca-8466-6df47fa69efe) 22:03:18 Result is kept for 500 seconds 22:03:18 default: run.background_task('100') (7dc516bb-7720-446a-acce-cbb272d7f598) Task running Simulating a 2 second delay 3 Task complete 22:03:20 default: Job OK (7dc516bb-7720-446a-acce-cbb272d7f598) 22:03:20 Result is kept for 500 seconds  You\u0026rsquo;ll notice, the app returns a response immediately while the task runs in the background.\nGo ahead and refresh the URL a few times to add multiple tasks to the queue!\nExample 2 Moving on to a more practical example of using the rq task queue.\nWe\u0026rsquo;re going to rearrange our application structure to the following:\napp ├── app │ ├── __init__.py │ ├── tasks.py │ ├── templates │ │ └── index.html │ └── views.py └── run.py  Rather than writing our task functions in the same file as our views, we\u0026rsquo;re going to separate them out into their own file called tasks.py.\nrun.py is the entry point to our application:\nrun.py\nfrom app import app if __name__ == \u0026quot;__main__\u0026quot;: app.run()  __init__.py is going to bring our app together as a package and initialize some key components:\ninit.py\nfrom flask import Flask import redis from rq import Queue app = Flask(__name__) r = redis.Redis() q = Queue(connection=r) from app import views from app import tasks  We start out by importing the required packages and creating the app variable.\n r = redis.Redis() creates our Redis connection q = Queue(connection=r) creates our task queue  There\u0026rsquo;s lots of things we can do with queues, but for now we\u0026rsquo;re just going to keep it simple and create a single queue.\nLastly, we import views and tasks from app. Where views.py contains our application routes and tasks.py contains our tasks.\nviews.py - For now, we\u0026rsquo;re just going to import a few objects from our app along with a couple of imports from flask and render a template. We\u0026rsquo;ll come back to it shortly:\nviews.py\nfrom app import app from app import r from app import q from flask import render_template, request @app.route(\u0026quot;/add-task\u0026quot;, methods=[\u0026quot;GET\u0026quot;, \u0026quot;POST\u0026quot;]) def add_task(): return render_template(\u0026quot;add_task.html\u0026quot;)  tasks.py is going to contain all of our task handler functions. We\u0026rsquo;re going to create a function that counts all of the occurances of each word at a given URL:\ntasks.py\nfrom urllib import request from bs4 import BeautifulSoup import lxml import time def count_words(url): print(f\u0026quot;Counting words at {url}\u0026quot;) start = time.time() r = request.urlopen(url) soup = BeautifulSoup(r.read().decode(), \u0026quot;lxml\u0026quot;) paragraphs = \u0026quot; \u0026quot;.join([p.text for p in soup.find_all(\u0026quot;p\u0026quot;)]) word_count = dict() for i in paragraphs.split(): if not i in word_count: word_count[i] = 1 else: word_count[i] += 1 end = time.time() time_elapsed = end - start print(word_count) print(f\u0026quot;Total words: {len(word_count)}\u0026quot;) print(f\u0026quot;Time elapsed: {time_elapsed} ms\u0026quot;) return len(word_count)  add_task.html is the HTML template rendered by the add_task view.\nThe first container holds a single form element, allowing us to submit a URL. The second container displays some information about the current tasks.\nWe\u0026rsquo;re also using Bootstrap 4 for our CSS\nadd_task.html\n\u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;!-- Required meta tags --\u0026gt; \u0026lt;meta charset=\u0026quot;utf-8\u0026quot;\u0026gt; \u0026lt;meta name=\u0026quot;viewport\u0026quot; content=\u0026quot;width=device-width, initial-scale=1, shrink-to-fit=no\u0026quot;\u0026gt; \u0026lt;!-- Bootstrap CSS --\u0026gt; \u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css\u0026quot; integrity=\u0026quot;sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T\u0026quot; crossorigin=\u0026quot;anonymous\u0026quot;\u0026gt; \u0026lt;title\u0026gt;Job queue\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div class=\u0026quot;container\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col\u0026quot;\u0026gt; \u0026lt;h5 class=\u0026quot;mt-3\u0026quot;\u0026gt;Word counter\u0026lt;/h5\u0026gt; \u0026lt;div class=\u0026quot;card mt-3\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;card-body\u0026quot;\u0026gt; \u0026lt;form action=\u0026quot;/add-task\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;form-group\u0026quot;\u0026gt; \u0026lt;label\u0026gt;Word count\u0026lt;/label\u0026gt; \u0026lt;input type=\u0026quot;text\u0026quot; class=\u0026quot;form-control\u0026quot; name=\u0026quot;url\u0026quot; placeholder=\u0026quot;Enter URL\u0026quot; required\u0026gt; {% if message %} \u0026lt;small id=\u0026quot;emailHelp\u0026quot; class=\u0026quot;form-text text-muted\u0026quot;\u0026gt;{{ message }}\u0026lt;/small\u0026gt; {% endif %} \u0026lt;/div\u0026gt; \u0026lt;button type=\u0026quot;submit\u0026quot; class=\u0026quot;btn btn-primary\u0026quot;\u0026gt;Submit\u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;container\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col\u0026quot;\u0026gt; \u0026lt;h5 class=\u0026quot;mt-3 mb-3\u0026quot;\u0026gt;Job queue\u0026lt;/h5\u0026gt; {% if jobs %} {% for job in jobs %} \u0026lt;div class=\u0026quot;card mb-3\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;card-body\u0026quot;\u0026gt; \u0026lt;h6\u0026gt;{{ job.func_name }}\u0026lt;/h6\u0026gt; \u0026lt;p\u0026gt;Args: {{ job.args }}\u0026lt;/p\u0026gt; \u0026lt;small class=\u0026quot;text-muted d-block\u0026quot;\u0026gt;Job ID: {{ job.id }}\u0026lt;/small\u0026gt; \u0026lt;small class=\u0026quot;text-muted d-block\u0026quot;\u0026gt;Status: {{ job.status }}\u0026lt;/small\u0026gt; \u0026lt;small class=\u0026quot;text-muted d-block\u0026quot;\u0026gt;Created at: {{ job.created_at.strftime('%a, %d %b %Y %H:%M:%S') }}\u0026lt;/small\u0026gt; \u0026lt;small class=\u0026quot;text-muted d-block\u0026quot;\u0026gt;Enqueued at: {{ job.enqueued_at.strftime('%a, %d %b %Y %H:%M:%S') }}\u0026lt;/small\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {% endfor %} {% else %} \u0026lt;p\u0026gt;No jobs in the queue\u0026lt;/p\u0026gt; {% endif %} \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  Adding tasks Before we run our app, we need to import the count_words function.\nWe\u0026rsquo;re also importing strftime to format the datetime object:\nviews.py\nfrom app.tasks import count_words from time import strftime`  We\u0026rsquo;ll now finish off the route:\nviews.py\n@app.route(\u0026quot;/add-task\u0026quot;, methods=[\u0026quot;GET\u0026quot;, \u0026quot;POST\u0026quot;]) def add_task(): jobs = q.jobs # Get a list of jobs in the queue message = None if request.args: # Only run if a query string is sent in the request url = request.args.get(\u0026quot;url\u0026quot;) # Gets the URL coming in as a query string task = q.enqueue(count_words, url) # Send a job to the task queue jobs = q.jobs # Get a list of jobs in the queue q_len = len(q) # Get the queue length message = f\u0026quot;Task queued at {task.enqueued_at.strftime('%a, %d %b %Y %H:%M:%S')}. {q_len} jobs queued\u0026quot; return render_template(\u0026quot;add_task.html\u0026quot;, message=message, jobs=jobs)  We\u0026rsquo;re posting the form data as a GET request so the data will come in as a query string, using request.args.get(\u0026quot;url\u0026quot;) to create a variable with the form value.\n q.jobs returns a list of any current jobs in the task queue task = q.enqueue(count_words, url) adds the job to the queue, with count_words as the function and url as the argument len(q) returns the number of jobs in the queue message is just a formatted string containing some information about the task and length of the queue  Running the app Before we run the app itself, we need to start the RQ worker.\nThe worker is a process that runs indipendently from our application and will communicate with the message broker.\nWhen a new task is added to the queue, the worker will carry out the task!\nTo start the rq worker, open a new terminal and from the same directory as run.py, run the following:\nrq worker  You should see something like:\n20:55:23 RQ worker 'rq:worker:jnwt.4968' started, version 0.13.0 20:55:23 *** Listening on default... 20:55:23 Cleaning registries for queue: default  We\u0026rsquo;re now ready to run our app. Start it as you normally would any other Flask app:\nexport FLASK_APP=run.py export FLASK_ENV = development flask run  Head over to /add-task and submit a URL, keeping an eye on the terminal window running the worker.\nDepending on the URL, you should see something like:\n20:19:44 default: app.tasks.count_words('https://pythonise.com/feed/flask/the-flask-request-object') (b29f3903-bd7d-4a10-a76f-f7586bb5bc37) Counting words at https://pythonise.com/feed/flask/the-flask-request-object  This should be followed by a dictionary containing all occurances of each word and their values, finishing up with:\nTotal words: 455 Time elapsed: 0.8473403453826904 ms  Wrapping up This was a gentle introduction to task queues using rq and Redis, there\u0026rsquo;s lots of extra goodies that we haven\u0026rsquo;t covered!\nHead over to the rq docs to learn more.\nLast modified · 14 Mar 2019\n Source : .\n "});index.add({'id':80,'href':'/library/tutorials/docs/python/flask/learning-flask/ep-22/','title':"Ep.22 Pillow, task queues \u0026 the HTML picture element",'content':" Pillow, task queues \u0026amp; the HTML picture element| Learning Flask Ep. 22 Using Pillow and task queues to offload image resizing to a worker process and using the HTML picture tag to increase image rendering performance\nImages on the web are important and we now have access to a plethora of devices to view them - from mobile to desktop and tablet to TV screens, to get the most performance from our images, we should consider showing a peoperly sized image based on their device.\nIn this guide, we\u0026rsquo;re going to:\n Create a form for uploading images Create a function that creates several duplicates of the image at different sizes whilst maintaining the original aspect ratio Offload said function to a task queue to be handled by a separate worker Render an HTML template using the HTML picture tag to see the different images being loaded as the browser viewport is resized  Tools We\u0026rsquo;re going to be using the following Python packages:\n Flask (Web framework) Redis (Message broker) RQ (Task queue/worker service) Pillow (Copying \u0026amp; resizing images)  App structure Our application structure:\napp ├── app │ ├── __init__.py │ ├── static │ │ └── img │ │ └── uploads \u0026lt;- Image uploads directory │ ├── tasks.py \u0026lt;- Task queue functions │ ├── templates │ │ ├── upload_image.html \u0026lt;- Uploading an image │ │ └── view_image.html \u0026lt;- Viewing images with the picture tag │ └── views.py \u0026lt;- Appliaction routes └── run.py \u0026lt;- appliation entry point  Getting started We\u0026rsquo;re going to start off creating a virtual environment for our project:\npython -m venv env  Where env is the name of our virtual environment.\nNext, activate the env:\nsource env/bin/activate  Install the required packages:\npip install flask redis rq Pillow  Go ahead and build out the appliaction structure and add the following:\nFlask entry point run.py will be the entry point to our application:\nrun.py\n`from app import app\nif name == \u0026ldquo;main\u0026ldquo;: app.run()`\nSetting up the app We\u0026rsquo;ll bring our app together in __init__.py and define some new variables:\n__init__.py\nfrom flask import Flask import redis from rq import Queue app = Flask(__name__) r = redis.Redis() q = Queue(connection=r) from app import views from app import tasks   r = redis.Redis() - Creates a connection to the redis-server instance running locally (without auth) q = Queue(connection=r) - Creates our task queue, using r as the message broker  The task queue function We\u0026rsquo;ll use this file to create our task queue function:\ntasks.py\nfrom PIL import Image import os import time def create_image_set(image_dir, image_name): start = time.time() thumb = 30, 30 small = 540, 540 medium = 768, 786 large = 1080, 1080 xl = 1200, 1200 image = Image.open(os.path.join(image_dir, image_name)) image_ext = image_name.split(\u0026quot;.\u0026quot;)[-1] image_name = image_name.split(\u0026quot;.\u0026quot;)[0] ### THUMBNAIL ### thumbnail_image = image.copy() thumbnail_image.thumbnail(thumb, Image.LANCZOS) thumbnail_image.save(f\u0026quot;{os.path.join(image_dir, image_name)}-thumbnail.{image_ext}\u0026quot;, optimize=True, quality=95) ### SMALL ### small_image = image.copy() small_image.thumbnail(small, Image.LANCZOS) small_image.save(f\u0026quot;{os.path.join(image_dir, image_name)}-540.{image_ext}\u0026quot;, optimize=True, quality=95) ### MEDIUM ### medium_image = image.copy() medium_image.thumbnail(medium, Image.LANCZOS) medium_image.save(f\u0026quot;{os.path.join(image_dir, image_name)}-768.{image_ext}\u0026quot;, optimize=True, quality=95) ### LARGE ### large_image = image.copy() large_image.thumbnail(large, Image.LANCZOS) large_image.save(f\u0026quot;{os.path.join(image_dir, image_name)}-1080.{image_ext}\u0026quot;, optimize=True, quality=95) ### XL ### xl_image = image.copy() xl_image.thumbnail(xl, Image.LANCZOS) xl_image.save(f\u0026quot;{os.path.join(image_dir, image_name)}-1200.{image_ext}\u0026quot;, optimize=True, quality=95) end = time.time() time_elapsed = end - start print(f\u0026quot;Task complete in: {time_elapsed}\u0026quot;) return True  The routes We\u0026rsquo;re going to have 2 routes in our application:\n /upload-image - Renders a template and handles the upload of a new image /image/\u0026lt;dir\u0026gt;/\u0026lt;img\u0026gt; - Will just be used to view an image after resizing  views.py\nfrom app.tasks import create_image_set from flask import render_template, request, flash import os import secrets app.config[\u0026quot;SECRET_KEY\u0026quot;] = \u0026quot;liruhfoi34uhfo8734yot8234h\u0026quot; app.config[\u0026quot;UPLOAD_DIRECTORY\u0026quot;] = \u0026quot;/mnt/c/wsl/projects/pythonise/tutorials/flask_series/ep_21_background_tasks/app/static/img/uploads\u0026quot; @app.route(\u0026quot;/upload-image\u0026quot;, methods=[\u0026quot;GET\u0026quot;, \u0026quot;POST\u0026quot;]) def upload_image(): message = None if request.method == \u0026quot;POST\u0026quot;: image = request.files[\u0026quot;image\u0026quot;] image_dir_name = secrets.token_hex(16) os.mkdir(os.path.join(app.config[\u0026quot;UPLOAD_DIRECTORY\u0026quot;], image_dir_name)) image.save(os.path.join(app.config[\u0026quot;UPLOAD_DIRECTORY\u0026quot;], image_dir_name, image.filename)) image_dir = os.path.join(app.config[\u0026quot;UPLOAD_DIRECTORY\u0026quot;], image_dir_name) q.enqueue(create_image_set, image_dir, image.filename) flash(\u0026quot;Image uploaded and sent for resizing\u0026quot;, \u0026quot;success\u0026quot;) message = f\u0026quot;/image/{image_dir_name}/{image.filename.split('.')[0]}\u0026quot; return render_template(\u0026quot;upload_image.html\u0026quot;, message=message) @app.route(\u0026quot;/image/\u0026lt;dir\u0026gt;/\u0026lt;img\u0026gt;\u0026quot;) def view_image(dir, img): return render_template(\u0026quot;view_image.html\u0026quot;, dir=dir, img=img)  Uploading an image This wile contains a section to display any flashed messages, along with a form for uploading a file:\nupload_image.html\n\u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;!-- Required meta tags --\u0026gt; \u0026lt;meta charset=\u0026quot;utf-8\u0026quot;\u0026gt; \u0026lt;meta name=\u0026quot;viewport\u0026quot; content=\u0026quot;width=device-width, initial-scale=1, shrink-to-fit=no\u0026quot;\u0026gt; \u0026lt;!-- Bootstrap CSS --\u0026gt; \u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css\u0026quot; integrity=\u0026quot;sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T\u0026quot; crossorigin=\u0026quot;anonymous\u0026quot;\u0026gt; \u0026lt;title\u0026gt;Upload image\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div class=\u0026quot;container\u0026quot;\u0026gt; {% with messages = get_flashed_messages(with_categories=true) %} {% if messages %} {% for category, message in messages %} \u0026lt;div class=\u0026quot;alert alert-{{ category }} alert-dismissible fade show mt-3\u0026quot; role=\u0026quot;alert\u0026quot;\u0026gt; {{ message }} \u0026lt;button type=\u0026quot;button\u0026quot; class=\u0026quot;close\u0026quot; data-dismiss=\u0026quot;alert\u0026quot; aria-label=\u0026quot;Close\u0026quot;\u0026gt; \u0026lt;span aria-hidden=\u0026quot;true\u0026quot;\u0026gt;\u0026amp;times;\u0026lt;/span\u0026gt; \u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; {% endfor %} {% endif %} {% endwith %} \u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;mb-3 mt-3\u0026quot;\u0026gt; \u0026lt;h2 class=\u0026quot;mb-3\u0026quot; style=\u0026quot;font-weight: 300\u0026quot;\u0026gt;Upload image\u0026lt;/h2\u0026gt; \u0026lt;form action=\u0026quot;/upload-image\u0026quot; method=\u0026quot;POST\u0026quot; enctype=\u0026quot;multipart/form-data\u0026quot; class=\u0026quot;mb-3\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;form-group mb-3\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;custom-file\u0026quot;\u0026gt; \u0026lt;input type=\u0026quot;file\u0026quot; class=\u0026quot;custom-file-input\u0026quot; name=\u0026quot;image\u0026quot;\u0026gt; \u0026lt;label id=\u0026quot;file_input_label\u0026quot; class=\u0026quot;custom-file-label\u0026quot; for=\u0026quot;image\u0026quot;\u0026gt;Select file\u0026lt;/label\u0026gt; \u0026lt;small class=\u0026quot;text-muted\u0026quot;\u0026gt;Images should be 2560px x 1440px and not contain a dot in the filename\u0026lt;/small\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;button type=\u0026quot;submit\u0026quot; class=\u0026quot;btn btn-primary\u0026quot;\u0026gt;Upload\u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; {% if message %} \u0026lt;a href=\u0026quot;{{ message }}\u0026quot; class=\u0026quot;mt-3\u0026quot;\u0026gt;View image\u0026lt;/a\u0026gt; {% endif %} \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;!-- import bootstrap JS here --\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  Viewing the resized images We\u0026rsquo;ll use this template to render the image set to the browser:\nview_image.html\n\u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;!-- Required meta tags --\u0026gt; \u0026lt;meta charset=\u0026quot;utf-8\u0026quot;\u0026gt; \u0026lt;meta name=\u0026quot;viewport\u0026quot; content=\u0026quot;width=device-width, initial-scale=1, shrink-to-fit=no\u0026quot;\u0026gt; \u0026lt;!-- Bootstrap CSS --\u0026gt; \u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css\u0026quot; integrity=\u0026quot;sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T\u0026quot; crossorigin=\u0026quot;anonymous\u0026quot;\u0026gt; \u0026lt;title\u0026gt;View image\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;main\u0026gt; \u0026lt;div class=\u0026quot;container mt-3\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col\u0026quot;\u0026gt; \u0026lt;picture\u0026gt; \u0026lt;!-- thumbnail --\u0026gt; \u0026lt;source class=\u0026quot;img-fluid\u0026quot; srcset=\u0026quot;/static/img/uploads/{{dir}}/{{img}}-thumbnail.png\u0026quot; media=\u0026quot;(max-width: 150px)\u0026quot;\u0026gt; \u0026lt;!-- small --\u0026gt; \u0026lt;source class=\u0026quot;img-fluid\u0026quot; srcset=\u0026quot;/static/img/uploads/{{dir}}/{{img}}-540.png\u0026quot; media=\u0026quot;(max-width: 540px)\u0026quot;\u0026gt; \u0026lt;!-- medium --\u0026gt; \u0026lt;source class=\u0026quot;img-fluid\u0026quot; srcset=\u0026quot;/static/img/uploads/{{dir}}/{{img}}-768.png\u0026quot; media=\u0026quot;(max-width: 768px)\u0026quot;\u0026gt; \u0026lt;!-- large --\u0026gt; \u0026lt;source class=\u0026quot;img-fluid\u0026quot; srcset=\u0026quot;/static/img/uploads/{{dir}}/{{img}}-1080.png\u0026quot; media=\u0026quot;(max-width: 1080px)\u0026quot;\u0026gt; \u0026lt;!-- xl --\u0026gt; \u0026lt;source class=\u0026quot;img-fluid\u0026quot; srcset=\u0026quot;/static/img/uploads/{{dir}}/{{img}}-1200.png\u0026quot; media=\u0026quot;(max-width: 1200px)\u0026quot;\u0026gt; \u0026lt;!-- original --\u0026gt; \u0026lt;img class=\u0026quot;img-fluid\u0026quot; src=\u0026quot;/static/img/uploads/{{dir}}/{{img}}.png\u0026quot; /\u0026gt; \u0026lt;/picture\u0026gt; \u0026lt;picture\u0026gt; \u0026lt;source srcset=\u0026quot;example-thumbnail.png\u0026quot; media=\u0026quot;(max-width: 150px)\u0026quot;\u0026gt; \u0026lt;source srcset=\u0026quot;example-540.png\u0026quot; media=\u0026quot;(max-width: 540px)\u0026quot;\u0026gt; \u0026lt;source srcset=\u0026quot;example-768.png\u0026quot; media=\u0026quot;(max-width: 768px)\u0026quot;\u0026gt; \u0026lt;source srcset=\u0026quot;example-1080.png\u0026quot; media=\u0026quot;(max-width: 1080px)\u0026quot;\u0026gt; \u0026lt;source srcset=\u0026quot;example-1200.png\u0026quot; media=\u0026quot;(max-width: 1200px)\u0026quot;\u0026gt; \u0026lt;img src=\u0026quot;/static/img/uploads/example.png\u0026quot; /\u0026gt; \u0026lt;/picture\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/main\u0026gt; \u0026lt;!-- Import bootstrap JS here --\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  HTML picture tag THe HTML picture tag allows us to provide a set of images, of which the browser will render the relevant version based on the viewport size of the users device.\nIn our example, we\u0026rsquo;ve provided 5 options using the source tag, along with a fallback using the img tag.\nEach source tag contains a srcset attribute; The path to the image we\u0026rsquo;d like to render.\nHowever, the source tag will only be rendered if the browser viewport falls wihin the max-width query in the media attribute.\nRunning the application Before we run the app, you\u0026rsquo;ll need to start redis.\nYou can do so (depending on your OS and installation of Redis), by running the following command:\nredis-server  This should start Redis and you should see a message in your terminal.\nTo run the application, you\u0026rsquo;ll need 2 more terminals open. From the root of the application (in the same directory as run.py), run the following:\nrq worker  You should see the RQ worker process start and a message like the following:\n16:29:55 RQ worker 'rq:worker:jnwt.8633' started, version 0.13.0 16:29:55 *** Listening on default... 16:29:55 Cleaning registries for queue: default  In another terminal (from the same directory), run the following:\nexport FLASK_APP=run.py export FLASK_ENV=development flask run  Testing the application Open up a browser and head to /upload-image.\nYou should be able to select and upload an image and your terminal running the rq worker should also print out some information to say it\u0026rsquo;s running a task.\nHead to the link returned by /upload-image and resize your browser viewport to see the different images being rendered by the picture tag!\ntip Open the developer tools, select the network tab and select the IMG filter to only show images being requested.\nAs you resize the viewport, you\u0026rsquo;ll see the dirrerent images being requested and rendered!\n Last modified · 13 Mar 2019\nSource : .\n "});index.add({'id':81,'href':'/library/tutorials/docs/backup/example/','title':"Example Site",'content':" Introduction Ferre hinnitibus erat accipitrem dixi Troiae tollens Lorem markdownum, a quoque nutu est quodcumque mandasset veluti. Passim inportuna totidemque nympha fert; repetens pendent, poenarum guttura sed vacet non, mortali undas. Omnis pharetramque gramen portentificisque membris servatum novabis fallit de nubibus atque silvas mihi. Dixit repetitaque Quid; verrit longa; sententia mandat quascumque nescio solebat litore; noctes. Hostem haerentem circuit plenaque tamen.\n Pedum ne indigenae finire invergens carpebat Velit posses summoque De fumos illa foret  Est simul fameque tauri qua ad Locum nullus nisi vomentes. Ab Persea sermone vela, miratur aratro; eandem Argolicas gener.\nMe sol Nec dis certa fuit socer, Nonacria dies manet tacitaque sibi? Sucis est iactata Castrumque iudex, et iactato quoque terraeque es tandem et maternos vittis. Lumina litus bene poenamque animos callem ne tuas in leones illam dea cadunt genus, et pleno nunc in quod. Anumque crescentesque sanguinis progenies nuribus rustica tinguet. Pater omnes liquido creditis noctem.\nif (mirrored(icmp_dvd_pim, 3, smbMirroredHard) != lion(clickImportQueue, viralItunesBalancing, bankruptcy_file_pptp)) { file += ip_cybercrime_suffix; } if (runtimeSmartRom == netMarketingWord) { virusBalancingWin *= scriptPromptBespoke + raster(post_drive, windowsSli); cd = address_hertz_trojan; soap_ccd.pcbServerGigahertz(asp_hardware_isa, offlinePeopleware, nui); } else { megabyte.api = modem_flowchart - web + syntaxHalftoneAddress; } if (3 \u0026lt; mebibyteNetworkAnimated) { pharming_regular_error *= jsp_ribbon + algorithm * recycleMediaKindle( dvrSyntax, cdma); adf_sla *= hoverCropDrive; templateNtfs = -1 - vertical; } else { expressionCompressionVariable.bootMulti = white_eup_javascript( table_suffix); guidPpiPram.tracerouteLinux += rtfTerabyteQuicktime(1, managementRosetta(webcamActivex), 740874); } var virusTweetSsl = nullGigo;  Trepident sitimque Sentiet et ferali errorem fessam, coercet superbus, Ascaniumque in pennis mediis; dolor? Vidit imi Aeacon perfida propositos adde, tua Somni Fluctibus errante lustrat non.\nTamen inde, vos videt e flammis Scythica parantem rupisque pectora umbras. Haec ficta canistris repercusso simul ego aris Dixit! Esse Fama trepidare hunc crescendo vigor ululasse vertice exspatiantur celer tepidique petita aversata oculis iussa est me ferro.\n"});index.add({'id':82,'href':'/library/tutorials/docs/backup/','title':"Backup",'content':" Backup "});index.add({'id':83,'href':'/library/tutorials/docs/articles/data-science/pandas/21-pandas-operations/','title':"21 Pandas operations",'content':" 21 Pandas operations for absolute beginners  Source  Prerequisites: Python and NumPy basics.\nA CSV file is comma-separated so in order to read a CSV file, do:\ndf = pd.read_csv(file_path, sep=’,’, header = 0, index_col=False,names=None)  Explanation:\nread_csv function has a plethora of parameters and I have specified only a few, ones that you may use most often. A few key points:\na) - header=0 means you have the names of columns in the first row in the file and if you don’t you will have to specify header=None b)  - index_col = False means to not use the first column of the data as an index in the data frame, you might want to set it to true if the first column is really an index. c) names = None implies you are not specifying the column- names and want it to be inferred from csv file, which means that your header = some_numbercontains column names. Otherwise, you can specify the names in here in the same order as you have the data in the csv file. If you are reading a text file separated by space or tab, you could simply change the sep to be:\nsep = \u0026quot; \u0026quot;` or `sep='\\t'`   How to create a data frame using a dictionary of pre-existing columns or NumPy 2D arrays? Using the dictionary\n# c1, c2, c3, c4 are column names. d_dic ={'first_col_name':c1,'second_col_names':c2,'3rd_col_name':c3} df = pd.DataFrame(data = d_dic)  Using NumPy arrays\nnp_data = np.zeros((no_of_samples,no_of_features))  any_numpy_array\ndf = pd.DataFrame(data=np_data, columns = list_of_Col_names)  How to visualize the top and bottom x values in a data frame?\ndf.head(num_of_rows_to_view) #top_values df.tail(num_of_rows_to_view) #bottom_values col = list_of_columns_to_view df[col].head(num_of_rows_to_view) df[col].tail(num_of_rows_to_view)  How to rename one or more columns?\ndf = pd.DataFrame(data={'a':[1,2,3,4,5],'b':[0,1,5,10,15]}) new_df = df.rename({'a':'new_a','b':'new_b'})  It is important to store the return data frame to a new data frame #as the renaming is not in-place.\n How to get column names in a list? df.columns.tolist() Not using tolist() function also does the job if you only want to iterate over the names but it returns everything as an index object.\n How to get the frequency of values in a series?\ndf[col].value_counts() #returns a mapper of key,frequency pair df[col].value_counts()[key] #to get frequency of a key value  How to reset an index to an existing column or another list or array?\nnew_df = df.reset_index(drop=True,inplace=False)  If you do inplace=True, there is no need to store it to a new_df. Also, when you are resetting the index to pandas RangeIndex(), you have the option to either keep the old index or drop it with ‘drop’ parameter. You may want to keep it, especially when it was one of the columns originally and you temporarily set it as the newindex.\n How to remove a column?\ndf.drop(columns = list_of_cols_to_drop)  How to change the index in a data frame?\ndf.set_index(col_name,inplace=True)  This will set col_name col as the index. You could pass more than one column to set them as index. inplace keyword serves the same purpose like before.\n How to remove rows or columns if they have nan values?\ndf.dropna(axis=0,inplace=True)  axis= 0 will drop any column that has nan values, which you might not want most times. axis = 1 will drop only the rows that have nan values in any of the columns. inplace is same like above.\n How to slice a data frame given a condition? You always need to specify a mask in the form of logical conditions.\n  For eg, if you have column age and you would want to select the data frame where age column has a particular value or lies in a list. Then you can achieve the slicing as follows:\nmask = df['age'] == age_value  or\nmask = df['age].isin(list_of_age_values) result = df[mask]  with multiple conditions: Eg. Choosing rows where both height and age correspond to particular values.\nmask = (df['age']==age_value) \u0026amp; (df['height'] == height_value) result = df[mask]   How to slice a data frame given names of columns or index values of rows? There are 4 options here: at,iat, loc and iloc. Among these ‘iat’ and ‘iloc’ are similar in the sense they provide integer-based indexing while ‘loc’ and ‘at’ provide name-based indexing. Another thing to note here is that iat at ‘provide’ indexing for single element while using ‘loc’ and iloc one can slice more than one element. Examples: a) df.iat[1,2] provides the element at 1th row and 2nd column. Here it\u0026rsquo;s important to note that number 1 doesn\u0026rsquo;t correspond to 1 in index column of dataframe. It\u0026rsquo;s totally possible that index in df does not have 1 at all. It\u0026rsquo;s like python array indexing. b) df.at[first,col_name] provides the value in the row where index value is first and column name is col_name c)\ndf.loc[list_of_indices,list_of_cols] eg df.loc[[4,5],['age','height']]  Slices dataframe for matching indices and column names d) df.iloc[[0,1],[5,6]] used for interger based indexing will return 0 and 1st row for 5th and 6th column.\n How to iterate over rows?\niterrows() and itertuples() for i,row in df.iterrows(): sum+=row['hieght']  iterrows() passess an iterators over rows which are returned as series. If a change is made to any of the data element of a row, it may reflect upon the dataframe as it does not return a copy of rows. itertuples() returns named tuples\nfor row in df.itertuples(): print(row.age)  How to sort by a column?\ndf.sort_values(by = list_of_cols,ascending=True)  How to apply a function to each element to a series?\ndf['series_name'].apply(f)  where f is the function you want to apply to each element of the series. If you also want to pass arguments to the custom function, you could modify it like this.\ndef f(x,**kwargs): #do_somthing return value_to_store df['series_name'].apply(f, a= 1, b=2,c =3)  If you want to apply a function to more than a series, then:\ndef f(row): age = row['age'] height = row['height'] df[['age','height']].apply(f,axis=1)  If you don\u0026rsquo;t use axis=1, f will be applied to each element of both the series. axis=1 helps to pass age and height of each row for any manipulation you want.\n How to apply a function to all elements in a data frame?\nnew_df = df.applymap(f)  How to slice a data frame if values of a series lie in a list? Use masking and isin. To choose data samples where age lies in the list:\ndf[df['age'].isin(age_list)]  To chose the opposite, data samples where age does not lie in the list use:\ndf[~df['age'].isin(age_list)]  How to group-by column values and aggregate over another column or apply a function to it?\ndf.groupby(['age']).agg({'height':'mean'})  This will group the data frame by series ‘age’ and for the height column, it will apply the mean of the grouped values. Sometimes it may happen, that you would want to group-by a certain column and convert all the corresponding grouped elements for other columns into a list. You may achieve this by:\ndf.groupby(['age']).agg(list)  How to create duplicates for other columns for each element in a list of a particular column? The question may be a little confusing. What I actually mean is, suppose you have the following data frame df:\nAge Height(in cm) 20 180 20 175 18 165 18 163 16 170  After applying group-by with a list aggregator, you may get something like:\nAge Height(in cm) 20 [180,175] 18 [165,163] 16 [170]  Now, what if you want to go back to the original data frame by undoing the last operation? You could achieve that using the newly introduced operation called explode in pandas version 0.25. df['height'].explode() will give the desired outcome.\n How to concatenate two data frames? Suppose you have two data-frames df1 and df2 with the given columns name, age, and height and you would want to achieve the concatenation of the two columns. axis=0 is the vertical axis. Here, the result data-frame will have the columns appended from the data-frames:\ndf1 --\u0026gt; name,age,height df2---\u0026gt; name,age,height result = pd.concat([df1,df2],axis=0)  For horizontal concatenation,\ndf1--\u0026gt; name,age df2---\u0026gt;height,salary result = pd.concat([df1,df2], axis=1)  How to merge two data frames? For the previous example, assume you have an employee database forming two dataframes like\ndf1--\u0026gt; name, age, height df2---\u0026gt; name, salary, pincode, sick_leaves_taken  You may want to combine these two dataframe such that each row has all details of an employee. In order to acheive this, you would have to perform a merge operation.\ndf1.merge(df2, on=['name'],how='inner')  This operation will provide a dataframe where each row will comprise of name, age, height, salary, pincode, sick_leaves_taken. how = 'inner' means include the row in result if there is a matching name in both the data frames. For more read: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html?highlight=merge#pandas.DataFrame.merge\n  Wrap-up For any data analysis project as a beginner, you may require to know these operations very well. I have always found Pandas to be a very useful library and now you can integrate with various other data analytics tools and languages. Knowing pandas operations may even help while learning languages that support distributed algorithms.\nContact If you liked this post, please clap and share it with others who might find it useful. I really love data science and if you are interested in it too, let’s connect on LinkedIn or follow me here on towards data science platform.\n"});index.add({'id':84,'href':'/library/tutorials/docs/articles/python/useful-python-tricks/','title':"An A-Z of useful Python tricks",'content':" An A-Z of useful Python tricks Source : FreeCodeCamp.org\nPython is one of the world’s most popular, in-demand programming languages. This is for many reasons:\n it’s easy to learn it’s super versatile it has a huge range of modules and libraries  I use Python daily as an integral part of my job as a data scientist. Along the way, I’ve picked up a few useful tricks and tips.\nHere, I’ve shared some of them in an A-Z format.\nMost of these ‘tricks’ are things I’ve used or stumbled upon during my day-to-day work. Some I found while browsing the Python Standard Library docs. A few others I found searching through PyPi.\nHowever, credit where it is due — I discovered four or five of them over at awesome-python.com. This is a curated list of hundreds of interesting Python tools and modules. It is worth browsing for inspiration!\nall or any One of the many reasons why Python is such a popular language is because it is readable and expressive.\nIt is often joked that Python is ‘executable pseudocode’. But when you can write code like this, it’s difficult to argue otherwise:\nx = [True, True, False] if any(x): print(\u0026quot;At least one True\u0026quot;) if all(x): print(\u0026quot;Not one False\u0026quot;) if any(x) and not all(x): print(\u0026quot;At least one True and one False\u0026quot;)  bashplotlib You want to plot graphs in the console?\n$ pip install bashplotlib  You can have graphs in the console.\ncollections Python has some great default datatypes, but sometimes they just won’t behave exactly how you’d like them to.\nLuckily, the Python Standard Library offers the collections module. This handy add-on provides you with further datatypes.\nfrom collections import OrderedDict, Counter # Remembers the order the keys are added! x = OrderedDict(a=1, b=2, c=3) # Counts the frequency of each character y = Counter(\u0026quot;Hello World!\u0026quot;)  dir Ever wondered how you can look inside a Python object and see what attributes it has? Of course you have.\nFrom the command line:\ndir() dir(\u0026quot;Hello World\u0026quot;) dir(dir)  This can be a really useful feature when running Python interactively, and for dynamically exploring objects and modules you are working with.\nRead more here.\nemoji Yes, really.\n$ pip install emoji  Don’t pretend you’re not gonna try it out…\nfrom emoji import emojize print(emojize(\u0026quot;:thumbs_up:\u0026quot;))  from future import One consequence of Python’s popularity is that there are always new versions under development. New versions mean new features — unless your version is out-of-date.\nFear not, however. The future module lets you import functionality from future versions of Python. It’s literally like time travel, or magic, or something.\nfrom __future__ import print_function print(\u0026quot;Hello World!\u0026quot;)  Why not have a go importing curly braces?\ngeopy Geography can be a challenging terrain for programmers to navigate (ha, a pun!). But the geopy module makes it unnervingly easy.\n$ pip install geopy  It works by abstracting the APIs of a range of different geocoding services. It enables you to obtain a place’s full street address, latitude, longitude, and even altitude.\nThere’s also a useful distance class. It calculates the distance between two locations in your favorite unit of measurement.\nfrom geopy import GoogleV3 place = \u0026quot;221b Baker Street, London\u0026quot; location = GoogleV3().geocode(place) print(location.address) print(location.location)  howdoi Stuck on a coding problem and can’t remember that solution you saw before? Need to check StackOverflow, but don’t want to leave the terminal?\nThen you need this useful command line tool.\npip install howdoi  Ask it whatever question you have, and it’ll do its best to return an answer.\n$ howdoi vertical align css $ howdoi for loop in java $ howdoi undo commits in git  Be aware though — it scrapes code from top answers from StackOverflow. It might not always give the most helpful information…\n$ howdoi exit vim  inspect Python’s inspect module is great for understanding what is happening behind the scenes. You can even call its methods on itself!\nThe code sample below uses inspect.getsource() to print its own source code. It also uses inspect.getmodule() to print the module in which it was defined.\nThe last line of code prints out its own line number.\nimport inspect print(inspect.getsource(inspect.getsource)) print(inspect.getmodule(inspect.getmodule)) print(inspect.currentframe().f_lineno)  Of course, beyond these trivial uses, the inspect module can prove useful for understanding what your code is doing. You could also use it for writing self-documenting code.\nJedi The Jedi library is an autocompletion and code analysis library. It makes writing code quicker and more productive.\nUnless you’re developing your own IDE, you’ll probably be most interested in using Jedi as an editor plugin. Luckily, there are already loads available!\nYou may already be using Jedi, however. The IPython project makes use of Jedi for its code autocompletion functionality.\nkwargs When learning any language, there are many milestones along the way. With Python, understanding the mysterious **kwargs syntax probably counts as one.\nThe double-asterisk in front of a dictionary object lets you pass the contents of that dictionary as named arguments to a function.\nThe dictionary’s keys are the argument names, and the values are the values passed to the function. You don’t even need to call it kwargs!\ndictionary = {\u0026quot;a\u0026quot;: 1, \u0026quot;b\u0026quot;: 2} def someFunction(a, b): print(a + b) return # these do the same thing: someFunction(**dictionary) someFunction(a=1, b=2)  This is useful when you want to write functions that can handle named arguments not defined in advance.\nList comprehensions One of my favourite things about programming in Python are its list comprehensions.\nThese expressions make it easy to write very clean code that reads almost like natural language.\nYou can read more about how to use them here.\nnumbers = [1,2,3,4,5,6,7] evens = [x for x in numbers if x % 2 is 0] odds = [y for y in numbers if y not in evens] cities = ['London', 'Dublin', 'Oslo'] def visit(city): print(\u0026quot;Welcome to \u0026quot;+city) for city in cities: visit(city)  map Python supports functional programming through a number of inbuilt features. One of the most useful is the map() function — especially in combination with lambda functions.\nx = [1, 2, 3] y = map(lambda x : x + 1 , x) # prints out [2,3,4]print(list(y))  In the example above, map() applies a simple lambda function to each element in x. It returns a map object, which can be converted to some iterable object such as a list or tuple.\nnewspaper3k If you haven’t seen it already, then be prepared to have your mind blown by Python’s newspaper module.\nIt lets you retrieve news articles and associated meta-data from a range of leading international publications. You can retrieve images, text and author names.\nIt even has some inbuilt NLP functionality.\nSo if you were thinking of using BeautifulSoup or some other DIY webscraping library for your next project, save yourself the time and effort and $ pip install newspaper3kinstead.\nOperator overloading Python provides support for operator overloading, which is one of those terms that make you sound like a legit computer scientist.\nIt’s actually a simple concept. Ever wondered why Python lets you use the + operator to add numbers and also to concatenate strings? That’s operator overloading in action.\nYou can define objects which use Python’s standard operator symbols in their own specific way. This lets you use them in contexts relevant to the objects you’re working with.\nclass Thing: def __init__(self, value): self.__value = value def __gt__(self, other): return self.__value \u0026gt; other.__value def __lt__(self, other): return self.__value \u0026lt; other.__value something = Thing(100) nothing = Thing(0) # True something \u0026gt; nothing # False something \u0026lt; nothing # Error something + nothing  pprint Python’s default print function does its job. But try printing out any large, nested object, and the result is rather ugly.\nHere’s where the Standard Library’s pretty-print module steps in. This prints out complex structured objects in an easy-to-read format.\nA must-have for any Python developer who works with non-trivial data structures.\nimport requests import pprint url = 'https://randomuser.me/api/?results=1' users = requests.get(url).json() pprint.pprint(users)  Queue Python supports multithreading, and this is facilitated by the Standard Library’s Queue module.\nThis module lets you implement queue data structures. These are data structures that let you add and retrieve entries according to a specific rule.\n‘First in, first out’ (or FIFO) queues let you retrieve objects in the order they were added. ‘Last in, first out’ (LIFO) queues let you access the most recently added objects first.\nFinally, priority queues let you retrieve objects according to the order in which they are sorted.\nHere’s an example of how to use queues for multithreaded programming in Python.\nrepr When defining a class or an object in Python, it is useful to provide an ‘official’ way of representing that object as a string. For example:\n\u0026gt;\u0026gt;\u0026gt; file = open('file.txt', 'r') \u0026gt;\u0026gt;\u0026gt; print(file) \u0026lt;open file 'file.txt', mode 'r' at 0x10d30aaf0\u0026gt;  This makes debugging code a lot easier. Add it to your class definitions as below:\nclass someClass: def __repr__(self): return \u0026quot;\u0026lt;some description here\u0026gt;\u0026quot; someInstance = someClass() # prints \u0026lt;some description here\u0026gt; print(someInstance)  sh Python makes a great scripting language. Sometimes using the standard os and subprocess libraries can be a bit of a headache.\nThe sh library provides a neat alternative.\nIt lets you call any program as if it were an ordinary function — useful for automating workflows and tasks, all from within Python.\nimport sh sh.pwd() sh.mkdir('new_folder') sh.touch('new_file.txt') sh.whoami() sh.echo('This is great!')  Type hints Python is a dynamically-typed language. You don’t need to specify datatypes when you define variables, functions, classes etc.\nThis allows for rapid development times. However, there are few things more annoying than a runtime error caused by a simple typing issue.\nSince Python 3.5, you have the option to provide type hints when defining functions.\ndef addTwo(x : Int) -\u0026gt; Int: return x + 2  You can also define type aliases:\nfrom typing import List  Vector = List[float]Matrix = List[Vector]  def addMatrix(a : Matrix, b : Matrix) -\u0026gt; Matrix: result = [] for i,row in enumerate(a): result_row =[] for j, col in enumerate(row): result_row += [a[i][j] + b[i][j]] result += [result_row] return result x = [[1.0, 0.0], [0.0, 1.0]] y = [[2.0, 1.0], [0.0, -2.0]] z = addMatrix(x, y)  Although not compulsory, type annotations can make your code easier to understand.\nThey also allow you to use type checking tools to catch those stray TypeErrors before runtime. Probably worthwhile if you are working on large, complex projects!\nuuid A quick and easy way to generate Universally Unique IDs (or ‘UUIDs’) is through the Python Standard Library’s uuid module.\nimport uuid user_id = uuid.uuid4() print(user_id)  This creates a randomized 128-bit number that will almost certainly be unique.\nIn fact, there are over 2¹²² possible UUIDs that can be generated. That’s over five undecillion (or 5,000,000,000,000,000,000,000,000,000,000,000,000).\nThe probability of finding duplicates in a given set is extremely low. Even with a trillion UUIDs, the probability of a duplicate existing is much, much less than one-in-a-billion.\nPretty good for two lines of code.\nVirtual environments This is probably my favorite Python thing of all.\nChances are you are working on multiple Python projects at any one time. Unfortunately, sometimes two projects will rely on different versions of the same dependency. Which do you install on your system?\nLuckily, Python’s support for virtual environments lets you have the best of both worlds. From the command line:\npython -m venv my-project source my-project/bin/activate pip install all-the-modules  Now you can have standalone versions and installations of Python running on the same machine. Sorted!\nwikipedia Wikipedia has a great API that allows users programmatic access to an unrivalled body of completely free knowledge and information.\nThe wikipedia module makes accessing this API almost embarrassingly convenient.\nimport wikipedia result = wikipedia.page('freeCodeCamp') print(result.summary) for link in result.links: print(link)  Like the real site, the module provides support for multiple languages, page disambiguation, random page retrieval, and even has a donate() method.\nxkcd Humour is a key feature of the Python language — after all, it is named after the British comedy sketch show Monty Python’s Flying Circus. Much of Python’s official documentation references the show’s most famous sketches.\nThe sense of humour isn’t restricted to the docs, though. Have a go running the line below:\nimport antigravity  Never change, Python. Never change.\nYAML YAML stands for ‘YAML Ain’t Markup Language’. It is a data formatting language, and is a superset of JSON.\nUnlike JSON, it can store more complex objects and refer to its own elements. You can also write comments, making it particularly suited to writing configuration files.\nThe PyYAML module lets you use YAML with Python. Install with:\n$ pip install pyyaml  And then import into your projects:\nimport yaml  PyYAML lets you store Python objects of any datatype, and instances of any user-defined classes also.\nzip One last trick for ya, and it really is a cool one. Ever needed to form a dictionary out of two lists?\nkeys = ['a', 'b', 'c'] vals = [1, 2, 3] zipped = dict(zip(keys, vals))  The zip() inbuilt function takes a number of iterable objects and returns a list of tuples. Each tuple groups the elements of the input objects by their positional index.\nYou can also ‘unzip’ objects by calling *zip() on them.\nThanks for reading! So there you have it, an A-Z of Python tricks — hopefully you’ve found something useful for your next project.\nPython’s a very diverse and well-developed language, so there’s bound to be many features I haven’t got round to including.\nPlease share any of your own favorite Python tricks by leaving a response below!\n Written with StackEdit.\n "});index.add({'id':85,'href':'/library/tutorials/docs/articles/data-science/pandas/pandas-house-market-analysis-2/','title':"Basic Data Analysis",'content':" Introduction to basic data analysis with Pandas (Private Munich Housemarket data set) Source\nThis article is the continuation from a previous article (here link to medium) where I explained my goal of identifying the value of House Market in Munich in order to buy a house.\nSince I get the data, buying a house in Munich is out the question, I don’t (and probably will never) earn enough to actually realize that but the data are still interesting in order to do a quick look at data analysis with pandas.\nThe first article was really focused on cleaning the data, because in order to do realize a proper data analysis you need clean data. Otherwise, you will stumble on a lot of issues when running your code. Also, I really like the saying that state : “Garbage in, Garbage out”\nIf you don’t clean your data, then you could analyse wrong data points and it would give you wrong results.\nOn this article, we will go deeper on what the pandas library can do for you regarding the analysis of your data set and some visualization. I like the idiom “_A picture is worth a thousand words_”. I am also very visual so it really helps to picture what you are seeing in your data set.\nPandas methods overview At the very beginning, by importing the last version of the data set (that you have cleaned or retrieved from my github account), you can start by doing some method that will give you some information.\nimport pandas as pd df = pd.read_csv('data_immo.clean.csv', delimiter='\\t') df.head(1).T ## I like the transpose function as it gives you a better view  using the transpose on one line allows you to see easily type of data and column name\ndf.describe() ## Always worth checking  As you have probably noticing, we have the same number of count for each column. Thanks to our cleaning, all of the remaining data are available for us to find some interesting information.\nAs you probably have realized by now, this data set is a time series, it means that there is a timestamp-like column and that would enable to see evolution of the data set over time.\nThis can be useful for our analysis, seeing if there is a evolution.\nIn order to set the time series, we would need to use some method to identify which column is containing this information and how to translate it into the pandas data frame.\nYou would want (but not need) to import the datetime library and transform the date_year_month column.\nWe import the datetime if we want to actually do other stuff from the datetime column we will create from this translation.\nimport datetime df['date'] = pd.to_datetime(df['date_year_month'],format= '%Y%m') ## This will create a new column that contains your datetime element ##Let's not stop here and analyze the different element identified in that column df['date'].value_counts() ##Unique values and number of occurences  We see that the April 2016, May and December\n2017 have low number of values.\nWe need to remember that in order to not get conclusion on those month. Not enough data points to assume anything there.\nContinuing from having an idea on your data set, you can realize some easy visualization in order to analyse your data set or just a series.\nIf we want to see the distribution of the price, we can realize this kind of box plotting\nax = df['price'].plot(kind='box', title='box plot visualization - price') #return an object from matplotlib ax.set_ylabel('price') ax.set_xlabel('data set')  oh oh… what are those data points near 0 ?\nHere you can see that most of the values (25–75%) are within 210 k and 500 K€.\nBut you can also see some extra point and more importantly, it seems that there are data points to clean. We have a price for it but it is 0, which is impossible, even if I would really like this.\ndf[df['price'] == df['price'].min()] ## look for the data that match the minimum.  In case you want to have some margin against the minimum, you can do something like this df[df['price'] \u0026lt; df['price'].min()*1.1]  Will take everything below 10% more than the minimum. it doesn\u0026rsquo;t work in our case as our minimum is 0 but we can set a hardcap nothing below 50K. df[df['price'] \u0026lt; 50000]  Let’s keep them for now, we could use that data later on.\nWe are just removing them away from the main analysis and keep them in a separate data frame.\ndf_0_price = df[df['price'] \u0026lt; 50000].copy() df_0_price.reset_index(inplace=True,drop=True) ## let's reset their index df = df[df['price'] \u0026gt; 50000] df.reset_index(inplace=True,drop=True) ## let's reset their index df['price'].plot(kind='box')  This is a lot better\nI think that this part is really a good example of what you are doing at your actual job. Even if you have spent some times cleaning your data set, you will always found something to clean afterwards when you are realizing the analysis. This is the moment when you are actually digging on data and you will face this kind of situation quite often. Re-cleaning the data.\nGetting back to the analysis, an interesting method from pandas is to look if there are correlation between 2 variables.\nIn order to do that, you can use the corr() between 2 series.\ndf[['date_year_month','price']].corr() ## returns 0.42 : So positive correlation, price are increasing with time ## note that we are taking the 'date_year_month' data that are a number such as 201801 so it increased over time. df[['rooms','price']].corr() ## returns 0.093 : No correlation between price and number of rooms. ## But this can be biased by the few number of different room number. df['rooms'].value_counts() ## returns 3 values 2 (821), 3 (24), 4 (8). ## The over representation of 2 rooms will bias the correlation here.  One of the interesting to do with your data is to see reverse the view on them by grouping element by categorical data. If you know a bit of SQL, you will tickle directly on the word “grouping”. Yes the groupby function exists with pandas and it is pretty easy to use.\nOne of interesting analyze that we could do is to see the average price per zip code. In order to have really comparison, we will take the price per square meter (price_surface).\nThis will return a groupby object, the best would be to store it in a variable.\ndf_groupby_zip = df.groupby('zip')['price_surface'].mean() ## The good thing is that you can do a groupby on multiple elements.  df_groupby_zip_room = df.groupby(['zip','rooms'])['price'].mean()  This method is actually very powerful. At this state, it gives a clearer view and a new way to see your data. You may also be like “that is nice, it gets ride of the complexity but I would like to know what is actually going on”\nWhat if I tell you that you can work with this method in order to see what is going on (how many data points have been aggregated) but adding more calculation into a single command.\ndf_groupby_zip_agg = df.groupby('zip').agg({'price_surface' : ['mean','count','max']})  WHAT ??? In one line ?\nYes, it is that easy to get the average price per square meter per zip code and the number or data points and the maximum of each group aggregation. The .agg is definitely something you need to remember.\nAs you could have guessed, it would just requires that we add another column name in the dictionary to actually take another column into account(with the appropriate calculation you would like to apply to it).\nThe problem comes here as the _pricesurface column will have a multiple index and this is not easy to deal with.\nThe way I use to select only one column from the _pricesurface data type is to use .loc[] selection.\ndf_groupby_zip_agg.loc[:,('price_surface','mean')]  Pandas Visualization Pandas has matplotlib integrated in order to realize some easy visualizations.\nYou have already seen the boxplot which is quite interesting to have a view on your data set distribution. On the next part of this article, we will see how to create such visualization in order to see your data set.\nIn order to see the visualization, you want to write this line of code :\n%matplotlib inline #will generate the graph in your console  As I explained earlier, the cool thing with our data set is that it is a time series.\nTo really get the most of this kind of data, you want to have the datetime column to be on your index.\nOnce you have done that, all the plot will be generated in a time series manner.\nddf = df.set_index('date') ddf_gby_mean = ddf.groupby('date').mean() ddf_gby_mean[['price_room','price']].plot()  simple visualization\nThis is a very basic plotting though.\nYou could change the type, using the kind attribute but there are so much more attributes you can use. The most useful ones for me are :\n kind : determine the type of plot, my favorite being barh or bar. figsize : takes a tuple to resize your graph title : give a title to your graph cmap : use a different color map, link to some docs\nddf_gby_mean[['price_room','price']].plot(kind='area',title='price per room \u0026amp; price overtime',figsize=(10,7),cmap='tab20')    How better is it ?\nYou can clearly see an evolution in the data set starting November 2016.\nWe get a higher price average, this may be because the maximum has been increase. I can tell you that is the case but let’s look at the data to confirm that.\ngraph = pd.DataFrame(df.groupby('date').agg({'price':['max','count']})) ##setting a new view with groupby ax = graph.loc[:,('price','max')].plot(kind='line',title='Maximum price per month',figsize=(13,6))  You can clearly see that I increased the maximum price that I was looking for. This is because the price in Munich are so high that there are no other choices.\nPandas graphic representation are quite useful and will help you to get a good understanding of your data. However, you can also use other plotting library that have some advance visual representation. This topic will deserve another blog post by itself but let’s look at another one, which is quite easy to use and can be quite powerful for additional graph visualization : seaborn\nimport seaborn as sns sns.relplot(x=\u0026quot;construction_year\u0026quot;, y=\u0026quot;price\u0026quot;, hue='rooms',sizes=(20, 400), alpha=.7, height=10, data=df)  Easy enough to visualize the price by construction year and number of room ?\nWe can see that most of the offer in the market (for my price range) is for between ~1960 till ~1990. There are even building that have expected construction year till 2020.\nOverall, the usage of plotting functions are often coming from a wrapper around matplotlib. Therefore, you should really start to know what this library is about so you can better integrate the possibilities that it offers.\nI hope this post was helping on knowing how to use pandas to actually doing basic data analysis. I planned to cover more topics and visualization but this is getting already long. I will be back ;)\n"});index.add({'id':86,'href':'/library/tutorials/docs/articles/python/python-code-example/','title':"Code Examples",'content':" Python Code Examples By : freeCodeCamp\nPython is a general purpose programming language which is dynamically typed, interpreted, and known for its easy readability with great design principles.\nPython Data Structures Example Some general information about floating point numbers and how they work in Python, can be found here.\nNearly all implementations of Python follow the IEEE 754 specification: Standard for Binary Floating-Point Arithmetic. More information found on the IEEE site.\nFloat objects can be created using floating point literals:\n\u0026gt;\u0026gt;\u0026gt; 3.14 3.14 \u0026gt;\u0026gt;\u0026gt; 314\\. # Trailing zero(s) not required. 314.0 \u0026gt;\u0026gt;\u0026gt; .314 # Leading zero(s) not required. 0.314 \u0026gt;\u0026gt;\u0026gt; 3e0 3.0 \u0026gt;\u0026gt;\u0026gt; 3E0 # 'e' or 'E' can be used. 3.0 \u0026gt;\u0026gt;\u0026gt; 3e1 # Positive value after e moves the decimal to the right. 30.0 \u0026gt;\u0026gt;\u0026gt; 3e-1 # Negative value after e moves the decimal to the left. 0.3 \u0026gt;\u0026gt;\u0026gt; 3.14e+2 # '+' not required but can be used for exponent part. 314.0  Numeric literals do not contain a sign, however creating negative float objects is possible by prefixing with a unary - (minus) operator with no space before the literal:\n\u0026gt;\u0026gt;\u0026gt; -3.141592653589793 -3.141592653589793 \u0026gt;\u0026gt;\u0026gt; type(-3.141592653589793) \u0026lt;class 'float'\u0026gt;  Likewise, positive float objects can be prefixed with a unary + (plus) operator with no space before the literal. Usually + is omitted:\n\u0026gt;\u0026gt;\u0026gt; +3.141592653589793 3.141592653589793  Note that leading and trailing zero(s) are valid for floating point literals.\n\u0026gt;\u0026gt;\u0026gt; 0.0 0.0 \u0026gt;\u0026gt;\u0026gt; 00.00 0.0 \u0026gt;\u0026gt;\u0026gt; 00100.00100 100.001 \u0026gt;\u0026gt;\u0026gt; 001e0010 # Same as 1e10 10000000000.0  The float constructor is another way to create float objects.\nCreating float objects with floating point literals is preferred when possible:\n\u0026gt;\u0026gt;\u0026gt; a = 3.14 # Prefer floating point literal when possible. \u0026gt;\u0026gt;\u0026gt; type(a) \u0026lt;class 'float'\u0026gt; \u0026gt;\u0026gt;\u0026gt; b = int(3.14) # Works but unnecessary. \u0026gt;\u0026gt;\u0026gt; type(b) \u0026lt;class 'float'\u0026gt;  However, the float constructor allows for creating float objects from other number types:\n\u0026gt;\u0026gt;\u0026gt; a = 4 \u0026gt;\u0026gt;\u0026gt; type(a) \u0026lt;class 'int'\u0026gt; \u0026gt;\u0026gt;\u0026gt; print(a) 4 \u0026gt;\u0026gt;\u0026gt; b = float(4) \u0026gt;\u0026gt;\u0026gt; type(b) \u0026lt;class 'float'\u0026gt; \u0026gt;\u0026gt;\u0026gt; print(b) 4.0 \u0026gt;\u0026gt;\u0026gt; float(400000000000000000000000000000000) 4e+32 \u0026gt;\u0026gt;\u0026gt; float(.00000000000000000000000000000004) 4e-32 \u0026gt;\u0026gt;\u0026gt; float(True) 1.0 \u0026gt;\u0026gt;\u0026gt; float(False) 0.0  The float constructor will also make float objects from strings that represent number literals:\n\u0026gt;\u0026gt;\u0026gt; float('1') 1.0 \u0026gt;\u0026gt;\u0026gt; float('.1') 0.1 \u0026gt;\u0026gt;\u0026gt; float('3.') 3.0 \u0026gt;\u0026gt;\u0026gt; float('1e-3') 0.001 \u0026gt;\u0026gt;\u0026gt; float('3.14') 3.14 \u0026gt;\u0026gt;\u0026gt; float('-.15e-2') -0.0015  The float constructor can also be used to make numeric representations of NaN (Not a Number), negative infinity and infinity (note that strings for these are case insensitive):\n\u0026gt;\u0026gt;\u0026gt; float('nan') nan \u0026gt;\u0026gt;\u0026gt; float('inf') inf \u0026gt;\u0026gt;\u0026gt; float('-inf') -inf \u0026gt;\u0026gt;\u0026gt; float('infinity') inf \u0026gt;\u0026gt;\u0026gt; float('-infinity') -inf  Python Bools Example bool() is a built-in function in Python 3. This function returns a Boolean value, i.e. True or False. It takes one argument, x.\nArguments It takes one argument, x. x is converted using the standard Truth Testing Procedure.\nReturn Value If x is false or omitted, this returns False; otherwise it returns True.\nCode Sample print(bool(4 \u0026gt; 2)) # Returns True as 4 is greater than 2 print(bool(4 \u0026lt; 2)) # Returns False as 4 is not less than 2 print(bool(4 == 4)) # Returns True as 4 is equal to 4 print(bool(4 != 4)) # Returns False as 4 is equal to 4 so inequality doesn't holds print(bool(4)) # Returns True as 4 is a non-zero value print(bool(-4)) # Returns True as -4 is a non-zero value print(bool(0)) # Returns False as it is a zero value print(bool('dskl')) # Returns True as the string is a non-zero value print(bool([1, 2, 3])) # Returns True as the list is a non-zero value print(bool((2,3,4))) # Returns True as tuple is a non-zero value print(bool([])) # Returns False as list is empty and equal to 0 according to truth value testing  Python Bool Operators Example and, or, not\nPython Docs - Boolean Operations\nThese are the Boolean operations, ordered by ascending priority:\nOperationResultNotes x or y if x is false, then y, else x (1) x and y if x is false, then x, else y (2) not x if x is false, then True, else False (3).\n*Notes:*\n This is a short-circuit operator, so it only evaluates the second argument if the first one is False. This is a short-circuit operator, so it only evaluates the second argument if the first one is True. not has a lower priority than non-Boolean operators, so not a == b is interpreted as not(a == b), and a == not b is a syntax error.  Examples: not: \u0026gt;\u0026gt;\u0026gt; not True False \u0026gt;\u0026gt;\u0026gt; not False True  and: \u0026gt;\u0026gt;\u0026gt; True and False # Short-circuited at first argument. False \u0026gt;\u0026gt;\u0026gt; False and True # Second argument is evaluated. False \u0026gt;\u0026gt;\u0026gt; True and True # Second argument is evaluated. True  or: \u0026gt;\u0026gt;\u0026gt; True or False # Short-circuited at first argument. True \u0026gt;\u0026gt;\u0026gt; False or True # Second argument is evaluated. True \u0026gt;\u0026gt;\u0026gt; False or False # Second argument is evaluated. False  Python Constant Example Three commonly used built-in constants:\n True: The true value of the bool type. Assignments to True raise a SyntaxError. False: The false value of the bool type. Assignments to False raise a SyntaxError. None : The sole value of the type NoneType. None is frequently used to represent the absence of a value, as when default arguments are not passed to a function. Assignments to None raise a SyntaxError.  Other built-in constants:\n NotImplemented: Special value which should be returned by the binary special methods, such as __eg__(), __add__(), __rsub__(), etc.) to indicate that the operation is not implemented with respect to the other type. Ellipsis: Special value used mostly in conjunction with extended slicing syntax for user-defined container data types. __debug__: True if Python was not started with an -o option.  Constants added by the site module. The site module (which is imported automatically during startup, except if the -S command-line option is given) adds several constants to the built-in namespace. They are useful for the interactive interpreter shell and should not be used in programs.\nObjects that, when printed, print a message like “Use quit() or Ctrl-D (i.e. EOF) to exit”, and when called, raise SystemExit with the specified exit code:\n quit(code=None) exit(code=None)  Objects that, when printed, print a message like “Type license() to see the full license text”, and when called, display the corresponding text in a pager-like fashion (one screen at a time):\n copyright license credits  Calling Python Function Example A function definition statement does not execute the function. Executing (calling) a function is done by using the name of the function followed by parenthesis enclosing required arguments (if any).\n\u0026gt;\u0026gt;\u0026gt; def say_hello(): ... print('Hello') ... \u0026gt;\u0026gt;\u0026gt; say_hello() Hello  The execution of a function introduces a new symbol table used for the local variables of the function. More precisely, all variable assignments in a function store the value in the local symbol table.\nOn the other hand, variable references first look in the local symbol table, then in the local symbol tables of enclosing functions, then in the global symbol table, and finally in the table of built-in names. Thus, global variables cannot be directly assigned a value within a function (unless named in a global statement), although they may be referenced.\n\u0026gt;\u0026gt;\u0026gt; a = 1 \u0026gt;\u0026gt;\u0026gt; b = 10 \u0026gt;\u0026gt;\u0026gt; def fn(): ... print(a) # local a is not assigned, no enclosing function, global a referenced. ... b = 20 # local b is assigned in the local symbol table for the function. ... print(b) # local b is referenced. ... \u0026gt;\u0026gt;\u0026gt; fn() 1 20 \u0026gt;\u0026gt;\u0026gt; b # global b is not changed by the function call. 10  The actual parameters (arguments) to a function call are introduced in the local symbol table of the called function when it is called. In this way, arguments are passed using call by value (where the value is always an object reference, not the value of the object). When a function calls another function, a new local symbol table is created for that call.\n\u0026gt;\u0026gt;\u0026gt; def greet(s): ... s = \u0026quot;Hello \u0026quot; + s # s in local symbol table is reassigned. ... print(s) ... \u0026gt;\u0026gt;\u0026gt; person = \u0026quot;Bob\u0026quot; \u0026gt;\u0026gt;\u0026gt; greet(person) Hello Bob \u0026gt;\u0026gt;\u0026gt; person # person used to call remains bound to original object, 'Bob'. 'Bob'  The arguments used to call a function cannot be reassigned by the function, but arguments that reference mutable objects can have their values changed:\n\u0026gt;\u0026gt;\u0026gt; def fn(arg): ... arg.append(1) ... \u0026gt;\u0026gt;\u0026gt; a = [1, 2, 3] \u0026gt;\u0026gt;\u0026gt; fn(a) \u0026gt;\u0026gt;\u0026gt; a [1, 2, 3, 1]  Python Class Example Classes provide a means of bundling data and functionality together. Creating a new class creates a new type of object, allowing new instances of that type to be made. Each class instance can have attributes attached to it for maintaining its state. Class instances can also have methods (defined by its class) for modifying its state.\nCompared with other programming languages, Python’s class mechanism adds classes with a minimum of new syntax and semantics. It is a mixture of the class mechanisms found in C++.\nPython classes provide all the standard features of Object Oriented Programming: the class inheritance mechanism allows multiple base classes, a derived class can override any methods of its base class or classes, and a method can call the method of a base class with the same name.\nObjects can contain arbitrary amounts and kinds of data. As is true for modules, classes partake of the dynamic nature of Python: they are created at runtime, and can be modified further after creation.\nClass Definition Syntax : The simplest form of class definition looks like this:\nclass ClassName: \u0026lt;statement-1\u0026gt; ... ... ... \u0026lt;statement-N\u0026gt;  Class Objects: Class objects support two kinds of operations: attribute references and instantiation.\nAttribute references use the standard syntax used for all attribute references in Python: obj.name. Valid attribute names are all the names that were in the class’s namespace when the class object was created. So, if the class definition looked like this:\nclass MyClass: \u0026quot;\u0026quot;\u0026quot; A simple example class \u0026quot;\u0026quot;\u0026quot; i = 12345 def f(self): return 'hello world'  Then MyClass.i and MyClass.f are valid attribute references, returning an integer and a function object, respectively. Class attributes can also be assigned to, so you can change the value of MyClass.i by assignment. __doc__ is also a valid attribute, returning the docstring belonging to the class: \u0026quot;A simple example class\u0026quot;.\nClass instantiation uses function notation. Just pretend that the class object is a parameterless function that returns a new instance of the class. For example (assuming the above class):\nx = MyClass()  Creates a new instance of the class and assigns this object to the local variable x.\nThe instantiation operation (“calling” a class object) creates an empty object. Many classes like to create objects with instances customized to a specific initial state. Therefore a class may define a special method named *init*(), like this:\ndef __init__(self): self.data = []  When a class defines an __init__() method, class instantiation automatically invokes __init__() for the newly-created class instance. So in this example, a new, initialized instance can be obtained by:\nx = MyClass()  Of course, the __init__() method may have arguments for greater flexibility. In that case, arguments given to the class instantiation operator are passed on to __init__(). For example,\nclass Complex: def __init__(self, realpart, imagpart): self.r = realpart self.i = imagpart ... x = Complex(3.0, -4.5) \u0026gt;\u0026gt;\u0026gt; x.r, x.i (3.0, -4.5)  Python Code Blocks and Indention Example It is generally good practice for you not to mix tabs and spaces when coding in Python. Doing this can possibly cause a TabError, and your program will crash. Be consistent when you code - choose either to indent using tabs or spaces and follow your chosen convention throughout your program.\nCode Blocks and Indentation One of the most distinctive features of Python is its use of indentation to mark blocks of code. Consider the if-statement from our simple password-checking program:\nif pwd == 'apple': print('Logging on ...') else: print('Incorrect password.') print('All done!')  The lines print(‘Logging on …’) and print(‘Incorrect password.’) are two separate code blocks. These happen to be only a single line long, but Python lets you write code blocks consisting of any number of statements.\nTo indicate a block of code in Python, you must indent each line of the block by the same amount. The two blocks of code in our example if-statement are both indented four spaces, which is a typical amount of indentation for Python.\nIn most other programming languages, indentation is used only to help make the code look pretty. But in Python, it is required for indicating what block of code a statement belongs to. For instance, the final print(‘All done!’) is not indented, and so is not part of the else-block.\nProgrammers familiar with other languages often bristle at the thought that indentation matters: Many programmers like the freedom to format their code how they please. However, Python indentation rules are quite simple, and most programmers already use indentation to make their code readable. Python simply takes this idea one step further and gives meaning to the indentation.\nIf/elif-statements An if/elif-statement is a generalized if-statement with more than one condition. It is used for making complex decisions. For example, suppose an airline has the following “child” ticket rates: Kids 2 years old or younger fly for free, kids older than 2 but younger than 13 pay a discounted child fare, and anyone 13 years or older pays a regular adult fare. The following program determines how much a passenger should pay:\n# airfare.py age = int(input('How old are you? ')) if age \u0026lt;= 2: print(' free') elif 2 \u0026lt; age \u0026lt; 13: print(' child fare) else: print('adult fare')  After Python gets age from the user, it enters the if/elif-statement and checks each condition one after the other in the order they are given.\nSo first it checks if age is less than 2, and if so, it indicates that the flying is free and jumps out of the elif-condition. If age is not less than 2, then it checks the next elif-condition to see if age is between 2 and 13. If so, it prints the appropriate message and jumps out of the if/elif-statement. If neither the if-condition nor the elif-condition is True, then it executes the code in the else-block.\nConditional expressions Python has one more logical operator that some programmers like (and some don’t!). It’s essentially a shorthand notation for if-statements that can be used directly within expressions. Consider this code:\nfood = input(\u0026quot;What's your favorite food? \u0026quot;) reply = 'yuck' if food == 'lamb' else 'yum'  The expression on the right-hand side of = in the second line is called a conditional expression, and it evaluates to either ‘yuck’ or ‘yum’. It’s equivalent to the following:\nfood = input(\u0026quot;What's your favorite food? \u0026quot;) if food == 'lamb': reply = 'yuck' else: reply = 'yum'  Conditional expressions are usually shorter than the corresponding if/else-statements, although not quite as flexible or easy to read. In general, you should use them when they make your code simpler.\nPython Comparison Operator Example There are eight comparison operations in Python. They all have the same priority (which is higher than that of the Boolean operations). Comparisons can be chained arbitrarily; for example, x \u0026lt; y \u0026lt;= z is equivalent to x \u0026lt; y and y \u0026lt;= z, except that y is evaluated only once (but in both cases z is not evaluated at all when x \u0026lt; y is found to be false).\nThe following summarizes the comparison operations:\nOperationMeaning\u0026lt;strictly less than\u0026lt;=less than or equal to\u0026gt;strictly greater than\u0026gt;=greater than or equal to==equal to!=not equal to is object identity is notnegated object identity\nObjects of different types, except different numeric types, never compare equal. Furthermore, some types (for example, function objects) support only a degenerate notion of comparison where any two objects of that type are unequal. The \u0026lt;, \u0026lt;=, \u0026gt; and \u0026gt;= operators will raise a TypeError exception when comparing a complex number with another built-in numeric type, when the objects are of different types that cannot be compared, or in other cases where there is no defined ordering.\nNon-identical instances of a class normally compare as non-equal unless the class defines the __eq__()method.\nInstances of a class cannot be ordered with respect to other instances of the same class, or other types of object, unless the class defines enough of the methods __lt__(), __le__(), __gt__(), and __ge__() (in general, __lt__() and __eq__() are sufficient, if you want the conventional meanings of the comparison operators).\nThe behavior of the is and is not operators cannot be customized; also they can be applied to any two objects and never raise an exception.\nWe can also chain \u0026lt; and \u0026gt; operators together. For instance, 3 \u0026lt; 4 \u0026lt; 5 will return True, but 3 \u0026lt; 4 \u0026gt; 5will not. We can also chain the equality operator. For instance, 3 == 3 \u0026lt; 5 will return True but 3 == 5 \u0026lt; 5 will not.\nEquality Comparisons - “is” vs ”==” In Python, there are two comparison operators which allow us to check to see if two objects are equal. The is operator and the == operator. However, there is a key difference between them!\nThe key difference between ‘is’ and ’==’ can be summed up as:\n is is used to compare *identity* == is used to compare *equality*  Example First, create a list in Python.\nmyListA = [1,2,3]  Next, create a copy of that list.\nmyListB = myListA  If we use the ’==’ operator or the ‘is’ operator, both will result in a *True* output.\n\u0026gt;\u0026gt;\u0026gt; myListA == myListB # both lists contains similar elements True \u0026gt;\u0026gt;\u0026gt; myListB is myListA # myListB contains the same elements True  This is because both myListA and myListB are pointing to the same list variable, which I defined at beginning of my Python program. Both lists are exactly the same, both in identity and in content.\nHowever, what if I now create a new list?\nmyListC = [1,2,3]  Performing the == operator still shows that both lists are the same, in terms of content.\n\u0026gt;\u0026gt;\u0026gt; myListA == myListC True  However, performing the is operator will now produce a False output. This is because myListA and myListC are two different variables, despite containing the same data. Even though they look the same, they are *different*.\n\u0026gt;\u0026gt;\u0026gt; myListA is myListC False # both lists have different reference  To sum up:\n An is expression outputs True if both variables are pointing to the same reference An == expression outputs True if both variables contain the same data  Python Dictionary Example A Dictionary (a.k.a “dict”) in python is a built-in datatype that can be used to store *key-value* pairs. This allows you to treat a *dict* like it’s a database to store and organize data.\nThe special thing about dictionaries is the way they are implemented. Hash-table-like structure makes it easy to check for existence - which means that we can easily determine if a specific key is present in the dictionary without needing to examine every element. The Python interpreter can just go to the location key and check if the key is there.\nDictionaries can use almost any arbitrary datatypes, like strings, integers etc, for keys. However, values that are not hashable, that is, values containing lists, dictionaries or other mutable types (that are compared by value rather than by object identity) may not be used as keys. Numeric types used for keys obey the normal rules for numeric comparison: if two numbers compare equal (such as 1 and 1.0) then they can be used interchangeably to index the same dictionary entry. (Note however, that since computers store floating-point numbers as approximations it is usually unwise to use them as dictionary keys.)\nOne most important requirement of a dictionary is that the keys *must* be unique.\nTo create an empty dictionary just use a pair of braces:\n\u0026gt;\u0026gt;\u0026gt; teams = {} \u0026gt;\u0026gt;\u0026gt; type(teams) \u0026gt;\u0026gt;\u0026gt; \u0026lt;class 'dict'\u0026gt;  To create a non-empty dictionary with some initial values, place a comma-seperated list of key-value pairs:\n\u0026gt;\u0026gt;\u0026gt; teams = {'barcelona': 1875, 'chelsea': 1910} \u0026gt;\u0026gt;\u0026gt; teams {'barcelona': 1875, 'chelsea': 1910}  It’s easy to add key-value pairs to an existing dictionary:\n\u0026gt;\u0026gt;\u0026gt; teams['santos'] = 1787 \u0026gt;\u0026gt;\u0026gt; teams {'chelsea': 1910, 'barcelona': 1875, 'santos': 1787} # Notice the order - Dictionaries are unordered ! \u0026gt;\u0026gt;\u0026gt; # extracting value - Just provide the key ... \u0026gt;\u0026gt;\u0026gt; teams['barcelona'] 1875  *del* operator is used to delete a key-value pair from the dict. In scenarios where a key that’s already in use is again used to store values, the old value associated with that key is completely lost. Also, keep in mind that it’s an error to extract the value using a non-existent key.\n\u0026gt;\u0026gt;\u0026gt; del teams['santos'] \u0026gt;\u0026gt;\u0026gt; teams {'chelsea': 1910, 'barcelona': 1875} \u0026gt;\u0026gt;\u0026gt; teams['chelsea'] = 2017 # overwriting \u0026gt;\u0026gt;\u0026gt; teams {'chelsea': 2017, 'barcelona': 1875}  *in* keyword can be used to check whether a key exist in the dict or not:\n\u0026gt;\u0026gt;\u0026gt; 'sanots' in teams False \u0026gt;\u0026gt;\u0026gt; 'barcelona' in teams True \u0026gt;\u0026gt;\u0026gt; 'chelsea' not in teams False  *keys* is a built-in method that can be used to get the keys of a given dictionary. To extract the keys present in a dict as lists:\n\u0026gt;\u0026gt;\u0026gt; club_names = list(teams.keys()) \u0026gt;\u0026gt;\u0026gt; club_names ['chelsea', 'barcelona']  Yet another way of creating a dictionary is using the *dict()* method:\n\u0026gt;\u0026gt;\u0026gt; players = dict( [('messi','argentina'), ('ronaldo','portugal'), ('kaka','brazil')] ) # sequence of key-value pair is passed \u0026gt;\u0026gt;\u0026gt; players {'ronaldo': 'portugal', 'kaka': 'brazil', 'messi': 'argentina'} \u0026gt;\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; # If keys are simple strings, it's quite easier to specify pairs using keyword arguments ... \u0026gt;\u0026gt;\u0026gt; dict( totti = 38, zidane = 43 ) {'zidane': 43, 'totti': 38}  Dict comprehensions can be used as well to create dictionaries from arbitrary key and value expressions:\n\u0026gt;\u0026gt;\u0026gt; {x: x**2 for x in (2, 4, 6)} {2: 4, 4: 16, 6: 36}  *Looping in Dictionary*\nTo simply loop over the keys in the dictionary, rather than the keys and values:\n\u0026gt;\u0026gt;\u0026gt; d = {'x': 1, 'y': 2, 'z': 3} \u0026gt;\u0026gt;\u0026gt; for key in d: ... print(key) # do something ... x y z  To loop over both key and value, you can use the following:\nFor Python 2.x:\n\u0026gt;\u0026gt;\u0026gt; for key, item in d.iteritems(): ... print items ... 1 2 3  Use *items()* for Python 3.x:\n\u0026gt;\u0026gt;\u0026gt; for key, item in d.items(): ... print(key, items) ... x 1 y 2 z 3  Python Objects Example In Python, everything is an object.\nObjects represent a logical grouping of attributes. Attributes are data and/or functions. When an object is created in Python it is created with an identity, type, and value.\nIn other languages, primitives are values that have no properties (attributes). For example, in javascript undefined, null, boolean, string, number, and symbol (new in ECMAScript 2015) are primitives.\nIn Python, there are no primitives. None, booleans, strings, numbers, and even _functions_are all objects regardless how they are created.\nWe can demonstrate this using some built-in functions:\n id type dir issubclass  Built-in constants None, True, and False are objects:\nWe test the None object here.\n\u0026gt;\u0026gt;\u0026gt; id(None) 4550218168 \u0026gt;\u0026gt;\u0026gt; type(None) \u0026lt;class 'NoneType'\u0026gt; \u0026gt;\u0026gt;\u0026gt; dir(None) [__bool__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__le__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__'] \u0026gt;\u0026gt;\u0026gt; issubclass(type(None), object) True  Next, let’s inspect True.\n\u0026gt;\u0026gt;\u0026gt; id(True) 4550117616 \u0026gt;\u0026gt;\u0026gt; type(True) \u0026lt;class 'bool'\u0026gt; \u0026gt;\u0026gt;\u0026gt; dir(True) ['__abs__', '__add__', '__and__', '__bool__', '__ceil__', '__class__', '__delattr__', '__dir__', '__divmod__', '__doc__', '__eq__', '__float__', '__floor__', '__floordiv__', '__format__', '__ge__', '__getattribute__', '__getnewargs__', '__gt__', '__hash__', '__index__', '__init__', '__int__', '__invert__', '__le__', '__lshift__', '__lt__', '__mod__', '__mul__', '__ne__', '__neg__', '__new__', '__or__', '__pos__', '__pow__', '__radd__', '__rand__', '__rdivmod__', '__reduce__', '__reduce_ex__', '__repr__', '__rfloordiv__', '__rlshift__', '__rmod__', '__rmul__', '__ror__', '__round__', '__rpow__', '__rrshift__', '__rshift__', '__rsub__', '__rtruediv__', '__rxor__', '__setattr__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__truediv__', '__trunc__', '__xor__', 'bit_length', 'conjugate', 'denominator', 'from_bytes', 'imag', 'numerator', 'real', 'to_bytes'] \u0026gt;\u0026gt;\u0026gt; issubclass(type(True), object) True  No reason to leave out False!\n\u0026gt;\u0026gt;\u0026gt; id(False) 4550117584 \u0026gt;\u0026gt;\u0026gt; type(False) \u0026lt;class 'bool'\u0026gt; \u0026gt;\u0026gt;\u0026gt; dir(False) ['__abs__', '__add__', '__and__', '__bool__', '__ceil__', '__class__', '__delattr__', '__dir__', '__divmod__', '__doc__', '__eq__', '__float__', '__floor__', '__floordiv__', '__format__', '__ge__', '__getattribute__', '__getnewargs__', '__gt__', '__hash__', '__index__', '__init__', '__int__', '__invert__', '__le__', '__lshift__', '__lt__', '__mod__', '__mul__', '__ne__', '__neg__', '__new__', '__or__', '__pos__', '__pow__', '__radd__', '__rand__', '__rdivmod__', '__reduce__', '__reduce_ex__', '__repr__', '__rfloordiv__', '__rlshift__', '__rmod__', '__rmul__', '__ror__', '__round__', '__rpow__', '__rrshift__', '__rshift__', '__rsub__', '__rtruediv__', '__rxor__', '__setattr__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__truediv__', '__trunc__', '__xor__', 'bit_length', 'conjugate', 'denominator', 'from_bytes', 'imag', 'numerator', 'real', 'to_bytes'] \u0026gt;\u0026gt;\u0026gt; issubclass(type(False), object) True  Strings, even when created by a string literals, are also objects.\n\u0026gt;\u0026gt;\u0026gt; id(\u0026quot;Hello campers!\u0026quot;) 4570186864 \u0026gt;\u0026gt;\u0026gt; type('Hello campers!') \u0026lt;class 'str'\u0026gt; \u0026gt;\u0026gt;\u0026gt; dir(\u0026quot;Hello campers!\u0026quot;) ['__add__', '__class__', '__contains__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getnewargs__', '__gt__', '__hash__', '__init__', '__iter__', '__le__', '__len__', '__lt__', '__mod__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__rmod__', '__rmul__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'capitalize', 'casefold', 'center', 'count', 'encode', 'endswith', 'expandtabs', 'find', 'format', 'format_map', 'index', 'isalnum', 'isalpha', 'isdecimal', 'isdigit', 'isidentifier', 'islower', 'isnumeric', 'isprintable', 'isspace', 'istitle', 'isupper', 'join', 'ljust', 'lower', 'lstrip', 'maketrans', 'partition', 'replace', 'rfind', 'rindex', 'rjust', 'rpartition', 'rsplit', 'rstrip', 'split', 'splitlines', 'startswith', 'strip', 'swapcase', 'title', 'translate', 'upper', 'zfill'] \u0026gt;\u0026gt;\u0026gt; issubclass(type('Hello campers!'), object) True  Same with numbers.\n\u0026gt;\u0026gt;\u0026gt; id(42) 4550495728 \u0026gt;\u0026gt;\u0026gt; type(42) \u0026lt;class 'int'\u0026gt; \u0026gt;\u0026gt;\u0026gt; dir(42) ['__abs__', '__add__', '__and__', '__bool__', '__ceil__', '__class__', '__delattr__', '__dir__', '__divmod__', '__doc__', '__eq__', '__float__', '__floor__', '__floordiv__', '__format__', '__ge__', '__getattribute__', '__getnewargs__', '__gt__', '__hash__', '__index__', '__init__', '__int__', '__invert__', '__le__', '__lshift__', '__lt__', '__mod__', '__mul__', '__ne__', '__neg__', '__new__', '__or__', '__pos__', '__pow__', '__radd__', '__rand__', '__rdivmod__', '__reduce__', '__reduce_ex__', '__repr__', '__rfloordiv__', '__rlshift__', '__rmod__', '__rmul__', '__ror__', '__round__', '__rpow__', '__rrshift__', '__rshift__', '__rsub__', '__rtruediv__', '__rxor__', '__setattr__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__truediv__', '__trunc__', '__xor__', 'bit_length', 'conjugate', 'denominator', 'from_bytes', 'imag', 'numerator', 'real', 'to_bytes'] \u0026gt;\u0026gt;\u0026gt; issubclass(type(42), object) True  Functions are Objects Too In Python, functions are first class objects.\nFunctions in Python are also objects, created with an identity, type, and value. They too can be passed into other functions:\n\u0026gt;\u0026gt;\u0026gt; id(dir) 4568035688 \u0026gt;\u0026gt;\u0026gt; type(dir) \u0026lt;class 'builtin_function_or_method'\u0026gt; \u0026gt;\u0026gt;\u0026gt; dir(dir) ['__call__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__le__', '__lt__', '__module__', '__name__', '__ne__', '__new__', '__qualname__', '__reduce__', '__reduce_ex__', '__repr__', '__self__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__text_signature__'] \u0026gt;\u0026gt;\u0026gt; issubclass(type(dir), object) True  It is also possible to bind functions to a name and called the bound function using that name:\n\u0026gt;\u0026gt;\u0026gt; a = dir \u0026gt;\u0026gt;\u0026gt; print(a) \u0026lt;built-in function dir\u0026gt; \u0026gt;\u0026gt;\u0026gt; a(a) ['__call__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__le__', '__lt__', '__module__', '__name__', '__ne__', '__new__', '__qualname__', '__reduce__', '__reduce_ex__', '__repr__', '__self__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__text_signature__']  Python Tuples A tuple is a sequence of Python objects. Tuples are immutable which means they cannot be modified after creation, unlike lists.\n*Creation:*\nAn empty tuple is created using a pair of round brackets, ():\n\u0026gt;\u0026gt;\u0026gt; empty_tuple = () \u0026gt;\u0026gt;\u0026gt; print(empty_tuple) () \u0026gt;\u0026gt;\u0026gt; type(empty_tuple) \u0026lt;class 'tuple'\u0026gt; \u0026gt;\u0026gt;\u0026gt; len(empty_tuple) 0  A tuple with elements is created by separating the elements with commas (surrounding round brackets, (), are optional with exceptions):\n\u0026gt;\u0026gt;\u0026gt; tuple_1 = 1, 2, 3 # Create tuple without round brackets. \u0026gt;\u0026gt;\u0026gt; print(tuple_1) (1, 2, 3) \u0026gt;\u0026gt;\u0026gt; type(tuple_1) \u0026lt;class 'tuple'\u0026gt; \u0026gt;\u0026gt;\u0026gt; len(tuple_1) 3 \u0026gt;\u0026gt;\u0026gt; tuple_2 = (1, 2, 3) # Create tuple with round brackets. \u0026gt;\u0026gt;\u0026gt; print(tuple_2) (1, 2, 3) \u0026gt;\u0026gt;\u0026gt; tuple_3 = 1, 2, 3, # Trailing comma is optional. \u0026gt;\u0026gt;\u0026gt; print(tuple_3) (1, 2, 3) \u0026gt;\u0026gt;\u0026gt; tuple_4 = (1, 2, 3,) # Trailing comma in round brackets is also optional. \u0026gt;\u0026gt;\u0026gt; print(tuple_4) (1, 2, 3)  A tuple with a single element must have the trailing comma (with or without round brackets):\n\u0026gt;\u0026gt;\u0026gt; not_tuple = (2) # No trailing comma makes this not a tuple. \u0026gt;\u0026gt;\u0026gt; print(not_tuple) 2 \u0026gt;\u0026gt;\u0026gt; type(not_tuple) \u0026lt;class 'int'\u0026gt; \u0026gt;\u0026gt;\u0026gt; a_tuple = (2,) # Single element tuple. Requires trailing comma. \u0026gt;\u0026gt;\u0026gt; print(a_tuple) (2,) \u0026gt;\u0026gt;\u0026gt; type(a_tuple) \u0026lt;class 'tuple'\u0026gt; \u0026gt;\u0026gt;\u0026gt; len(a_tuple) 1 \u0026gt;\u0026gt;\u0026gt; also_tuple = 2, # Round brackets omitted. Requires trailing comma. \u0026gt;\u0026gt;\u0026gt; print(also_tuple) (2,) \u0026gt;\u0026gt;\u0026gt; type(also_tuple) \u0026lt;class 'tuple'\u0026gt;  Round brackets are required in cases of ambiguity (if the tuple is part of a larger expression):\nNote that it is actually the comma which makes a tuple, not the parentheses. The parentheses are optional, except in the empty tuple case, or when they are needed to avoid syntactic ambiguity.\nFor example, f(a, b, c) is a function call with three arguments, while f((a, b, c)) is a function call with a 3-tuple as the sole argument.\n\u0026gt;\u0026gt;\u0026gt; print(1,2,3,4,) # Calls print with 4 arguments: 1, 2, 3, and 4 1 2 3 4 \u0026gt;\u0026gt;\u0026gt; print((1,2,3,4,)) # Calls print with 1 argument: (1, 2, 3, 4,) (1, 2, 3, 4) \u0026gt;\u0026gt;\u0026gt; 1, 2, 3 == (1, 2, 3) # Equivalent to 1, 2, (3 == (1, 2, 3)) (1, 2, False) \u0026gt;\u0026gt;\u0026gt; (1, 2, 3) == (1, 2, 3) # Use surrounding round brackets when ambiguous. True  A tuple can also be created with the tuple constructor:\n\u0026gt;\u0026gt;\u0026gt; empty_tuple = tuple() \u0026gt;\u0026gt;\u0026gt; print(empty_tuple) () \u0026gt;\u0026gt;\u0026gt; tuple_from_list = tuple([1,2,3,4]) \u0026gt;\u0026gt;\u0026gt; print(tuple_from_list) (1, 2, 3, 4) \u0026gt;\u0026gt;\u0026gt; tuple_from_string = tuple(\u0026quot;Hello campers!\u0026quot;) \u0026gt;\u0026gt;\u0026gt; print(tuple_from_string) ('H', 'e', 'l', 'l', 'o', ' ', 'c', 'a', 'm', 'p', 'e', 'r', 's', '!') \u0026gt;\u0026gt;\u0026gt; a_tuple = 1, 2, 3 \u0026gt;\u0026gt;\u0026gt; b_tuple = tuple(a_tuple) # If the constructor is called with a tuple for the iterable, \u0026gt;\u0026gt;\u0026gt; a_tuple is b_tuple # the tuple argument is returned. True  *Accessing elements of a tuple:*\nElements of tuples are accessed and indexed the same way that lists are.\n\u0026gt;\u0026gt;\u0026gt; my_tuple = 1, 2, 9, 16, 25 \u0026gt;\u0026gt;\u0026gt; print(my_tuple) (1, 2, 9, 16, 25)  Zero indexed\n\u0026gt;\u0026gt;\u0026gt; my_tuple[0] 1 \u0026gt;\u0026gt;\u0026gt; my_tuple[1] 2 \u0026gt;\u0026gt;\u0026gt; my_tuple[2] 9  Wrap around indexing\n\u0026gt;\u0026gt;\u0026gt; my_tuple[-1] 25 \u0026gt;\u0026gt;\u0026gt; my_tuple[-2] 16  *Packing and Unpacking:*\nThe statement t = 12345, 54321, 'hello!' is an example of tuple packing: the values 12345, 54321and 'hello!' are packed together in a tuple. The reverse operation is also possible:\n\u0026gt;\u0026gt;\u0026gt; x, y, z = t  This is called, appropriately enough, sequence unpacking and works for any sequence on the right-hand side. Sequence unpacking requires that there are as many variables on the left side of the equals sign as there are elements in the sequence. Note that multiple assignment is really just a combination of tuple packing and sequence unpacking.\n\u0026gt;\u0026gt;\u0026gt; t = 1, 2, 3 # Tuple packing. \u0026gt;\u0026gt;\u0026gt; print(t) (1, 2, 3) \u0026gt;\u0026gt;\u0026gt; a, b, c = t # Sequence unpacking. \u0026gt;\u0026gt;\u0026gt; print(a) 1 \u0026gt;\u0026gt;\u0026gt; print(b) 2 \u0026gt;\u0026gt;\u0026gt; print(c) 3 \u0026gt;\u0026gt;\u0026gt; d, e, f = 4, 5, 6 # Multiple assignment combines packing and unpacking. \u0026gt;\u0026gt;\u0026gt; print(d) 4 \u0026gt;\u0026gt;\u0026gt; print(e) 5 \u0026gt;\u0026gt;\u0026gt; print(f) 6 \u0026gt;\u0026gt;\u0026gt; a, b = 1, 2, 3 # Multiple assignment requires each variable (right) have a matching element (left). Traceback (most recent call last): File \u0026quot;\u0026lt;stdin\u0026gt;\u0026quot;, line 1, in \u0026lt;module\u0026gt; ValueError: too many values to unpack (expected 2)  *Immutable:*\ntuples are immutable containers, guaranteeing *which* objects they contain will not change. It does *not* guarantee that the objects they contain will not change:\n\u0026gt;\u0026gt;\u0026gt; a_list = [] \u0026gt;\u0026gt;\u0026gt; a_tuple = (a_list,) # A tuple (immutable) with a list (mutable) element. \u0026gt;\u0026gt;\u0026gt; print(a_tuple) ([],) \u0026gt;\u0026gt;\u0026gt; a_list.append(\u0026quot;Hello campers!\u0026quot;) \u0026gt;\u0026gt;\u0026gt; print(a_tuple) # Element of the immutable is mutated. (['Hello campers!'],)  *Uses:*\nFunctions can only return a single value, however, a heterogenuous tuple can be used to return multiple values from a function. One example is the built-in enumeratefunction that returns an iterable of heterogenuous tuples:\n\u0026gt;\u0026gt;\u0026gt; greeting = [\u0026quot;Hello\u0026quot;, \u0026quot;campers!\u0026quot;] \u0026gt;\u0026gt;\u0026gt; enumerator = enumerate(greeting) \u0026gt;\u0026gt;\u0026gt; enumerator.next() \u0026gt;\u0026gt;\u0026gt; enumerator.__next__() (0, 'Hello') \u0026gt;\u0026gt;\u0026gt; enumerator.__next__() (1, 'campers!')  Python Decorators Decorators essentially work as wrappers. They modify the behaviour of the code before and after a target function execution, without the need to modify the function itself, augmenting the original functionality, thus decorating it.\nBefore going in detail about decorators, there are some concepts that should be clear. In Python, functions are objects and we can do a lot of useful stuff with them.\n*Assigning funtions to a variables:* def greet(name): return \u0026quot;Hello \u0026quot;+name greet_someone = greet print greet_someone(\u0026quot;John\u0026quot;)  Output: Hello John\nRun code\n*Defining functions inside other functions:* def greet(name): def get_message(): return \u0026quot;Hello \u0026quot; result = get_message()+name return result print(greet(\u0026quot;John\u0026quot;))  Output: Hello John\nRun code\n*Functions can also be passed as parameters to other functions:* def greet(name): return \u0026quot;Hello \u0026quot; + name def call_func(func): other_name = \u0026quot;John\u0026quot; return func(other_name) print call_func(greet)  Output: Hello John\nRun code\n*Functions can return other functions:* In other words, functions generating other functions.\ndef compose_greet_func(): def get_message(): return \u0026quot;Hello there!\u0026quot; return get_message greet = compose_greet_func() print(greet())  Output: Hello there!\nRun code\n*Inner functions have access to the enclosing scope* More commonly known as a closure. A very powerful pattern that we will come across while building decorators. Another thing to note, Python only allows read access to the outer scope and not assignment. Notice how we modified the example above to read a “name” argument from the enclosing scope of the inner function and return the new function.\ndef compose_greet_func(name): def get_message(): return \u0026quot;Hello there \u0026quot;+name+\u0026quot;!\u0026quot; return get_message greet = compose_greet_func(\u0026quot;John\u0026quot;) print(greet())  Output: Hello there John!\nRun code\nComposition of Decorators Function decorators are simply wrappers to existing functions. Putting the ideas mentioned above together, we can build a decorator. In this example let’s consider a function that wraps the string output of another function by p tags.\ndef get_text(name): return \u0026quot;lorem ipsum, {0} dolor sit amet\u0026quot;.format(name) def p_decorate(func): def func_wrapper(name): return \u0026quot;`\u0026lt;p\u0026gt;`{0}`\u0026lt;/p\u0026gt;`\u0026quot;.format(func(name)) return func_wrapper my_get_text = p_decorate(get_text) print (my_get_text(\u0026quot;John\u0026quot;))  Output: \u0026lt;p\u0026gt;lorem ipsum, John dolor sit amet\u0026lt;/p\u0026gt;\nRun code\nThat was our first decorator. A function that takes another function as an argument, generates a new function, augmenting the work of the original function, and returning the generated function so we can use it anywhere. To have get_text itself be decorated by p_decorate, we just have to assign get text to the result of p decorate.\nget_text = p_decorate(get_text) print (get_text(\u0026quot;John\u0026quot;))  Output: lorem ipsum, John dolor sit amet\nAnother thing to notice is that our decorated function takes a name argument. All that we have to do in the decorator is to let the wrapper of get_text pass that argument.\n*Python’s Decorator Syntax* Python makes creating and using decorators a bit cleaner and nicer for the programmer through some syntactic sugar. To decorate get_text we don’t have to get_text = p_decorator(get_text). There is a neat shortcut for that, which is to mention the name of the decorating function before the function to be decorated. The name of the decorator should be perpended with an @ symbol.\ndef p_decorate(func): def func_wrapper(name): return \u0026quot;`\u0026lt;p\u0026gt;`{0}`\u0026lt;/p\u0026gt;`\u0026quot;.format(func(name)) return func_wrapper @p_decorate def get_text(name): return \u0026quot;lorem ipsum, {0} dolor sit amet\u0026quot;.format(name) print get_text(\u0026quot;John\u0026quot;)  Output: \u0026lt;p\u0026gt;lorem ipsum, John dolor sit amet\u0026lt;/p\u0026gt;\nRun code\nNow let’s consider we wanted to decorate our get_text function by 2 other functions to wrap a div and strong tag around the string output.\ndef p_decorate(func): def func_wrapper(name): return \u0026quot;`\u0026lt;p\u0026gt;`{0}`\u0026lt;/p\u0026gt;`\u0026quot;.format(func(name)) return func_wrapper def strong_decorate(func): def func_wrapper(name): return \u0026quot;`\u0026lt;strong\u0026gt;`{0}`\u0026lt;/strong\u0026gt;`\u0026quot;.format(func(name)) return func_wrapper def div_decorate(func): def func_wrapper(name): return \u0026quot;`\u0026lt;div\u0026gt;`{0}`\u0026lt;/div\u0026gt;`\u0026quot;.format(func(name)) return func_wrapper  With the basic approach, decorating get_text would be along the lines of\nget_text = div_decorate(p_decorate(strong_decorate(get_text)))  With Python’s decorator syntax, the same thing can be achieved with much more expressive power.\n@div_decorate @p_decorate @strong_decorate def get_text(name): return \u0026quot;lorem ipsum, {0} dolor sit amet\u0026quot;.format(name) print (get_text(\u0026quot;John\u0026quot;))  Output: \u0026lt;div\u0026gt;\u0026lt;p\u0026gt;\u0026lt;strong\u0026gt;lorem ipsum, John dolor sit amet\u0026lt;/strong\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;/div\u0026gt;\nRun code\nOne important thing to notice here is that the order of setting our decorators matters. If the order was different in the example above, the output would have been different.\nDecorating Methods In Python, methods are functions that expect their first parameter to be a reference to the current object. We can build decorators for methods the same way, while taking self into consideration in the wrapper function.\ndef p_decorate(func): def func_wrapper(self): return \u0026quot;`\u0026lt;p\u0026gt;`{0}`\u0026lt;/p\u0026gt;`\u0026quot;.format(func(self)) return func_wrapper class Person(object): def __init__(self): self.name = \u0026quot;John\u0026quot; self.family = \u0026quot;Doe\u0026quot; @p_decorate def get_fullname(self): return self.name+\u0026quot; \u0026quot;+self.family my_person = Person() print (my_person.get_fullname())  Output: \u0026lt;p\u0026gt;John Doe\u0026lt;/p\u0026gt;\nRun code\nA much better approach would be to make our decorator useful for functions and methods alike. This can be done by putting *args and **kwargs as parameters for the wrapper, then it can accept any arbitrary number of arguments and keyword arguments.\ndef p_decorate(func): def func_wrapper(*args, **kwargs): return \u0026quot;`\u0026lt;p\u0026gt;`{0}`\u0026lt;/p\u0026gt;`\u0026quot;.format(func(*args, **kwargs)) return func_wrapper class Person(object): def __init__(self): self.name = \u0026quot;John\u0026quot; self.family = \u0026quot;Doe\u0026quot; @p_decorate def get_fullname(self): return self.name+\u0026quot; \u0026quot;+self.family my_person = Person() print (my_person.get_fullname())  Output : \u0026lt;p\u0026gt;John Doe\u0026lt;/p\u0026gt;\nRun code\nPassing arguments to decorators Looking back at the example before the one above, you can notice how redundant the decorators in the example are. 3 decorators (divdecorate, pdecorate, strong_decorate) each with the same functionality, but wrapping the string with different tags.\nWe can definitely do much better than that. Why not have a more general implementation for one that takes the tag to wrap with as a string? Yes please!\ndef tags(tag_name): def tags_decorator(func): def func_wrapper(name): return \u0026quot;\u0026lt;{0}\u0026gt;{1}\u0026lt;/{0}\u0026gt;\u0026quot;.format(tag_name, func(name)) return func_wrapper return tags_decorator @tags(\u0026quot;p\u0026quot;) def get_text(name): return \u0026quot;Hello \u0026quot;+name print (get_text(\u0026quot;John\u0026quot;))  Output: \u0026lt;p\u0026gt;Hello John\u0026lt;/p\u0026gt;\nRun code\nIt took a bit more work in this case. Decorators expect to receive a function as an argument, that is why we will have to build a function that takes those extra arguments and generate our decorator on the fly. In the example above, tags is our decorator generator.\nDebugging decorated functions At the end of the day, decorators are just wrapping our functions. In case of debugging, that can be problematic since the wrapper function does not carry the name, module and docstring of the original function. Based on the example above if we do:\nprint (get_text.__name__)  Output: func_wrapper. The output was expected to be get_text yet, the attributes *name*, *doc*, and *module* of get_text got overridden by those of the wrapper(func_wrapper.\nObviously we can re-set them within func_wrapper but Python provides a much nicer way.\nFunctools to the rescue\nfrom functools import wraps def tags(tag_name): def tags_decorator(func): @wraps(func) def func_wrapper(name): return \u0026quot;`\u0026lt;{0}\u0026gt;`{1}`\u0026lt;/{0}\u0026gt;`\u0026quot;.format(tag_name, func(name)) return func_wrapper return tags_decorator @tags(\u0026quot;p\u0026quot;) def get_text(name): \u0026quot;\u0026quot;\u0026quot;returns some text\u0026quot;\u0026quot;\u0026quot; return \u0026quot;Hello \u0026quot;+name print (get_text.__name__) # get_text print (get_text.__doc__) # returns some text print (get_text.__module__) # __main__  Run code\nYou can notice from the output that the attributes of get_text are the correct ones now.\nPython For Loop Statement Example Python utilizes a for loop to iterate over a list of elements. This is unlike C or Java, which use the for loop to change a value in steps and access something such as an array using that value.\nFor loops iterate over collection-based data structures like lists, tuples, and dictionaries.\nThe basic syntax is:\nfor value in list_of_values: # use value inside this block  In general, you can use anything as the iterator value, where entries of the iterable can be assigned to. E.g. you can unpack tuples from a list of tuples:\nlist_of_tuples = [(1,2), (3,4)] for a, b in list_of_tuples: print(\u0026quot;a:\u0026quot;, a, \u0026quot;b:\u0026quot;, b)  On the other hand, you can loop over anything that is iterable. You can call a function or use a list literal.\nfor person in load_persons(): print(\u0026quot;The name is:\u0026quot;, person.name)  for character in [\u0026quot;P\u0026quot;, \u0026quot;y\u0026quot;, \u0026quot;t\u0026quot;, \u0026quot;h\u0026quot;, \u0026quot;o\u0026quot;, \u0026quot;n\u0026quot;]: print(\u0026quot;Give me a '{}'!\u0026quot;.format(character))  Some ways in which For loops are used:\n*Iterate over the range() function*\nfor i in range(10): print(i)  Rather than being a function, range is actually an immutable sequence type. The output will contain results from lower bound i.e 0 to the upper bound i.e 10, but excluding 10. By default the lower bound or the starting index is set to zero. Output:\n0 1 2 3 4 5 6 7 8 9  Additionally, one can specify the lower bound of the sequence and even the step of the sequence by adding a second and a third parameter.\nfor i in range(4,10,2): #From 4 to 9 using a step of two print(i)  Output:\n4 6 8  *xrange() function*\nFor the most part, xrange and range are the exact same in terms of functionality. They both provide a way to generate a list of integers for you to use, however you please. The only difference is that range returns a Python list object and xrange returns an xrange object. It means that xrange doesn’t actually generate a static list at run-time like range does. It creates the values as you need them with a special technique called yielding. This technique is used with a type of object known as generators.\nOne more thing to add. In Python 3.x, the xrange function does not exist anymore. The range function now does what xrange does in Python 2.x\n*Iterate over values in a list or tuple*\nA = [\u0026quot;hello\u0026quot;, 1, 65, \u0026quot;thank you\u0026quot;, [2, 3]] for value in A: print(value)  Output:\nhello 1 65 thank you [2, 3]  *Iterate over keys in a dictionary (aka hashmap)*\nfruits_to_colors = {\u0026quot;apple\u0026quot;: \u0026quot;#ff0000\u0026quot;, \u0026quot;lemon\u0026quot;: \u0026quot;#ffff00\u0026quot;, \u0026quot;orange\u0026quot;: \u0026quot;#ffa500\u0026quot;} for key in fruits_to_colors: print(key, fruits_to_colors[key])  Output:\napple #ff0000 lemon #ffff00 orange #ffa500  *Iterate over two lists of same size in a single loop with the zip() function*\nA = [\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;] B = [\u0026quot;a\u0026quot;, \u0026quot;d\u0026quot;, \u0026quot;e\u0026quot;] for a, b in zip(A, B): print a, b, a == b  Output:\n\u0026gt; a a True b d False c e False \u0026gt;  *Iterate over a list and get the corresponding index with the enumerate() function*\nA = [\u0026quot;this\u0026quot;, \u0026quot;is\u0026quot;, \u0026quot;something\u0026quot;, \u0026quot;fun\u0026quot;] for index,word in enumerate(A): print(index, word)  Output:\n0 this 1 is 2 something 3 fun  A common use case is iterating over a dictionary:\nfor name, phonenumber in contacts.items(): print(name, \u0026quot;is reachable under\u0026quot;, phonenumber)  If you absolutely need to access the current index of your iteration, do *NOT* use range(len(iterable))! This is an extremely bad practice and will get you plenty of chuckles from senior Python developers. Use the built in function enumerate() instead:\nfor index, item in enumerate(shopping_basket): print(\u0026quot;Item\u0026quot;, index, \u0026quot;is a\u0026quot;, item)  *for/else statements* Pyhton permits you to use else with for loops, the else case is executed when none of the conditions with in the loop body was satisfied. To use the else we have to make use of break statement so that we can break out of the loop on a satisfied condition. If we do not break out then the else part will be executed.\nweek_days = ['Monday','Tuesday','Wednesday','Thursday','Friday'] today = 'Saturday' for day in week_days: if day == today: print('today is a week day') break else: print('today is not a week day')  In the above case the output will be today is not a week day since the break within the loop will never be executed.\n*Iterate over a list using inline loop function*\nWe could also iterate inline using python. For example if we need to uppercase all the words in a list from a list, we could simply do the following:\nA = [\u0026quot;this\u0026quot;, \u0026quot;is\u0026quot;, \u0026quot;awesome\u0026quot;, \u0026quot;shinning\u0026quot;, \u0026quot;star\u0026quot;] UPPERCASE = [word.upper() for word in A] print (UPPERCASE)  Output:\n['THIS', 'IS', 'AWESOME', 'SHINNING', 'STAR']  Python Function Example A function allows you to define a reusable block of code that can be executed many times within your program.\nFunctions allow you to create more modular and DRY solutions to complex problems.\nWhile Python already provides many built-in functions such as print() and len(), you can also define your own functions to use within your projects.\nOne of the great advantages of using functions in your code is that it reduces the overall number of lines of code in your project.\nSyntax In Python, a function definition has the following features:\n The keyword def a function name parentheses’()’, and within parentheses input parameters, although the input parameters are optional. a colon ’:’ some block of code to execute a return statement (optional)\n# a function with no parameters or returned values def sayHello(): print(\u0026quot;Hello!\u0026quot;) sayHello() # calls the function, 'Hello!' is printed to the console # a function with a parameter def helloWithName(name): print(\u0026quot;Hello \u0026quot; + name + \u0026quot;!\u0026quot;) helloWithName(\u0026quot;Ada\u0026quot;) # calls the function, 'Hello Ada!' is printed to the console # a function with multiple parameters with a return statement def multiply(val1, val2): return val1 * val2 multiply(3, 5) # prints 15 to the console   Functions are blocks of code that can be reused simply by calling the function. This enables simple, elegant code reuse without explicitly re-writing sections of code. This makes code more readable, easier to debug, and limits typing errors.\nFunctions in Python are created using the def keyword, followed by a function name and function parameters inside parentheses.\nA function always returns a value. The return keyword is used by the function to return a value. If you don’t want to return any value, the default value None will be returned.\nThe function name is used to call the function, passing the needed parameters inside parentheses.\n# this is a basic sum function def sum(a, b): return a + b result = sum(1, 2) # result = 3  You can define default values for the parameters, and that way Python will interpret that the value of that parameter is the default one if none is given.\ndef sum(a, b=3): return a + b result = sum(1) # result = 4  You can pass the parameters in the order you want, using the name of the parameter.\nresult = sum(b=2, a=2) # result = 4  However, it is not possible to pass a keyword argument before a non-keyword one.\nresult = sum(3, b=2) #result = 5 result2 = sum(b=2, 3) #Will raise SyntaxError  Functions are also Objects, so you can assign them to a variable, and use that variable like a function.\ns = sum result = s(1, 2) # result = 3  Notes If a function definition includes parameters, you must provide the same number of parameters when you call the function.\nprint(multiply(3)) # TypeError: multiply() takes exactly 2 arguments (0 given) print(multiply('a', 5)) # 'aaaaa' printed to the console print(multiply('a', 'b')) # TypeError: Python can't multiply two strings  The block of code that the function will run includes all statements indented within the function.\ndef myFunc(): print('this will print') print('so will this') x = 7 # the assignment of x is not a part of the function since it is not indented  Variables defined within a function only exist within the scope of that function.\ndef double(num): x = num * 2 return x print(x) # error - x is not defined print(double(4)) # prints 8  Python interprets the function block only when the function is called and not when the function is defined. So even if the function definition block contains some sort of error, the python interpreter will point that out only when the function is called.\nPython Generator Example Generators are a special type of function that allows you to return values without ending a function. It does this by using the yield keyword. Similar to return, the yieldexpression will return a value to the caller. The key difference between the two is that yield will suspend the function, allowing for more values to be returned in the future.\nGenerators are iterable so they can be used cleanly with for loops or anything else that iterates.\ndef my_generator(): yield 'hello' yield 'world' yield '!' for item in my_generator(): print(item) # output: # hello # world # !  Like other iterators, generators can be passed to the next function to retrieve the next item. When a generator has no more values to yield, a StopIteration error is raised.\ng = my_generator() print(next(g)) # 'hello' print(next(g)) # 'world' print(next(g)) # '!' print(next(g)) # Traceback (most recent call last): # File \u0026quot;\u0026lt;stdin\u0026gt;\u0026quot;, line 1, in \u0026lt;module\u0026gt; # StopIteration  Generators are particularly useful when you need to create a large set of values but do not need to keep them all in memory at the same time. For example, if you need to print the first million fibonacci numbers, you would typically return a list of a million values and iterate over the list to print each value. However with a generator, you can return each value one at a time:\ndef fib(n): a = 1 b = 1 for i in range(n): yield a a, b = b, a + b for x in fib(1000000): print(x)  Python Iterator Example Python supports a concept of iteration over containers. This is implemented using two distinct methods; these are used to allow user-defined classes to support iteration.\nPython Docs - Iterator Types\nIteration is the process of programmatically repeating a step a given number of times. A programmer can make use of iteration to perform the same operation on every item in a collection of data, for example printing out every item in a list.\n Objects can implement a __iter__() method that returns an iterator object to support iteration.  Iterator objects must implement:\n __iter__(): returns the iterator object. __next__(): returns the next object of the container.iterator_object = ‘abc’.*iter*() print(iterator_object) print(id(iterator_object)) print(id(iterator_object.*iter*())) # Returns the iterator itself. print(iterator_object.*next*()) # Returns 1st object and advances iterator. print(iterator_object.*next*()) # Returns 2nd object and advances iterator. print(iterator_object.*next*()) # Returns 3rd object and advances iterator. print(iterator_object.*next*()) # Raises StopIteration Exception.  Output :\n\u0026lt;str_iterator object at 0x102e196a0\u0026gt; 4343305888 4343305888 a b c --------------------------------------------------------------------------- StopIteration Traceback (most recent call last) \u0026lt;ipython-input-1-d466eea8c1b0\u0026gt; in \u0026lt;module\u0026gt;() 6 print(iterator_object.__next__()) # Returns 2nd object and advances iterator. 7 print(iterator_object.__next__()) # Returns 3rd object and advances iterator. ----\u0026gt; 8 print(iterator_object.__next__()) # Raises StopIteration Exception. StopIteration:  Ternary operator in Python Example Ternary operations in Python, often also referred to as conditional expressions, allow the programmer to perform an evaluation and return a value based on the truth of the given condition.\nThe ternary operator differs from a standard if, else, elif structure in the sense that it is not a control flow structure, and behaves more like other operators such as == or != in the Python language.\nExample In this example, the string Even is returned if the val variable is even, otherwise the string Odd is returned. The returned string is then assigned to the is_even variable and printed to the console.\nInput for val in range(1, 11): is_even = \u0026quot;Even\u0026quot; if val % 2 == 0 else \u0026quot;Odd\u0026quot; print(val, is_even, sep=' = ')  Output 1 = Odd 2 = Even 3 = Odd 4 = Even 5 = Odd 6 = Even 7 = Odd 8 = Even 9 = Odd 10 = Even  Python While Loop Statement Example Python utilizes the while loop similarly to other popular languages. The while loop evaluates a condition then executes a block of code if the condition is true. The block of code executes repeatedly until the condition becomes false.\nThe basic syntax is:\ncounter = 0 while counter \u0026lt; 10: # Execute the block of code here as # long as counter is less than 10  An example is shown below:\ndays = 0 week = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'] while days \u0026lt; 7: print(\u0026quot;Today is \u0026quot; + week[days]) days += 1  Output:\nToday is Monday Today is Tuesday Today is Wednesday Today is Thursday Today is Friday Today is Saturday Today is Sunday  Line-by-Line explanation of the above CODE:\n the variable ‘days’ is set to a value 0. a variable week is assigned to a list containing all the days of the week. while loop starts the block of code will be executed until the condition returns ‘true’. the condition is ‘days\u0026lt;7’ which roughly says run the while loop until the point the variable days is less than 7 So when the days=7 the while loop stops executing. the days variable gets updated on every iteration. When the while loop runs for the first time, the line ‘Today is Monday’ is printed onto the console and the variable days becomes equal to 1. Since the variable days is equal to 1 which is less than 7, the while loop is executed again. It goes on again and again and when the console prints ‘Today is Sunday’ the variable days is now equal to 7 and the while loop stops executing.  How to Install Python 3 You can download Python from this official link. Based on your OS (Windows or Linux or OSX), you might want to install Python 3 following these instructions.\nUsing Virtual Environments It is always a great idea to sandbox your Python installation and keep it separate from your System Python. The System Python is the path to Python interpreter, which is used by other modules installed along with your OS.\nIt’s *not safe* to install Python Web-frameworks or libraries directly using System Python. Instead, you can use Virtualenv to create and spawn a separate Python process when you are developing Python applications.\nVirtualenvwrapper The Virtualenvwrapper module makes it easy for you to manage and sandbox multiple Python sandboxed environments in one machine, without corrupting any modules or services written in Python and used by your machine.\nOf course, most cloud hosted development environments such as Nitrous or Cloud9 also come with these pre-installed and ready for you to get coding! You can quickly pick a box from your dashboard and start coding after activating a Python 3 environment.\nIn Cloud9, you need to select the Django box while creating a new development environment.\nA few shell command examples follow. If you wish to copy-paste, do note that the $ sign is a shorthand for the terminal prompt, it’s not part of the command. My terminal prompt looks something like this:\nalayek:~/workspace (master) $  And, an ls would look like\nalayek:~/workspace (master) $ ls  But, while writing the same in this documentation, I would be writing it as\n$ ls  Getting back to our discussion, you can create a Python 3 interpreter-included sandbox on Cloud9 by running on your cloud terminal:\n$ mkvirtualenv py3 --python=/usr/bin/python3  You have to run it only once after creating a new box for your project. Once executed, this command would create a new sandboxed virtualenv ready for you to use, named py3.\nTo view available virtual environments, you can use\n$ workon  To activate py3, you can use the workon command with the name of the environment:\n$ workon py3  All three terminal commands above would also work on local Linux machines or OSX machines. These are virtualenvwrapper commands; so if you are planning on using them, make sure you have this module installed and added to PATH variable.\nIf you are inside a virtual environment; you can easily find that out by checking your terminal prompt. The environment name will be clearly shown in your terminal prompt.\nFor instance, when I am inside the py3 environment, I will be seeing this as my terminal prompt:\n(py3)alayek:~/workspace (master) $  Notice the (py3) in braces! If for some reason you are not seeing this, even if you are inside a virtual env; you can try doing one of the things mentioned here.\nTo get out of a virtual environment or to deactivate one - use this command:\n$ deactivate  Again, this works only with virtualenvwrapper module.\nPipenv An alternative to using virtualenvwrapper is Pipenv. It automatically creates virtual environments for your projects, and maintains a Pipfile which contains the dependencies. Using Pipenv means you no longer need to use pip and virtualenv separately, or manage your own requirements.txt file. For those familiar with JavaScript, Pipenv is similar to using a packaging tool like npm.\nTo get started with Pipenv, you can follow this very detailed guide. Pipenv makes it easy to specify which version of Python you wish to use for each project, import from an existing requirements.txt file and graph your dependencies.\n"});index.add({'id':87,'href':'/library/tutorials/docs/articles/python/onverting-strings-to-datetime/','title':"Converting Strings using datetime",'content':" Converting Strings using datetime The datetime module consists of three different object types: date, time and datetime. As you may have guessed, date holds the date, time holds the time, and datetime holds both date and time.\nFor example, the following example will print the current date and time:\nimport datetime print ('Current date/time: {}'.format(datetime.datetime.now()))  Running this code will print an output similar to below:\n$ python3 datetime-print-1.py Current date/time: 2018-06-29 08:15:27.243860  When no custom formatting is given, the default string format is used, i.e. the format for \u0026ldquo;2018-06-29 08:15:27.243860\u0026rdquo; is in ISO 8601 format (YYYY-MM-DDTHH:MM:SS.mmmmmm). If our input string to create a datetime object is in the same ISO 8601 format, we can easily parse it to a datetime object.\nLet\u0026rsquo;s take a look at the code below:\nimport datetime date_time_str = '2018-06-29 08:15:27.243860' date_time_obj = datetime.datetime.strptime(date_time_str, '%Y-%m-%d %H:%M:%S.%f') print('Date:', date_time_obj.date()) print('Time:', date_time_obj.time()) print('Date-time:', date_time_obj)  Running it will print the below output:\n$ python3 datetime-print-2.py Date: 2018-06-29 Time: 08:15:27.243860 Date-time: 2018-06-29 08:15:27.243860  In this example, we are using a new method called strptime. This method takes two arguments: the first one is the string representation of the date-time and the second one is the format of the input string. The return value is of the type datetime. In our example, \u0026quot;2018-06-29 08:15:27.243860\u0026quot; is the input string and \u0026quot;%Y-%m-%d %H:%M:%S.%f\u0026quot; is the format of this date string. The returned datetime value is stored in date_time_obj variable. Since this is a datetime variable, we can call date() and time() methods directly on it. As you can see from the output, it prints the \u0026lsquo;date\u0026rsquo; and \u0026lsquo;time\u0026rsquo; part of the input string.\nYou might be wondering what is the meaning of the format \u0026quot;%Y-%m-%d %H:%M:%S.%f\u0026quot;. These are known as format tokens with different meaning for each token. Check out the strptime documentation for the list of all different types of format code supported in Python.\nSo, if the format of a string is known, it can be easily parsed to a datetime object using strptime. Let me show you one more non-trivial example:\nimport datetime date_time_str = 'Jun 28 2018 7:40AM' date_time_obj = datetime.datetime.strptime(date_time_str, '%b %d %Y %I:%M%p') print('Date:', date_time_obj.date()) print('Time:', date_time_obj.time()) print('Date-time:', date_time_obj)  From the following output you can see that the string was successfully parsed since it is being properly printed by the datetime object here.\n$ python3 datetime-print-3.py Date: 2018-06-28 Time: 07:40:00 Date-time: 2018-06-28 07:40:00  Here are a few more examples of commonly used time formats and the tokens used for parsing:\n\u0026quot;Jun 28 2018 at 7:40AM\u0026quot; -\u0026gt; \u0026quot;%b %d %Y at %I:%M%p\u0026quot; \u0026quot;September 18, 2017, 22:19:55\u0026quot; -\u0026gt; \u0026quot;%B %d, %Y, %H:%M:%S\u0026quot; \u0026quot;Sun,05/12/99,12:30PM\u0026quot; -\u0026gt; \u0026quot;%a,%d/%m/%y,%I:%M%p\u0026quot; \u0026quot;Mon, 21 March, 2015\u0026quot; -\u0026gt; \u0026quot;%a, %d %B, %Y\u0026quot; \u0026quot;2018-03-12T10:12:45Z\u0026quot; -\u0026gt; \u0026quot;%Y-%m-%dT%H:%M:%SZ\u0026quot;  You can parse a date-time string of any format using the table mentioned in the strptime documentation.\nDealing with Timezones and datetime Handling date-times becomes more complex while dealing with timezones. All above examples we have discussed are naive datetime objects, i.e. these objects don\u0026rsquo;t contain any timezone-related data. The datetime object has one variable tzinfo, that holds the timezone information.\nimport datetime as dt dtime = dt.datetime.now() print(dtime) print(dtime.tzinfo)  This code will print:\n$ python3 datetime-tzinfo-1.py 2018-06-29 22:16:36.132767 None  The output of tzinfo is None since it is a naive datetime object. For timezone conversion, one library called pytz is available for Python. You can install it as described in these instructions. Now, let\u0026rsquo;s use the pytz library to convert the above timestamp to UTC.\nimport datetime as dt import pytz dtime = dt.datetime.now(pytz.utc) print(dtime) print(dtime.tzinfo)  Output:\n$ python3 datetime-tzinfo-2.py 2018-06-29 17:08:00.586525+00:00 UTC  +00:00 is the difference between the displayed time and the UTC time. In this example the value of tzinfo happens to be UTC as well, hence the 00:00 offset. In this case, the datetime object is a timezone-aware object.\nSimilarly, we can convert date-time strings to any other timezone. For example, we can convert the string \u0026ldquo;2018-06-29 17:08:00.586525+00:00\u0026rdquo; to \u0026ldquo;America/New_York\u0026rdquo; timezone, as shown below:\nimport datetime as dt import pytz date_time_str = '2018-06-29 17:08:00' date_time_obj = dt.datetime.strptime(date_time_str, '%Y-%m-%d %H:%M:%S') timezone = pytz.timezone('America/New_York') timezone_date_time_obj = timezone.localize(date_time_obj) print(timezone_date_time_obj) print(timezone_date_time_obj.tzinfo)  Output:\n$ python3 datetime-tzinfo-3.py 2018-06-29 17:08:00-04:00 America/New_York  First, we have converted the string to a datetime object, date_time_obj. Then we converted it to a timezone-enabled datetime object, timezone_date_time_obj. Since we have mentioned the timezone as \u0026ldquo;America/New_York\u0026rdquo;, the output time shows that it is 4 hours behind than UTC time. You can check this Wikipedia page to find the full list of available time zones.\nConverting Timezones We can convert timezone of a datetime object from one region to another, as shown in the example below:\nimport datetime as dt import pytz timezone_nw = pytz.timezone('America/New_York') nw_datetime_obj = dt.datetime.now(timezone_nw) timezone_london = pytz.timezone('Europe/London') london_datetime_obj = nw_datetime_obj.astimezone(timezone_london) print('America/New_York:', nw_datetime_obj) print('Europe/London:', london_datetime_obj)  First, it created one datetime object with the current time on \u0026ldquo;America/New_York\u0026rdquo; timezone. Then using astimezone() method, we have converted this datetime to \u0026ldquo;Europe/London\u0026rdquo; timezone. Both datetimes will print different values like:\n$ python3 datetime-tzinfo-4.py America/New_York: 2018-06-29 22:21:41.349491-04:00 Europe/London: 2018-06-30 03:21:41.349491+01:00  Using Third Party Libraries Python\u0026rsquo;s datetime module can convert all different types of strings to a datetime object. But the main problem is that in order to do this you need to create the appropriate formatting code string that strptime can understand. Creating this string takes time and it makes the code harder to read. Instead, we can use other third-party libraries to make it easier.\nIn some cases these third party libraries also have better built-in support for manipulating and comparing date-times, and some even have timezones built-in, so you don\u0026rsquo;t need to include an extra package.\nLet\u0026rsquo;s take a look at few of these libraries in the following sections.\ndateutil The dateutil module is an extension to the datetime module. We don\u0026rsquo;t need to pass any parsing code to parse a string. For example:\nfrom dateutil.parser import parse datetime = parse('2018-06-29 22:21:41') print(datetime)  This parse function will parse the string automatically and store it in the datetime variable. Parsing is done automatically. You don\u0026rsquo;t have to mention any format string. Let\u0026rsquo;s try to parse different types of strings using dateutil:\nfrom dateutil.parser import parse date_array = [ '2018-06-29 08:15:27.243860', 'Jun 28 2018 7:40AM', 'Jun 28 2018 at 7:40AM', 'September 18, 2017, 22:19:55', 'Sun, 05/12/1999, 12:30PM', 'Mon, 21 March, 2015', '2018-03-12T10:12:45Z', '2018-06-29 17:08:00.586525+00:00', '2018-06-29 17:08:00.586525+05:00', 'Tuesday , 6th September, 2017 at 4:30pm' ] for date in date_array: print('Parsing: ' + date) dt = parse(date) print(dt.date()) print(dt.time()) print(dt.tzinfo) print('\\n')  Output:\n$ python3 dateutil-1.py Parsing: 2018-06-29 08:15:27.243860 2018-06-29 08:15:27.243860 None Parsing: Jun 28 2018 7:40AM 2018-06-28 07:40:00 None Parsing: Jun 28 2018 at 7:40AM 2018-06-28 07:40:00 None Parsing: September 18, 2017, 22:19:55 2017-09-18 22:19:55 None Parsing: Sun, 05/12/1999, 12:30PM 1999-05-12 12:30:00 None Parsing: Mon, 21 March, 2015 2015-03-21 00:00:00 None Parsing: 2018-03-12T10:12:45Z 2018-03-12 10:12:45 tzutc() Parsing: 2018-06-29 17:08:00.586525+00:00 2018-06-29 17:08:00.586525 tzutc() Parsing: 2018-06-29 17:08:00.586525+05:00 2018-06-29 17:08:00.586525 tzoffset(None, 18000) Parsing: Tuesday , 6th September, 2017 at 4:30pm 2017-09-06 16:30:00 None  You can see that almost any type of string can be parsed easily using the dateutil module.\nMaya Maya also makes it very easy to parse a string and for changing timezones. Some simple examples are shown below:\nimport maya dt = maya.parse('2018-04-29T17:45:25Z').datetime() print(dt.date()) print(dt.time()) print(dt.tzinfo)  Output:\n$ python3 maya-1.py 2018-04-29 17:45:25 UTC  For converting the time to a different timezone:\nimport maya dt = maya.parse('2018-04-29T17:45:25Z').datetime(to_timezone='America/New_York', naive=False) print(dt.date()) print(dt.time()) print(dt.tzinfo)  Output:\n$ python3 maya-2.py 2018-04-29 13:45:25 America/New_York  Now isn\u0026rsquo;t that easy to use? Let\u0026rsquo;s try out maya with the same set of strings we have used with dateutil:\nimport maya date_array = [ '2018-06-29 08:15:27.243860', 'Jun 28 2018 7:40AM', 'Jun 28 2018 at 7:40AM', 'September 18, 2017, 22:19:55', 'Sun, 05/12/1999, 12:30PM', 'Mon, 21 March, 2015', '2018-03-12T10:12:45Z', '2018-06-29 17:08:00.586525+00:00', '2018-06-29 17:08:00.586525+05:00', 'Tuesday , 6th September, 2017 at 4:30pm' ] for date in date_array: print('Parsing: ' + date) dt = maya.parse(date).datetime() print(dt) print(dt.date()) print(dt.time()) print(dt.tzinfo)  Output:\n$ python3 maya-3.py Parsing: 2018-06-29 08:15:27.243860 2018-06-29 08:15:27.243860+00:00 2018-06-29 08:15:27.243860 UTC Parsing: Jun 28 2018 7:40AM 2018-06-28 07:40:00+00:00 2018-06-28 07:40:00 UTC Parsing: Jun 28 2018 at 7:40AM 2018-06-28 07:40:00+00:00 2018-06-28 07:40:00 UTC Parsing: September 18, 2017, 22:19:55 2017-09-18 22:19:55+00:00 2017-09-18 22:19:55 UTC Parsing: Sun, 05/12/1999, 12:30PM 1999-05-12 12:30:00+00:00 1999-05-12 12:30:00 UTC Parsing: Mon, 21 March, 2015 2015-03-21 00:00:00+00:00 2015-03-21 00:00:00 UTC Parsing: 2018-03-12T10:12:45Z 2018-03-12 10:12:45+00:00 2018-03-12 10:12:45 UTC Parsing: 2018-06-29 17:08:00.586525+00:00 2018-06-29 17:08:00.586525+00:00 2018-06-29 17:08:00.586525 UTC Parsing: 2018-06-29 17:08:00.586525+05:00 2018-06-29 12:08:00.586525+00:00 2018-06-29 12:08:00.586525 UTC Parsing: Tuesday , 6th September, 2017 at 4:30pm 2017-09-06 16:30:00+00:00 2017-09-06 16:30:00 UTC  As you can see, all date formats were parsed, but did you notice the difference? If we are not providing the timezone info it automatically converts it to UTC. So, it is important to note that we need to provide to_timezone and naive parameters if the time is not in UTC.\nArrow Arrow is another library for dealing with datetime in Python. We can get the Python datetime object from an arrow object. Let\u0026rsquo;s try this with the same example string we have used for maya:\nimport arrow dt = arrow.get('2018-04-29T17:45:25Z') print(dt.date()) print(dt.time()) print(dt.tzinfo)  Output:\n$ python3 arrow-1.py 2018-04-29 17:45:25 tzutc()  Timezone conversion:\nimport arrow dt = arrow.get('2018-04-29T17:45:25Z').to('America/New_York') print(dt) print(dt.date()) print(dt.time())  Output:\n$ python3 arrow-2.py 2018-04-29T13:45:25-04:00 2018-04-29 13:45:25  As you can see the date-time string is converted to the \u0026ldquo;America/New_York\u0026rdquo; region.\nNow, let\u0026rsquo;s again use the same set of strings we have used above:\nimport arrow date_array = [ '2018-06-29 08:15:27.243860', #'Jun 28 2018 7:40AM', #'Jun 28 2018 at 7:40AM', #'September 18, 2017, 22:19:55', #'Sun, 05/12/1999, 12:30PM', #'Mon, 21 March, 2015', '2018-03-12T10:12:45Z', '2018-06-29 17:08:00.586525+00:00', '2018-06-29 17:08:00.586525+05:00', #'Tuesday , 6th September, 2017 at 4:30pm' ] for date in date_array: dt = arrow.get(date) print('Parsing: ' + date) print(dt) print(dt.date()) print(dt.time()) print(dt.tzinfo)  This code will fail for the date-time strings that have been commented out. The output for other strings will be:\n$ python3 arrow-3.py Parsing: 2018-06-29 08:15:27.243860 2018-06-29T08:15:27.243860+00:00 2018-06-29 08:15:27.243860 tzutc() Parsing: 2018-03-12T10:12:45Z 2018-03-12T10:12:45+00:00 2018-03-12 10:12:45 tzutc() Parsing: 2018-06-29 17:08:00.586525+00:00 2018-06-29T17:08:00.586525+00:00 2018-06-29 17:08:00.586525 tzoffset(None, 0) Parsing: 2018-06-29 17:08:00.586525+05:00 2018-06-29T17:08:00.586525+05:00 2018-06-29 17:08:00.586525 tzoffset(None, 18000)  In order to correctly parse the date-time strings that I have commented out, you\u0026rsquo;ll need to pass the corresponding format tokens. For example, \u0026ldquo;MMM\u0026rdquo; for months name, like \u0026ldquo;Jan, Feb, Mar\u0026rdquo; etc. You can check this guide for all available tokens.\nConclusion We have checked different ways to parse a string to a datetime object in Python. You can either opt for the default Python datetime library or any of the third party library mentioned in this article, among many others. The main problem with default datetime package is that we need to specify the parsing code manually for almost all date-time string formats. So, if your string format changes in the future, you will likely have to change your code as well. But many third-party libraries, like the ones mentioned here, handle it automatically.\nOne more problem we face is dealing with timezones. The best way to handle them is always to store the time in UTC format on the server and convert it to the user\u0026rsquo;s local timezone while parsing. Not only for parsing string, these libraries can be used for a lot of different types of date-time related operations. I\u0026rsquo;d encourage you to go through the documents to learn the functionalities in detail.\n Source stackabuse.com.\n "});index.add({'id':88,'href':'/library/tutorials/docs/articles/python/date-time/','title':"Datetime",'content':" Datetime import datetime x = datetime.datetime.now() print(x)  2019-09-26 00:21:06.668559  Date Output import datetime x = datetime.datetime.now() print(x.year) print(x.strftime(\u0026quot;%A\u0026quot;))  2019 Thursday  Creating Date Objects import datetime x = datetime.datetime(2020, 5, 17) print(x)  2020-05-17 00:00:00  The strftime() Method import datetime x = datetime.datetime(2018, 6, 1) print(x.strftime(\u0026quot;%B\u0026quot;))  June  A reference of all the legal format codes:    Directive Description Example     %a Weekday, short version Wed   %A Weekday, full version Wednesday   %w Weekday as a number 0-6, 0 is Sunday 3   %d Day of month 01-31 31   %b Month name, short version Dec   %B Month name, full version December   %m Month as a number 01-12 12   %y Year, short version, without century 18   %Y Year, full version 2018   %H Hour 00-23 17   %I Hour 00-12 05   %p AM/PM PM   %M Minute 00-59 41   %S Second 00-59 08   %f Microsecond 000000-999999 548513   %z UTC offset +0100   %Z Timezone CST   %j Day number of year 001-366 365   %U Week number of year, Sunday as the first day of week, 00-53 52   %W Week number of year, Monday as the first day of week, 00-53 52   %c Local version of date and time Mon Dec 31 17:41:00 2018   %x Local version of date 12/31/18   %X Local version of time 17:41:00   %% A % character %    timedelta ตัวอย่างการหาผลต่างของวันที่\nimport datetime import pytz my_birthday = datetime.datetime(1985, 10, 20, 17, 55) brothers_birthday = datetime.datetime(1992, 6, 25, 18, 30) indy = pytz.timezone(\u0026quot;America/Indianapolis\u0026quot;) my_birthday = indy.localize(my_birthday) brothers_birthday = indy.localize(brothers_birthday) diff = brothers_birthday - my_birthday print(diff)  2440 days, 0:35:00  หาวัน โดยบวกจากวันปัจจุบันไปอีก 90 วัน\nimport datetime today = datetime.datetime.now() ninety_days = datetime.timedelta(days=90) target_date = today + ninety_days target_date.strftime(\u0026quot;%A\u0026quot;)  'Wednesday'  "});index.add({'id':89,'href':'/library/tutorials/docs/articles/data-science/finance/exploration-stock-index/','title':"Exploration of S\u0026P 500 Index",'content':" Exploration of S\u0026amp;P 500 Index Using Pandas and Matplotlib In this article we want to explore whether it is true that staying in the market over a longer duration can be lucrative.\nImport the Python libraries that are commonly used for data analysis and data exploration such as Pandas and Matplotlib.\nIn [1]:\nimport pandas as pd import numpy as np import matplotlib.pyplot as plt  Read the files with S\u0026amp;P 500 data into Pandas dataframes.\nIn [2]:\ndf1 = pd.read_csv('SP5001.csv') df2 = pd.read_csv('SP5002.csv') df3 = pd.read_csv('SP5003.csv') df = pd.concat([df1,df2,df3])  The dataset has a number of columns such as Open, Close etc. For the purposes of our exploration we will focus only on the Close price since we are interested in trends and not necessarily accuracy of returns.\nIn [3]:\ndf.head()  Take a look at the datatypes\nIn [4]:\ndf.info()  \u0026lt;class 'pandas.core.frame.DataFrame'\u0026gt; Int64Index: 15429 entries, 0 to 118 Data columns (total 7 columns): Adj Close 15429 non-null float64 Close 15429 non-null float64 Date 15429 non-null object High 15429 non-null float64 Low 15429 non-null float64 Open 15429 non-null float64 Volume 15429 non-null int64 dtypes: float64(5), int64(1), object(1) memory usage: 964.3+ KB  The datatype of the Date field needs to be converted into datetime64. This will help with plotting and computations as we shall see ahead.\nIn [5]:\ndf['Date'] = df.loc[:,'Date'].astype('datetime64[ns]')  Extracting just the fields that we need into a new dataframe with daily data\nIn [6]:\ndfd = df[[\u0026quot;Date\u0026quot;, \u0026quot;Close\u0026quot;]]  Setting the index of the dataframe to date\nIn [7]:\ndfd = dfd.set_index('Date')  Take a look at the first few rows of the dataframe\nIn [8]:\ndfd.head()  Sort the dataframe by date field\nIn [9]:\ndfd = dfd.sort_index()  Create 2 new dataframes to hold the monthly average and yearly averages\nIn [10]:\ndfm = dfd.resample('M').mean() dfy = dfd.resample('Y').mean()  Take a look at the monthly average price. Notice that after sorting the initial rows go all the way back to 1957.\nIn [11]:\ndfm.head()  S\u0026amp;P 500 closed today Nov. 6, 2018 at 2747.62. What is the monthly return today had one unit been purchased monthly starting at the very first month that we have data for?\nIn [12]:\ntday = 2747.62dfm['Return'] = (tday - dfm['Close'])/dfm['Close']*100  So if one had bought one unit of S\u0026amp;P 500 back in 1957 then it would at today’s price return 6138%.\nIn [13]:\ndfm.head()  We calculated the returns for every day that we have data for in our dataframe dating back to 1957. Over the past 30 year period here is the return of a single unit of S\u0026amp;P 500 over time as of Nov. 6, 2018.\nIn [29]:\ndfm.iloc[-360:,1].plot()  Now let us explore the yearly average data\nIn [15]:\ndfy.head()  The chart above is useful to show the distribution of return over time. It confirms our intuition that returns are higher if stocks are held over a longer period and gradually decline as we hold them for lesser periods.\nIt will be interesting to see how much the five, ten, fifteen, twenty, twenty five and thirty year returns have changed over time. For this we will use the yearly average data.\nIn [16]:\ndfy['5y'] = dfy['Close'].shift(5)  In [17]:\ndfy['10y'] = dfy['Close'].shift(10) dfy['15y'] = dfy['Close'].shift(15) dfy['20y'] = dfy['Close'].shift(20) dfy['25y'] = dfy['Close'].shift(25) dfy['30y'] = dfy['Close'].shift(30)  Create a new dataframe to calculate the five year returns over time\nIn [18]:\nfiveyearreturn = dfy[['Close','5y']].dropna() fiveyearreturn['Return'] = (fiveyearreturn['Close'] - fiveyearreturn['5y'])/fiveyearreturn['5y']*100  Create a boxplot and a kde plot of 5 year returns. The vast majority of the 5 year returns are above zero, which means that more often than not, it is hard to lose money in the market if held over a 5 year period. Although there are some years with negative returns. So had the index been purchased during some months, you could still be in the red after 5 years!\nIn [19]:\nplt.figure(figsize=(12,6)) ax = plt.subplot(121) fiveyearreturn['Return'].plot(kind='box')ax = plt.subplot(122) fiveyearreturn['Return'].plot(kind='kde')  tenyearreturn = dfy[['Close','10y']].dropna() tenyearreturn['Return'] = (tenyearreturn['Close'] - tenyearreturn['10y'])/tenyearreturn['10y']*100  A look at the 10 year returns shows that holding S\u0026amp;P 500 index over 10 years shows a largely positive returns, with a median return of 85%. Vast majority of the returns were over 100%. In some years the returns were above 300% while in others it may have been below 0%!\nIn [21]:\nplt.figure(figsize=(12,6)) ax = plt.subplot(121) tenyearreturn['Return'].plot(kind='box') ax = plt.subplot(122) tenyearreturn['Return'].plot(kind='kde')  Repeating this exercise for 15, 20, 25 and 30 years will provide the following plots:\n15 Years\n20 Years\n25 Years\n30 Years\ncombinedreturn = pd.concat([fiveyearreturn['Return'], tenyearreturn['Return'], fifteenyearreturn['Return'], twentyyearreturn['Return'], x25yearreturn['Return'], thirtyyearreturn['Return']],axis=1, keys=['5y', '10y', '15y', '20y', '25y', '30y'])  Here is a side by side box plot of returns over 5, 10, 15, 20, 25 and 30 year periods.\nIn [28]:\ncombinedreturn.plot(kind='box', figsize=(8,6))  Combined Returns for 5,10,15,20,25 and 30 Year Returns\nThis chart aligns with our understanding of the markets that keeping money over longer term has a greater chance of producing returns and lesser chance of losing money, however some people may have had better success with some of their 20 year investments than those that they bought at the wrong time and held for longer than 20 years.\nSo what are those periods when the five year returns were negative? Some of these years are familiar such as 2003, 2009 etc.\nYears with Negative 5 year returns\nYears with Negative 10 year returns\nThe real question is if we were to buy the S\u0026amp;P 500 today, will we be under the water in 5 or 10 years? Take 2010 and 10 years prior to 2010. What did S\u0026amp;P do during this period?\nMy son is 10 years from college. If I invest 10,000 in S\u0026amp;P today and 10 years from now when he is ready for college, and my S\u0026amp;P stock is worth 8000, then that could have a significant impact on our finances 10 years from now.\nBut the S\u0026amp;P need not look like this. Could it look like the 10 years leading up to 2000.\nNow someone in 1991 would have done well in the market over a 10 year period.\nNow let us look at the period from 2008 onward and compare it side by side with the period from 1991 through 2000. The returns have been spectacular in both periods, especially 2009 onward. The similarity is uncanny.\nSo it is quite possible that the S\u0026amp;P will look like the 2000 to 2010 period in the next 10 years which means there is a good chance that the stock market will yield a lower return 10 years from now.\n Source.\n "});index.add({'id':90,'href':'/library/tutorials/docs/articles/python/python-for-pdf-02/','title':"Extract table from PDF",'content':" tabula-py: Extract table from PDF into Python DataFrame As of Oct. 2019, I launched a documentation site and Google Colab notebook for tabula-py. The FAQ would be good place to execute accurate extraction.\nIt is simple wrapper of tabula-java and it enables you to extract table into DataFrame or JSON with Python. You also can extract tables from PDF into CSV, TSV or JSON file.\ntabula is a tool to extract tables from PDFs. It is GUI based software, but tabula-java is a tool based on CUI. Though there were Ruby, R, and Node.js bindings of tabula-java, before tabula-py there isn’t any Python binding of it. I believe PyData is a great ecosystem for data analysis and that’s why I created tabula-py. If you are familiar with R, I highly recommend to use tabulizer, which has the most richest bindings including rich GUI.\nYou can install tabula-py via pip:\npip install tabula-py  With tabula-py, you can get DataFrame with read_pdf() method.\nexample of read_pdf()\nYou can also extract tables as JSON format:\nexample of JSON\nYou can extract tables into a file like JSON, CSV or TSV with convert_into() method.\nYou can see more examples in Jupyter notebook.\nWaiting for your collaboration! If you have any trouble with tabula-py, please file an issue on GitHub. I don’t want to receive emails because the answer will not share with other people. Make sure to fill the issue template, it will reduce many costs for me to solve the problem. Or, I also check StackOverflow. You can ask about it.\nOther tabula-py articles  https://blog.chezo.uno/tabula-py-now-able-to-extract-remote-pdf-and-multiple-tables-at-once-6108e24ac07c https://blog.chezo.uno/a-recent-update-of-tabula-py-a923d2ab667b   Written with StackEdit.\n "});index.add({'id':91,'href':'/library/tutorials/docs/articles/python/python-functions_and-functional-programming/','title':"Functions and Functional Programming",'content':" Tutorial: Python Functions and Functional Programming  https://www.dataquest.io/blog/introduction-functional-programming-python/  Most of us have been introduced to Python as an object-oriented language, but Python functions are also useful tools for data scientists and programmers alike. While classes, and objects, are easy to start working with, there are other ways to write your Python code. Languages like Java can make it hard to move away from object-oriented thinking, but Python makes it easy.\nGiven that Python facilitates different approaches to writing code, a logical follow-up question is: what is a different way to write code? While there are several answers to this question, the most common alternative style of writing code is called functional programming. Functional programming gets its name from writing functions which provides the main source of logic in a program.\nIn this post, we will:\n Explain the basics of functional programming by comparing it to object-oriented programming. Cover why you might want to incorporate functional programming in your own code. Show you how Python allows you to switch between the two.  Comparing object-oriented to functional The easiest way to introduce functional programming is to compare it to something we’re already aware of: object-oriented programming. Suppose we wanted to create a line counter class that takes in a file, reads each line, then counts the total amount of lines in the file. Using a class, it could look something like the following:\nclass LineCounter: def __init__(self, filename): self.file = open(filename, 'r') self.lines = [] def read(self): self.lines = [line for line in self.file] def count(self): return len(self.lines)  While not the best implementation, it does provide an insight into object-oriented design. Within the class, there are the familiar concepts of methods and properties. The properties set and retrieve the state of the object, and the methods manipulate that state.\nFor both these concepts to work, the object’s state must change over time. This change of state is evident in the lines property after calling the read() method. As an example, here’s how we would use this class:\n# example_file.txt contains 100 lines. lc = LineCounter('example_file.txt') print(lc.lines) \u0026gt;\u0026gt; [] print(lc.count()) \u0026gt;\u0026gt; 0 # The lc object must read the file to # set the lines property. lc.read() # The `lc.lines` property has been changed. # This is called changing the state of the lc # object. print(lc.lines) \u0026gt;\u0026gt; [['Hello world!', ...]] print(lc.count()) \u0026gt;\u0026gt; 100  The ever-changing state of an object is both its blessing and curse. To understand why a changing state can be seen as a negative, we have to introduce an alternative. The alternative is to build the line counter as a series of independent functions.\ndef read(filename): with open(filename, 'r') as f: return [line for line in f] def count(lines): return len(lines) example_lines = read('example_log.txt') lines_count = count(example_lines)  Working with pure functions In the previous example, we were able to count the lines only with the use of functions. When we only use functions, we are applying a functional approach to programming which is, non-excitingly, called functional programming. The concepts behind functional programming requires functions to be stateless, and rely only on their given inputs to produce an output.\nThe functions that meet the above criteria are called pure functions. Here’s an example to highlight the difference between pure functions, and non-pure:\n# Create a global variable `A`. A = 5 def impure_sum(b): # Adds two numbers, but uses the # global `A` variable. return b + A def pure_sum(a, b): # Adds two numbers, using # ONLY the local function inputs. return a + b print(impure_sum(6)) \u0026gt;\u0026gt; 11 print(pure_sum(4, 6)) \u0026gt;\u0026gt; 10  The benefit of using pure functions over impure (non-pure) functions is the reduction of side effects. Side effects occur when there are changes performed within a function’s operation that are outside its scope. For example, they occur when we change the state of an object, perform any I/O operation, or even call print():\ndef read_and_print(filename): with open(filename) as f: # Side effect of opening a # file outside of function. data = [line for line in f] for line in data: # Call out to the operating system # \u0026quot;println\u0026quot; method (side effect). print(line)  Programmers reduce side effects in their code to make it easier to follow, test, and debug. The more side effects a codebase has, the harder it is to step through a program and understand its sequence of execution.\nWhile it’s convienent to try and eliminate all side effects, they’re often used to make programming easier. If we were to ban all side effects, then you wouldn’t be able to read in a file, call print, or even assign a variable within a function. Advocates for functional programming understand this tradeoff, and try to eliminate side effects where possible without sacrificing development implementation time.\nThe Lambda Expression Instead of the def syntax for function declaration, we can use a lambda expression to write Python functions. The lambda syntax closely follows the def syntax, but it’s not a 1-to-1 mapping. Here’s an example of building a function that adds two integers:\n# Using `def` (old way). def old_add(a, b): return a + b # Using `lambda` (new way). new_add = lambda a, b: a + bold_add(10, 5) == new_add(10, 5) \u0026gt;\u0026gt; True  The lambda expression takes in a comma seperated sequences of inputs (like def). Then, immediately following the colon, it returns the expression without using an explicit return statement. Finally, when assigning the lambda expression to a variable, it acts exactly like a Python function, and can be called using the the function call syntax: new_add().\nIf we didn’t assign lambda to a variable name, it would be called an anonymous function. These anonymous functions are extremely helpful, especially when using them as an input for another function. For example, the sorted() function takes in an optional key argument (a function) that describes how the items in a list should be sorted.\nunsorted = [('b', 6), ('a', 10), ('d', 0), ('c', 4)] # Sort on the second tuple value (the integer). print(sorted(unsorted, key=lambda x: x[1])) \u0026gt;\u0026gt; [('d', 0), ('c', 4), ('b', 6), ('a', 10)]  The Map Function While the ability to pass in functions as arguments is not unique to Python, it is a recent development in programming languages. Functions that allow for this type of behavior are called first-class functions. Any language that contains first-class functions can be written in a functional style.\nThere are a set of important first-class functions that are commonly used within the functional paradigm. These functions take in a Python iterable, and, like sorted(), apply a function for each element in the list. Over the next few sections, we will examine each of these functions, but they all follow the general form of function_name(function_to_apply, iterable_of_elements).\nThe first function we’ll work with is the map() function. The map() function takes in an iterable (ie. list), and creates a new iterable object, a special map object. The new object has the first-class function applied to every element.\n# Pseudocode for map. def map(func, seq): # Return `Map` object with # the function applied to every # element. return Map( func(x) for x in seq )  Here’s how we could use map to add 10 or 20 to every element in a list:\nvalues = [1, 2, 3, 4, 5] # Note: We convert the returned map object to # a list data structure. add_10 = list(map(lambda x: x + 10, values)) add_20 = list(map(lambda x: x + 20, values)) print(add_10) \u0026gt;\u0026gt; [11, 12, 13, 14, 15] print(add_20) \u0026gt;\u0026gt; [21, 22, 23, 24, 25]  Note that it’s important to cast the return value from map() as a list object. Using the returned map object is difficult to work with if you’re expecting it to function like a list. First, printing it does not show each of its items, and secondly, you can only iterate over it once.\nThe Filter Function The second function we’ll work with is the filter() function. The filter() function takes in an iterable, creates a new iterable object (again, a special map object), and a first-class function that must return a bool value. The new map object is a filtered iterable of all elements that returned True.\n# Pseudocode for filter. def filter(evaluate, seq): # Return `Map` object with # the evaluate function applied to every # element. return Map( x for x in seq if evaluate(x) is True )  Here’s how we could filter odd or even values from a list:\nvalues = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] # Note: We convert the returned filter object to # a list data structure. even = list(filter(lambda x: x % 2 == 0, values)) odd = list(filter(lambda x: x % 2 == 1, values)) print(even) \u0026gt;\u0026gt; [2, 4, 6, 8, 10] print(odd) \u0026gt;\u0026gt; [1, 3, 5, 7, 9]  The Reduce Function The last function we’ll look at is the reduce() function from the functools package. The reduce() function takes in an iterable, and then reduces the iterable to a single value. Reduce is different from filter() and map(), because reduce() takes in a function that has two input values.\nHere’s an example of how we can use reduce() to sum all elements in a list.\nfrom functools import reduce values = [1, 2, 3, 4] summed = reduce(lambda a, b: a + b, values) print(summed) \u0026gt;\u0026gt; 10  An interesting note to make is that you do not have to operate on the second value in the lambda expression. For example, you can write a function that always returns the first value of an iterable:\nfrom functools import reduce values = [1, 2, 3, 4, 5] # By convention, we add `_` as a placeholder for an input # we do not use. first_value = reduce(lambda a, _: a, values) print(first_value) \u0026gt;\u0026gt; 1  Rewriting with list comprehensions Because we eventually convert to lists, we should rewrite the map() and filter() functions using list comprehension instead. This is the more pythonic way of writing them, as we are taking advantage of the Python syntax for making lists. Here’s how you could translate the previous examples of map() and filter() to list comprehensions:\nvalues = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] # Map. add_10 = [x + 10 for x in values] print(add_10) \u0026gt;\u0026gt; [11, 12, 13, 14, 15, 16, 17, 18, 19, 20] # Filter. even = [x for x in values if x % 2 == 0] print(even) \u0026gt;\u0026gt; [2, 4, 6, 8, 10]  From the examples, you can see that we don’t need to add the lambda expressions. If you are looking to add map(), or filter() functions to your own code, this is usually the recommended way. However, in the next section, we’ll provide a case to still use the map() and filter() functions.\nWriting Function Partials Sometimes we want to use the behavior of a function, but decrease the number of arguments it takes. The purpose is to “save” one of the inputs, and create a new function that defaults the behavior using the saved input. Suppose we wanted to write a function that would always add 2 to any number:\ndef add_two(b): return 2 + b print(add_two(4)) \u0026gt;\u0026gt; 6  The add_two function is similar to the general function, $f(a,b) = a + b$, only it defaults one of the arguments ($a = 2$). In Python, we can use the partial module from the functools package to set these argument defaults. The partial module takes in a function, and “freezes” any number of args (or kwargs), starting from the first argument, then returns a new function with the default inputs.\nfrom functools import partialdef add(a, b): return a + b add_two = partial(add, 2) add_ten = partial(add, 10) print(add_two(4)) \u0026gt;\u0026gt; 6 print(add_ten(4)) \u0026gt;\u0026gt; 14  Partials can take in any function, including ones from the standard library.\n# A partial that grabs IP addresses using # the `map` function from the standard library. extract_ips = partial( map, lambda x: x.split(' ')[0] ) lines = read('example_log.txt') ip_addresses = list(extract_ip(lines))  Next steps In this post, we introduced the paradigm of functional programming. We learned about the lambda expression in Python, important functional functions, and the concept of partials. Overall, we showed that Python provides a programmer with the tools to easily switch between functional programming and object-oriented programming.\nIf you’ve enjoyed functional programming, our newest course: Building a Data Pipeline uses functional programming concepts to build a data pipeline. In this course, you’ll find more advanced Python concepts, examples of good API design, and a final project that uses your own data pipeline built from scratch!\n"});index.add({'id':92,'href':'/library/tutorials/docs/articles/python/python-api-tutorial/','title':"Getting Started with APIs",'content':" Python API Tutorial: Getting Started with APIs In this Python API tutorial, we’ll learn how to retrieve data for data science projects. There are millions of APIs online which provide access to data. Websites like Reddit, Twitter, and Facebook all offer certain data through their APIs.\nTo use an API, you make a request to a remote web server, and retrieve the data you need.\nBut why use an API instead of a static CSV dataset you can download from the web? APIs are useful in the following cases:\n The data is changing quickly. An example of this is stock price data. It doesn’t really make sense to regenerate a dataset and download it every minute — this will take a lot of bandwidth, and be pretty slow. You want a small piece of a much larger set of data. Reddit comments are one example. What if you want to just pull your own comments on Reddit? It doesn’t make much sense to download the entire Reddit database, then filter just your own comments. There is repeated computation involved. Spotify has an API that can tell you the genre of a piece of music. You could theoretically create your own classifier, and use it to compute music categories, but you’ll never have as much data as Spotify does.  In cases like the ones above, an API is the right solution. In this blog post, we’ll be querying a simple API to retrieve data about the International Space Station (ISS).\nAbout this Python API Tutorial This tutorial is based on part of our interactive course on APIs and Webscraping in Python, which you can start for free.\nFor this tutorial, we assume that you know some of the fundamentals of working with data in Python. If you don’t, you might like to try our free Python Fundamentals course.\nWhat is an API? An API, or Application Programming Interface, is a server that you can use to retrieve and send data to using code. APIs are most commonly used to retrieve data, and that will be the focus of this beginner tutorial.\nWhen we want to receive data from an API, we need to make a request. Requests are used all over the web. For instance, when you visited this blog post, your web browser made a request to the Dataquest web server, which responded with the content of this web page\nAPI requests work in exactly the same way – you make a request to an API server for data, and it responds to your request.\nMaking API Requests in Python In order to work with APIs in Python, we need tools that will make those requests. In Python, the most common library for making requests and working with APIs is the requests library. The requests library isn’t part of the standard Python library, so you’ll need to install it to get started.\nIf you use pip to manage your Python packages, you can install requests using the following command:\npip install requests  If you use conda, the command you’ll need is:\nconda install requests  Once you’ve installed the library, you’ll need to import it. Let’s start with that important step:\nimport requests  Now that we’ve installed and imported the requests library, let’s start using it.\nMaking Our First API Request There are many different types of requests. The most commonly used one, a GET request, is used to retrieve data. Because we’ll just be working with retrieving data, our focus will be on making ‘get’ requests.\nWhen we make a request, the response from the API comes with a response code which tells us whether our request was successful. Response codes are important because they immediately tell us if something went wrong.\nTo make a ‘GET’ request, we’ll use the requests.get() function, which requires one argument — the URL we want to make the request to. We’ll start by making a request to an API endpoint that doesn’t exist, so we can see what that response code looks like.\nresponse = requests.get(\u0026quot;http://api.open-notify.org/this-api-doesnt-exist\u0026quot;)  The get() function returns a response object. We can use the response.status_code attribute to receive the status code for our request:\nprint(response.status_code)  404  The ‘404’ status code might be familiar to you — it’s the status code that a server returns if it can’t find the file we requested. In this case, we asked for this-api-doesnt-exist which (surprise, surprise) didn’t exist!\nLet’s learn a little more about common status codes.\nAPI Status Codes Status codes are returned with every request that is made to a web server. Status codes indicate information about what happened with a request. Here are some codes that are relevant to GET requests:\n 200: Everything went okay, and the result has been returned (if any). 301: The server is redirecting you to a different endpoint. This can happen when a company switches domain names, or an endpoint name is changed. 400: The server thinks you made a bad request. This can happen when you don’t send along the right data, among other things. 401: The server thinks you’re not authenticated. Many APIs require login ccredentials, so this happens when you don’t send the right credentials to access an API. 403: The resource you’re trying to access is forbidden: you don’t have the right permissions to see it. 404: The resource you tried to access wasn’t found on the server. 503: The server is not ready to handle the request.  You might notice that all of the status codes that begin with a ‘4’ indicate some sort of error. The first number of status codes indicate their categorization. This is useful — you can know that if your status code starts with a ‘2’ it was successful and if it starts with a ‘4’ or ‘5’ there was an error. If you’re interested you can read more about status codes\nAPI Documentation In order to ensure we make a succesful request, when we work with APIs it’s important to consult the documentation. Documentation can seem scary at first, but as you use documentation more and more you’ll find it gets easier.\nWe’ll be working with the Open Notify API, which gives access to data about the international space station. It’s a great API for learning because it has a very simple design, and doesn’t require authentication. We’ll teach you how to use an API that requires authentication in a later post.\nOften there will be multiple APIs available on a particular server. Each of these APIs are commonly called endpoints. The first endpoint we’ll use is http://api.open-notify.org/astros.json, which returns data about astronauts currently in space.\nIf you click the link above to look at the documentation for this endpoint, you’ll see that it says This API takes no inputs. This makes it a simple API for us to get started with. We’ll start by making a GET request to the endpoint using the requests library:\nresponse = requests.get(\u0026quot;http://api.open-notify.org/astros.json\u0026quot;) print(response.status_code)  200  We received a ‘200’ code which tells us our request was successful. The documentation tells us that the API response we’ll get is in JSON format. In the next section we’ll learn about JSON, but first let’s use the response.json() method to see the data we received back from the API:\nprint(response.json())  {'message': 'success', 'people': [{'name': 'Alexey Ovchinin', 'craft': 'ISS'}, {'name': 'Nick Hague', 'craft': 'ISS'}, {'name': 'Christina Koch', 'craft': 'ISS'}, {'name': 'Alexander Skvortsov', 'craft': 'ISS'}, {'name': 'Luca Parmitano', 'craft': 'ISS'}, {'name': 'Andrew Morgan', 'craft': 'ISS'}], 'number': 6}  Working with JSON Data in Python JSON (JavaScript Object Notation) is the language of APIs. JSON is a way to encode data structures that ensures that they are easily readable by machines. JSON is the primary format in which data is passed back and forth to APIs, and most API servers will send their responses in JSON format.\nYou might have noticed that the JSON output we received from the API looked like it contained Python dictionaries, lists, strings and integers. You can think of JSON as being a combination of these objects represented as strings. Let’s look at a simple example:\nPython has great JSON support with the json package. The json package is part of the standard library, so we don’t have to install anything to use it. We can both convert lists and dictionaries to JSON, and convert strings to lists and dictionaries. In the case of our ISS Pass data, it is a dictionary encoded to a string in JSON format.\nThe json library has two main functions:\n json.dumps() — Takes in a Python object, and converts (dumps) it to a string. json.loads() — Takes a JSON string, and converts (loads) it to a Python object.  The dumps() function is particularly useful as we can use it to print a formatted string which makes it easier to understand the JSON output, like in the diagram we saw above:\nimport json def jprint(obj): # create a formatted string of the Python JSON object text = json.dumps(obj, sort_keys=True, indent=4) print(text) jprint(response.json())  { \u0026quot;message\u0026quot;: \u0026quot;success\u0026quot;, \u0026quot;number\u0026quot;: 6, \u0026quot;people\u0026quot;: [ { \u0026quot;craft\u0026quot;: \u0026quot;ISS\u0026quot;, \u0026quot;name\u0026quot;: \u0026quot;Alexey Ovchinin\u0026quot; }, { \u0026quot;craft\u0026quot;: \u0026quot;ISS\u0026quot;, \u0026quot;name\u0026quot;: \u0026quot;Nick Hague\u0026quot; }, { \u0026quot;craft\u0026quot;: \u0026quot;ISS\u0026quot;, \u0026quot;name\u0026quot;: \u0026quot;Christina Koch\u0026quot; }, { \u0026quot;craft\u0026quot;: \u0026quot;ISS\u0026quot;, \u0026quot;name\u0026quot;: \u0026quot;Alexander Skvortsov\u0026quot; }, { \u0026quot;craft\u0026quot;: \u0026quot;ISS\u0026quot;, \u0026quot;name\u0026quot;: \u0026quot;Luca Parmitano\u0026quot; }, { \u0026quot;craft\u0026quot;: \u0026quot;ISS\u0026quot;, \u0026quot;name\u0026quot;: \u0026quot;Andrew Morgan\u0026quot; } ] }  Immediately we can understand the structure of the data more easily – we can see that their are six people currently in space, with their names existing as dictionaries inside a list.\nIf we compare this to the documentation for the endpoint we’ll see that this matches the specified output for the endpoint.\nUsing an API with Query Parameters The http://api.open-notify.org/astros.json endpoint we used earlier does not take any parameters. We just send a GET request and the API sends back data about the number of people currently in space.\nIt’s very common, however, to have an API endpoint that requires us to specify parameters. An example of this the http://api.open-notify.org/iss-pass.json endpoint. This endpoint tells us the next times that the international space station will pass over a given location on the earth.\nIf we look at the documentation, it specifies required lat (latitude) and long (longitude) parameters.\nWe can do this by adding an optional keyword argument, params, to our request. We can make a dictionary with these parameters, and then pass them into the requests.get function. Here’s what our dictionary would look like, using coordinates for New York City:\nparameters = { \u0026quot;lat\u0026quot;: 40.71, \u0026quot;lon\u0026quot;: -74 }  We can also do the same thing directly by adding the parameters directly to the URL. like this: http://api.open-notify.org/iss-pass.json?lat=40.71\u0026amp;lon=-74.\nIt’s almost always preferable to setup the parameters as a dictionary, because requests takes care of some things that come up, like properly formatting the query parameters, and we don’t need to worry about inserting the values into the URL string.\nLet’s make a request using these coordinates and see what response we get.\nresponse = requests.get(\u0026quot;http://api.open-notify.org/iss-pass.json\u0026quot;, params=parameters) jprint(response.json())  { \u0026quot;message\u0026quot;: \u0026quot;success\u0026quot;, \u0026quot;request\u0026quot;: { \u0026quot;altitude\u0026quot;: 100, \u0026quot;datetime\u0026quot;: 1568062811, \u0026quot;latitude\u0026quot;: 40.71, \u0026quot;longitude\u0026quot;: -74.0, \u0026quot;passes\u0026quot;: 5 }, \u0026quot;response\u0026quot;: [ { \u0026quot;duration\u0026quot;: 395, \u0026quot;risetime\u0026quot;: 1568082479 }, { \u0026quot;duration\u0026quot;: 640, \u0026quot;risetime\u0026quot;: 1568088118 }, { \u0026quot;duration\u0026quot;: 614, \u0026quot;risetime\u0026quot;: 1568093944 }, { \u0026quot;duration\u0026quot;: 555, \u0026quot;risetime\u0026quot;: 1568099831 }, { \u0026quot;duration\u0026quot;: 595, \u0026quot;risetime\u0026quot;: 1568105674 } ] }  Understanding the Pass Times The JSON response matches what the documentation specified:\n A dictionary with three keys The third key, response, contains a list of pass times Each pass time is a dictionary with risetime (pass start time) and duration keys.  Let’s extract the pass times from our JSON object:\npass_times = response.json()['response'] jprint(pass_times)  [ { \u0026quot;duration\u0026quot;: 395, \u0026quot;risetime\u0026quot;: 1568082479 }, { \u0026quot;duration\u0026quot;: 640, \u0026quot;risetime\u0026quot;: 1568088118 }, { \u0026quot;duration\u0026quot;: 614, \u0026quot;risetime\u0026quot;: 1568093944 }, { \u0026quot;duration\u0026quot;: 555, \u0026quot;risetime\u0026quot;: 1568099831 }, { \u0026quot;duration\u0026quot;: 595, \u0026quot;risetime\u0026quot;: 1568105674 } ]  Next we’ll usea loop to extract just the five risetime values:\nrisetimes = [] for d in pass_times: time = d['risetime'] risetimes.append(time) print(risetimes)  [1568082479, 1568088118, 1568093944, 1568099831, 1568105674]  These times are difficult to understand – they are in a format known as timestamp or epoch. Essentially the time is measured in the number of seconds since January 1st 1970. We can use the Python datetime.fromtimestamp() method to convert these into easier to understand times:\nfrom datetime import datetime times = [] for rt in risetimes: time = datetime.fromtimestamp(rt) times.append(time) print(time)  2019-09-09 21:27:59 2019-09-09 23:01:58 2019-09-10 00:39:04 2019-09-10 02:17:11 2019-09-10 03:54:34  It looks like the ISS passes over New York City often – the next five times happen within a seven hour period!\nPython API Tutorial: Next Steps In this tutorial, we learned:\n What an API is Types of requests and response codes How to make a get request How to make a request with parameters How to display and extract JSON data from an API  These fundamental steps will help you to start working with APIs. Remember that key to each time we used the API was to carefully read the API documentation and use that to understand what request to make and what parameters to provide.\nNow you’ve completed our Python API tutorial, you might like to:\n Complete our interactive Dataquest APIs and scraping course, which you can start for free. Try working with some data from this list of Free Public APIs — we recommend selecting an API that doesn’t require authentication as a good first step.  Ref : https://www.dataquest.io/blog/python-api-tutorial/\n"});index.add({'id':93,'href':'/library/tutorials/docs/articles/data-science/pandas/pandas-house-market-analysis-1/','title':"House Market Analysis 1",'content':" Python Pandas : House Market Analysis – Munich (2016-2017) (1/.2) Source\nI started to use python for other things than Data Analysis at the beginning. I was a technical SEO consultant and wanted to use a crawler (or built one) and not knowing any programming language, python looked as the perfect language to start with…\nFlash forward to nowadays, I am even more fan of python now because of its versatility to do what I just mentioned and also to realize data analysis easily.\nWhat if we could bring both of these worlds together ? I created my first crawler when I was injured from breaking my wrist, it is not beautiful, it was written with one hand but it worked.\nNow that I am looking at the data and I thought it would be a very nice and easy example on how to use the data that you have gathered, or have at your disposal, with python and mostly with Pandas.\nHouse Market in Munich I am living in Munich now and I really like the city, I traveled a lot during the beginning of my career (New York / San Francisco / Taiwan / Paris) and I thought quickly that I would need some data to help searching for my home. If I want to buy somewhere, it is not a small amount that you need to pay, it is probably a lot of money, so you need to back up your wish with some solid data.\nI gather data on the house market around Munich on my own with my little crawler. It is still a manual program because when I created it, I didn’t know and didn’t have time to make it a cloud native application that run 24\u0026frasl;7.\nI will probably try to improve it and make it cloud native so I can monitor it. This will be a blog post if I succeed in doing so.\nIn the meantime, I ran this crawler time to time, in a stochastic way some may\nThe House Market in Munich is expensive, not a bit, but really expensive.\nSo I was doing my crawler in order to find a home that would match my budget. It is mostly apartment (because Houses are not in my budget) and in the area of Munich.\nSo to start with the bias of this analysis, here comes some :\n I looked for “up to 4 room apartments” I looked for “up to 600 000 €” apartment (around 690 000$) I looked for “up to 20km away from Munich center”. I looked if the flat was on the ground floor or up in the building, but I didn’t look at the specific floor.  I saved my data as csv and you can find it on my github account : https://github.com/pitchmuc/munich_housemarket.git\nUnderstanding the data with Pandas When I have a data set to look at, I first do 2 things :\n I look at the size of the data set. I look at the type of data set.  For me, the data set is not so large (150 kb) so there is no problem for my computer to handle that.\nIf it would be bigger, I would have split it to chunk of 100MB maximum so I can play and test my script easily. I would then produce a robust script to take all of your data through.\nWhen you execute your analysis on your full data set (ie: 5GB), you want to make sure that this is working before spending hours on running your analysis and finding it didn’t do what you wanted.\nThe type of the data that you have to handle can be :\n clean : you just have to import it half clean : you have to import it and take care of few missing data. not clean at all : you have to clean it a bit, import it and take care of the missing data.  In our case, I have managed to have a pretty clean to half clean data but still some cleaning is required.\nOn the following steps, you will see how to realize basic cleaning with python pandas :\n Import the libraries you want to use. In our case, you want to have pandas and numpy.\nimport pandas as pd #naming convention import numpy as np #naming convention  import your data set in your environment.\nIn my example, I am using ipython (or called jupyter notebook). I really like this environment for exploration. When things get serious, I usually go to Spyder.\ndf = pd.read_csv('data_immoscout.csv',delimiter='\\t') # df is going to be our dataframe. (place where we store all the data). I used tab as delimiter.  Look at the data you have. Using the .head() function will give a preview of your data.\ndf.head() ## use df.head(20) to see the first 20 lines  On top of df.head(), you can also try to see the exact type the data have been processed.\nIn order to do that, you can use the\ndf.dtypes ##it will give you something like this :  index0 int64 terrace object bedrooms object construction_year object date_month int64 date_year int64 date_year_month object floor object rooms object price_room object price_surface object price object surface object zip int64 dtype: object  Look at the type of column you have is quite important because this usually give you an idea of the type of data store. Or type of data that should be store.\ndf.columns #it will give you something like this :  Index(['index0', 'terrace', 'bedrooms', 'construction_year', 'date_month', 'date_year', 'date_year_month', 'floor', 'rooms', 'price_room', 'price_surface', 'price', 'scout_id', 'surface'], dtype='object')   From that I can give you some explanation about these data, but looking at the data through dtypes and head() should actually already gave you the idea :\n index0 : This is the index of the table terrace : does there is a terrace or not bedrooms : how many bedrooms there is construction_year : when has it been built date_month : Month of the year when the crawl has been realized date_year : Year when the crawl has been realized date_year_month : month and year when the crawl has been realized floor : is it ground floor or not ? rooms : number of rooms price_rooms : price of the apartment divided by number of room price_surface : price of the apartment divided by surface price : price of the flat surface : surface of the flat zip : zip code of the flat  The first thing you want to do when you start with these data is that you make sure that they are recognized the correct way in the system.\nWhat does it mean “the correct way”?\nThe correct way is : numbers are seen as numbers, strings as strings, dates as dates and NaN as NaN.\nWhat is a NaN ?\nNaN stands for “Not a Number”. This is very important to know because this is the type of data we want to clean before we are finally processing them.\nAs you may have seen already, there are some rows where NAN is actually written. Is it recognized as NaN ?\nIn order to see how many NaN you have, you can actually use this very useful function :\ndf.isna().sum() ## The result will look like this :  index0 0 terrace 0 bedrooms 0 construction_year 0 date_month 0 date_year 0 date_year_month 0 floor 0 rooms 0 price_room 0 price_surface 0 price 0 surface 0 zip 0 dtype: int64  This means that there is no NaN recognized in your current data set (or dataframe).\nThe ‘NAN’ is just a string that I set when I actually ran my crawler.\nYou will then replaced the “NAN” string with the correct definition of a NaN. In order to do that, we will use the numpy library, you will just need to use it that way :\ndf.replace('NAN',np.NaN,inplace=True)  When we have done that, we will then see different result on the previous method :\ndf.isna().sum() ## The result will look like this :  index0 0 terrace 0 bedrooms 319 construction_year 49 date_month 0 date_year 0 date_year_month 0 floor 113 rooms 34 price_room 35 price_surface 212 price 1 surface 211 zip 0 dtype: int64  Here we start to see what is actually going on on these data.\nYou see that we are missing a lot of data for bedrooms information.\nOur role in the next steps is to make sure to have as less as NaN as possible.\nWe will try to assume some different strategies to fill the NaN here.\nIf you want to see the global quality of your data set, you can actually use some calculation.\nLike this :\n(df.isnull().sum() / len(df))*100 ## result will look like this  index0 0.000000 terrace 0.000000 bedrooms 36.708861 construction_year 5.638665 date_month 0.000000 date_year 0.000000 date_year_month 0.000000 floor 13.003452 rooms 3.912543 price_room 4.027618 price_surface 24.395857 price 0.115075 surface 24.280783 zip 0.000000 dtype: float64  So the data I provided is not perfect but you will probably see lots of data set uglier than that.\nTo understand the data : 36,7% of the rows don’t have bedrooms information.\nWhat was really troubling is that we are missing the price information for one specific data point.\nPrice is really hard to forecast but let see what data it is and we may figure out something :\ndf[df['price'].isna()].T ##the result will look like this :  You will see that we are missing the price and the number of bedrooms.\nThere are 2 options we can do :\n Estimate the price with the information we have (5 room, 209 square meter, construction year : 2016) Remove this line from your dataset  On our case, 200 square meter built in 2016 will probably be out of my data set restriction (\u0026lt;600 K€). I will then remove the line from the data set.\nFrom my extract, I saw that the index of that line is 367.\nI can remove the line by doing this simple manipulation :\ndf.drop(df.index[367],inplace=True)  but if you have more than one index, how do you manage ?\nYou just need to call out the index of your condition :\ndf.drop(df[df['price'].isna()].index,inplace = True)  As we are deleting useless information, we can take the opportunity to delete the index0 column as you could have seen that pandas automatically generate an index to your dataframe.\nIn order to delete a column completely, you will need to realize this action :\ndf.drop(['index0'],axis=1,inplace=True) #axis = 1 make sure that you are deleting column  Now we want to have the correct data type recognize by pandas.\nHaving the correct data type will allow us to realize numeric operation on numeric type (int or float).\nWe will be able to deal with NaN in a better way if we have the correct data type set.\nWhat I would recommend is always to try to set the numeric value to int.\nWhy int ?\nBecause it easier to handle and interpret but you could try to have everything into float.\nFloating numbers can represent integer (2.0 == 2) but integers cannot represent some floating numbers (2.1 != 2)\nA easy loop could look like :\nfor col in list(df.columns): # for each column try: df[col] = df[col].astype(int) #try to set it as int except: df[col] = df[col].astype(str) # if not sucessful try to set it as string  When you have realized this operation, you can see that not all columns have been changed to numeric.\nThis is mostly due to some column not being an integer but being a float. (so a decimal)\nYou can realize another loop on that :\nfor col in list(df.columns): if df[col].dtypes == object: try: df[col] = df[col].astype(float) except: df[col] = df[col].astype(str)  Then by doing a simple overview, your data start to look like something you can work :\ndf.dtypes # it will show something like this :  Filling the NaN Now that we are ready to manipulate the difference type of data, we will be using our brain a bit to deal with the different data type and fill the NaN values.\nAs explained previously, before doing any analysis, you would want to feel the maximum of the missing value in order to do calculation to the maximum of values.\n Filling the Floor Column\nAs you should remember, this column tells us if this is Ground floor or not.\nBy doing this simple method, you can see the different values and the number of time they are appearing.\ndf['floor'].value_counts() ### Should show something like this :  up floor 687 nan 112 ground floor 69 Name: floor, dtype: int64  what you would need to do is to calculate the distribution between an the up floor and the ground floor and apply this distribution to the remaining data.\nYou can easily calculate that the number of ground floor apartment represent around 10% of this column.\nTherefore we would need to replace 1\u0026frasl;10 of the na with a “ground floor” value.\nWe can do that by simply creating a function :\ndef fill10pct(): if np.random.random_integers(0,9) == 0: return 'ground floor' else: return 'up floor'  Then you need to apply this to the your rows :\nfor index, value in df.iterrows(): if df.loc[index,'floor']=='nan': df.loc[index,'floor'] = fill10pct()  You can run a df[‘floor’].value_counts() to check if the distribution was kept.\n Filling the room\n  Now we will try to fill the room.\nWe will try a different technique here. We have some information that can help us identify how many rooms there is in total.\nThere are the bedroom information, so in Germany in the post of apartment, the bedrooms are the only room counted separated from the number of room.\nWhich is : 3 rooms mean 2 bedroom, one big room and a kitchen and a bathroom.\nSo we could say that the number of room is number of bedroom + 1But what if we don’t have the number of bedrooms ?\nThen, to make it simple we can say that the number of room is 2. which is the minimum I would get.For this we will create our 2 conditions (there is a number of bedroom, or there isn’t)\nconditions = [ (df['rooms'].isnull()) \u0026amp;amp; (df['bedrooms'].isnull()), (df['rooms'].isnull()) \u0026amp;amp; (df['bedrooms'].notnull())] choices = [2,df['bedrooms']+1]  And we are going to use the numpy select function to decide which option to apply\ndf['rooms'] = np.select(conditions, choices, default=2)  Pretty easy when you know how to do it. :) It is so easy that we will make it a bit more robust and integrate the surface in it. We will say that if the surface is bigger than 75 square meter, we will set the number of room to 3.\nconditions =[ (df['rooms'].isnull()) \u0026amp;amp; (df['bedrooms'].isnull()) \u0026amp;amp; (df['surface'].isnull()), (df['rooms'].isnull()) \u0026amp;amp; (df['bedrooms'].isnull()) \u0026amp;amp; (df['surface']\u0026amp;gt;75), (df['rooms'].isnull()) \u0026amp;amp; (df['bedrooms'].notnull()), ] choices = [2,3,df['bedrooms']+1] df['rooms'] = np.select(conditions,choices,default=2)   Filling the bedrooms\nFilling the bedroom is actually the opposite logic. If you have the number of room, you can actually guess the number of bedroom.\n  This time, we will use the method select from numpy :\ndf['bedrooms'] = np.where(df['bedrooms'].isnull(), df['rooms']-1, df['bedrooms'])   Filling the Surface\nFor the surface, we are missing 211 data points. We can have the same strategy than the number of rooms. Extrapolate the surface of the existing apartment to fill the missing value of the surface.\nIf we can the average surface for the 2, 3 and 4 room apartment, we could assign the mean value to these room.   For realizing this, we are going to use one of the most important function of pandas. The groupby.\ndf.groupby(['rooms'])['surface'].mean() ##it should give you something like :  2.0 89.988924 3.0 91.100000 4.0 100.400000  It is interesting to see that the average surface for your 2 and 3 rooms apartment are not that different.\nMost probably our data are not that clean and some 3 rooms apartment were fetched as 2 rooms apartment.\nconditions = [ (df['rooms']==2 \u0026amp;amp; df['surface'].isnull()), (df['rooms']==3 \u0026amp;amp; df['surface'].isnull()), (df['rooms']==4 \u0026amp;amp; df['surface'].isnull())] choices = [90,91.1,100] df['surface'] = np.select(conditions,choices,default=90.5) #default in between 2 and 3 rooms   Filling the construction year\nOn this one, this is pretty hard as the construction year can be really random. You cannot really guess a construction year based on the previous data.\nOn that case, in order to not false the data to much, I would chose to fill the blank with the mean of this dimension.\nThis is another method you can use quick often with pandas :\ndf['construction_year'].fillna(df['construction_year'].mean(),inplace=True)  Filling the rest…\n  As you may notice while doing a df.isnull().sum() some other columns have NaN but they are actually calculation of other columns.\nSo you just have to redo the calculation with your primary columns filled and all the NaN will disappear.\nI hope this tutorial on how to clean your data will help you if you are discovering Data Analysis with Python and Pandas.\nThis is a very important part of working with Data and if you plan to machine learning, cleaning the data and creating value out of NaN data points is one of the most important aspect of Machine Learning.\nAs the title suggest, we will have a 2nd article where we actually analyze the data and we will probably try to do some visualization.\nDon’t hesitate to comment and give your tip to analyze this data set.\nAs explained above, both data set (the clean one and the uncleane one) and the Jupyter notebook are available on my Github account : https://github.com/pitchmuc/munich_housemarket\n"});index.add({'id':94,'href':'/library/tutorials/','title':"Introduction",'content':" ประวัติและความสำคัญของคอมพิวเตอร์ คอมพิวเตอร์ถูกพัฒนาขึ้นมาโดยมีจุดประสงค์หลักคือเพื่อไว้เป็นอุปกรณ์ในการคำนวณ การคำนวณนั้นที่จริงแล้วมนุษย์ก็ทำได้ แต่หากต้องคำนวณตัวเลขจำนวนมากๆคำนวณซ้ำๆไปเรื่อยๆไม่ว่าใครก็คงจะเบื่อและอาจเริ่มมีการคำนวณผิดพลาดขึ้นได้ เช่นสมมุติว่าต้องการหาค่าแฟ็กทอเรียล 100! = 1×2×3×\u0026hellip;×100 กว่าเราจะคูณเสร็จก็คงใช้เวลาหลายนาที แต่คอมพิวเตอร์สามารถทำได้ภายในพริบตา อะไรก็ตามที่เป็นการคำนวณที่มีรูปแบบตายตัวอย่างเป็นระบบเราสามารถสั่งให้คอมพิวเตอร์ทำแทนได้ มันสามารถทำได้อย่างไม่รู้จักเบื่อ รวดเร็วแถมไม่มีข้อผิดพลาดด้วย (ยกเว้นคนจะป้อนคำสั่งให้มันผิดเอง)\nที่จริงแล้วแนวคิดเกี่ยวกับเรื่องการคำนวณอย่างเป็นระบบนั้นมีมาตั้งแต่โบราณก่อนที่จะมีคอมพิวเตอร์ใช้กันแล้ว ดังจะเห็นได้จากที่ชื่อระเบียบวิธีการเชิงตัวเลขมีชื่อนักคณิตศาสตร์สมัยก่อนติดอยู่ เช่นระเบียบวิธีของนิวตัน, ระเบียบวิธีของออยเลอร์ ซึ่งเอาไว้คำนวณแบบวนซ้ำๆเพื่อหาคำตอบของสมการหรือค่าที่ต้องการ แนวคิดพวกนี้มีมานานแล้วแต่สมัยแรกๆเขาได้แต่คำนวณด้วยตัวเอง คำนวณซ้ำๆไปเรื่อยๆ ถ้าผิดเมื่อไหร่ก็อาจต้องคำนวณใหม่\nต่อมาจึงได้เริ่มมีแนวคิดที่จะใช้เครื่องจักรเพื่อช่วยในการคำนวณ ซึ่งเรียกว่าเครื่องคำนวณเชิงกล เครื่องแรกถูกสร้างโดยเบลซ ปาสกาล (Blaise Pascal) เมื่อปี 1642 ชื่อว่า ปาสกาลีน (pascaline) เครื่องคำนวณเชิงกลช่วยให้การคำนวณอย่างเป็นระบบสามารถเป็นไปได้ ในยุคแรกใช้เฟืองและแรงคน ต่อมาก็เริ่มมีการนำพลังงานธรรมชาติเช่นพลังไอน้ำเข้าช่วย แล้วก็ถูกพัฒนาขึ้นมาเรื่อยๆอย่างช้าๆ อุปกรณ์ที่ใช้ก็ค่อยๆเปลี่ยนไป และคำนวณได้ดีมากขึ้น ในที่สุดก็เริ่มมีการนำวงจรอิเล็กทรอนิกส์มาใช้สร้างเป็นเครื่องคำนวณเป็นครั้งแรกในช่วงสงครามโลกครั้งที่สอง และนั่นก็เป็นจุดกำเนิดของคอมพิวเตอร์ในปัจจุบัน\nในยุคแรกๆคอมพิวเตอร์ใช้หลอดสุญญากาศ เป็นส่วนประกอบ ซึ่งทำให้มีขนาดใหญ่มาก แต่ต่อมาก็ได้เปลี่ยนมาใช้สารกึ่งตัวนำ ทำให้ขนาดเล็กลง และยิ่งพัฒนาต่อมาก็ยิ่งเล็กลงเรื่อยๆ กลายเป็นคอมพิวเตอร์แบบที่ใช้กันอยู่ในปัจจุบัน เมื่อคอมพิวเตอร์ เริ่มเล็กและมีราคาถูกก็ทำให้คนทั่วไปเริ่มสามารถใช้กันได้ คอมพิวเตอร์จึงไม่ได้เป็นแค่อุปกรณ์คำนวณอีกต่อไปแต่ถูกใช้ในอีกหลายด้าน เช่นเพื่อการบันเทิง นำไปสู่การสร้างเกมต่างๆมากมายให้พวกเราได้เล่นกัน\nการเขียนโปรแกรม เราได้รู้กันไปแล้วว่าคอมพิวเตอร์ถูกสร้างขึ้นมาเพื่อคำนวณ แต่ว่าต้องทำยังไงมันถึงจะทำการคำนวณสิ่งที่เราต้องการให้?\nการจะให้คอมทำงานนั้นเราต้องป้อนคำสั่งให้เพื่อให้มันทำงาน และชุดของคำสั่งจำนวนมากที่ถูกกำหนดขึ้นเพื่อให้คอมทำงานเป็นระบบตามที่ ต้องการนั้นเรียกว่าโปรแกรมคอมพิวเตอร์ ดังนั้นการกำหนดติดตั้งคำสั่งที่จะให้คอมพิวเตอร์ทำงานนั้นเป็นระบบตามที่ต้องการจึงเรียกว่าการเขียนโปรแกรม (programming) แล้วการป้อนคำสั่งนั้นทำได้อย่างไร? ที่จริงแล้วการทำงานของคอมพิวเตอร์นันซับซ้อนมาก และมีตรรกะการทำงานที่ต่างจากมนุษย์ ภาษาที่ใช้สั่งการคอมนั้นเรียกว่าภาษาเครื่อง ซึ่งยากที่มนุษย์จะทำความเข้าใจ ทำให้ในยุคแรกๆผู้ที่จะใช้คอมพิวเตอร์ต้องมีความเชี่ยวชาญเฉพาะทางอย่างมาก เพื่อให้ง่ายต่อการใช้งานมากขึ้นจึงมีการสร้างภาษาที่ใกล้เคียงกับที่มนุษย์ใช้ กันมากขึ้นตั้งแต่ปี 1950 กว่าๆ คือภาษาแอสเซมบลี (assembly) แต่ภาษาแอสเซมบลีก็ยังยากต่อการใช้งานอยู่ จึงมีการคิดค้นภาษาที่เข้าใจง่ายขึ้น ซึ่งถูกเรียกว่าภาษาระดับสูง ภาษาเหล่านี้เวลาที่ทำงานต้องไปแปลงเป็นภาษาเครื่องอีกทีเพื่อให้คอมเข้าใจ จึงทำให้ช้าลงบ้าง แต่ก็สะดวกในการเขียนมากขึ้น เหมาะสำหรับให้คนทั่วไปใช้งานได้โดยไม่ต้องมีความรู้ด้านคอมพิวเตอร์มากนัก\nภาษาระดับสูงในยุคแรกๆ ได้แก่ ฟอร์แทรน (fortran), ปาสกาล (pascal) และ ซี \u0026copy; เป็นต้น และเวลาผ่านไปก็มีคนคิดภาษาระดับสูงใหม่ๆขึ้นมาเรื่อยๆจนปัจจุบันมีอยู่ จำนวนมากมายนับไม่ถ้วน ในจำนวนนั้น หนึ่งในภาษาที่ได้รับความนิยมก็คือภาษาไพธอน (python) ปัจจุบันภาษาที่ได้รับความนิยมสูงสุดสำหรับเรียนในมหาวิทยาลัยในไทยน่าจะยังคงเป็น ภาษาซี อย่างไรก็ตาม มีบางแห่งเริ่มหันมาสอนภาษาไพธอนแทนกันแล้ว ภาษาไพธอนมีแนวโน้มที่จะเป็นที่นิยมสูงขึ้นเรื่อยๆ ดังนั้นจึงเป็นภาษาหนึ่งที่น่าศึกษาไว้\n"});index.add({'id':95,'href':'/library/tutorials/docs/articles/python/python-pickle-module/','title':"Introduction Pickle Module",'content':" Introduction to the Python Pickle Module Introduction Pickling is a popular method of preserving food. According to Wikipedia, it is also a pretty ancient procedure – although the origins of pickling are unknown, the ancient Mesopotamians probably used the process 4400 years ago. By placing a product in a specific solution, it is possible to drastically increase its shelf life. In other words, it\u0026rsquo;s a method that lets us store food for later consumption.\nIf you\u0026rsquo;re a Python developer, you might one day find yourself in need of a way to store your Python objects for later use. Well, what if I told you, you can pickle Python objects too?\nSerialization Serialization is a process of transforming objects or data structures into byte streams or strings. A byte stream is, well, a stream of bytes – one byte is composed of 8 bits of zeros and ones. These byte streams can then be stored or transferred easily. This allows the developers to save, for example, configuration data or user\u0026rsquo;s progress, and then store it (on disk or in a database) or send it to another location.\nPython objects can also be serialized using a module called Pickle.\nOne of the main differences between pickling Python objects and pickling vegetables is the inevitable and irreversible change of the pickled food\u0026rsquo;s flavor and texture. Meanwhile, pickled Python objects can be easily unpickled back to their original form. This process, by the way, is universally known as deserialization.\nPickling (or serialization in general) should not be confused with compression. The purpose of pickling is to translate data into a format that can be transferred from RAM to disk. Compression, on the other hand, is a process of encoding data using fewer bits (in order to save disk space).\nSerialization is especially useful in any software where it\u0026rsquo;s important to be able to save some progress on disk, quit the program and then load the progress back after reopening the program. Video games might be the most intuitive example of serialization\u0026rsquo;s usefulness, but there are many other programs where saving and loading a user\u0026rsquo;s progress or data is crucial.\nPickle vs JSON There is a chance that you have heard of JSON (JavaScript Object Notation), which is a popular format that also lets developers save and transmit objects encoded as strings. This method of serialization has some advantages over pickling. JSON format is human-readable, language-independent, and faster than pickle.\nIt does have, however, some important limitations as well. Most importantly, by default, only a limited subset of Python built-in types can be represented by JSON. With Pickle, we can easily serialize a very large spectrum of Python types, and, importantly, custom classes. This means we don\u0026rsquo;t need to create a custom schema (like we do for JSON) and write error-prone serializers and parsers. All of the heavy liftings is done for you with Pickle.\nWhat can be Pickled and Unpickled The following types can be serialized and deserialized using the Pickle module:\n All native datatypes supported by Python (booleans, None, integers, floats, complex numbers, strings, bytes, byte arrays) Dictionaries, sets, lists, and tuples - as long as they contain pickleable objects Functions and classes that are defined at the top level of a module  It is important to remember that pickling is not a language-independent serialization method, therefore your pickled data can only be unpickled using Python. Moreover, it\u0026rsquo;s important to make sure that objects are pickled using the same version of Python that is going to be used to unpickle them. Mixing Python versions, in this case, can cause many problems.\nAdditionally, functions are pickled by their name references, and not by their value. The resulting pickle does not contain information on the function\u0026rsquo;s code or attributes. Therefore, you have to make sure that the environment where the function is unpickled is able to import the function. In other words, if we pickle a function and then unpickle it in an environment where it\u0026rsquo;s either not defined or not imported, an exception will be raised.\nIt is also very important to note that pickled objects can be used in malevolent ways. For instance, unpickling data from an untrusted source can result in the execution of a malicious piece of code.\nPickling a Python List The following very simple example shows the basics of using the Pickle module in Python 3:\nimport pickle test_list = ['cucumber', 'pumpkin', 'carrot'] with open('test_pickle.pkl', 'wb') as pickle_out: pickle.dump(test_list, pickle_out)  First, we have to import the pickle module, which is done in line 1. In line 3 we define a simple, three element list that will be pickled.\nIn line 5 we state that our output pickle file\u0026rsquo;s name will be test_pickle.pkl. By using the wb option, we tell the program that we want to write (w) binary data (b) inside of it (because we want to create a byte stream). Note that the pkl extension is not necessary – we\u0026rsquo;re using it in this tutorial because that\u0026rsquo;s the extension included in Python\u0026rsquo;s documentation.\nIn line 6 we use the pickle.dump() method to pickle our test list and store it inside the test_pickle.pkl file.\nSubscribe to our Newsletter Get occassional tutorials, guides, and reviews in your inbox. No spam ever. Unsubscribe at any time.\nSubscribe\nI encourage you to try and open the generated pickle file in your text editor. You\u0026rsquo;ll quickly notice that a byte stream is definitely not a human-readable format.\nUnpickling a Python List Now, let\u0026rsquo;s unpickle the contents of the test pickle file and bring our object back to its original form.\nimport pickle with open('test_pickle.pkl', 'rb') as pickle_in: unpickled_list = pickle.load(pickle_in) print(unpickled_list)  As you can see, this procedure is not more complicated than when we pickled the object. In line 3 we open our test_pickle.pkl file again, but this time our goal is to read (r) the binary data (b) stored within it.\nNext, in line 5, we use the pickle.load() method to unpickle our list and store it in the unpickled_list variable.\nYou can then print the contents of the list to see for yourself that it is identical to the list we pickled in the previous example. Here is the output from running the code above:\n$ python unpickle.py ['cucumber', 'pumpkin', 'carrot']  Pickling and Unpickling Custom Objects As I mentioned before, using Pickle, you can serialize your own custom objects. Take a look at the following example:\nimport pickle class Veggy(): def __init__(self): self.color = '' def set_color(self, color): self.color = color cucumber = Veggy() cucumber.set_color('green') with open('test_pickle.pkl', 'wb') as pickle_out: pickle.dump(cucumber, pickle_out) with open('test_pickle.pkl', 'rb') as pickle_in: unpickled_cucumber = pickle.load(pickle_in) print(unpickled_cucumber.color)  As you can see, this example is almost as simple as the previous one. Between the lines 3 and 7 we define a simple class that contains one attribute and one method that changes this attribute. In line 9 we create an instance of that class and store it in the cucumber variable, and in line 10 we set its attribute color to \u0026ldquo;green\u0026rdquo;.\nThen, using the exact same functions as in the previous example, we pickle and unpickle our freshly created cucumber object. Running the code above results in the following output:\n$ python unpickle_custom.py green  Remember, that we can only unpickle the object in an environment where the class Veggy is either defined or imported. If we create a new script and try to unpickle the object without importing the Veggy class, we\u0026rsquo;ll get an \u0026ldquo;AttributeError\u0026rdquo;. For example, execute the following script:\nimport pickle with open('test_pickle.pkl', 'rb') as pickle_in: unpickled_cucumber = pickle.load(pickle_in) print(unpickled_cucumber.color)  In the output of the script above, you will see the following error:\n$ python unpickle_simple.py Traceback (most recent call last): File \u0026quot;\u0026lt;pyshell#40\u0026gt;\u0026quot;, line 2, in \u0026lt;module\u0026gt; unpickled_cucumber = pickle.load(pickle_in) AttributeError: Can't get attribute 'Veggy' on \u0026lt;module '__main__' (built-in)\u0026gt;  Conclusion As you can see, thanks to the Pickle module, serialization of Python objects is pretty simple. In our examples, we pickled a simple Python list – but you can use the exact same method to save a large spectrum of Python data types, as long as you make sure your objects contain only other pickleable objects.\nPickling has some disadvantages, the biggest of which might be the fact that you can only unpickle your data using Python – if you need a cross-language solution, JSON is definitely a better option. And finally, remember that pickles can be used to carry the code that you don\u0026rsquo;t necessarily want to execute. Similarly to pickled food, as long as you get your pickles from trusted sources, you should be fine.\nReference : https://stackabuse.com/introduction-to-the-python-pickle-module/\nศึกษาเพิ่มเติม : https://python3.wannaphong.com/\n"});index.add({'id':96,'href':'/library/tutorials/docs/articles/python/oop-in-python/','title':"OOP in Python",'content':" Object Oriented Programming in Python  Introduction Pros and Cons of OOP Class Objects Attributes Methods Constructors Local vs Global Variables Access Modifiers Inheritance Polymorphism Encapsulation Conclusion  Introduction Object-Oriented Programming (OOP) is a programming paradigm where different components of a computer program are modeled after real-world objects. An object is anything that has some characteristics and can perform a function.\nConsider a scenario where you have to develop a Formula 1 car racing game using the object-oriented programming approach. The first thing you need to do is to identify real-world objects in the actual Formula 1 race. What are the entities in a Formula 1 race that have some characteristics and can perform any function? One of the obvious answers to this question is the car. A car can have characteristics like engine capacity, make, model, manufacturer, and so on. Similarly, a car can be started, stopped, accelerated and so on. A driver can be another object in a Formula 1 race. A driver has a nationality, age, gender, and so on, and he can perform functionalities like driving the car, moving the steering or changing the transmission.\nJust like in this example, in object-oriented programming we will create objects for the corresponding real-world entity.\nIt is important to mention here that object-oriented programming is not a language-dependent concept. It is a general programming concept and most of the modern languages, such as Java, C#, C++, and Python, support object-oriented programming. In this article, we will see a detailed introduction to Object-Oriented Programming in Python, but before that, we will see some of the advantages and disadvantages of object-oriented programming.\nPros and Cons of OOP Following are some of the advantages of object-oriented programming:\n Object-oriented programming fosters reusability. A computer program is written in the form of objects and classes, which can be reused in other projects as well. The modular approach used in object-oriented programming results in highly maintainable code. In object-oriented programming, every class has a specific task. If an error occurs in one part of the code, you can rectify it locally without having to affect other parts of the code. Data encapsulation (which we will study later in the article) adds an extra layer of security to the program developed using the object-oriented approach.  Though object-oriented programming has several advantages as discussed, it has some downsides as well, some of which have been enlisted below:\n Detailed domain knowledge of the software being developed is needed in order to create objects. Not every entity in software is a candidate for being implemented as an object. It can be hard for newbies to identify this fine line. As you add more and more classes to the code, the size and complexity of the program grows exponentially.  In the next section, we will see some of the most important concepts of object-oriented programming.\nAs the name suggests, object-oriented programming is all about objects. However, before an object can be created we need to define the class for the object.\nClass A class in object-oriented programming serves as a blueprint for the object. A class can be considered as a map for the house. You can get an idea of what the house looks like by simply seeing the map. However, a class itself is nothing. For instance, a map is not a house, it only explains how the actual house will look.\nThe relationship between a class and object can be understood by looking at the relationship between a car and an Audi. An Audi is actually a car. However, there is no such thing as a car only. A car is an abstract concept, it is actually implemented in the form of Toyota, Ferrari, Honda, etc.\nThe keyword class is used in order to create a class in Python. The name of the class follows the class keyword, followed by the colon character. The body of the class starts on a new line, indented one tab from the left.\nLet\u0026rsquo;s see how we can create a very basic class in Python. Take a look at the following code:\n# Creates class Car class Car: # create class attributes name = \u0026quot;c200\u0026quot; make = \u0026quot;mercedez\u0026quot; model = 2008 # create class methods def start(self): print (\u0026quot;Engine started\u0026quot;) def stop(self): print (\u0026quot;Engine switched off\u0026quot;)  In the example above, we create a class named Car with three attributes: name, make, and model. The car class also contains two methods: start() and stop().\nObjects Earlier, we said that a class provides a blueprint. However, to actually use the objects and methods of a class, you need to create an object out of that class. There are few class methods and attributes that can be used without an object, which we will see in the later section. For now, just keep in mind that by default, we need to create an object of a class before we can use its methods and attributes.\nAn object is also called an instance; therefore, the process of creating an object of a class is called instantiation. In Python, to create an object of a class we simply need to write the class name followed by opening and closing parenthesis.\nLet\u0026rsquo;s create an object of the Car class that we created in the last section.\n# Creates car_a object of Car class car_a = Car() # Creates car_b object of car class car_b = Car()  In the script above, we created two objects of the car class: car_a and car_b. To check the type of the objects we created, we can use the type method and pass it the name of our object. Execute the following script:\nprint(type(car_b))  In the output, you will see:\n\u0026lt;class '__main__.Car'\u0026gt;  Which says that the type of car_b object is a class Car.\nAt this point we\u0026rsquo;ve created our class and the corresponding objects. Now is the time to access class attributes and call class method using the class object. To do so, you simply have to write the object name, followed by dot operator and the name of the attribute or the method that you want to access or call, respectively. Take a look at the following example:\ncar_b.start()  In the script above, we call the start() method via the car_b object. The output will be as follows:\nEngine started  Similarly, you can access an attribute using the following syntax:\nprint(car_b.model)  In the output, you will see the value of the model attribute, as shown below:\n2008  Attributes In the previous section, we saw how we can create objects of a class and can use those objects to access the attributes of a class.\nIn Python, every object has some default attributes and methods in addition to user-defined attributes. To see all the attributes and methods of an object, the built-in dir() function can be used. Let\u0026rsquo;s try to see all the attributes of the car_b object that we created in the last section. Execute the following script:\ndir(car_b)  In the output, you will see the following attributes:\n['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'make', 'model', 'name', 'start', 'stop']  This built-in function is useful for inspecting all of the attributes and functions of an object, especially when used via Python\u0026rsquo;s REPL.\nClass vs Instance Attributes Attributes can be broadly categorized into two types: Class attributes and Instance attributes. Class attributes are shared by all the objects of a class while instance attributes are the exclusive property of the instance.\nRemember, an instance is just another name for the object. Instance attributes are declared inside any method while class attributes are declared outside of any method. The following example clarifies the difference:\nclass Car: # create class attributes car_count = 0 # create class methods def start(self, name, make, model): print (\u0026quot;Engine started\u0026quot;) self.name = name self.make = make self.model = model Car.car_count += 1  In the script above, we create a class Car with one class attribute car_count and three instance attributes name, make and mode. The class contains one method start() which contains the three instance attributes. The values for the instance attributes are passed as arguments to the start() method. Inside the start method, the car_count attribute is incremented by one.\nIt is important to mention that inside the method, the instance attributes are referred using the self keyword, while class attributes are referred by the class name.\nLet\u0026rsquo;s create an object of the Car class and call the start() method.\ncar_a = Car() car_a.start(\u0026quot;Corrola\u0026quot;, \u0026quot;Toyota\u0026quot;, 2015) print(car_a.name) print(car_a.car_count)  In the above script we print the instance attribute name and class attribute car_count. You will see in the output that the car_count attribute will have a value of 1, as shown below:\nEngine started Corrola 1  Now, let\u0026rsquo;s create another object of the car class and call the start() method.\ncar_b = Car() car_b.start(\u0026quot;City\u0026quot;, \u0026quot;Honda\u0026quot;, 2013) print(car_b.name) print(car_b.car_count)  Now if you print the value of the car_count attribute, you will see 2 in the output. This is because the car_count attribute is a class attribute and hence it is shared between the instances. The car_a object incremented its value to 1, while car_b object incremented it again, hence the final value became 2. The output looks like this:\nEngine started City 2  Methods As we described earlier, in object-oriented programming, the methods are used to implement the functionalities of an object. In the previous section, we created start() and stop() methods for the Car class. Till now, we have been using the objects of a class in order to call the methods. However, there is a type of method that can be called directly using the class name. Such a method is called a static method.\nStatic Methods To declare a static method, you have to specify the @staticmethod descriptor before the name of the method as shown below:\nclass Car: @staticmethod def get_class_details(): print (\u0026quot;This is a car class\u0026quot;) Car.get_class_details()  In the above script, we create a class Car with one static method get_class_details(). Let\u0026rsquo;s call this method using the class name.\nCar.get_class_details()  You can see that we did not need to create an instance of the Car class in order to call the get_class_details() method, rather we simply used the class name. It is important to mention that static methods can only access class attributes in Python.\nReturning Multiple Values from a Method One of the best features of the Python language is the ability of class methods to return multiple values. Take a look at the following example:\nclass Square: @staticmethod def get_squares(a, b): return a*a, b*b print(Square.get_squares(3, 5))  In the above script, we created a class named Square with one static method get_squares(). The method takes two parameters; multiply each parameter with itself and returns both the results using return statement. In the output of the script above, you will see the squares of 3 and 5.\nThe str Method Till now we have been printing attributes using the print() method. Let\u0026rsquo;s see what happens if we print the object of a class.\nTo do so we\u0026rsquo;ll create a simple Car class with one method and try to print the object of the class to the console. Execute the following script:\nclass Car: # create class methods def start(self): print (\u0026quot;Engine started\u0026quot;) car_a = Car() print(car_a)  In the script above we create car_a object of the Car class and print its value on the screen. Basically here we are treating car_a object as a string. The output looks likes this:\n\u0026lt;__main__.Car object at 0x000001CCCF4335C0\u0026gt;  The output shows the memory location where our object is stored. Every Python object has a __str__ method by default. When you use the object as a string, the __str__ method is called, which by default prints the memory location of the object. However, you can provide your own definition for the __str__ method as well. For instance, look at the following example:\n# Creates class Car class Car: # create class methods def __str__(self): return \u0026quot;Car class Object\u0026quot; def start(self): print (\u0026quot;Engine started\u0026quot;) car_a = Car() print(car_a)  In the script above, we override the __str__ method by providing our own custom definition for the method. Now, if you print the car_a object, you will see the message \u0026ldquo;Car class Object\u0026rdquo; on the console. This is the message that we printed inside our custom the __str__ method.\nUsing this method you can create custom and more meaningful descriptions for when an object is printed. You could even display some of the data within the class, like the name of a Person class.\nConstructors A constructor is a special method that is called by default whenever you create an object of a class.\nTo create a constructor, you have to create a method with keyword __init__. Take a look at the following example:\nclass Car: # create class attributes car_count = 0 # create class methods def __init__(self): Car.car_count +=1 print(Car.car_count)  In the script above, we create a Car class with one class attribute car_count. The class contains a constructor which increments the value of car_count and prints the resultant value on screen.\nNow, whenever an object of the Car class will be created the constructor will be called, the value of the car_count will be incremented and displayed on the screen. Let\u0026rsquo;s create a simple object and see what happens:\ncar_a = Car() car_b = Car() car_c = Car()  Subscribe to our Newsletter Get occassional tutorials, guides, and reviews in your inbox. No spam ever. Unsubscribe at any time.\nSubscribe\nIn the output, you will see a value of 1, 2, and 3 printed since with every object the value of car_count variable is incremented and displayed on the screen.\nExcept for the name, the constructor can be used as an ordinary method. You can pass and receive values from a constructor. It is usually used in this way when you want to initialize attribute values upon instantiating the class.\nLocal vs Global Variables We know that there are two types of Python attributes, instance attributes, and class attributes. The attributes of a class are also referred to as variables. Depending on the scope, variables can also be categorized into two types: Local variables and Global variables.\nLocal Variables A local variable in a class is a variable that can only be accessed inside the code block where it is defined. For instance, if you define a variable inside a method, it cannot be accessed anywhere outside that method. Look at the following script:\n# Creates class Car class Car: def start(self): message = \u0026quot;Engine started\u0026quot; return message  In the script above we create a local variable message inside the start() method of the Car class. Now let\u0026rsquo;s create an object of the Car class and try to access the local variable message as shown below:\ncar_a = Car() print(car_a.message)  The above script will return the following error:\nAttributeError: 'Car' object has no attribute 'message'  This is because we cannot access the local variable outside the block in which the local variable is defined.\nGlobal Variable A global variable is defined outside of any code block e.g method, if-statements, etc. A global variable can be accessed anywhere in the class. Take a look at the following example.\n# Creates class Car class Car: message1 = \u0026quot;Engine started\u0026quot; def start(self): message2 = \u0026quot;Car started\u0026quot; return message2 car_a = Car() print(car_a.message1)  In the script above, we created a global variable message1 and printed its value on the screen. In the output, you will see the value of the message1 variable, printed without an error.\nIt is important to mention that there is a difference between class and instance attributes, and local vs global variables. The class and instance attributes differ in the way they are accessed i.e. using class name and using instance name. On the other hand, local vs global variables differ in their scope, or in other words the place where they can be accessed. A local variable can only be accessed inside the method. Though in this article, both the local variable and instance attributes are defined inside the method, local attribute is defined with the self-keyword.\nAccess Modifiers The access modifiers in Python are used to modify the default scope of variables. There are three types of access modifiers in Python: public, private, and protected.\nVariables with the public access modifiers can be accessed anywhere inside or outside the class, the private variables can only be accessed inside the class, while protected variables can be accessed within the same package.\nTo create a private variable, you need to prefix double underscores with the name of the variable. To create a protected variable, you need to prefix a single underscore with the variable name. For public variables, you do not have to add any prefixes at all.\nLet\u0026rsquo;s see public, private, and protected variables in action. Execute the following script:\nclass Car: def __init__(self): print (\u0026quot;Engine started\u0026quot;) self.name = \u0026quot;corolla\u0026quot; self.__make = \u0026quot;toyota\u0026quot; self._model = 1999  In the script above, we create a simple Car class with a constructor and three variables name, make, and model. The name variable is public while the make and model variables have been declared private and protected, respectively.\nLet\u0026rsquo;s create an object of the Car class and try to access the name variable. Execute the following script:\ncar_a = Car() print(car_a.name)  Since name is a public variable, therefore we can access it outside the class. In the output, you will see the value for the name printed on the console.\nNow let\u0026rsquo;s try to print the value of the make variable. Execute the following script:\nprint(car_a.make)  In the output, you will see the following error message:\nAttributeError: 'Car' object has no attribute 'make'  We have covered most of the basic object-oriented programming concepts in the last few sections. Now, let\u0026rsquo;s talk about the pillars of the object-oriented programming: Polymorphism, Inheritance, and Encapsulation, collectively referred to as PIE.\nInheritance Inheritance in object-oriented programming is pretty similar to real-world inheritance where a child inherits some of the characteristics from his parents, in addition to his/her own unique characteristics.\nIn object-oriented programming, inheritance signifies an IS-A relation. For instance, a car is a vehicle. Inheritance is one of the most amazing concepts of object-oriented programming as it fosters code re-usability.\nThe basic idea of inheritance in object-oriented programming is that a class can inherit the characteristics of another class. The class which inherits another class is called the child class or derived class, and the class which is inherited by another class is called parent or base class.\nLet\u0026rsquo;s take a look at a very simple example of inheritance. Execute the following script:\n# Create Class Vehicle class Vehicle: def vehicle_method(self): print(\u0026quot;This is parent Vehicle class method\u0026quot;) # Create Class Car that inherits Vehicle class Car(Vehicle): def car_method(self): print(\u0026quot;This is child Car class method\u0026quot;)  In the script above, we create two classes Vehicle class, and the Car class which inherits the Vehicle class. To inherit a class, you simply have to write the parent class name inside the parenthesis that follows the child class name. The Vehicle class contains a method vehicle_method() and the child class contains a method car_method(). However, since the Car class inherits the Vehicle class, it will also inherit the vehicle_method().\nLet\u0026rsquo;s see this in action. Execute the following script:\ncar_a = Car() car_a.vehicle_method() # Calling parent class method  In the script above, we create an object of the Car class and call the vehicle_method() using that Car class object. You can see that the Car class doesn\u0026rsquo;t have any vehicle_method() but since it has inherited the Vehicle class that contains the vehicle_method(), the car class can also use it. The output looks likes this:\nThis is parent Vehicle class method  In Python, a parent class can have multiple children and similarly, a child class can have multiple parent classes. Let\u0026rsquo;s take a look at the first scenario. Execute the following script:\n# Create Class Vehicle class Vehicle: def vehicle_method(self): print(\u0026quot;This is parent Vehicle class method\u0026quot;) # Create Class Car that inherits Vehicle class Car(Vehicle): def car_method(self): print(\u0026quot;This is child Car class method\u0026quot;) # Create Class Cycle that inherits Vehicle class Cycle(Vehicle): def cycleMethod(self): print(\u0026quot;This is child Cycle class method\u0026quot;)  In the script above the parent Vehicle class is inherited by two child classes Car and Cycle. Both the child classes will have access to the vehicle_method() of the parent class. Execute the following script to see that:\ncar_a = Car() car_a.vehicle_method() # Calling parent class method car_b = Cycle() car_b.vehicle_method() # Calling parent class method  In the output, you will see the output of the vehicle_method() method twice as shown below:\nThis is parent Vehicle class method This is parent Vehicle class method  You can see how a parent class can be inherited by two child classes. In the same way, a child can have multiple parents. Let\u0026rsquo;s take a look at the example:\nclass Camera: def camera_method(self): print(\u0026quot;This is parent Camera class method\u0026quot;) class Radio: def radio_method(self): print(\u0026quot;This is parent Radio class method\u0026quot;) class CellPhone(Camera, Radio): def cell_phone_method(self): print(\u0026quot;This is child CellPhone class method\u0026quot;)  In the script above, we create three classes: Camera, Radio, and CellPhone. The Camera class and the Radio classes are inherited by the CellPhoneclass which means that the CellPhone class will have access to the methods of both Camera and Radio classes. The following script verifies this:\ncell_phone_a = CellPhone() cell_phone_a.camera_method() cell_phone_a.radio_method()  The output looks likes this:\nThis is parent Camera class method This is parent Radio class method  Polymorphism The term polymorphism literally means having multiple forms. In the context of object-oriented programming, polymorphism refers to the ability of an object to behave in multiple ways.\nPolymorphism in programming is implemented via method-overloading and method overriding.\nMethod Overloading Method overloading refers to the property of a method to behave in different ways depending upon the number or types of the parameters. Take a look at a very simple example of method overloading. Execute the following script:\n# Creates class Car class Car: def start(self, a, b=None): if b is not None: print (a + b) else: print (a)  In the script above, if the start() method is called by passing a single argument, the parameter will be printed on the screen. However, if we pass 2 arguments to the start() method, it will add both the arguments and will print the result of the sum.\nLet\u0026rsquo;s try with single argument first:\ncar_a = Car() car_a.start(10)  In the output, you will see 10. Now let\u0026rsquo;s try to pass 2 arguments:\ncar_a.start(10,20)  In the output, you will see 30.\nMethod Overriding Method overriding refers to having a method with the same name in the child class as in the parent class. The definition of the method differs in parent and child classes but the name remains the same. Let\u0026rsquo;s take a simple example method overriding in Python.\n# Create Class Vehicle class Vehicle: def print_details(self): print(\u0026quot;This is parent Vehicle class method\u0026quot;) # Create Class Car that inherits Vehicle class Car(Vehicle): def print_details(self): print(\u0026quot;This is child Car class method\u0026quot;) # Create Class Cycle that inherits Vehicle class Cycle(Vehicle): def print_details(self): print(\u0026quot;This is child Cycle class method\u0026quot;)  In the script above the Car and Cycle classes inherit the Vehicle class. The vehicle class has print_details() method, which is overridden by the child classes. Now if you call the print_details() method, the output will depend upon the object through which the method is being called. Execute the following script to see this concept in action:\ncar_a = Vehicle() car_a. print_details() car_b = Car() car_b.print_details() car_c = Cycle() car_c.print_details()  The output will look like this:\nThis is parent Vehicle class method This is child Car class method This is child Cycle class method  You can see that the output is different, although the print_details() method is being called through derived classes of the same base class. However, since the child classes have overridden the parent class method, the methods behave differently.\nEncapsulation Encapsulation is the third pillar of object-oriented programming. Encapsulation simply refers to data hiding. As a general principle, in object-oriented programming, one class should not have direct access to the data of the other class. Rather, the access should be controlled via class methods.\nTo provide controlled access to class data in Python, the access modifiers and properties are used. We have already seen access modifiers, in this section, we will see properties in action.\nSuppose we want to ensure that the car model should always be between 2000 and 2018. If a user tries to enter a value less than 2000 for the car model, the value is automatically set to 2000 and if the entered value is greater than 2018, it should be set to 2018. If the value is between 2000 and 2018, it should not be changed. We can create a property for the model attribute which implements this logic as follows:\n# Creates class Car class Car: # Creates Car class constructor def __init__(self, model): # initialize instance variables self.model = model # Creates model property @property def model(self): return self.__model # Create property setter @model.setter def model(self, model): if model \u0026lt; 2000: self.__model = 2000 elif model \u0026gt; 2018: self.__model = 2018 else: self.__model = model def getCarModel(self): return \u0026quot;The car model is \u0026quot; + str(self.model) carA = Car(2088) print(carA.getCarModel())  A property has three parts. You have to define the attribute, which is model in the above script. Next, you have to define the property for the attribute using the @property decorator. Finally, you have to create property setter which is @model.setter descriptor in the above script.\nNow, if you try to enter a value greater than 2018 for the model attribute, you will see that the value is set to 2018. Let\u0026rsquo;s test this. Execute the following script:\ncar_a = Car(2088) print(car_a.get_car_model())  Here we are passing 2088 as the value for model, however if you print the value for the model attribute via get_car_model() function, you will see 2018 in the output.\nConclusion In this article, we studied some of the most important object-oriented programming concepts. Object-oriented programming is one of the most famous and commonly used programming paradigms. The importance of object-oriented programming is reflected by the fact that most of the modern programming languages are either fully object-oriented or support object-oriented programming.\nRef : https://stackabuse.com/object-oriented-programming-in-python/\n"});index.add({'id':97,'href':'/library/tutorials/docs/articles/python/python-optimizations/','title':"Optimizations",'content':" Python Optimizations Peephole is a way Python optimizes certain things of your program at compile time by either pre-calculating constant expressions or transforming certain data structures. Constant Expressions Optimizing constant expressions is really simple. What Python does is basically pre-calculate constants. Suppose that along your program you have the following multiplication for some reason,\nsecondsInADay = 60*60*24  What python will do is pre-calculate that multiplication and will replace it for 86400 . You might be wondering why not just write directly 86400 in code, the answer is clarity. On the expression above you can see that in order to calculate how many seconds a day has, you have to multiply 60 seconds time 60 minutes of an hour times 24 hours of a day. This way your code might look clearer. Python won’t make that calculation each time that multiplication appears, it will just pre-calculate it and replace it for the final value. Short sequences also get pre-calculated. Imagine you have this code,\nmyTuple = (2, 4)*5 # -\u0026gt; (2, 4, 2, 4, 2, 4, 2, 4, 2, 4) myString = \u0026quot;qwerty \u0026quot;*2 # -\u0026gt; \u0026quot;qwerty qwerty \u0026quot;  As you can see on the code above we have two variables, the first one is a tuple multiplied by 5 and the second one is a short string multiplied by 2, this short sequences will be pre-calculated and Python will replace the original expression with the value on the comments. It is worth to mention that Python has to balance between storage and computation, if it pre-calculates long sequences the program might be faster but it will end up using a lot of memory. In order to see that this is happening you can simply open a Python console and write the following code,\ndef my_func(): a = 60*60*24 myString = (\u0026quot;querty \u0026quot;) * 2 myTupple = (2, 4) *5 myString = (\u0026quot;This is a sequence with a lot of characters\u0026quot;) * 100  Once this function is declared you can write the following code to access all the constants declared on the scope of that funcion,\nmy_func.__code__.co_consts  The output should be the following,\nmy_func.__code__.co_consts(None, 86400, 'querty querty ', (2, 4, 2, 4, 2, 4, 2, 4, 2, 4), 'This is a sequence with a lot of characters', 100)  As you can see, on the output above Python has already pre-calculated the constant values and short sequences, instead of having 60*60*24 the function has already the constant value 86400 , the same thing happens with the tuple and the short string, but as you can see the long sequence didn’t get pre-calculated and instead we get two different constants, \u0026lsquo;This is a sequence with a lot of characters\u0026rsquo; and 100 . As mentioned above, Python has to balance between storage and computation. Membership Tests: Replacing mutable data structures for inmutable data structures What Python does here is basically transforming mutable data structures to its inmutable version. Lists get transformed into tuples and sets to frozensets. For instance,\ndef my_func(element): if element in [\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;]: print(element)  The code above will be transformed to this,\ndef my_func(element): if element in (\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;): print(element)  This is done just because accessing to the inmutable version of a data structure is faster than accessing the mutable one. You can check this doing the same thing as before running the follwing code,\nmy_func.__code__.co_consts  The output should be the following,\nmy_func.__code__.co_consts  (None, ('a', 'b', 'c'))  As you can see, the function has a constant value which is the inmutable version (a tuple) of the declared list. Finally doing the same as before but with a set you will see that it will be transformed into a frozenset,\ndef my_func(element): if element in {\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;}: print(element) my_func.__code__.co_consts  (None, frozenset({'a', 'b', 'c'}))  If you are interested on Python optimizations you could check out my article about Python optimizations (Intering).\n Written with StackEdit.\n "});index.add({'id':98,'href':'/library/tutorials/docs/articles/python/overloading-functions/','title':"Overloading Functions and Operators",'content':" Overloading Functions and Operators in Python What is Overloading? Overloading, in the context of programming, refers to the ability of a function or an operator to behave in different ways depending on the parameters that are passed to the function, or the operands that the operator acts on. In this article, we will see how we can perform function overloading and operator overloading in Python.\nOverloading a method fosters reusability. For instance, instead of writing multiple methods that differ only slightly, we can write one method and overload it. Overloading also improves code clarity and eliminates complexity.\nOverloading is a very useful concept. However, it has a number of disadvantages associated with it. Overloading can cause confusion when used across inheritance boundaries. When used excessively, it becomes cumbersome to manage overloaded functions.\nIn the remaining section of this article, we will be discussing the function and operator overloading in detail.\nFunction Overloading in Python Depending on how the function has been defined, we can call it with zero, one, two, or even many parameters. This is referred to as \u0026ldquo;function overloading\u0026rdquo;.\nFunction overloading is further divided into two types: overloading built-in functions and overloading custom functions. We will look at both the types in the upcoming sections.\nOverloading Built-in Functions It is possible for us to change the default behavior of Python\u0026rsquo;s built-in functions. We only have to define the corresponding special method in our class.\nLet us demonstrate this using Python\u0026rsquo;s len() function on our Purchase class:\nclass Purchase: def __init__(self, basket, buyer): self.basket = list(basket) self.buyer = buyer def __len__(self): return len(self.basket) purchase = Purchase(['pen', 'book', 'pencil'], 'Python') print(len(purchase))  Output:\n3  To change how the len() function behaves, we defined a special method named _len_() in our class. Anytime we pass an object of our class to len(), the result will be obtained by calling our custom defined function, that is, _len_().\nThe output shows that we are able to use len() to get the length of the basket.\nIf we call len() on the object without the __len__() function overloaded, we will get a TypeError as shown below:\nclass Purchase: def __init__(self, basket, buyer): self.basket = list(basket) self.buyer = buyer purchase = Purchase(['pen', 'book', 'pencil'], 'Python') print(len(purchase))  Output:\nTraceback (most recent call last): File \u0026quot;C:/Users/admin/func.py\u0026quot;, line 8, in \u0026lt;module\u0026gt; print(len(purchase)) TypeError: object of type 'Purchase' has no len()  Note: Python expects the len() function to return an integer, hence this should be put into consideration when overloading the function. If your overloaded function is expected to return anything else other than an integer, you will get a TypeError.\nWe can change the behavior of the len() method in the above example from within the definition of its implementation, that is, __len__(). Instead of returning the length of the basket, let us make it return something else:\nclass Purchase: def __init__(self, basket, buyer): self.basket = list(basket) self.buyer = buyer def __len__(self): return 10; purchase = Purchase(['pen', 'book', 'pencil'], 'Python') print(len(purchase))  Output:\n10  Instead of returning the length of the basket, it now returns the value that we have specified.\nOverloading User-Defined Functions To overload a user-defined function in Python, we need to write the function logic in such a way that depending upon the parameters passed, a different piece of code executes inside the function. Take a look at the following example:\nclass Student: def hello(self, name=None): if name is not None: print('Hey ' + name) else: print('Hey ') # Creating a class instance std = Student() # Call the method std.hello() # Call the method and pass a parameter std.hello('Nicholas')  Output:\nHey Hey Nicholas  We have created the class Student with one function named hello(). The class takes the parameter name which has been set to None. This means the method can be called with or without a parameter.\nWe have created an instance of the class which has been used to call the function twice, first with zero parameters and secondly with one parameter. We have implemented function overloading since there are two ways to call the function.\nNow we know how function overloading works, the next section focusses on operator overloading.\nOperator Overloading Python allows us to change the default behavior of an operator depending on the operands that we use. This practice is referred to as \u0026ldquo;operator overloading\u0026rdquo;.\nThe functionality of Python operators depends on built-in classes. However, the same operator will behave differently when applied to different types. A good example is the \u0026ldquo;+\u0026rdquo; operator. This operator will perform an arithmetic operation when applied on two numbers, will concatenate two strings, and will merge two lists.\nExamples of Operator Overloading To see Python\u0026rsquo;s operator overloading in action, launch the Python terminal and run the following commands:\n\u0026gt;\u0026gt;\u0026gt; 4 + 4 8 \u0026gt;\u0026gt;\u0026gt; \u0026quot;Py\u0026quot; + \u0026quot;thon\u0026quot; 'Python'  In the first command, we have used the \u0026ldquo;+\u0026rdquo; operator to add two numbers. In the second command, we used the same operator to concatenate two strings.\nIn this case, the \u0026ldquo;+\u0026rdquo; operator has two interpretations. When used to add numbers, it is referred to as an \u0026ldquo;addition operator\u0026rdquo;. When used to add strings, it is referred to as \u0026ldquo;concatenation operator\u0026rdquo;. In short, we can say that the \u0026ldquo;+\u0026rdquo; operator has been overloaded for int and str classes.\nTo achieve operator overloading, we define a special method in a class definition. The name of the method should begin and end with a double underscore (__). The + operator is overloaded using a special method named __add__(). This method is implemented by both the int and str classes.\nConsider the following expression:\nx + y  Python will interpret the expression as x.__add__(y). The version of __add__() that is called will depend on the types of x and y. For example:\n\u0026gt;\u0026gt;\u0026gt; x, y = 5, 7 \u0026gt;\u0026gt;\u0026gt; x + y 12 \u0026gt;\u0026gt;\u0026gt; x.__add__(y) 12 \u0026gt;\u0026gt;\u0026gt;  The above example demonstrates how to use the + operator as well as its special method.\nThe following example demonstrates how to overload various operators in Python:\nimport math class Point: def __init__(self, xCoord=0, yCoord=0): self.__xCoord = xCoord self.__yCoord = yCoord # get x coordinate def get_xCoord(self): return self.__xCoord # set x coordinate def set_xCoord(self, xCoord): self.__xCoord = xCoord # get y coordinate def get_yCoord(self): return self.__yCoord # set y coordinate def set_yCoord(self, yCoord): self.__yCoord = yCoord # get current position def get_position(self): return self.__xCoord, self.__yCoord # change x \u0026amp; y coordinates by p \u0026amp; q def move(self, p, q): self.__xCoord += p self.__yCoord += q # overload + operator def __add__(self, point_ov): return Point(self.__xCoord + point_ov.__xCoord, self.__yCoord + point_ov.__yCoord) # overload - operator def __sub__(self, point_ov): return Point(self.__xCoord - point_ov.__xCoord, self.__yCoord - point_ov.__yCoord) # overload \u0026lt; (less than) operator def __lt__(self, point_ov): return math.sqrt(self.__xCoord ** 2 + self.__yCoord ** 2) \u0026lt; math.sqrt(point_ov.__xCoord ** 2 + point_ov.__yCoord ** 2) # overload \u0026gt; (greater than) operator def __gt__(self, point_ov): return math.sqrt(self.__xCoord ** 2 + self.__yCoord ** 2) \u0026gt; math.sqrt(point_ov.__xCoord ** 2 + point_ov.__yCoord ** 2) # overload \u0026lt;= (less than or equal to) operator def __le__(self, point_ov): return math.sqrt(self.__xCoord ** 2 + self.__yCoord ** 2) \u0026lt;= math.sqrt(point_ov.__xCoord ** 2 + point_ov.__yCoord ** 2) # overload \u0026gt;= (greater than or equal to) operator def __ge__(self, point_ov): return math.sqrt(self.__xCoord ** 2 + self.__yCoord ** 2) \u0026gt;= math.sqrt(point_ov.__xCoord ** 2 + point_ov.__yCoord ** 2) # overload == (equal to) operator def __eq__(self, point_ov): return math.sqrt(self.__xCoord ** 2 + self.__yCoord ** 2) == math.sqrt(point_ov.__xCoord ** 2 + point_ov.__yCoord ** 2) point1 = Point(2, 4) point2 = Point(12, 8) print(\u0026quot;point1 \u0026lt; point2:\u0026quot;, point1 \u0026lt; point2) print(\u0026quot;point1 \u0026gt; point2:\u0026quot;, point1 \u0026gt; point2) print(\u0026quot;point1 \u0026lt;= point2:\u0026quot;, point1 \u0026lt;= point2) print(\u0026quot;point1 \u0026gt;= point2:\u0026quot;, point1 \u0026gt;= point2) print(\u0026quot;point1 == point2:\u0026quot;, point1 == point2)```  Output:\npoint1 \u0026lt; point2: True point1 \u0026gt; point2: False point1 \u0026lt;= point2: True point1 \u0026gt;= point2: False point1 == point2: False  We have two private attributes in the Point class, namely, __xCoord and __yCoord representing cartesian plain coordinates named xCoord and yCoord. We have defined the setter and getter methods for these attributes. The get_position() method helps us get the current position while the move() method helps us change the coordinates.\nConsider the following line extracted from the code:\ndef __add__(self, point_ov):  The line helps us overload the + operator for our class. The __add__() method should create a new Point object by adding the individual coordinates of a single Point object to another Point object. It finally returns the newly created object to the caller. This helps us write expressions such as:\npoint3 = point1 + point2  Python will interpret the above as point3 = point1.__add__(point2). It will then call the __add__() method to add two Point objects. The result will be assigned to \u0026ldquo;point3\u0026rdquo;.\nNote that once the __add__() method is called, the value of point1 will be assigned to self parameter while the value of point2 will be assigned to point_ovparameter. All the other special methods will work in a similar way.\nOperators to Overload The following table shows some of the more commonly overloaded mathematical operators, and the class method to overload:\n   Operator Method     + __add__(self, other)   - __sub__(self, other)   * __mul__(self, other)   / __truediv__(self, other)   % __mod__(self, other)   \u0026lt; __lt__(self, other)   \u0026lt;= __le__(self, other)   == __eq__(self, other)   != __ne__(self, other)   \u0026gt; __gt__(self, other)   \u0026gt;= __ge__(self, other)    Conclusion Python supports both function and operator overloading. In function overloading, we can use the same name for many Python functions but with the different number or types of parameters. With operator overloading, we are able to change the meaning of a Python operator within the scope of a class.\nReference : https://stackabuse.com/overloading-functions-and-operators-in-python/\n"});index.add({'id':99,'href':'/library/tutorials/docs/articles/data-science/pandas/cheatsheet-pandas/','title':"Pandas Cheatsheet",'content':" Cheatsheet วิธีใช้ และเทคนิคใน Pandas (Python) ฉบับสมบูรณ์ Pandas คืออะไร? Pandas เป็น Library ใน Python ที่ทำให้เราเล่นกับข้อมูลได้ง่ายขึ้น เหมาะมากสำหรับทำ Data Cleaning / Wrangling ครับผม\nวิธีการใช้งาน Pandas คือ โหลดไฟล์ข้อมูล เช่น CSV เข้าไป แล้วเราจะได้ข้อมูลในรูปแบบตาราง (DataFrame) ที่แบ่งข้อมูลตามแถวและคอลัมน์ หรือเหมือน Excel ที่เราใช้กันนั่นเอง\n\nตัวอย่าง DataFrame ของ Pandas เป็นตารางเหมือน Excel เลยครับ\nป.ล. Pandas ไม่เกี่ยวกับหมีแพนด้านะฮะ จริง ๆ แล้วมาจากคำว่า PANel DAta ซึ่งหมายถึงข้อมูลที่มีหลายมิตินั่นเอง\nเทคนิคการใช้ Pandas อย่างที่แอดมินเคยเล่า ว่าการทำ Data Wrangling เป็นงานที่ค่อนข้างถึกครับ วันนี้เลยรวบรวมโค้ดต่าง ๆ ในการใช้ Pandas มาให้ ซึ่งน่าจะครอบคลุมการใช้งานประมาณ 80 – 90% แล้วครับผม\nโค้ดบางส่วนมาจากคลาส Data Wrangling ที่แอดมินเรียน และจากเว็บไซต์ MyCheatSheet ครับ\nวิธีเช็ค Version Pandas โค้ดนี้เหมือนไม่สำคัญ แต่จริง ๆ แล้วสำคัญมากเวลาเราอ่าน Documentation ครับ เพราะถ้าเกิดมีอะไรพัง เราจะเทียบได้ว่า Pandas ของเราเป็นเวอร์ชั่นตามใน Documentation มั้ย\nprint (\u0026quot;Pandas version\u0026quot;,pandas.__version__)  วิธีการโหลดไฟล์ CSV (Import) จุดเริ่มต้นของการทำ Data Exploration \u0026amp; Analysis ใน Pandas ก็คือการโหลดไฟล์ข้อมูลแบบ CSV มาใช้งานนั่นเองครับ\nเราสามารถใช้คำสั่ง .head หรือ .tail เพื่อดูข้อมูลแถวบนสุด หรือแถวล่างสุดได้\n# Read DF csvdf = pd.read_csv('data.csv') # Sometimes reading CSV for Excel need encoding csvdf = pd.read_csv('data.csv',encoding = \u0026quot;ISO-8859-1\u0026quot;) # Print head and tail csvdf.head() csvdf.tail()  วิธีสุ่มข้อมูลสำหรับเช็ค (Sample) ปกติเราเช็คข้อมูลว่าถูกต้องมั้ยด้วย head กับ tail ซึ่งเป็นการเช็คจากด้านบนหรือด้านล่าง อีกวิธีที่น่าสนใจ คือ เช็คแบบสุ่มข้อมูลขึ้นมานั่นเองครับ ทำได้ง่าย ๆ โดยใช้\ncsvdf.sample()  วิธีเช็คข้อมูลหาความผิดปกติใน DataFrame เบื้องต้น หลังจากโหลดข้อมูลมาแล้ว เราอยากรู้ว่าข้อมูลมีกี่แถว, Missing value เท่าไหร่, แต่ละคอลัมน์เป็น Data Type อะไรบ้าง ก็รันคำสั่งนี้ได้เลย มีประโยชน์มากครับ\ndf.info()  df.info() # จะแสดงสรุปข้อมูลมาให้  นอกจากนั้นยังมีคำสั่ง df.dtypes (ไม่มีวงเล็บ) สำหรับดู Data Type แต่ละคอลัมน์อย่างเดียว\nวิธีแปลงประเภทข้อมูล (Data Type) ใน Data Frame บางครั้งประเภทข้อมูลของคอลัมน์เป็น String แต่เราต้องการ Integer หรือเราต้องการ Date เราสามารถแปลงข้อมูลได้ง่าย ๆ ดังนี้เลยครับ\ndf['hour'] = pd.to_numeric(df['hour']) # แปลงเป็น Numeric df['hour'] = df['hour'].astype('int') # อีกวิธีในการแปลงค่า สามารถใช้วิธีนี้แปลงเป็น float ได้  วิธีเช็ค Summary ของแต่ละคอลัมน์ (count, min, max, mean) ถ้าเราอยากรู้ Distribution คร่าว ๆ ของแต่ละคอลัมน์ว่าเป็นอย่างไร สามารถใช้คำสั่ง describe() ได้\ndf.describe()  วิธีเช็ค Summary (count, min, max, mean) แบบแยกกลุ่ม บางครั้งเราไม่ได้ต้องการรู้ Summary ของทั้งคอลัมน์ แต่อยากให้แยกตามแต่ละค่าในคอลัมน์นั้น ๆ ครับ ซึ่งมีประโยชน์มากเวลาเราทำ Data Analysis แล้วอยากรู้ว่าบางกลุ่มมีอะไรผิดปกติหรือเปล่า\ntest = df.groupby(['Gender']) test.describe()  วิธีสร้าง DataFrame ใหม่ วิธีสร้างแบบง่ายที่สุด ถ้าต้องการข้อมูลหลายรูปแบบ เราสามารถใช้ Dictionary แบบนี้เลยครับ\ndataframe = pandas.DataFrame({ 'C1': pandas.date_range('20170101', periods=4), 'C2' : [10,20,30,40], 'C3': pandas.Categorical(['A','B','C','D']), 'C4': 1})  แต่ถ้าเราต้องการแค่เป็นแบบตัวเลขทั่วไป ใช้ Numpy แบบนี้ได้เลย\narray = numpy.array([(1,2,3), (4,5,6),(7,8,9)]) dataframe = pandas.DataFrame(array,columns=['C1','C2','C3'])  วิธีเลือกหลายคอลัมน์จาก DataFrame ปกติถ้าเราต้องการเลือกแค่ 1 Column ก็เขียนแบบนี้ได้เลย\ndf['C1']  แต่ถ้าต้องการเลือกหลายคอลัมน์ ให้ทำแบบนี้\ndf[['C1','C2']]  วิธีเลือกคอลัมน์ตามเงื่อนไขที่ต้องการ บางทีเราอยาก Filter เฉพาะคอลัมน์ที่มีค่าตามที่เราต้องการโดยใช้ .loc ได้ โดยสามารถเลือก Filter แบบ .all() (ทุกค่าในคอลัมน์ต้องตรงตามเงื่อนไข) หรือ .any() (บางค่าในคอลัมน์ต้องตรงตามเงื่อนไข)\ndataframe2 = dataframe.loc[:,(dataframe\u0026gt;50).any()] dataframe3 = dataframe.loc[:,(dataframe\u0026gt;50).all()]  เราสามารถใช้หาคอลัมน์ที่มี Missing Values หรือหาคอลัมน์ที่ไม่มี Missing Values เลยก็ได้\ndataframe2 = dataframe.loc[:,dataframe.isnull().any()] dataframe3 = dataframe.loc[:,dataframe.notnull().all()]  วิธีเลือกแถวตามเงื่อนไขที่ต้องการ dataframe[dataframe['C1']\u0026gt;50] # เงื่อนไขแบบง่าย ๆ dataframe2 = dataframe.loc[dataframe.C1.isin([1,2,3])] # เงื่อนไขแบบซับซ้อน  ถ้ามีหลายเงื่อนไขเราสามารถใช้ \u0026amp; (and) หรือ | (or) ได้\ndataframe[(dataframe['C1']\u0026gt;50) \u0026amp; ((dataframe['C2']\u0026lt;25) | (dataframe['C2']\u0026gt;75))]  หรือใช้ Query เป็นเงื่อนไขได้ด้วย มีประโยชน์มากเวลาเรามีเงื่อนไขแปลก ๆ ไม่ต้องเขียนลูปขึ้นมาเองเลยครับ\ndataframe2 = dataframe.query('C1 \u0026gt; C2')  วิธีเพิ่มคอลัมน์ใหม่ สามารถเพิ่มคอลัมน์ใหม่ได้ 2 แบบ คือ\n เพิ่มโดยอิงจากคอลัมน์เดิม (เช่น เอาคอลัมน์เดิม + 10 หรือ เอาคอลัมน์ A – คอลัมน์ B มีประโยชน์มากตอนทำ Feature Engineering) เพิ่มคอลัมน์โดยตั้งค่า Fix ไปเลยสำหรับทุกแถว ส่วนใหญ่จะใช้วิธีนี้เวลาเราอยากได้ค่าอะไรแปลก ๆ ที่ต้องเขียนลูปเพื่อใส่ค่า ก็สร้างคอลัมน์แบบ Fix ค่าก่อน แล้วต่อด้วยลูป\ndf['new'] = dataframe['old'] + 10 # use old values df['new2'] = 5 # apply the same value  การสลับ Row \u0026lt;-\u0026gt; Column (Transpose)  ถ้าเราต้องการ Transpose (อารมณ์เหมือน Vector) เราสามารถใช้คำสั่งนี้ได้เลย\ndataframe.T  การต่อ DataFrame การต่อ Data Frame คือการเอา Data Set 2 ชุดมาต่อกันในแถวตั้งหรือแนวนอน สำหรับการต่อแบบปะติดไปเลย\nมี 2 คำสั่งที่เหมือนกัน คือ concat กับ append แต่ให้ใช้ concat ไปเลย เพราะ append เป็นคำสั่งที่ไม่ Memory Efficient\npd.concat([df1,df2], axis=1) # รวมกัน 2 คอลัมน์ (axis = 0 คือแถว, axis = 1 คือคอลัมน์) pd.concat([df1,df2,df3)] # รวมมากกว่า 2 คอลัมน์ก็ได้ pd.concat(…, ignore_index=True) # รวมเสร็จแล้ว reset index ให้ด้วย ควรใช้ ไม่งั้นจะเจอ row ID ซ้ำกันตอนรวมร่าง pd.concat(…, join='inner') # รวมร่างเฉพาะคอลัมน์ที่ df1 กับ df2 มีทั้งคู่ pd.concat(…, keys=['source1', 'source2']) # เพิ่มคอลัมน์เข้าไปด้วยเพื่อระบุว่า Row แต่ละอันมาจาก Data Frame อันไหน pd.concat(…, join_axes=[df2.index]) # เลือกรวมร่างเฉพาะ row index ที่เรากำหนดได้  การต่อ DataFrame แบบ Join ถ้าต้องการต่อ DataFrame แบบ Advance หน่อย เราก็สามารถ Join DataFrame ได้เหมือน Join Table ใครเขียน SQL มาก่อนน่าจะถนัดเลย\npd.merge(df1, df2, left_on=\u0026quot;col1\u0026quot;, right_on=\u0026quot;col2\u0026quot;, how=\u0026quot;inner\u0026quot;)  เราสามารถเปลี่ยนตรง how=”inner” เป็น “outer”, “left”, “right” เพื่อเปลี่ยนเป็น Outer Join, Left Join, Right Join ได้อีกด้วย\nการหาค่า Mean, Sum, Max (Aggregate) แบบทั้ง DataFrame Pandas สามารถสั่ง Aggregate เพื่อหาค่า Mean, Sum, และ Max ได้เลย เหมาะมากเวลาเราต้องการรวบข้อมูลก่อนเอาไป Visualize หรือต้องการทำ Feature Engineering ก็ได้\nnewdf = df.agg(['sum', 'max','mean'])  การ Aggregate แบบตามกลุ่มที่ต้องการ บางทีเราอยาก Aggregate ข้อมูลตามการจัดกลุ่มในคอลัมน์อื่น เช่น เราอยากได้รายจ่ายทั้งหมดของแต่ละคน (ต้อง aggregate sum ของคอลัมน์รายจ่าย โดยแบ่งกลุ่มตามคอลัมน์ User ID) ใช้แบบนี้\naggregate = dataframe.groupby('C1').sum()  การรัน Function เดียวกันทุกแถว หรือทุกคอลัมน์ เวลาเราอยากรันคำสั่งอะไรสักอย่างสำหรับทุกแถว หรือทุกคอลัมน์ เราสามารถเขียนได้แบบนี้\n# sum for columns sum_columns = dataframe[['C1','C2']].apply(sum,axis=0) # sum for rows sum_rows = dataframe[['C1','C2']].apply(sum,axis=1)  เหมือนกับฟังก์ชั่น apply() ใน R นั่นเอง\nรันคำสั่งที่เขียนเองกับทุกแถวใน 1 คอลัมน์ ถ้าต้องการรันคำสั่ง (Function) ที่เขียนเอง สำหรับทุกแถวในคอลัมน์อันใดอันหนึ่ง ใช้แบบนี้ได้\ndataframe['C1'] = dataframe['C1'].map(lambda x: x-100)  รันคำสั่งที่เขียนเองกับทุกค่า ถ้าต้องการรันคำสั่งที่เขียนเองกับทุกค่าใน DataFrame ใช้โค้ดนี้\nfunction_result = dataframe.applymap(lambda x: x*10)  หรือใช้ transform ก็ได้\nnew_dataframe = dataframe.transform(lambda x: x*100)  คำนวณ Correlation \u0026amp; Covariance เวลาเราอยากรู้ว่าค่าต่าง ๆ ใน Data Set เรา Correlate กันมั้ย\ndataframe.corr() # Correlation dataframe.cov() # Covariance  แต่ค่าที่ออกมาเป็นตัวเลขอาจจะดูยากนิดนึง เราสามารถพลอตสวย ๆ ด้วย Seaborn ได้ครับ สามารถใช้โค้ดด้านล่างนี้ได้เลย\nimport seaborn as sns corr = modeldf.corr() # Set up the matplotlib figure f, ax = plt.subplots(figsize=(15, 8)) # Generate a custom diverging colormap cmap = sns.diverging_palette(10, 10, as_cmap=True) # Draw the heatmap with the mask and correct aspect ratio sns.heatmap(corr, annot=True)  Correlation Plot สวย ๆ ด้วย Seaborn\nคำนวณ Cross Tabulation Cross Tabulation มีประโยชน์มากเวลาเราอยากรู้ว่ามี Data ที่ตรงกับกรุ๊ป A ของคอลัมน์ 1 และกรุ๊ป B ของคอลัมน์ 2 เท่าไหร่ เช่น มีนักเรียนผู้ชาย (คอลัมน์ gender) กี่คนในมัธยมปลาย (คอลัมน์ education) แบบนี้เป็นต้น\nหรือถ้าใครใช้ PivotTable ใน Excel มาก่อน ก็เหมือนกันเลยครับ\naggregate = pandas.crosstab(dataframe.C1, dataframe.C2)  วิธีหาค่า Unique ในแต่ละคอลัมน์ คำสั่งนี้มีประโยชน์มาก เอาไว้ใช้เช็คว่าแต่ละคอลัมน์มีค่าแปลก ๆ มั้ย\nตัวอย่างการใช้งานก็คือ เราอยากรู้ว่า มีบ้านไหนที่มีจำนวนห้องนอนแปลก ๆ มั้ย (เช่น 50 ห้องนอน หรือ -5 ห้องนอน) ก็หาค่า unique จากคอลัมน์ “bedrooms”\ndataframe['C1'].unique()  วิธีเช็คว่ามีแถวไหนข้อมูลซ้ำมั้ย (Duplicated) อันนี้มีประโยชน์มาก เอาไว้ใช้เช็คว่ามีข้อมูลแปลก ๆ มั้ย เช่น ทุกคอลัมน์ซ้ำกันหมด (อันนี้มีโอกาสว่าเป็นข้อมูลซ้ำ อาจจะต้องลบออก) หรือซ้ำกันบางคอลัมน์ (อันนี้ต้องเช็คอีกทีว่าคืออะไร)\ndataframe.duplicated() # หาอันที่เหมือนกันทุกคอลัมน์ dataframe.duplicated('C1') # หาอันที่ซ้ำกันเฉพาะคอลัมน์ C1 dataframe.duplicated(['C1', 'C2']) # หาอันที่ซ้ำกันเฉพาะคอลัมน์ C1 และ C2  ปกติแล้วถ้ามีไอเทมซ้ำ คำสั่งนี้จะไม่แสดงไอเทมแรกในกลุ่มที่ซ้ำ (เช่น ถ้า C1=5 มี 2 แถว มันจะแสดงเฉพาะแถวที่ 2) เราสามารถใส่ Argument keep=False เข้าไปเพื่อบังคับให้มันแสดงทุกแถวได้\nนอกจากนั้นเรายังสามารถนับจำนวนแถวที่ Duplicate และลบทิ้งได้ด้วย\nวิธีการนับจำนวน Duplicate len(df[ df.duplicated(['A', 'B', 'C'], keep = False) ])  วิธีการลบ Duplicate เอาไว้ใช้ตอนเราเจอว่าทุกคอลัมน์ซ้ำกันหมดเลย ซึ่งเป็นเคสที่บอกว่าข้อมูลน่าจะซ้ำ ลบออกได้ (ขึ้นอยู่กับข้อมูลด้วยนะครับ บางข้อมูลอาจจะไม่ได้แปลว่าซ้ำแล้วลบได้):\n# Remove the duplicates df.drop_duplicates(['A', 'B', 'C'], inplace=True) # Reset dataframe index after drop_duplicates. df.reset_index(drop=True, inplace=True) len(df)  สำหรับโค้ดข้างบน จะเห็นว่าเราต้อง reset index หลังลบ duplicate ด้วยนะครับ\nวิธีการลบแถว และลบคอลัมน์ ลบคอลัมน์สามารถทำได้แบบนี้\ndataframe = dataframe.drop('C1', axis=1) df.drop(['C1'], axis=1, inplace=True) # แบบนี้ก็ได้ df.drop(['C1', 'C2', 'C3'], 1, inplace=True) # ลบทีละหลายคอลัมน์ก็ได้  ส่วนการลบแถวจะลำบากหน่อย เพราะต้องใส่ Row Index (เลขที่อยู่ซ้ายสุดเวลาเราปรินท์ DataFrame)\ndataframe = dataframe.drop(5, axis=0) dataframe.reset_index(drop=True) # Reset index  ลบแถวแล้วอย่าลืมเช็คด้วยว่าที่ลบไปถูกต้องมั้ย และหลังจากลบแถวต้อง Reset Index ด้วย\nวิธีการลบแถวที่มี Missing Value ข้อควรระวัง: การที่อยู่ ๆ เราลบแถวที่มี Missing Value ทิ้งไปเลยอาจจะไม่ใช่วิธีที่ดีที่สุดในการทำ Data Analysis เสมอไปนะครับ บางเคสการ Impute (คำนวณหาค่าไปใส่) จะดีกว่าครับ\ndataframe2 = dataframe.dropna(axis=0)  วิธีแทนค่า Missing Value ด้วยค่าเฉลี่ย (Mean Imputation) วิธีหนึ่งในการแทนค่าที่หายไป คือการทำสิ่งที่เรียกว่า Mean Imputation หรือหาค่าเฉลี่ยของคอลัมน์นั้น แล้วเอามาแทนค่าที่หายไปนั่นเองครับ\nข้อดีของการทำ Mean Imputation คือ สามารถทำได้ง่าย แต่ก็ต้องระวังเรื่องข้อเสีย เช่น ทำแบบนี้จะเป็นการไม่สนใจความสัมพันธ์ระหว่างตัวแปร ทำให้เกิด Bias สูง ควรใช้เฉพาะเวลา Missing Value ไม่เยอะเท่านั้นครับ\nสามารถรันโค้ดด้านล่างเพื่อทำ Mean Imputation ได้ง่าย ๆ เลย\nimport numpy as np meanAge = np.mean(df.Age) # Get mean value df.Age = df.Age.fillna(meanAge) # Fill missing values with mean  การลูปข้อมูลแต่ละคอลัมน์ และแต่ละแถว การลูปมีประโยชน์มากถ้าเราต้องการเขียนฟังก์ชั่นแปลก ๆ ใช้เองที่ Pandas ไม่รองรับ (หรืออาจจะรองรับแต่เราหาไม่เจอ เขียนเองง่ายกว่า) สามารถลูปได้ทั้งแต่ละคอลัมน์ และแต่ละแถว\nfor col_idx,data in dataframe.iteritems(): print (\u0026quot;column:\u0026quot;,col_idx) print (\u0026quot;column data:\u0026quot;) print (data,\u0026quot;\\n\u0026quot;)  การลูปข้อมูลแต่ละแถว\nfor col_idx,data in dataframe.iterrows(): print (\u0026quot;row:\u0026quot;,col_idx) print (\u0026quot;row data:\u0026quot;) print (data,\u0026quot;\\n\u0026quot;)  วิธีเปลี่ยน DataFrame จากแบบ Wide เป็น Long (Melt) การ Melt Data มีประโยชน์มากเวลาเราต้องการเอาข้อมูลไปพลอต Data Visualization หรือเราต้องการ Aggregate ครับ\ndataframe2 = dataframe.melt()  วิธีการเปลี่ยนชื่อคอลัมน์ (Rename) บางทีเราต้องการเปลี่ยนชื่อเพื่อให้สั้นลง ให้พิมพ์สะดวกขึ้น สามารถทำได้ดังนี้\ndataframe.rename(columns={'old':'new'},inplace=True)  วิธีการใส่คำนำหน้าคอลัมน์ (Prefix) อันนี้มีประโยชน์มากตอนเรามีข้อมูลหลาย ๆ ชุด และต้องการ Merge โดยอยากให้ชื่อคอลัมน์ไม่ซ้ำกัน\nthisdata = thisdata.add_prefix('data_')  วิธีการแทนค่าใน DataFrame เหมาะมากเวลาต้องการแก้ Typo Error เช่น เราอยากได้ค่า Bangkok แต่เรารู้ว่ามีคนเขียนเป็น BKK อะไรแบบนี้ (รันคำสั่ง .unique เพื่อดูก่อน)\nเราสามารถ Replace ทั้ง DataFrame ได้เลยแบบนี้\ndataframe2 = dataframe.replace(1, -100)  เราสามารถ Replace หลายค่าพร้อมกันได้ด้วยครับ และสามารถกำหนด Column ที่ต้องการให้แทนค่าได้ด้วย\ndf['city'].replace({ 'BKK':'Bangkok', 'BNK':'Bangkok' }, inplace=True)  วิธีการ Export DataFrame เป็นไฟล์ CSV หลังจากที่เราจัดการ Data เรียบร้อยแล้ว ก็สามารถ Export เป็น CSV เอาไปใช้ต่อกับโปรแกรมอื่น หรืองานส่วนอื่น ๆ ได้ (แอดทำบ่อยเพราะบางทีต้องสลับ Python \u0026lt;-\u0026gt; R รัว ๆ)\ndataframe.to_csv('dataframe.csv')   Source: Data TH.com - Data Science ชิลชิล.\n "});index.add({'id':100,'href':'/library/tutorials/docs/articles/python/python-dictionary-tutorial/','title':"Python Dictionary Tutorial",'content':" Python Dictionary Tutorial  Introduction Creating a Dictionary Accessing Elements Adding Elements Updating Elements Removing Elements Other Common Methods Conclusion  Introduction Python comes with a variety of built-in data structures, capable of storing different types of data. A Python dictionary is one such data structure that can store data in the form of key-value pairs. The values in a Python dictionary can be accessed using the keys. In this article, we will be discussing the Python dictionary in detail.\nCreating a Dictionary To create a Python dictionary, we need to pass a sequence of items inside curly braces {}, and separate them using a comma (,). Each item has a key and a value expressed as a \u0026ldquo;key:value\u0026rdquo; pair.\nThe values can belong to any data type and they can repeat, but the keys must remain unique.\nThe following examples demonstrate how to create Python dictionaries:\nCreating an empty dictionary:\ndict_sample = {}  Creating a dictionary with integer keys:\ndict_sample = {1: 'mango', 2: 'pawpaw'}  Creating a dictionary with mixed keys:\ndict_sample = {'fruit': 'mango', 1: [4, 6, 8]}  We can also create a dictionary by explicitly calling the Python\u0026rsquo;s dict() method:\ndict_sample = dict({1:'mango', 2:'pawpaw'})  A dictionary can also be created from a sequence as shown below:\ndict_sample = dict([(1,'mango'), (2,'pawpaw')])  Dictionaries can also be nested, which means that we can create a dictionary inside another dictionary. For example:\ndict_sample = {1: {'student1' : 'Nicholas', 'student2' : 'John', 'student3' : 'Mercy'}, 2: {'course1' : 'Computer Science', 'course2' : 'Mathematics', 'course3' : 'Accounting'}}  To print the dictionary contents, we can use the Python\u0026rsquo;s print() function and pass the dictionary name as the argument to the function. For example:\ndict_sample = { \u0026quot;Company\u0026quot;: \u0026quot;Toyota\u0026quot;, \u0026quot;model\u0026quot;: \u0026quot;Premio\u0026quot;, \u0026quot;year\u0026quot;: 2012 } print(dict_sample)  Output:\n{'Company': 'Toyota', 'model': 'Premio', 'year': 2012}  Accessing Elements To access dictionary items, pass the key inside square brackets []. For example:\ndict_sample = { \u0026quot;Company\u0026quot;: \u0026quot;Toyota\u0026quot;, \u0026quot;model\u0026quot;: \u0026quot;Premio\u0026quot;, \u0026quot;year\u0026quot;: 2012 } x = dict_sample[\u0026quot;model\u0026quot;] print(x)  Output:\nPremio  We created a dictionary named dict_sample. A variable named x was then created and its value is set to be the value for the key \u0026ldquo;model\u0026rdquo; in the dictionary.\nHere is another example:\ndict = {'Name': 'Mercy', 'Age': 23, 'Course': 'Accounting'} print(\u0026quot;Student Name:\u0026quot;, dict['Name']) print(\u0026quot;Course:\u0026quot;, dict['Course']) print(\u0026quot;Age:\u0026quot;, dict['Age'])  Output:\nStudent Name: Mercy Course: Accounting Age: 23  The dictionary object also provides the get() function, which can be used to access dictionary elements as well. We append the function with the dictionary name using the dot operator and then pass the name of the key as the argument to the function. For example:\ndict_sample = { \u0026quot;Company\u0026quot;: \u0026quot;Toyota\u0026quot;, \u0026quot;model\u0026quot;: \u0026quot;Premio\u0026quot;, \u0026quot;year\u0026quot;: 2012 } x = dict_sample.get(\u0026quot;model\u0026quot;) print(x)  Output:\nPremio  Now we know how to access dictionary elements using a few different methods. In the next section we\u0026rsquo;ll discuss how to add new elements to an already existing dictionary.\nAdding Elements There are numerous ways to add new elements to a dictionary. We can use a new index key and assign a value to it. For example:\ndict_sample = { \u0026quot;Company\u0026quot;: \u0026quot;Toyota\u0026quot;, \u0026quot;model\u0026quot;: \u0026quot;Premio\u0026quot;, \u0026quot;year\u0026quot;: 2012 } dict_sample[\u0026quot;Capacity\u0026quot;] = \u0026quot;1800CC\u0026quot; print(dict_sample)  Output:\n{'Capacity': '1800CC', 'year': 2012, 'Company': 'Toyota', 'model': 'Premio'}  The new element has \u0026ldquo;Capacity\u0026rdquo; as the key and \u0026ldquo;1800CC\u0026rdquo; as its corresponding value. It has been added as the first element of the dictionary.\nHere is another example. First let\u0026rsquo;s first create an empty dictionary:\nMyDictionary = {} print(\u0026quot;An Empty Dictionary: \u0026quot;) print(MyDictionary)  Output:\nAn Empty Dictionary:  The dictionary returns nothing as it has nothing stored yet. Let us add some elements to it, one at a time:\nMyDictionary[0] = 'Apples' MyDictionary[2] = 'Mangoes' MyDictionary[3] = 20 print(\u0026quot;\\n3 elements have been added: \u0026quot;) print(MyDictionary)  Output:\n3 elements have been added: {0: 'Apples', 2: 'Mangoes', 3: 20}  To add the elements, we specified keys as well as the corresponding values. For example:\nMyDictionary[0] = 'Apples'  In the above example, 0 is the key while \u0026ldquo;Apples\u0026rdquo; is the value.\nIt is even possible for us to add a set of values to one key. For example:\nMyDictionary['Values'] = 1, \u0026quot;Pairs\u0026quot;, 4 print(\u0026quot;\\n3 elements have been added: \u0026quot;) print(MyDictionary)  Output:\n3 elements have been added: {'Values': (1, 'Pairs', 4)}  In the above example, the name of the key is \u0026ldquo;Values\u0026rdquo; while everything after the = sign are the actual values for that key, stored as a Set.\nOther than adding new elements to a dictionary, dictionary elements can also be updated/changed, which we\u0026rsquo;ll go over in the next section.\nUpdating Elements After adding a value to a dictionary we can then modify the existing dictionary element. You use the key of the element to change the corresponding value. For example:\ndict_sample = { \u0026quot;Company\u0026quot;: \u0026quot;Toyota\u0026quot;, \u0026quot;model\u0026quot;: \u0026quot;Premio\u0026quot;, \u0026quot;year\u0026quot;: 2012 } dict_sample[\u0026quot;year\u0026quot;] = 2014 print(dict_sample)  Output:\n{'year': 2014, 'model': 'Premio', 'Company': 'Toyota'}  In this example you can see that we have updated the value for the key \u0026ldquo;year\u0026rdquo; from the old value of 2012 to a new value of 2014.\nRemoving Elements The removal of an element from a dictionary can be done in several ways, which we\u0026rsquo;ll discuss one-by-one in this section:\nThe del keyword can be used to remove the element with the specified key. For example:\ndict_sample = { \u0026quot;Company\u0026quot;: \u0026quot;Toyota\u0026quot;, \u0026quot;model\u0026quot;: \u0026quot;Premio\u0026quot;, \u0026quot;year\u0026quot;: 2012 } del dict_sample[\u0026quot;year\u0026quot;] print(dict_sample)  Output:\n{'Company': 'Toyota', 'model': 'Premio'}  We called the del keyword followed by the dictionary name. Inside the square brackets that follow the dictionary name, we passed the key of the element we need to delete from the dictionary, which in this example was \u0026ldquo;year\u0026rdquo;. The entry for \u0026ldquo;year\u0026rdquo; in the dictionary was then deleted.\nAnother way to delete a key-value pair is to use the pop() function and pass the key of the entry to be deleted as the argument to the function. For example:\ndict_sample = { \u0026quot;Company\u0026quot;: \u0026quot;Toyota\u0026quot;, \u0026quot;model\u0026quot;: \u0026quot;Premio\u0026quot;, \u0026quot;year\u0026quot;: 2012 } dict_sample.pop(\u0026quot;year\u0026quot;) print(dict_sample)  Output:\n{'Company': 'Toyota', 'model': 'Premio'}  We invoked the pop() function by appending it with the dictionary name. Again, in this example the entry for \u0026ldquo;year\u0026rdquo; in the dictionary will be deleted.\nThe popitem() function removes the last item inserted into the dictionary, without needing to specify the key. Take a look at the following example:\ndict_sample = { \u0026quot;Company\u0026quot;: \u0026quot;Toyota\u0026quot;, \u0026quot;model\u0026quot;: \u0026quot;Premio\u0026quot;, \u0026quot;year\u0026quot;: 2012 } dict_sample.popitem() print(dict_sample)  Output:\n{'Company': 'Toyota', 'model': 'Premio'}  The last entry into the dictionary was \u0026ldquo;year\u0026rdquo;. It has been removed after calling the popitem() function.\nSubscribe to our Newsletter Get occassional tutorials, guides, and reviews in your inbox. No spam ever. Unsubscribe at any time.\nSubscribe\nBut what if you want to delete the entire dictionary? It would be difficult and cumbersome to use one of these methods on every single key. Instead, you can use the del keyword to delete the entire dictionary. For example:\ndict_sample = { \u0026quot;Company\u0026quot;: \u0026quot;Toyota\u0026quot;, \u0026quot;model\u0026quot;: \u0026quot;Premio\u0026quot;, \u0026quot;year\u0026quot;: 2012 } del dict_sample print(dict_sample)  Output:\nNameError: name 'dict_sample' is not defined  The code returns an error. The reason is that we are trying to access a dictionary which doesn\u0026rsquo;t exist since it has been deleted.\nHowever, your use-case may require you to just remove all dictionary elements and be left with an empty dictionary. This can be achieved by calling the clear() function on the dictionary:\ndict_sample = { \u0026quot;Company\u0026quot;: \u0026quot;Toyota\u0026quot;, \u0026quot;model\u0026quot;: \u0026quot;Premio\u0026quot;, \u0026quot;year\u0026quot;: 2012 } dict_sample.clear() print(dict_sample)  Output:\n{}  The code returns an empty dictionary since all the dictionary elements have been removed.\nOther Common Methods The len() Method\nWith this method, you can count the number of elements in a dictionary. For example:\ndict_sample = { \u0026quot;Company\u0026quot;: \u0026quot;Toyota\u0026quot;, \u0026quot;model\u0026quot;: \u0026quot;Premio\u0026quot;, \u0026quot;year\u0026quot;: 2012 } print(len(dict_sample))  Output:\n3  There are three entries in the dictionary, hence the method returned 3.\nThe copy() Method\nThis method returns a copy of the existing dictionary. For example:\ndict_sample = { \u0026quot;Company\u0026quot;: \u0026quot;Toyota\u0026quot;, \u0026quot;model\u0026quot;: \u0026quot;Premio\u0026quot;, \u0026quot;year\u0026quot;: 2012 } x = dict_sample.copy() print(x)  Output:\n{'Company': 'Toyota', 'year': 2012, 'model': 'Premio'}  We created a copy of dictionary named dict_sample and assigned it to the variable x. If x is printed on the console, you will see that it contains the same elements as those stored by dict_sample dictionary.\nNote that this is useful because modifications made to the copied dictionary won\u0026rsquo;t affect the original one.\nThe items() Method\nWhen called, this method returns an iterable object. The iterable object has key-value pairs for the dictionary, as tuples in a list. This method is primarily used when you want to iterate through a dictionary.\nThe method is simply called on the dictionary object name as shown below:\ndict_sample = { \u0026quot;Company\u0026quot;: \u0026quot;Toyota\u0026quot;, \u0026quot;model\u0026quot;: \u0026quot;Premio\u0026quot;, \u0026quot;year\u0026quot;: 2012 } for k, v in dict_sample.items(): print(k, v)  Output:\n('Company', 'Toyota') ('model', 'Premio') ('year', 2012)  The object returned by items() can also be used to show the changes that have been implemented on the dictionary. This is demonstrated below:\ndict_sample = { \u0026quot;Company\u0026quot;: \u0026quot;Toyota\u0026quot;, \u0026quot;model\u0026quot;: \u0026quot;Premio\u0026quot;, \u0026quot;year\u0026quot;: 2012 } x = dict_sample.items() print(x) dict_sample[\u0026quot;model\u0026quot;] = \u0026quot;Mark X\u0026quot; print(x)  Output:\ndict_items([('Company', 'Toyota'), ('model', 'Premio'), ('year', 2012)]) dict_items([('Company', 'Toyota'), ('model', 'Mark X'), ('year', 2012)])  The output shows that when you change a value in the dictionary, the items object is also updated to reflect this change.\nThe fromkeys() Method\nThis method returns a dictionary having specified keys and values. It takes the syntax given below:\ndictionary.fromkeys(keys, value)  The value for required keys parameter is an iterable and it specifies the keys for the new dictionary. The value for value parameter is optional and it specifies the default value for all the keys. The default value for this is None.\nSuppose we need to create a dictionary of three keys all with the same value. We can do so as follows:\nname = ('John', 'Nicholas', 'Mercy') age = 25 dict_sample = dict.fromkeys(name, age) print(dict_sample)  Output:\n{'John': 25, 'Mercy': 25, 'Nicholas': 25}  In the script above, we specified the keys and one value. The fromkeys() method was able to pick the keys and combine them with this value to create a populated dictionary.\nThe value for the keys parameter is mandatory. The following example demonstrates what happens when the value for the values parameter is not specified:\nname = ('John', 'Nicholas', 'Mercy') dict_sample = dict.fromkeys(name) print(dict_sample)  Output:\n{'John': None, 'Mercy': None, 'Nicholas': None}  The default value, which is None, was used.\nThe setdefault() Method\nThis method is applicable when we need to get the value of the element with the specified key. If the key is not found, it will be inserted into the dictionary alongside the specified value.\nThe method takes the following syntax:\ndictionary.setdefault(keyname, value)  In this function the keyname parameter is required. It represents the keyname of the item you need to return a value from. The value parameter is optional. If the dictionary already has the key, this parameter won\u0026rsquo;t have any effect. If the key doesn\u0026rsquo;t exist, then the value given in this function will become the value of the key. It has a default value of None.\nFor example:\ndict_sample = { \u0026quot;Company\u0026quot;: \u0026quot;Toyota\u0026quot;, \u0026quot;model\u0026quot;: \u0026quot;Premio\u0026quot;, \u0026quot;year\u0026quot;: 2012 } x = dict_sample.setdefault(\u0026quot;color\u0026quot;, \u0026quot;Gray\u0026quot;) print(x)  Output\nGray  The dictionary doesn\u0026rsquo;t have the key for color. The setdefault() method has inserted this key and the specified a value, that is, \u0026ldquo;Gray\u0026rdquo;, has been used as its value.\nThe following example demonstrates how the method behaves if the value for the key does exist:\ndict_sample = { \u0026quot;Company\u0026quot;: \u0026quot;Toyota\u0026quot;, \u0026quot;model\u0026quot;: \u0026quot;Premio\u0026quot;, \u0026quot;year\u0026quot;: 2012 } x = dict_sample.setdefault(\u0026quot;model\u0026quot;, \u0026quot;Allion\u0026quot;) print(x)  Output:\nPremio  The value \u0026ldquo;Allion\u0026rdquo; has no effect on the dictionary since we already have a value for the key.\nThe keys() Method\nThis method also returns an iterable object. The object returned is a list of all keys in the dictionary. And just like with the items() method, the returned object can be used to reflect the changes made to the dictionary.\nTo use this method, we only call it on the name of the dictionary, as shown below:\ndictionary.keys()  For example:\ndict_sample = { \u0026quot;Company\u0026quot;: \u0026quot;Toyota\u0026quot;, \u0026quot;model\u0026quot;: \u0026quot;Premio\u0026quot;, \u0026quot;year\u0026quot;: 2012 } x = dict_sample.keys() print(x)  Output:\ndict_keys(['model', 'Company', 'year'])  Often times this method is used to iterate through each key in your dictionary, like so:\ndict_sample = { \u0026quot;Company\u0026quot;: \u0026quot;Toyota\u0026quot;, \u0026quot;model\u0026quot;: \u0026quot;Premio\u0026quot;, \u0026quot;year\u0026quot;: 2012 } for k in dict_sample.keys(): print(k)  Output:\nCompany model year  Conclusion This marks the end of this tutorial on Python dictionaries. These dictionaries store data in \u0026ldquo;key:value\u0026rdquo; pairs. The \u0026ldquo;key\u0026rdquo; acts as the identifier for the item while \u0026ldquo;value\u0026rdquo; is the value of the item. The Python dictionary comes with a variety of functions that can be applied for retrieval or manipulation of data. In this article, we saw how Python dictionary can be created, modified and deleted along with some of the most commonly used dictionary methods.\nRef : https://stackabuse.com/python-dictionary-tutorial/\n"});index.add({'id':101,'href':'/library/tutorials/docs/articles/python/python-for-pdf-01/','title':"Python for PDF",'content':" Python for Pdf Why Python for PDF processing PDF processing comes under text analytics. Most of the Text Analytics Library or frameworks are designed in Python only. This gives leverage on text analytics. Once you extract the useful information from PDF you can easily use that data into any Machine Learning or Natural Language Processing Model.\nCommon Python Libraries Here is the list of some Python Libraries could be used to handle PDF files\n PDFMiner is a tool for extracting information from PDF documents. Unlike other PDF-related tools, it focuses entirely on getting and analyzing text data. PyPDF2 is a pure-python PDF library capable of splitting, merging together, cropping, and transforming the pages of PDF files. It can also add custom data, viewing options, and passwords to PDF files. It can retrieve text and metadata from PDFs as well as merge entire files together. Tabula-py is a simple Python wrapper of tabula-java, which can read the table of PDF. You can read tables from PDF and convert into pandas’ DataFrame. tabula-py also enables you to convert a PDF file into CSV/TSV/JSON file. Slate is wrapper Implementation of PDFMiner PDFQuery is a light wrapper around pdfminer, lxml and pyquery. It’s designed to reliably extract data from sets of PDFs with as little code as possible. xpdf Python wrapper for xpdf (currently just the “pdftotext” utility)  Extracting Text from pdf First, we need to Install the\n!pip install PyPDF2  Following is the code to extract simple Text from pdf using PyPDF2\n# modules for import PyPDF2 # pdf file object # you can find find the pdf file with complete code in below pdfFileObj = open('example.pdf', 'rb') # pdf reader object pdfReader = PyPDF2.PdfFileReader(pdfFileObj) # number of pages in pdf print(pdfReader.numPages) # a page object pageObj = pdfReader.getPage(0) # extracting text from page. # this will print the text you can also save that into String print(pageObj.extractText())  You can read more Details from here\nReading the Table data from pdf In order to work with the Table data in Pdf, we can use Tabula-py\npip install tabula-py  Following is the code to extract simple Text from pdf using PyPDF2\nimport tabula # readinf the PDF file that contain Table Data # you can find find the pdf file with complete code in below # read_pdf will save the pdf table into Pandas Dataframe df = tabula.read_pdf(\u0026quot;offense.pdf\u0026quot;) # in order to print first 5 lines of Table df.head()  import PyPDF2 PDFfilename = \u0026quot;Sammamish.pdf\u0026quot; #filename of your PDF/directory where your PDF is stored pfr = PyPDF2.PdfFileReader(open(PDFfilename, \u0026quot;rb\u0026quot;)) #PdfFileReader object pg4 = pfr.getPage(126) #extract pg 127 writer = PyPDF2.PdfFileWriter() #create PdfFileWriter object #add pages writer.addPage(pg4) NewPDFfilename = \u0026quot;allTables.pdf\u0026quot; #filename of your PDF/directory where you want your new PDF to be with open(NewPDFfilename, \u0026quot;wb\u0026quot;) as outputStream: writer.write(outputStream) #write pages to new PDF  #the table will be returned in a list of dataframe,for working with dataframe you need pandas import pandas as pd import tabula file = \u0026quot;filename.pdf\u0026quot; path = 'enter your directory path here' + file df = tabula.read_pdf(path, pages = '1', multiple_tables = True) print(df)  Your question is near similar with:\n Extract / Identify Tables from PDF python\n Extracting tables from a pdf\n Extract table from a PDF\n How to scrape tables in thousands of PDF files?\n PDF Data and Table Scraping to Excel\n Extracting table contents from a collection of PDF files  If you Pdf file contain Multiple Table\ndf = tabula.read_pdf(“offense.pdf”,multiple_tables=True)  you can extract Information from the specific part of any specific page of PDF\ntabula.read_pdf(\u0026quot;offense.pdf\u0026quot;, area=(126,149,212,462), pages=1)  If you want the output into JSON Format\ntabula.read_pdf(\u0026quot;offense.pdf\u0026quot;, output_format=\u0026quot;json\u0026quot;)  Export Pdf into Excel you can us Below code to convert the PDF Data into Excel or CSV\ntabula.convert_into(\u0026quot;offense.pdf\u0026quot;, \u0026quot;offense_testing.xlsx\u0026quot;, output_format=\u0026quot;xlsx\u0026quot;)  Further Readings you can find the complete code and Pdf files in This Github Link\n This question on StackOverflow also has a lot of useful link in its Answer How to extract table as text from the PDF using Python? Working with PDF files in Python using PyPDF2 Working with PDF and Word Documents 3 WAYS TO SCRAPE TABLES FROM PDFS WITH PYTHON How to Convert a PDF to Excel   ที่มาบทความ towardsdatascience.com.\n "});index.add({'id':102,'href':'/library/tutorials/docs/articles/python/python-programming-in-r/','title':"Python Programming in R",'content':" Python Programming in R  All code used in this tutorial can be found here: https://github.com/joelalcedo/Python_in_R\n I am a Data Scientist working in New York. I have worked on a number of different projects spanning data visualization, machine learning and software development all in hopes to better understand the complexities associated with the financial markets. I started learning how to program about 10 years ago in visual basic. One thing led to another (as it does) and I learned SQL, R, Python, JavaScript (regrettably), C++ and others. Currently, I am working on some Flutter projects, using Google’s Dart framework.\nDo my credentials sound like an alphabet soup? If you yourself are a programmer, chances are you have a few languages on the resume. If you are interested in hiring a programmer, but do not know quite what to look for, chances are you have been inundated with a spectrum of programming languages and obscure libraries on candidate resumes, wondering to yourself, “am I still reading English?”.\nWhy am I writing this? To address a question I hear all time on Wall Street from aspiring programmers:\n“Should I learn Python or R?”\nWell gather around, because I am about to show you it is possible to use both Python and R seamlessly. Personally, I say learn them both. There are certain advantages Python brings to the table versus R, and vice-versa.\nUsing the reticulate package in R, it is very easy to interface between the two. I will write a simple function in Python to pull some data in from Quandl, then clean up and visualize the data in R using ggplot2.\nHere’s the 30,000 foot view. We have some directory that contains our Python code and R code (you can download the full directory here on my GitHub). Using the reticulate package in R, we will call a Python file, which will then port over to R, which can then continue to be used in R.\nHere’s our function in Python:\nFull code is available on my GitHub\nIf you don’t have an API key in Quandl, sign up for an account to get an API key— it is free. You don’t necessarily need an API key for this, but if you make enough queries they will time you out.\nAnyhow, here’s what the output looks like in Python:\nPassing “WIKI/AAPL” through “grab_from_quandl”, will return the data as expected.\nJust in case an incorrect code is input, I added a custom handler:\nOutput of error handler.\nLet’s port this Python function over to R.\nAll it takes is one line of code!\nThe “source_python” function essentially ports your Python code into R, which then will enable you to continue using your Python function in R:\nThe error handler works, too:\nNow that we can run our Python code in R, we can use dplyr to wrangle the data and ggplot2 to visualize the results…\nVoila! There you have it. While this was a simple example, the benefits of the reticulate package in R are very broad in scope.\nHopefully you find this helpful. Give me a shout if you have questions about any of this..\nJoel Alcedo is a Data Scientist working at BNP Paribas in New York. Prior to his time at BNP Paribas, he worked at Porsche North America HQ, Virgin Galactic and Cantor Fitzgerald.\nSource :\n"});index.add({'id':103,'href':'/library/tutorials/docs/articles/python/python-time-module./','title':"Python Time Module",'content':" A Beginner’s Guide to the Python time Module Table of Contents\n Dealing With Python Time Using Seconds  The Epoch Python Time in Seconds as a Floating Point Number Python Time in Seconds as a String Representing Local Time  Understanding Time Zones  UTC and Time Zones Daylight Savings Time  Dealing With Python Time Using Data Structures  Python Time as a Tuple Python Time as an Object  Converting Python Time in Seconds to an Object  Coordinated Universal Time (UTC) Local Time  Converting a Local Time Object to Seconds Converting a Python Time Object to a String  asctime() strftime()  Converting a Python Time String to an Object Suspending Execution Measuring Performance Conclusion Further Reading  The Python time module provides many ways of representing time in code, such as objects, numbers, and strings. It also provides functionality other than representing time, like waiting during code execution and measuring the efficiency of your code.\nThis article will walk you through the most commonly used functions and objects in time.\nBy the end of this article, you’ll be able to:\n Understand core concepts at the heart of working with dates and times, such as epochs, time zones, and daylight savings time Represent time in code using floats, tuples, and struct_time Convert between different time representations Suspend thread execution Measure code performance using perf_counter()  You’ll start by learning how you can use a floating point number to represent time.\nFree Bonus: Click here to get our free Python Cheat Sheet that shows you the basics of Python 3, like working with data types, dictionaries, lists, and Python functions.\nRemove ads\nDealing With Python Time Using Seconds One of the ways you can manage the concept of Python time in your application is by using a floating point number that represents the number of seconds that have passed since the beginning of an era—that is, since a certain starting point.\nLet’s dive deeper into what that means, why it’s useful, and how you can use it to implement logic, based on Python time, in your application.\nThe Epoch You learned in the previous section that you can manage Python time with a floating point number representing elapsed time since the beginning of an era.\nMerriam-Webster defines an era as:\n A fixed point in time from which a series of years is reckoned A system of chronological notation computed from a given date as basis  The important concept to grasp here is that, when dealing with Python time, you’re considering a period of time identified by a starting point. In computing, you call this starting point the epoch.\nThe epoch, then, is the starting point against which you can measure the passage of time.\nFor example, if you define the epoch to be midnight on January 1, 1970 UTC—the epoch as defined on Windows and most UNIX systems—then you can represent midnight on January 2, 1970 UTC as 86400 seconds since the epoch.\nThis is because there are 60 seconds in a minute, 60 minutes in an hour, and 24 hours in a day. January 2, 1970 UTC is only one day after the epoch, so you can apply basic math to arrive at that result:\n60 * 60 * 24  86400  It is also important to note that you can still represent time before the epoch. The number of seconds would just be negative.\nFor example, you would represent midnight on December 31, 1969 UTC (using an epoch of January 1, 1970) as -86400 seconds.\nWhile January 1, 1970 UTC is a common epoch, it is not the only epoch used in computing. In fact, different operating systems, filesystems, and APIs sometimes use different epochs.\nAs you saw before, UNIX systems define the epoch as January 1, 1970. The Win32 API, on the other hand, defines the epoch as January 1, 1601.\nYou can use time.gmtime() to determine your system’s epoch:\nimport time time.gmtime(0)  time.struct_time(tm_year=1970, tm_mon=1, tm_mday=1, tm_hour=0, tm_min=0, tm_sec=0, tm_wday=3, tm_yday=1, tm_isdst=0)  You’ll learn about gmtime() and struct_time throughout the course of this article. For now, just know that you can use time to discover the epoch using this function.\nNow that you understand more about how to measure time in seconds using an epoch, let’s take a look at Python’s time module to see what functions it offers that help you do so.\nPython Time in Seconds as a Floating Point Number First, time.time() returns the number of seconds that have passed since the epoch. The return value is a floating point number to account for fractional seconds:\nfrom time import time time()  1551143536.9323719  The number you get on your machine may be very different because the reference point considered to be the epoch may be very different.\nFurther Reading: Python 3.7 introduced time_ns(), which returns an integer value representing the same elapsed time since the epoch, but in nanoseconds rather than seconds.\nMeasuring time in seconds is useful for a number of reasons:\n You can use a float to calculate the difference between two points in time. A float is easily serializable, meaning that it can be stored for data transfer and come out intact on the other side.  Sometimes, however, you may want to see the current time represented as a string. To do so, you can pass the number of seconds you get from time() into time.ctime().\nPython Time in Seconds as a String Representing Local Time As you saw before, you may want to convert the Python time, represented as the number of elapsed seconds since the epoch, to a string. You can do so using ctime():\nfrom time import time, ctime t = time() ctime(t)  'Mon Feb 25 19:11:59 2019'  Here, you’ve recorded the current time in seconds into the variable t, then passed t as an argument to ctime(), which returns a string representation of that same time.\nTechnical Detail: The argument, representing seconds since the epoch, is optional according to the ctime() definition. If you don’t pass an argument, then ctime() uses the return value of time() by default. So, you could simplify the example above:\nfrom time import ctime ctime()  'Mon Feb 25 19:11:59 2019'  The string representation of time, also known as a timestamp, returned by ctime() is formatted with the following structure:\n Day of the week: Mon (Monday) Month of the year: Feb (February) Day of the month: 25 Hours, minutes, and seconds using the 24-hour clock notation: 19:11:59 Year: 2019  The previous example displays the timestamp of a particular moment captured from a computer in the South Central region of the United States. But, let’s say you live in Sydney, Australia, and you executed the same command at the same instant.\nInstead of the above output, you’d see the following:\nfrom time import time, ctime t = time() ctime(t)  'Tue Feb 26 12:11:59 2019'  Notice that the day of week, day of month, and hour portions of the timestamp are different than the first example.\nThese outputs are different because the timestamp returned by ctime() depends on your geographical location.\nNote: While the concept of time zones is relative to your physical location, you can modify this in your computer’s settings without actually relocating.\nThe representation of time dependent on your physical location is called local time and makes use of a concept called time zones.\nNote: Since local time is related to your locale, timestamps often account for locale-specific details such as the order of the elements in the string and translations of the day and month abbreviations. ctime() ignores these details.\nLet’s dig a little deeper into the notion of time zones so that you can better understand Python time representations.\nUnderstanding Time Zones A time zone is a region of the world that conforms to a standardized time. Time zones are defined by their offset from Coordinated Universal Time (UTC) and, potentially, the inclusion of daylight savings time (which we’ll cover in more detail later in this article).\nFun Fact: If you’re a native English speaker, you might be wondering why the abbreviation for “Coordinated Universal Time” is UTC rather than the more obvious CUT. However, if you’re a native French speaker, you would call it “Temps Universel Coordonné,” which suggests a different abbreviation: TUC.\nUltimately, the International Telecommunication Union and the International Astronomical Union compromised on UTC as the official abbreviation so that, regardless of language, the abbreviation would be the same.\nUTC and Time Zones UTC is the time standard against which all the world’s timekeeping is synchronized (or coordinated). It is not, itself, a time zone but rather a transcendent standard that defines what time zones are.\nUTC time is precisely measured using astronomical time, referring to the Earth’s rotation, and atomic clocks.\nTime zones are then defined by their offset from UTC. For example, in North and South America, the Central Time Zone (CT) is behind UTC by five or six hours and, therefore, uses the notation UTC-5:00 or UTC-6:00.\nSydney, Australia, on the other hand, belongs to the Australian Eastern Time Zone (AET), which is ten or eleven hours ahead of UTC (UTC+10:00 or UTC+11:00).\nThis difference (UTC-6:00 to UTC+10:00) is the reason for the variance you observed in the two outputs from ctime() in the previous examples:\n Central Time (CT): 'Mon Feb 25 19:11:59 2019' Australian Eastern Time (AET): 'Tue Feb 26 12:11:59 2019'  These times are exactly sixteen hours apart, which is consistent with the time zone offsets mentioned above.\nYou may be wondering why CT can be either five or six hours behind UTC or why AET can be ten or eleven hours ahead. The reason for this is that some areas around the world, including parts of these time zones, observe daylight savings time.\nDaylight Savings Time Summer months generally experience more daylight hours than winter months. Because of this, some areas observe daylight savings time (DST) during the spring and summer to make better use of those daylight hours.\nFor places that observe DST, their clocks will jump ahead one hour at the beginning of spring (effectively losing an hour). Then, in the fall, the clocks will be reset to standard time.\nThe letters S and D represent standard time and daylight savings time in time zone notation:\n Central Standard Time (CST) Australian Eastern Daylight Time (AEDT)  When you represent times as timestamps in local time, it is always important to consider whether DST is applicable or not.\nctime() accounts for daylight savings time. So, the output difference listed previously would be more accurate as the following:\n Central Standard Time (CST): 'Mon Feb 25 19:11:59 2019' Australian Eastern Daylight Time (AEDT): 'Tue Feb 26 12:11:59 2019'  Dealing With Python Time Using Data Structures Now that you have a firm grasp on many fundamental concepts of time including epochs, time zones, and UTC, let’s take a look at more ways to represent time using the Python time module.\nPython Time as a Tuple Instead of using a number to represent Python time, you can use another primitive data structure: a tuple.\nThe tuple allows you to manage time a little more easily by abstracting some of the data and making it more readable.\nWhen you represent time as a tuple, each element in your tuple corresponds to a specific element of time:\n Year Month as an integer, ranging between 1 (January) and 12 (December) Day of the month Hour as an integer, ranging between 0 (12 A.M.) and 23 (11 P.M.) Minute Second Day of the week as an integer, ranging between 0 (Monday) and 6 (Sunday) Day of the year Daylight savings time as an integer with the following values:  1 is daylight savings time. 0 is standard time. -1 is unknown.   Using the methods you’ve already learned, you can represent the same Python time in two different ways:\nfrom time import time, ctime t = time() t  1551186415.360564  ctime(t)  'Tue Feb 26 07:06:55 2019'  time_tuple = (2019, 2, 26, 7, 6, 55, 1, 57, 0)  In this case, both t and time_tuple represent the same time, but the tuple provides a more readable interface for working with time components.\nTechnical Detail: Actually, if you look at the Python time represented by time_tuple in seconds (which you’ll see how to do later in this article), you’ll see that it resolves to 1551186415.0 rather than 1551186415.360564.\nThis is because the tuple doesn’t have a way to represent fractional seconds.\nWhile the tuple provides a more manageable interface for working with Python time, there is an even better object: struct_time.\nPython Time as an Object The problem with the tuple construct is that it still looks like a bunch of numbers, even though it’s better organized than a single, seconds-based number.\nstruct_time provides a solution to this by utilizing NamedTuple, from Python’s collections module, to associate the tuple’s sequence of numbers with useful identifiers:\nfrom time import struct_time time_tuple = (2019, 2, 26, 7, 6, 55, 1, 57, 0) time_obj = struct_time(time_tuple) time_obj  time.struct_time(tm_year=2019, tm_mon=2, tm_mday=26, tm_hour=7, tm_min=6, tm_sec=55, tm_wday=1, tm_yday=57, tm_isdst=0)  Technical Detail: If you’re coming from another language, the terms struct and object might be in opposition to one another.\nIn Python, there is no data type called struct. Instead, everything is an object.\nHowever, the name struct_time is derived from the C-based time library where the data type is actually a struct.\nIn fact, Python’s time module, which is implemented in C, uses this struct directly by including the header file times.h.\nNow, you can access specific elements of time_obj using the attribute’s name rather than an index:\nday_of_year = time_obj.tm_yday day_of_year  57  day_of_month = time_obj.tm_mday day_of_month  26  Beyond the readability and usability of struct_time, it is also important to know because it is the return type of many of the functions in the Python time module.\nConverting Python Time in Seconds to an Object Now that you’ve seen the three primary ways of working with Python time, you’ll learn how to convert between the different time data types.\nConverting between time data types is dependent on whether the time is in UTC or local time.\nCoordinated Universal Time (UTC) The epoch uses UTC for its definition rather than a time zone. Therefore, the seconds elapsed since the epoch is not variable depending on your geographical location.\nHowever, the same cannot be said of struct_time. The object representation of Python time may or may not take your time zone into account.\nThere are two ways to convert a float representing seconds to a struct_time:\n UTC Local time  To convert a Python time float to a UTC-based struct_time, the Python time module provides a function called gmtime().\nYou’ve seen gmtime() used once before in this article:\nimport time time.gmtime(0)  time.struct_time(tm_year=1970, tm_mon=1, tm_mday=1, tm_hour=0, tm_min=0, tm_sec=0, tm_wday=3, tm_yday=1, tm_isdst=0)  You used this call to discover your system’s epoch. Now, you have a better foundation for understanding what’s actually happening here.\ngmtime() converts the number of elapsed seconds since the epoch to a struct_time in UTC. In this case, you’ve passed 0 as the number of seconds, meaning you’re trying to find the epoch, itself, in UTC.\nNote: Notice the attribute tm_isdst is set to 0. This attribute represents whether the time zone is using daylight savings time. UTC never subscribes to DST, so that flag will always be 0 when using gmtime().\nAs you saw before, struct_time cannot represent fractional seconds, so gmtime() ignores the fractional seconds in the argument:\nimport time time.gmtime(1.99)  time.struct_time(tm_year=1970, tm_mon=1, tm_mday=1, tm_hour=0, tm_min=0, tm_sec=1, tm_wday=3, tm_yday=1, tm_isdst=0)  Notice that even though the number of seconds you passed was very close to 2, the .99 fractional seconds were simply ignored, as shown by tm_sec=1.\nThe secs parameter for gmtime() is optional, meaning you can call gmtime() with no arguments. Doing so will provide the current time in UTC:\nimport time time.gmtime()  time.struct_time(tm_year=2019, tm_mon=2, tm_mday=28, tm_hour=12, tm_min=57, tm_sec=24, tm_wday=3, tm_yday=59, tm_isdst=0)  Interestingly, there is no inverse for this function within time. Instead, you’ll have to look in Python’s calendar module for a function named timegm():\nimport calendar import time time.gmtime()  time.struct_time(tm_year=2019, tm_mon=2, tm_mday=28, tm_hour=13, tm_min=23, tm_sec=12, tm_wday=3, tm_yday=59, tm_isdst=0)  calendar.timegm(time.gmtime())  1551360204  timegm() takes a tuple (or struct_time, since it is a subclass of tuple) and returns the corresponding number of seconds since the epoch.\nHistorical Context: If you’re interested in why timegm() is not in time, you can view the discussion in Python Issue 6280.\nIn short, it was originally added to calendar because time closely follows C’s time library (defined in time.h), which contains no matching function. The above-mentioned issue proposed the idea of moving or copying timegm() into time.\nHowever, with advances to the datetime library, inconsistencies in the patched implementation of time.timegm(), and a question of how to then handle calendar.timegm(), the maintainers declined the patch, encouraging the use of datetime instead.\nWorking with UTC is valuable in programming because it’s a standard. You don’t have to worry about DST, time zone, or locale information.\nThat said, there are plenty of cases when you’d want to use local time. Next, you’ll see how to convert from seconds to local time so that you can do just that.\nLocal Time In your application, you may need to work with local time rather than UTC. Python’s time module provides a function for getting local time from the number of seconds elapsed since the epoch called localtime().\nThe signature of localtime() is similar to gmtime() in that it takes an optional secs argument, which it uses to build a struct_time using your local time zone:\nimport time time.time()  1551448206.86196  time.localtime(1551448206.86196)  time.struct_time(tm_year=2019, tm_mon=3, tm_mday=1, tm_hour=7, tm_min=50, tm_sec=6, tm_wday=4, tm_yday=60, tm_isdst=0)  Notice that tm_isdst=0. Since DST matters with local time, tm_isdst will change between 0 and 1 depending on whether or not DST is applicable for the given time. Since tm_isdst=0, DST is not applicable for March 1, 2019.\nIn the United States in 2019, daylight savings time begins on March 10. So, to test if the DST flag will change correctly, you need to add 9 days’ worth of seconds to the secs argument.\nTo compute this, you take the number of seconds in a day (86,400) and multiply that by 9 days:\nnew_secs = 1551448206.86196 + (86400 * 9) time.localtime(new_secs)  time.struct_time(tm_year=2019, tm_mon=3, tm_mday=10, tm_hour=8, tm_min=50, tm_sec=6, tm_wday=6, tm_yday=69, tm_isdst=1)  Now, you’ll see that the struct_time shows the date to be March 10, 2019 with tm_isdst=1. Also, notice that tm_hour has also jumped ahead, to 8 instead of 7 in the previous example, because of daylight savings time.\nSince Python 3.3, struct_time has also included two attributes that are useful in determining the time zone of the struct_time:\n tm_zone tm_gmtoff  At first, these attributes were platform dependent, but they have been available on all platforms since Python 3.6.\nFirst, tm_zone stores the local time zone:\nimport time current_local = time.localtime() current_local.tm_zone  'CST'  Here, you can see that localtime() returns a struct_time with the time zone set to CST (Central Standard Time).\nAs you saw before, you can also tell the time zone based on two pieces of information, the UTC offset and DST (if applicable):\nimport time current_local = time.localtime() current_local.tm_gmtoff  -21600  current_local.tm_isdst  0  In this case, you can see that current_local is 21600 seconds behind GMT, which stands for Greenwich Mean Time. GMT is the time zone with no UTC offset: UTC±00:00.\n21600 seconds divided by seconds per hour (3,600) means that current_local time is GMT-06:00 (or UTC-06:00).\nYou can use the GMT offset plus the DST status to deduce that current_local is UTC-06:00 at standard time, which corresponds to the Central standard time zone.\nLike gmtime(), you can ignore the secs argument when calling localtime(), and it will return the current local time in a struct_time:\nimport time time.localtime()  time.struct_time(tm_year=2019, tm_mon=3, tm_mday=1, tm_hour=8, tm_min=34, tm_sec=28, tm_wday=4, tm_yday=60, tm_isdst=0)  Unlike gmtime(), the inverse function of localtime() does exist in the Python time module. Let’s take a look at how that works.\nConverting a Local Time Object to Seconds You’ve already seen how to convert a UTC time object to seconds using calendar.timegm(). To convert local time to seconds, you’ll use mktime().\nmktime() requires you to pass a parameter called t that takes the form of either a normal 9-tuple or a struct_time object representing local time:\nimport time time_tuple = (2019, 3, 10, 8, 50, 6, 6, 69, 1) time.mktime(time_tuple)  1552225806.0  time_struct = time.struct_time(time_tuple) time.mktime(time_struct)  1552225806.0  It’s important to keep in mind that t must be a tuple representing local time, not UTC:\nfrom time import gmtime, mktime # 1 current_utc = time.gmtime() current_utc  time.struct_time(tm_year=2019, tm_mon=3, tm_mday=1, tm_hour=14, tm_min=51, tm_sec=19, tm_wday=4, tm_yday=60, tm_isdst=0)  # 2 current_utc_secs = mktime(current_utc) current_utc_secs  1551473479.0  # 3 time.gmtime(current_utc_secs)  time.struct_time(tm_year=2019, tm_mon=3, tm_mday=1, tm_hour=20, tm_min=51, tm_sec=19, tm_wday=4, tm_yday=60, tm_isdst=0)  Note: For this example, assume that the local time is March 1, 2019 08:51:19 CST.\nThis example shows why it’s important to use mktime() with local time, rather than UTC:\n gmtime() with no argument returns a struct_time using UTC. current_utc shows March 1, 2019 14:51:19 UTC. This is accurate because CST is UTC-06:00, so UTC should be 6 hours ahead of local time.\n mktime() tries to return the number of seconds, expecting local time, but you passed current_utc instead. So, instead of understanding that current_utc is UTC time, it assumes you meant March 1, 2019 14:51:19 CST.\n gmtime() is then used to convert those seconds back into UTC, which results in an inconsistency. The time is now March 1, 2019 20:51:19 UTC. The reason for this discrepancy is the fact that mktime() expected local time. So, the conversion back to UTC adds another 6 hours to local time.\n  Working with time zones is notoriously difficult, so it’s important to set yourself up for success by understanding the differences between UTC and local time and the Python time functions that deal with each.\nConverting a Python Time Object to a String While working with tuples is fun and all, sometimes it’s best to work with strings.\nString representations of time, also known as timestamps, help make times more readable and can be especially useful for building intuitive user interfaces.\nThere are two Python time functions that you use for converting a time.struct_time object to a string:\n asctime() strftime()  You’ll begin by learning aboutasctime().\nasctime() You use asctime() for converting a time tuple or struct_time to a timestamp:\nimport time time.asctime(time.gmtime())  'Fri Mar 1 18:42:08 2019'  time.asctime(time.localtime())  'Fri Mar 1 12:42:15 2019'  Both gmtime() and localtime() return struct_time instances, for UTC and local time respectively.\nYou can use asctime() to convert either struct_time to a timestamp. asctime() works similarly to ctime(), which you learned about earlier in this article, except instead of passing a floating point number, you pass a tuple. Even the timestamp format is the same between the two functions.\nAs with ctime(), the parameter for asctime() is optional. If you do not pass a time object to asctime(), then it will use the current local time:\nimport time time.asctime()  'Fri Mar 1 12:56:07 2019'  As with ctime(), it also ignores locale information.\nOne of the biggest drawbacks of asctime() is its format inflexibility. strftime() solves this problem by allowing you to format your timestamps.\nstrftime() You may find yourself in a position where the string format from ctime() and asctime() isn’t satisfactory for your application. Instead, you may want to format your strings in a way that’s more meaningful to your users.\nOne example of this is if you would like to display your time in a string that takes locale information into account.\nTo format strings, given a struct_time or Python time tuple, you use strftime(), which stands for “string format time.”\nstrftime() takes two arguments:\n format specifies the order and form of the time elements in your string. t is an optional time tuple.  To format a string, you use directives. Directives are character sequences that begin with a % that specify a particular time element, such as:\n %d: Day of the month %m: Month of the year %Y: Year  For example, you can output the date in your local time using the ISO 8601 standard like this:\nimport time time.strftime('%Y-%m-%d', time.localtime())  '2019-03-01'  Further Reading: While representing dates using Python time is completely valid and acceptable, you should also consider using Python’s datetime module, which provides shortcuts and a more robust framework for working with dates and times together.\nFor example, you can simplify outputting a date in the ISO 8601 format using datetime:\nfrom datetime import date date(year=2019, month=3, day=1).isoformat()  '2019-03-01'  As you saw before, a great benefit of using strftime() over asctime() is its ability to render timestamps that make use of locale-specific information.\nFor example, if you want to represent the date and time in a locale-sensitive way, you can’t use asctime():\nfrom time import asctime asctime()  'Sat Mar 2 15:21:14 2019'  import locale locale.setlocale(locale.LC_TIME, 'zh_HK') # Chinese - Hong Kong  'zh_HK'  asctime()  'Sat Mar 2 15:58:49 2019'  Notice that even after programmatically changing your locale, asctime() still returns the date and time in the same format as before.\nTechnical Detail: LC_TIME is the locale category for date and time formatting. The locale argument 'zh_HK' may be different, depending on your system.\nWhen you use strftime(), however, you’ll see that it accounts for locale:\nfrom time import strftime, localtime strftime('%c', localtime())  'Sat Mar 2 15:23:20 2019'  import locale locale.setlocale(locale.LC_TIME, 'zh_HK') # Chinese - Hong Kong  'zh_HK'  strftime('%c', localtime())  '六 3/ 2 15:58:12 2019' 2019'  Here, you have successfully utilized the locale information because you used strftime().\nNote: %c is the directive for locale-appropriate date and time.\nIf the time tuple is not passed to the parameter t, then strftime() will use the result of localtime() by default. So, you could simplify the examples above by removing the optional second argument:\nfrom time import strftime strftime('The current local datetime is: %c')  'The current local datetime is: Fri Mar 1 23:18:32 2019'  Here, you’ve used the default time instead of passing your own as an argument. Also, notice that the format argument can consist of text other than formatting directives.\nFurther Reading: Check out this thorough list of directives available to strftime().\nThe Python time module also includes the inverse operation of converting a timestamp back into a struct_time object.\nConverting a Python Time String to an Object When you’re working with date and time related strings, it can be very valuable to convert the timestamp to a time object.\nTo convert a time string to a struct_time, you use strptime(), which stands for “string parse time”:\nfrom time import strptime strptime('2019-03-01', '%Y-%m-%d')  time.struct_time(tm_year=2019, tm_mon=3, tm_mday=1, tm_hour=0, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=60, tm_isdst=-1)  The first argument to strptime() must be the timestamp you wish to convert. The second argument is the format that the timestamp is in.\nThe format parameter is optional and defaults to '%a %b %d %H:%M:%S %Y'. Therefore, if you have a timestamp in that format, you don’t need to pass it as an argument:\nstrptime('Fri Mar 01 23:38:40 2019')  time.struct_time(tm_year=2019, tm_mon=3, tm_mday=1, tm_hour=23, tm_min=38, tm_sec=40, tm_wday=4, tm_yday=60, tm_isdst=-1)  Since a struct_time has 9 key date and time components, strptime() must provide reasonable defaults for values for those components it can’t parse from string.\nIn the previous examples, tm_isdst=-1. This means that strptime() can’t determine by the timestamp whether it represents daylight savings time or not.\nNow you know how to work with Python times and dates using the time module in a variety of ways. However, there are other uses for time outside of simply creating time objects, getting Python time strings, and using seconds elapsed since the epoch.\nSuspending Execution One really useful Python time function is sleep(), which suspends the thread’s execution for a specified amount of time.\nFor example, you can suspend your program’s execution for 10 seconds like this:\nfrom time import sleep, strftime strftime('%c')  'Fri Mar 1 23:49:26 2019'  sleep(10) strftime('%c')  'Fri Mar 1 23:49:36 2019'  Your program will print the first formatted datetime string, then pause for 10 seconds, and finally print the second formatted datetime string.\nYou can also pass fractional seconds to sleep():\nfrom time import sleep sleep(0.5)  sleep() is useful for testing or making your program wait for any reason, but you must be careful not to halt your production code unless you have good reason to do so.\nBefore Python 3.5, a signal sent to your process could interrupt sleep(). However, in 3.5 and later, sleep() will always suspend execution for at least the amount of specified time, even if the process receives a signal.\nsleep() is just one Python time function that can help you test your programs and make them more robust.\nMeasuring Performance You can use time to measure the performance of your program.\nThe way you do this is to use perf_counter() which, as the name suggests, provides a performance counter with a high resolution to measure short distances of time.\nTo use perf_counter(), you place a counter before your code begins execution as well as after your code’s execution completes:\nfrom time import perf_counter def longrunning_function(): for i in range(1, 11): time.sleep(i / i ** 2) start = perf_counter() longrunning_function() end = perf_counter() execution_time = (end - start) execution_time  8.201258441999926  First, start captures the moment before you call the function. end captures the moment after the function returns. The function’s total execution time took (end - start) seconds.\nTechnical Detail: Python 3.7 introduced perf_counter_ns(), which works the same as perf_counter(), but uses nanoseconds instead of seconds.\nperf_counter() (or perf_counter_ns()) is the most precise way to measure the performance of your code using one execution. However, if you’re trying to accurately gauge the performance of a code snippet, I recommend using the Python timeit module.\ntimeit specializes in running code many times to get a more accurate performance analysis and helps you to avoid oversimplifying your time measurement as well as other common pitfalls.\nConclusion Congratulations! You now have a great foundation for working with dates and times in Python.\nNow, you’re able to:\n Use a floating point number, representing seconds elapsed since the epoch, to deal with time Manage time using tuples and struct_time objects Convert between seconds, tuples, and timestamp strings Suspend the execution of a Python thread Measure performance using perf_counter()  On top of all that, you’ve learned some fundamental concepts surrounding date and time, such as:\n Epochs UTC Time zones Daylight savings time  Now, it’s time for you to apply your newfound knowledge of Python time in your real world applications!\nRef : https://realpython.com/python-time-module/\n"});index.add({'id':104,'href':'/library/tutorials/docs/articles/python/python-scala-comparison-part-1/','title':"Python vs. Scala  (Part I)",'content':" Python vs. Scala: a comparison of the basic commands (Part I) Source :\nI recently started playing a little bit with Scala, and I have to say it has been kind of traumatic. I love learning new things but after months of programming with Python, it is just not natural to set that aside and switch mode while solving Data Science problems. When learning a new language, whether it is a coding or a spoken one, it is normal for this to happen. We tend to fill in the gaps of the things we don’t know with the things we know, even if they don’t belong to the language we are trying to write/speak! When trying to learn a new language, it is important to be completely surrounded by the language you want to learn, but first of all, it is important to have well established parallelisms between the known and the new language, at least in the beginning. This works for me, a bilingual person who learned a second language really quickly, at an adult age. At the beginning, I needed connections between Italian (the language I knew) and English (the language I was learning), but as I became more and more fluent in English, I started to forget the parallelisms because it was just becoming natural and I didn’t need to translate it in my head first, anymore. The reason why I decided to write this post is, in fact, to establish parallelisms between Python and Scala, for people who are fluent in one of the two, and are starting to learn the other one, like myself.\nI initially wanted to focus on Pandas/Sklearn and Spark, but I realized that it doesn’t make much sense without covering the foundations first. This is why in this post we’ll look at the basics of Python and Scala: how to handle strings, lists, dictionaries and so on. I intend in the near future to publish a second part, where I will cover how to handle dataframes and build predictive models in both languages.\n1. First things first The first difference is the convention used when coding is these two languages: this will not throw an error or anything like that if you don’t follow it, but it’s just a non-written rule that coders follow.\nWhen defining a new variable, function or whatever, we always pick a name that makes sense to us, that most likely will be composed by two or more words. If this is the case, in Python we will use snake_case, while in ScalacamelCase: the difference is immediately noticeable. In snake case, all words all lower-case and we use _ to separate them, in camel case there is no separation, and all words are capitalized except for the first one.\nAnother striking difference is how we define the variables in the two languages. In Python we just make up a name and assign it to the value we need it to be, while in Scala, we need to specify whether we are defining a variable or a value, and we do this by placing var or val respectively, before the name (notice that this is valid whether we are assigning numerical values or strings).\nInitializing values and variables in Scala.\nThe difference between var and val is simple: variables can be modified, while values cannot. In the example represented in the image, I instantiated avar string and then changed it: all good. Then, I assigned the same string to a val and tried to change it again: not doable.\nIn Python there is no need to specify: if you want to change something you previously assigned, it’s up to you. In Python’s case I would just dostring = 'my_string'.\nAnother general difference regards commenting. In Python there is only one way to do it, whether it’s a single or multi-line, and that is putting a # before the comment, on each line:\n# this is a commented line in Python\nScala offers a couple of ways to comment, and these are either putting // on each line, or wrap the comment between /* and */:\n// this is a commented line in Scala /* and this is a multiline comment, still in Scala... ...just choose! */  Now that the very basics are explained, let’s see dive deeper.\n2. Lists and arrays List (in Python) or Array (in Scala) are among the most important objects: they can contain strings and/or numbers, we can manipulate them, iterate over them, add or subtract elements and so on. They can basically serve any purposes, and I don’t think I have ever coded anything without using them, so let’s see what we can do with them, and how.\n2.1. Define Let’s create a list containing a mix of numbers and strings.\nmy_list = [2, 5, 'apple', 78] **# Python** var myArray = Array(2, 5, \u0026quot;apple\u0026quot;, 78) **// Scala**  /* notice that in Scala I wrapped the string between \u0026ldquo;\u0026rdquo;, and that is the only way to do it! In python you can use both \u0026ldquo;\u0026rdquo; and \u0026ldquo; indifferently */\n2.2. Indexing Both lists and arrays are zero indexed, which means that the first element is placed at the index 0. So, if we want to extract the second element:\nmy_list[1] **# Python** uses [] to index myArray(1) **// Scala** uses () to index  2.3. Slicing In both languages, the second index will not be counted when slicing. So, if we want to extract the first 3 elements:\nmy_list[0:3] **# Python** slicing works like indexing\nmyArray.slice(0,3) **// Scala** needs the .slice()\n2.4. Checking first, last, maximum and minimum element **# Python**my_list[0] # first element my_list[-1] # last element max(my_list) # maximum element min(my_list) # minimum element#  NOTE: min() and max() will work exclusively if the list contains\n# numbers only!**// Scala**myArray.head // first element myArray(0) // other way to check the first element myArray.last // last element myArray.max // maximum element myArray.min // minimum element/*  NOTE: .min and .max will work exclusively if the array contains numbers only!*/\n2.5. Sum and product These operations, as for min and max, will be supported only if the lists/arrays contain exclusively numbers. Also, to multiply all the elements in a Python’s list, we will need to set up a for loop, which will be covered further down in the post. There is no preloaded function for that, as opposed to Scala.\nsum(my_list) # summing elements in **Python**'s list // **Scala** myArray.sum // summing elements in array myArray.product // multiplying elements in array  2.6. Adding elements Lists and arrays are not ordered, so it’s common practice to add elements at the end. Let’s say we want to add the string \u0026quot;last words\u0026quot;:\nmy_list.append('last words') # adding at the end of **Python**'s list myArray :+= \u0026quot;last words\u0026quot; // adding at the end of **Scala**'s array  If, for some reason, we want to add something at the very beginning, let’s say the number 99:\nmy_list.insert(0, 99) # this is a generic method in **Python**. The # first number you specify in the parenthesis is the index of the # position where you want to add the element. # 0 means that you want the element to be added at the very # beginningmyArray +:= 99 /* adding an element at the beginning of **Scala**'s array */  3. Print This is also something that we use all the time while coding, luckily there is a only a slight difference between the two languages.\nprint(\u0026quot;whatever you want\u0026quot;) # printing in **Python** println(\u0026quot;whatever you want\u0026quot;) // printing in **Scala**  4. For loop Quite a few differences here: while Python requires indentation to create a block and colon after the statement, Scala wants the for conditions in parenthesis, and the block in curly brackets with no indentation needed. I like to use indentation anyway though, it makes the code look neater.\n# for loop in **Python** for i in my_list: print(i)// for loop in **Scala** for (i \u0026lt;- myArray){ println(i) }  5. Mapping and/or filtering All things that, in Python, can be done by using list comprehensions. In Scala we will have to use functions.\n5.1. Mapping Let’s say we have a list/array with only numeric values and we want to triple all of them.\n[i*3 for i in my_list] # mapping in **Python** myArray.map(i =\u0026gt; i*3) // mapping in **Scala**  5.2. Filtering Let’s say we have a list/array with only numeric values and we want to filter only those divisible by 3.\n[i for i in my_list if i%3 == 0] # filtering in **Python** myArray.filter(i =\u0026gt; i%3 == 0) // filtering in **Scala**  5.3. Filtering and mapping What if we want to find the even numbers and multiply only them by 3?\n[i*3 for i in my_list if i%2 == 0] # **Python** myArray.filter(i =\u0026gt; i%2 == 0).map(i =\u0026gt; i*3) // **Scala**  6. Dictionaries/Maps Although they have different names in the two languages, they are exactly the same thing. They both have keys to which we assign values.\n6.1. Create dictionary/map Let’s create one storing my first, last name and age… and let’s also pretend I am 18.\n# **Python** my_dict = { 'first_name': 'Emma', 'last_name': 'Grimaldi', 'age': 18 }  In Scala we can do this in two different ways.\n// **Scala** mode 1 var myMap = ( \u0026quot;firstName\u0026quot; -\u0026gt; \u0026quot;Emma\u0026quot;, \u0026quot;lastName\u0026quot; -\u0026gt; \u0026quot;Grimaldi\u0026quot;, \u0026quot;age\u0026quot; -\u0026gt; 18 )// Scala mode 2 var myMap = ( (\u0026quot;firstName\u0026quot;, \u0026quot;Emma\u0026quot;), (\u0026quot;lastName\u0026quot;, \u0026quot;Grimaldi\u0026quot;), (\u0026quot;age\u0026quot;, 18) )  6.2. Adding to dictionary/map Let’s add my Country of origin to my dictionary/map.\nmy_dict['country_of_origin'] = 'Italy' # creating new key in **Python** myMap += (\u0026quot;countryOfOrigin\u0026quot; -\u0026gt; \u0026quot;Italy\u0026quot;) /* creating new key in **Scala** */  6.3. Indexing This works the same way as indexing lists/array, but instead of positions, we are using keys. If I want to see my first name:\n# **Python** my_dict['first_name']/  / **Scala** myMap(\u0026quot;firstName\u0026quot;)  6.4. Looping If we want to print the dictionary/map, we will have to for loop in both cases, over keys and values.\n# Python for key, value in my_dict.items(): print(key) print(value)// Scala for ((key, value) \u0026lt;- myMap){ println(key) println(value) }  #\n7. Tuples Yes, they are called the same in both languages! But, while they are zero-index in Python, they are not in Scala. Let’s create a tuple (1, 2, 3) and then call the first value.\n# Python my_tup = (1, 2, 3) my_tup[0]  # the indexing is the same as lists// Scala myTup = (1, 2, 3) myTup._1 // the indexing is way different than arrays!  8. Sets Yes, another name in common! In both examples below, the sets will contain only 1, 3, 5 because sets don’t accept duplicates.\nmy_set = {1, 3, 5, 1} # in **Python**, sets are defined by curly braces mySet = Set(1, 3, 5, 1) // **Scala**  9. Functions We have covered a lot so far, good job if you made it down here! This is the last thing paragraph of this post, and luckily defining a function is not that different between Python and Scala. They both start with def and while the former requires a return statement, the latter does not. On the other hand, Scala wants to know what types of variables we are going to input and output, while Python doesn’t care. Let’s write a very simple function that takes a string as input and returns the first 5 characters.\n# **Python** def chop_string(input_string): return input_string[0:5]  Indentation is also important in Python, or the function will not work. Scala instead just likes its curly braces.\n// **Scala** def chopString(inputString: String): String = { inputString.slice(0, 5) }  That’s it! I hope you found this helpful as an immediate reference for those of you who are just starting to get familiar with either Python or Scala. The following step will be to build a similar guide to explore the differences between pandas/sklearn and sparks, looking forward to it! I hope you do as well!\nIf you are wondering why you should use Python rather than Scala, or vice versa, I found the image below rather helpful in clarifying the immediate differences between the two.\nsource link\nFeel free to check out:\npart II of this post\nmy other Medium posts.\nmy LinkedIn profile.\n"});index.add({'id':105,'href':'/library/tutorials/docs/articles/python/python-scala-comparison-part-2/','title':"Python vs. Scala  (Part II)",'content':" Pandas vs. Spark: how to handle dataframes (Part II) “Panda statues on gray concrete stairs during daytime” by chuttersnap on Unsplash. “Scala” means “stairway” in Italian, my native language: hence the choice of the picture. It just seemed appropriate.\nA few days ago I published a post comparing the basic commands of Python and Scala: how to deal with lists and arrays, functions, loops, dictionaries and so on. As I continue practicing with Scala, it seemed appropriate to follow-up with a second part, comparing how to handle dataframes in the two programming languages, in order to get the data ready before the modeling process. In Python, we will do all this by using Pandas library, while in Scala we will use Spark.\n For this exercise, I will use the Titanic train dataset that can be easily downloaded at this link. Also, I do my Scala practices in Databricks: if you do so as well, remember to import your dataset first by clicking on Data and then Add Data.\n 1. Read the dataframe I will import and name my dataframe df, in Python this will be just two lines of code. This will work if you saved your train.csv in the same folder where your notebook is.\nimport pandas as pd df = pd.read_csv('train.csv')  Scala will require more typing.\nvar df = sqlContext .read .format(\u0026quot;csv\u0026quot;) .option(\u0026quot;header\u0026quot;, \u0026quot;true\u0026quot;) .option(\u0026quot;inferSchema\u0026quot;, \u0026quot;true\u0026quot;) .load(\u0026quot;Filestore/tables/train.csv\u0026quot;)  Let’s see what’s going on up here. Scala does not assume your dataset has a header, so we need to specify that. Also, Python will assign automatically a dtype to the dataframe columns, while Scala doesn’t do so, unless we specify .option(\u0026quot;inferSchema\u0026quot;, \u0026quot;true\u0026quot;). Also notice that I did not import Spark Dataframe, because I practice Scala in Databricks, and it is preloaded. Otherwise we will need to do so.\n Notice: booleans are capitalized in Python, while they are all lower-case in Scala!\n 2. Display the first rows of the dataframe In Python, df.head() will show the first five rows by default: the output will look like this.\ndf.head() output in Python.\nIf you want to see a number of rows different than five, you can just pass a different number in the parenthesis. Scala, with its df.show(),will display the first 20 rows by default.\ndf.show() in Scala.\nIf we want to keep it shorter, and also get rid of the ellipsis in order to read the entire content of the columns, we can run df.show(5, false).\n3. Dataframe Columns and Dtypes To retrieve the column names, in both cases we can just type df.columns: Scala and Pandas will return an Array and an Index of strings, respectively.\nIf we want to check the dtypes, the command is again the same for both languages: df.dtypes. Pandas will return a Series object, while Scala will return an Array of tuples, each tuple containing respectively the name of the\ndf.dtypes in Python\ncolumn and the dtype. So, if we are in Python and we want to check what type is the Age column, we run df.dtypes['Age'], while in Scala we will need to filter and use the Tuple indexing: df.dtypes.filter(colTup =\u0026gt; colTup._1 == \u0026quot;Age\u0026quot;).\n4. Summary Statistics This is another thing that every Data Scientist does while exploring his/her data: summary statistics. For every numerical column, we can see information such as count, mean, median, deviation, so on and so forth, to see immediately if there is something that doesn’t look right. In both cases this will return a dataframe, where the columns are the numerical columns of the original dataframe, and the rows are the statistical values.\nIn Python, we type df.describe(), while in Scala df.describe().show(). The reason we have to add the .show() in the latter case, is because Scala doesn’t output the resulting dataframe automatically, while Python does so (as long as we don’t assign it to a new variable).\n5. Select Columns Suppose we want to see a subset of columns, for example Name and Survived.\nIn Python we can use either df[['Name','Survived]] or df.loc[:,['Name','Survived] indistinctly. Remember that the : in this case means “all the rows”.\nIn Scala, we will type df.select(\u0026quot;Name\u0026quot;,\u0026quot;Survived\u0026quot;).show(). If you want to assign the subset to a new variable, remember to omit the .show().\n6. Filtering Let’s say we want to have a look at the Name and Pclass of the passengers who survived. We will need to filter a condition on the Survived column and then select the the other ones.\nIn Python, we will use .loc again, by passing the filter in the rows place and then selecting the columns with a list. Basically like the example above but substituting the : with a filter, which means\ndf.loc[df['Survived'] == 1, ['Name','Pclass']].  In Scala we will use .filter followed by .select, which will be df.filter(\u0026quot;Survived = 1\u0026quot;).select(\u0026quot;Name\u0026quot;,\u0026quot;Pclass\u0026quot;).show().\n6.1. Filtering null values If we want to check the null values, for example in the Embarked column, it will work like a normal filter, just with a different condition.\nIn Python, we apply the .isnull() when passing the condition, in this casedf[df['Embarked'].isnull()]. Since we didn’t specify any columns, this will return a dataframe will all the original columns, but only the rows where the Embarked values are empty.\nIn Scala, we will use .filter again: df.filter(\u0026quot;Embarked IS NULL\u0026quot;).show(). Notice that the boolean filters we pass in Scala, kind of look like SQL queries.\n7. Imputing Null Values We should always give some thought before imputing null values in a dataset, because it is something that will influence our final model and we want to be careful with that. However, just for demonstrative purposes, let’s say we want to impute the string “N/A” to the null values in our dataframe.\nWe can do so in Python with either df = df.fillna('N/A') or df.fillna('N/A', inplace = True).\nIn Scala, quite similarly, this would be achieved with df = df.na.fill(\u0026quot;N/A\u0026quot;). Remember to not use the .show() in this case, because we are assigning the revised dataframe to a variable.\n8. Renaming Columns This is something that you will need to for sure in Scala, since the machine learning models will need two columns named features and label in order to be trained. However, this is something you might want to do also in Pandas if you don’t like how a column has been named, for example. For this purpose, we want to change the Survived column into label.\nIn Python we will pass a dictionary, where the key and the value are respectively the old and the new name of the column. In this case, it will be\ndf.rename(columns = {\u0026quot;Survived\u0026quot;: \u0026quot;label\u0026quot;}, inplace = True).  In Scala, this equals to df = df.withColumnRenamed(\u0026quot;Survived\u0026quot;, \u0026quot;label\u0026quot;).\n9. Group By and Aggregation Let’s say we want to calculate the maximum Age for men and women distinctively, in this case .groubpby comes in handy. Not only to retrieve the maximum value; after .groupby we can use all sorts of aggregation functions: mean, count, median, so on and so forth. We stick with .max() for this example.\nIn Python this will be df.groupby('Sex').mean()['Age']. If we don’t specify ['Age'] after .mean(), this will return a dataframe with the maximum values for all numerical columns, grouped by Sex.\nIn Scala, we will need to import the aggregation function we want to use, first.\nimport org.apache.spark.sql.functions.max df.groupBy(\u0026quot;Sex\u0026quot;).agg(max(\u0026quot;Age\u0026quot;)).show()  10. Create a New Column This is really useful for feature engineering, we might want to combine two variables to see how their interaction is related to the target. For purely demonstrative purpose, let’s see how to create a column containing the product between Age and Fare.\nIn Python it is pretty straightforward.\ndf['Age_times_Fare'] = df['Age'] * df['Fare']  In Scala, we will need to put $ before the names of the columns we want to use, so that the column object with the corresponding name will be considered.\ndf = df.withColumn(\u0026quot;AgeTimesFare\u0026quot;, $\u0026quot;Age\u0026quot; * $\u0026quot;Fare\u0026quot;)  11. Correlation Exploring correlation among numerical variables and target is always convenient, and obtaining a matrix of correlation coefficients among all numeric variables is pretty easy in Python, just by running df.corr(). If you want to look at the correlation, let’s say between Age and Fare, we will just need to specify the columns: df[['Age','Fare']].corr().\nIn Scala, we will need to import first, and then run the command by specifying the columns.\nimport org.apache.spark.sql.functions.corr df.select(corr(\u0026quot;Age\u0026quot;,\u0026quot;Fare\u0026quot;)).show()  This is it! I hope you found this post useful as much as it has been useful for me writing it. I intend to publish a Part III where I can walk through a machine learning model example to kind of complete the circle!\n Written with StackEdit.\n "});index.add({'id':106,'href':'/library/tutorials/docs/articles/data-science/pandas/selecting-subsets-pandas-1/','title':"Selecting Subsets of Data 1",'content':" Selecting Subsets of Data in Pandas Part 1  Source  This article is available as a Jupyter Notebook complete with exercises at the bottom to practice and detailed solutions in another notebook.\nBecome an Expert  My book Master Data Analysis with Python is the most comprehensive text on the market to learn data analysis using Python and comes with 300+ exercises and projects. Sign-up for the FREE Intro to Pandas class Follow me on Twitter @TedPetrou for my daily data science tricks  Part 1: Selection with [ ], .loc and .iloc This is the beginning of a four-part series on how to select subsets of data from a pandas DataFrame or Series. Pandas offers a wide variety of options for subset selection which necessitates multiple articles. This series is broken down into the following four topics.\n Selection with [], .loc and .iloc` Boolean indexing Assigning subsets of data How NOT to select subsets of data  Assumptions before we begin These series of articles assume you have no knowledge of pandas, but that you understand the fundamentals of the Python programming language. It also assumes that you have installed pandas on your machine.\nThe easiest way to get pandas along with Python and the rest of the main scientific computing libraries is to install the Miniconda distribution (follow the link for a comprehensive tutorial).\nIf you have no knowledge of Python then I suggest completing the following two books cover to cover before even touching pandas. They are both free.\n Think Python by Allen B. Downey Automate the Boring Stuff by Al Sweigart  I also have a book titled Exercise Python ($15) which covers the fundamentals as well as providing 100+ exercises with detailed solutions.\nThe importance of making subset selections You might be wondering why there need to be so many articles on selecting subsets of data. This topic is extremely important to pandas and it’s unfortunate that it is fairly complicated because subset selection happens frequently during an actual analysis. Because you are frequently making subset selections, you need to master it in order to make your life with pandas easier.\nAlways reference the documentation The material in this article is also covered in the official pandas documentation on Indexing and Selecting Data. I highly recommend that you read that part of the documentation along with this tutorial. In fact, the documentation is one of the primary means for mastering pandas. I wrote a step-by-step article, How to Learn Pandas, which gives suggestions on how to use the documentation as you master pandas.\nThe anatomy of a DataFrame and a Series The pandas library has two primary containers of data, the DataFrame and the Series. You will spend nearly all your time working with both of the objects when you use pandas. The DataFrame is used more than the Series, so let’s take a look at an image of it first.\nAnatomy of a DataFrame\nThis image comes with some added illustrations to highlight its components. At first glance, the DataFrame looks like any other two-dimensional table of data that you have seen. It has rows and it has columns. Technically, there are three main components of the DataFrame.\nThe three components of a DataFrame A DataFrame is composed of three different components, the index, columns, and the data. The data is also known as the values.\nThe index represents the sequence of values on the far left-hand side of the DataFrame. All the values in the index are in bold font. Each individual value of the index is called a label. Sometimes the index is referred to as the row labels. In the example above, the row labels are not very interesting and are just the integers beginning from 0 up to n-1, where n is the number of rows in the table. Pandas defaults DataFrames with this simple index.\nThe columns are the sequence of values at the very top of the DataFrame. They are also in bold font. Each individual value of the columns is called a column, but can also be referred to as column name or column label.\nEverything else not in bold font is the data or values. You will sometimes hear DataFrames referred to as tabular data. This is just another name for a rectangular table data with rows and columns.\nAxis and axes It is also common terminology to refer to the rows or columns as an axis. Collectively, we call them axes. So, a row is an axis and a column is another axis.\nThe word axis appears as a parameter in many DataFrame methods. Pandas allows you to choose the direction of how the method will work with this parameter. This has nothing to do with subset selection so you can just ignore it for now.\nEach row has a label and each column has a label The main takeaway from the DataFrame anatomy is that each row has a label and each column has a label. These labels are used to refer to specific rows or columns in the DataFrame. It’s the same as how humans use names to refer to specific people.\nWhat is subset selection? Before we start doing subset selection, it might be good to define what it is. Subset selection is simply selecting particular rows and columns of data from a DataFrame (or Series). This could mean selecting all the rows and some of the columns, some of the rows and all of the columns, or some of each of the rows and columns.\nExample selecting some columns and all rows Let’s see some images of subset selection. We will first look at a sample DataFrame with fake data.\nSample DataFrame\nLet’s say we want to select just the columns color, age, and height but keep all the rows.\nOur final DataFrame would look like this:\nExample selecting some rows and all columns We can also make selections that select just some of the rows. Let’s select the rows with labels Aaron and Dean along with all of the columns:\nOur final DataFrame would like:\nExample selecting some rows and some columns Let’s combine the selections from above and select the columns color, age, and height for only the rows with labels Aaron and Dean.\nOur final DataFrame would look like this:\nPandas dual references: by label and by integer location We already mentioned that each row and each column have a specific label that can be used to reference them. This is displayed in bold font in the DataFrame.\nBut, what hasn’t been mentioned, is that each row and column may be referenced by an integer as well. I call this integer location. The integer location begins at 0 and ends at n-1 for each row and column. Take a look above at our sample DataFrame one more time.\nThe rows with labels Aaron and Dean can also be referenced by their respective integer locations 2 and 4. Similarly, the columns color, age and height can be referenced by their integer locations 1, 3, and 4.\nThe documentation refers to integer location as position. I don’t particularly like this terminology as its not as explicit as integer location. The key thing term here is INTEGER.\nWhat’s the difference between indexing and selecting subsets of data? The documentation uses the term indexing frequently. This term is essentially just a one-word phrase to say ‘subset selection’. I prefer the term subset selection as, again, it is more descriptive of what is actually happening. Indexing is also the term used in the official Python documentation.\nFocusing only on [], .loc, and .iloc There are many ways to select subsets of data, but in this article we will only cover the usage of the square brackets [ ], .loc and .iloc. Collectively, they are called the indexers. These are by far the most common ways to select data. A different part of this Series will discuss a few methods that can be used to make subset selections.\nIf you have a DataFrame, df, your subset selection will look something like the following:\ndf[ ] df.loc[ ] df.iloc[ ]  A real subset selection will have something inside of the square brackets. All selections in this article will take place inside of those square brackets.\nNotice that the square brackets also follow .loc and .iloc. All indexing in Python happens inside of these square brackets.\nA term for just those square brackets The term indexing operator is used to refer to the square brackets following an object. The .loc and .iloc indexers also use the indexing operator to make selections. I will use the term just the indexing operator to refer to df[]. This will distinguish it from df.loc[] and df.iloc[].\nRead in data into a DataFrame with read_csv Let’s begin using pandas to read in a DataFrame, and from there, use the indexing operator by itself to select subsets of data. All the data for these tutorials are in the data directory.\nWe will use the read_csv function to read in data into a DataFrame. We pass the path to the file as the first argument to the function. We will also use the index_col parameter to select the first column of data as the index (more on this later).\nimport pandas as pd import numpy as np df = pd.read_csv('data/sample_data.csv', index_col=0) df  Extracting the individual DataFrame components Earlier, we mentioned the three components of the DataFrame. The index, columns and data (values). We can extract each of these components into their own variables. Let’s do that and then inspect them:\nindex = df.index columns = df.columns values = df.values index  Index(['Jane', 'Niko', 'Aaron', 'Penelope', 'Dean', 'Christina', 'Cornelia'], dtype='object')  columns  Index(['state', 'color', 'food', 'age', 'height', 'score'], dtype='object')  values  array([['NY', 'blue', 'Steak', 30, 165, 4.6], ['TX', 'green', 'Lamb', 2, 70, 8.3], ['FL', 'red', 'Mango', 12, 120, 9.0], ['AL', 'white', 'Apple', 4, 80, 3.3], ['AK', 'gray', 'Cheese', 32, 180, 1.8], ['TX', 'black', 'Melon', 33, 172, 9.5], ['TX', 'red', 'Beans', 69, 150, 2.2]], dtype=object)  Data types of the components Let’s output the type of each component to understand exactly what kind of object they are.\ntype(index)  pandas.core.indexes.base.Index  type(columns)  pandas.core.indexes.base.Index  type(values)  numpy.ndarray  Understanding these types Interestingly, both the index and the columns are the same type. They are both a pandas Index object. This object is quite powerful in itself, but for now you can just think of it as a sequence of labels for either the rows or the columns.\nThe values are a NumPy ndarray, which stands for n-dimensional array, and is the primary container of data in the NumPy library. Pandas is built directly on top of NumPy and it\u0026rsquo;s this array that is responsible for the bulk of the workload.\nBeginning with just the indexing operator on DataFrames We will begin our journey of selecting subsets by using just the indexing operator on a DataFrame. Its main purpose is to select a single column or multiple columns of data.\nSelecting a single column as a Series To select a single column of data, simply put the name of the column in-between the brackets. Let’s select the food column:\ndf['food']  Jane Steak Niko Lamb Aaron Mango Penelope Apple Dean Cheese Christina Melon Cornelia Beans Name: food, dtype: object  Anatomy of a Series Selecting a single column of data returns the other pandas data container, the Series. A Series is a one-dimensional sequence of labeled data. There are two main components of a Series, the index and the data(or values). There are NO columns in a Series.\nThe visual display of a Series is just plain text, as opposed to the nicely styled table for DataFrames. The sequence of person names on the left is the index. The sequence of food items on the right is the values.\nYou will also notice two extra pieces of data on the bottom of the Series. The name of the Series becomes the old-column name. You will also see the data type or dtype of the Series. You can ignore both these items for now.\nSelecting multiple columns with just the indexing operator It’s possible to select multiple columns with just the indexing operator by passing it a list of column names. Let’s select color, food, and score:\ndf[['color', 'food', 'score']]  Selecting multiple columns returns a DataFrame Selecting multiple columns returns a DataFrame. You can actually select a single column as a DataFrame with a one-item list:\ndf[['food']]  Although, this resembles the Series from above, it is technically a DataFrame, a different object.\nColumn order doesn’t matter When selecting multiple columns, you can select them in any order that you choose. It doesn’t have to be the same order as the original DataFrame. For instance, let’s select height and color.\ndf[['height', 'color']]  Exceptions There are a couple common exceptions that arise when doing selections with just the indexing operator.\n If you misspell a word, you will get a KeyError If you forgot to use a list to contain multiple columns you will also get a KeyError\ndf['hight']  KeyError: 'hight'\u0026gt;\u0026gt;\u0026gt; df['color', 'age'] # should be: df[['color', 'age']] KeyError: ('color', 'age')  Summary of just the indexing operator Its primary purpose is to select columns by the column names\n Select a single column as a Series by passing the column name directly to it: df[\u0026lsquo;col_name\u0026rsquo;]\n Select multiple columns as a DataFrame by passing a list to it: df[[\u0026lsquo;col_name1, col_name2\u0026rsquo;]]\n You actually can select rows with it, but this will not be shown here as it is confusing and not used often.\n  Getting started with .loc The = .loc indexer selects data in a different way than just the indexing operator. It can select subsets of rows or columns. It can also simultaneously select subsets of rows and columns. Most importantly, it only selects data by the LABEL of the rows and columns.\nSelect a single row as a Series with .loc The .loc indexer will return a single row as a Series when given a single row label. Let\u0026rsquo;s select the row for Niko.\ndf.loc['Niko']  state TX color green food Lamb age 2 height 70 score 8.3 Name: Niko, dtype: object  We now have a Series, where the old column names are now the index labels. The name of the Series has become the old index label, Niko in this case.\nSelect multiple rows as a DataFrame with .loc To select multiple rows, put all the row labels you want to select in a list and pass that to .loc. Let\u0026rsquo;s select Niko and Penelope.\ndf.loc[['Niko', 'Penelope']]  Use slice notation to select a range of rows with .loc It is possible to ‘slice’ the rows of a DataFrame with .loc by using slice notation. Slice notation uses a colon to separate start, stop and step values. For instance we can select all the rows from Niko through Dean like this:\ndf.loc['Niko':'Dean']  .loc includes the last value with slice notation Notice that the row labeled with Dean was kept. In other data containers such as Python lists, the last value is excluded.\nOther slices You can use slice notation similarly to how you use it with lists. Let’s slice from the beginning through Aaron:\ndf.loc[:'Aaron']  Slice from Niko to Christina stepping by 2:\ndf.loc['Niko':'Christina':2]  Slice from Dean to the end:\ndf.loc['Dean':]  Selecting rows and columns simultaneously with .loc Unlike just the indexing operator, it is possible to select rows and columns simultaneously with .loc. You do it by separating your row and column selections by a comma. It will look something like this:\ndf.loc[row_selection, column_selection]  Select two rows and three columns For instance, if we wanted to select the rows Dean and Cornelia along with the columns age, state and score we would do this:\ndf.loc[['Dean', 'Cornelia'], ['age', 'state', 'score']]  Use any combination of selections for either row or columns for .loc Row or column selections can be any of the following as we have already seen:\n A single label A list of labels A slice with labels  We can use any of these three for either row or column selections with .loc. Let\u0026rsquo;s see some examples.\nLet’s select two rows and a single column:\ndf.loc[['Dean', 'Aaron'], 'food']  Dean Cheese Aaron Mango Name: food, dtype: object  Select a slice of rows and a list of columns:\ndf.loc['Jane':'Penelope', ['state', 'color']]  Select a single row and a single column. This returns a scalar value.\ndf.loc['Jane', 'age']  30  Select a slice of rows and columns\ndf.loc[:'Dean', 'height':]  Selecting all of the rows and some columns It is possible to select all of the rows by using a single colon. You can then select columns as normal:\ndf.loc[:, ['food', 'color']]  You can also use this notation to select all of the columns:\ndf.loc[['Penelope','Cornelia'], :]  But, it isn’t necessary as we have seen, so you can leave out that last colon:\ndf.loc[['Penelope','Cornelia']]  Assign row and column selections to variables It might be easier to assign row and column selections to variables before you use .loc. This is useful if you are selecting many rows or columns:\nrows = ['Jane', 'Niko', 'Dean', 'Penelope', 'Christina'] cols = ['state', 'age', 'height', 'score'] df.loc[rows, cols]  Summary of .loc  Only uses labels Can select rows and columns simultaneously Selection can be a single label, a list of labels or a slice of labels Put a comma between row and column selections  If you are enjoying this article, consider purchasing the All Access Pass! which includes all my current and future material for one low price.\nGetting started with .iloc The .iloc indexer is very similar to .loc but only uses integer locations to make its selections. The word .iloc itself stands for integer location so that should help with remember what it does.\nSelecting a single row with .iloc By passing a single integer to .iloc, it will select one row as a Series:\ndf.iloc[3]  state AL color white food Apple age 4 height 80 score 3.3 Name: Penelope, dtype: object  Selecting multiple rows with .iloc Use a list of integers to select multiple rows:\ndf.iloc[[5, 2, 4]] # remember, don't do df.iloc[5, 2, 4]  Use slice notation to select a range of rows with .iloc Slice notation works just like a list in this instance and is exclusive of the last element\ndf.iloc[3:5]  Select 3rd position until end:\ndf.iloc[3:]  Select 3rd position to end by 2:\ndf.iloc[3::2]  Selecting rows and columns simultaneously with .iloc Just like with .iloc any combination of a single integer, lists of integers or slices can be used to select rows and columns simultaneously. Just remember to separate the selections with a comma.\nSelect two rows and two columns:\ndf.iloc[[2,3], [0, 4]]  Select a slice of the rows and two columns:\ndf.iloc[3:6, [1, 4]]  Select slices for both\ndf.iloc[2:5, 2:5]  Select a single row and column\ndf.iloc[0, 2]  'Steak'  Select all the rows and a single column\ndf.iloc[:, 5]  Jane 4.6 Niko 8.3 Aaron 9.0 Penelope 3.3 Dean 1.8 Christina 9.5 Cornelia 2.2 Name: score, dtype: float64  Deprecation of .ix Early in the development of pandas, there existed another indexer, **ix**. This indexer was capable of selecting both by label and by integer location. While it was versatile, it caused lots of confusion because it\u0026rsquo;s not explicit. Sometimes integers can also be labels for rows or columns. Thus there were instances where it was ambiguous.\nYou can still call .ix, but it has been deprecated, so please never use it.\nSelecting subsets of Series We can also, of course, do subset selection with a Series. Earlier I recommended using just the indexing operator for column selection on a DataFrame. Since Series do not have columns, I suggest using only .loc and .iloc. You can use just the indexing operator, but its ambiguous as it can take both labels and integers. I will come back to this at the end of the tutorial.\nTypically, you will create a Series by selecting a single column from a DataFrame. Let’s select the food column:\nfood = df['food'] food  Jane Steak Niko Lamb Aaron Mango Penelope Apple Dean Cheese Christina Melon Cornelia Beans Name: food, dtype: object  Series selection with .loc Series selection with .loc is quite simple, since we are only dealing with a single dimension. You can again use a single row label, a list of row labels or a slice of row labels to make your selection. Let\u0026rsquo;s see several examples.\nLet’s select a single value:\nfood.loc['Aaron']  'Mango'  Select three different values. This returns a Series:\nfood.loc[['Dean', 'Niko', 'Cornelia']]  Dean Cheese Niko Lamb Cornelia Beans Name: food, dtype: object  Slice from Niko to Christina - is inclusive of last index\nfood.loc['Niko':'Christina']  Niko Lamb Aaron Mango Penelope Apple Dean Cheese Christina Melon Name: food, dtype: object  Slice from Penelope to the end:\nfood.loc['Penelope':]  Penelope Apple Dean Cheese Christina Melon Cornelia Beans Name: food, dtype: object  Select a single value in a list which returns a Series\nfood.loc[['Aaron']]  Aaron Mango Name: food, dtype: object  Series selection with .iloc Series subset selection with .iloc happens similarly to .loc except it uses integer location. You can use a single integer, a list of integers or a slice of integers. Let\u0026rsquo;s see some examples.\nSelect a single value:\nfood.iloc[0]  'Steak'  Use a list of integers to select multiple values:\nfood.iloc[[4, 1, 3]]  Dean Cheese Niko Lamb Penelope Apple Name: food, dtype: object  Use a slice — is exclusive of last integer\nfood.iloc[4:6]  Dean Cheese Christina Melon Name: food, dtype: object  Comparison to Python lists and dictionaries It may be helpful to compare pandas ability to make selections by label and integer location to that of Python lists and dictionaries.\nPython lists allow for selection of data only through integer location. You can use a single integer or slice notation to make the selection but NOT a list of integers.\nLet’s see examples of subset selection of lists using integers:\nsome_list = ['a', 'two', 10, 4, 0, 'asdf', 'mgmt', 434, 99] some_list[5]  asdf  some_list[-1]  99  some_list[:4]  ['a', 'two', 10, 4]  some_list[3:]  [4, 0, 'asdf', 'mgmt', 434, 99]\u0026gt;\u0026gt;\u0026gt; some_list[2:6:3] [10, 'asdf']  Selection by label with Python dictionaries All values in each dictionary are labeled by a key. We use this key to make single selections. Dictionaries only allow selection with a single label. Slices and lists of labels are not allowed.\nd = {'a':1, 'b':2, 't':20, 'z':26, 'A':27} d['a']  1  d['A']  27  Pandas has power of lists and dictionaries DataFrames and Series are able to make selections with integers like a list and with labels like a dictionary.\nExtra Topics There are a few more items that are important and belong in this tutorial and will be mentioned now.\nUsing just the indexing operator to select rows from a DataFrame — Confusing! Above, I used just the indexing operator to select a column or columns from a DataFrame. But, it can also be used to select rows using a slice. This behavior is very confusing in my opinion. The entire operation changes completely when a slice is passed.\nLet’s use an integer slice as our first example:\ndf[3:6]  To add to this confusion, you can slice by labels as well.\ndf['Aaron':'Christina']  I recommend not doing this! This feature is not deprecated and completely up to you whether you wish to use it. But, I highly prefer not to select rows in this manner as can be ambiguous, especially if you have integers in your index.\nUsing .iloc and .loc is explicit and clearly tells the person reading the code what is going to happen. Let\u0026rsquo;s rewrite the above using .iloc and .loc.\ndf.iloc[3:6] # More explicit that df[3:6]  df.loc['Aaron':'Christina']  Cannot simultaneously select rows and columns with [] An exception will be raised if you try and select rows and columns simultaneously with just the indexing operator. You must use .loc or .iloc to do so.\ndf[3:6, 'Aaron':'Christina']  TypeError: unhashable type: 'slice'  Using just the indexing operator to select rows from a Series — Confusing! You can also use just the indexing operator with a Series. Again, this is confusing because it can accept integers or labels. Let’s see some examples\nfood  Jane Steak Niko Lamb Aaron Mango Penelope Apple Dean Cheese Christina Melon Cornelia Beans Name: food, dtype: object  food[2:4]  Aaron Mango Penelope Apple Name: food, dtype: object  food['Niko':'Dean']  Niko Lamb Aaron Mango Penelope Apple Dean Cheese Name: food, dtype: object  Since Series don’t have columns you can use a single label and list of labels to make selections as well\nfood['Dean']  'Cheese'  food[['Dean', 'Christina', 'Aaron']]  Dean Cheese Christina Melon Aaron Mango Name: food, dtype: object  Again, I recommend against doing this and always use .iloc or .loc\nImporting data without choosing an index column We imported data by choosing the first column to be the index with the index_col parameter of the read_csv function. This is not typically how most DataFrames are read into pandas.\nUsually, all the columns in the csv file become DataFrame columns. Pandas will use the integers 0 to n-1 as the labels. See the example data below with a slightly different dataset:\ndf2 = pd.read_csv('data/sample_data2.csv') df2  The default RangeIndex If you don’t specify a column to be the index when first reading in the data, pandas will use the integers 0 to n-1 as the index. This technically creates a **RangeIndex** object. Let\u0026rsquo;s take a look at it.\ndf2.index  RangeIndex(start=0, stop=7, step=1)  This object is similar to Python range objects. Let\u0026rsquo;s create one:\nrange(7)  range(0, 7)  Converting both of these objects to a list produces the exact same thing:\nlist(df2.index)  [0, 1, 2, 3, 4, 5, 6]  list(range(7))  [0, 1, 2, 3, 4, 5, 6]  For now, it’s not at all important that you have a **RangeIndex**. Selections from it happen just the same with **.loc** and **.iloc**. Let\u0026rsquo;s look at some examples.\ndf2.loc[[2, 4, 5], ['food', 'color']]  df2.iloc[[2, 4, 5], [3,2]]  There is a subtle difference when using a slice. .iloc excludes the last value, while .loc includes it:\ndf2.iloc[:3]  df2.loc[:3]  Setting an index from a column after reading in data It is common to see pandas code that reads in a DataFrame with a RangeIndex and then sets the index to be one of the columns. This is typically done with the set_index method:\ndf2_idx = df2.set_index('Names') df2_idx  The index has a name Notice that this DataFrame does not look exactly like our first one from the very top of this tutorial. Directly above the index is the bold-faced word Names. This is technically the name of the index. Our original DataFrame had no name for its index. You can ignore this small detail for now. Subset selections will happen in the same fashion.\nDataFrame column selection with dot notation Pandas allows you to select a single column as a Series by using dot notation. This is also referred to as attribute access. You simply place the name of the column without quotes following a dot and the DataFrame like this:\ndf.state  Jane NY Niko TX Aaron FL Penelope AL Dean AK Christina TX Cornelia TX Name: state, dtype: object  df.age  Jane 30 Niko 2 Aaron 12 Penelope 4 Dean 32 Christina 33 Cornelia 69 Name: age, dtype: int64  Pros and cons when selecting columns by attribute access The best benefit of selecting columns like this is that you get help when chaining methods after selection. For instance, if you place another dot after the column name and press tab, a list of all the Series methods will appear in a pop-up menu. It will look like this:\nThis help disappears when you use just the indexing operator:\nThe biggest drawback is that you cannot select columns that have spaces or other characters that are not valid as Python identifiers (variable names).\nSelecting the same column twice? This is rather peculiar, but you can actually select the same column more than once:\ndf[['age', 'age', 'age']]  Summary of Part 1 We covered an incredible amount of ground. Let’s summarize all the main points:\n Before learning pandas, ensure you have the fundamentals of Python Always refer to the documentation when learning new pandas operations The DataFrame and the Series are the containers of data A DataFrame is two-dimensional, tabular data A Series is a single dimension of data The three components of a DataFrame are the index, the columns and the data (or values) Each row and column of the DataFrame is referenced by both a label and an integer location There are three primary ways to select subsets from a DataFrame — [], .loc and .iloc I use the term just the indexing operator to refer to [] immediately following a DataFrame/Series Just the indexing operator’s primary purpose is to select a column or columns from a DataFrame Using a single column name to just the indexing operator returns a single column of data as a Series Passing multiple columns in a list to just the indexing operator returns a DataFrame A Series has two components, the index and the data (values). It has no columns .loc makes selections only by label .loc can simultaneously select rows and columns .loc can make selections with either a single label, a list of labels, or a slice of labels .loc makes row selections first followed by column selections: df.loc[row_selection, col_selection] .iloc is analogous to .loc but uses only integer location to refer to rows or columns. .ix is deprecated and should never be used .loc and .iloc work the same for Series except they only select based on the index as there are no columns Pandas combines the power of python lists (selection via integer location) and dictionaries (selection by label) You can use just the indexing operator to select rows from a DataFrame, but I recommend against this and instead sticking with the explicit .loc and .iloc Normally data is imported without setting an index. Use the set_index method to use a column as an index. You can select a single column as a Series from a DataFrame with dot notation  Way more to the story This is only part 1 of the series, so there is much more to cover on how to select subsets of data in pandas. Some of the explanations in this part will be expanded to include other possibilities.\nExercises This best way to learn pandas is to practice on your own. All these exercises will use the Chicago food inspections dataset found here at data.world.\n Download the Jupyter Notebook to get started on the exercises. Make sure to review the detailed solutions as well after you attempt the exercises  Get the All Access Pass! Get all of my current and future material for one low price with the All Access Pass! The primary courses available are the following:\n Exercise Python Master Data Analysis with Python Master Machine Learning with Python  "});index.add({'id':107,'href':'/library/tutorials/docs/articles/python/use-python-send-email/','title':"Send email using SMTP",'content':" Use Python to send email using SMTP Use Python to send emails\nIn this tutorial, we will learn to use python to send emails. If you are new to python, you can see our beginner’s series. In case you are having trouble installing Python, you can see our posts on installing python on MacOS and Windows.\nWe will start with sending plain email using python and then learn to send advanced automated emails, HTML emails, emails with attachments etc. In this tutorial, we will be using gmail to send email via python, which is the most common email service used. However, you can use any other email service.(You will have to use slightly different setting in that case.)\nOpen your gmail account. If you are not using\n2-Step Verification, you will have to allow less secure apps from this link.\nHowever, if you are using 2-Step Verification (which I highly recommend), you need to create app password for your account for this project from here. You can learn to create app passwords from google’s official documentation.\nWe do not want to hard code our username and password, so we will be using environment variable to set them. Open the .bash_profile of your MacOS and save the email and password (or app password in case of 2-step verification) as under:-\n$ nano .bash_profile  # .bash_profile export EMAIL_USER=\u0026quot;your_email\u0026quot; export PASSWORD=\u0026quot;your_password\u0026quot;  $ source .bash_profile  Sending simple email using python\nNow create a file called ‘python_send_email.py’ and import smtplib and write down the following code:-\n# python_send_email.py import os import smtplib EMAIL = os.environ.get('EMAIL_USER') PASSWORD = os.environ.get('PASSWORD') with smtplib.SMTP('smtp.gmail.com', 587) as smtp: smtp.ehlo() smtp.starttls() smtp.ehlo() smtp.login(EMAIL, PASSWORD) subject = 'Python Send Email' body = 'This email is sent using python' message = f'Subject:{subject}\\n\\n{body}' smtp.sendmail(EMAIL, EMAIL, message)  Let me quickly go through each step.\nWe have used os to use environment variables where we have saved our username and password.\nThen we have used the context manager, so that the connection ends by itself after the script is complete.\nThen we identified ourselves using smtp.ehlo(), then we put it in the connection mode using smtp.starttls() and logged in using smtp.login().\nFinally, we will draft the email by adding subject, body, message and send it using smtp.sendmail(sender, receipient, message). Running the script will send the simple email to the user.\nSending email using local debugging server\nWhile we are testing/learning, it could be frustrating to use real email, so we will start local debugging server using the following command. When we will run this, all the future emails which we will send using our script will be displayed on the terminal.\n$ python -m smtpd -c DebuggingServer -n localhost:1025  Now, we will have to make following changes to python_send_email.py :-\n# python_send_email.py # with smtplib.SMTP('smtp.gmail.com', 587) as smtp: with smtplib.SMTP('localhost', 1025) as smtp: #add this and comment out the rest # smtp.ehlo() # smtp.starttls() # smtp.ehlo() # smtp.login(EMAIL, PASSWORD)  Now if we will run our python_send_email.py, it will be displayed in the terminal.\nCleaning it up\nInstead of calling the server using smtp.ehlo() we will be creating a SSL connection from the very beginning using smptlib.SMTP_SSL and instead of port 587, we will use port 465. Now, we will be taking advantage of EmailMessage class of email.message to create a message and finally smtp.send_message() to send that message. The modified code is as under:-\n# python_send_email.py import os import smtplib from email.message import EmailMessage #new EMAIL = os.environ.get('EMAIL_USER') PASSWORD = os.environ.get('PASSWORD') message = EmailMessage() message['Subject'] = 'Python Send Email' message['From'] = EMAIL message['To'] = EMAIL message.set_content('This email is sent using python.') with smtplib.SMTP_SSL('smtp.gmail.com', 465) as smtp: smtp.login(EMAIL, PASSWORD) smtp.send_message(message)  Python - send email with attachment\nNow we will be sending the emails with attachment. In order to send an image we will be using imghdr to find out the type of the image. Now place the image python_send_email.jpg in the same directory as the script python_send_email.py and change the code as under:\n# python_send_email.py import imghdr # new with open('python_send_email.jpg', 'rb') as f: file_data = f.read() file_type = imghdr.what(f.name) file_name = f.name message.add_attachment(file_data, maintype='image', subtype=file_type, filename=file_name)   Written with StackEdit.\n "});index.add({'id':108,'href':'/library/tutorials/docs/articles/python/set-passwords-and-secret-keys/','title':"Set Passwords and Secret Keys",'content':" Set Passwords and Secret Keys in Environment Variables (Mac/Linux/Windows) Hide Passwords and Secret Keys in Environment Variables\nIf you are into python , there is a fair chance that you would have contributed to open-source or had your code snippets/projects on Github or BitBucket.Some time your code involves some important credentials like passwords or secret keys etc. like the code for our post on how to send emails using python uses google/app password. You surely do not want to hard code the password in your code and accidentaly push it to a remote repository. Hence, the safest way is to do so is saving your secret keys/password in envirnoment variables. In this post we will learn how to save/hide the passwords, secret keys in environment variables for MacOS, Linux and Windows.\nThe wrong way\nHard coding your username, passwords or secret keys in your code is wrong way and it exposes you to vulnerability. Have a look at the code below:-\n# The wrong way user_name = 'my_user_name' password = 'my_password' print(user_name, password) # output my_user_name my_password  Set Passwords and Secret Keys in Environment Variables on Mac/Linux\nTo set password and secret keys in environment variable on Mac and Linux. You will need to open and modify .bash_profile . To do that open the terminal on your Mac or Linux and cd to the home directory. (You can read about useful terminal commands of mac here)\nuser desktop $ cd user ~ $  Now open the .bash_profile using your favorite editor like nano , vim , sublime text , atom etc. You can read a bit more about the text editors here\nuser ~ $ nano .bash_profile  The following file will open . You may not have the same text like mine there.\nNow we need to add our environment variables. For that we will have to write the following code. Remember that there is no whitespace on either side of =.\nexport USER=\u0026quot;my_user_name\u0026quot; export PASSWORD=\u0026quot;my_password\u0026quot;  Press ctrl + x and Y to save the nano file.\nNow either restart the terminal or use the following command to effect the changes.\nuser ~ $ source .bash_profile  Now to use these variables in our python script, we will be needing os module. Have a look at the following code. Here instead of hard coding the username and password like the example above, we have used the environment variables and still the result is same.\nimport os user_name = os.environ.get('USER') password = os.environ.get('password') print(user_name, password) # output my_user_name my_password  Set Passwords and Secret Keys in Environment Variables on Windows\nTo set the passwords and secret keys in environment variables on Windows, you will have to open Advance System Setting. You can either type ‘Advanced System Setting’ in search bar or browse to it by right clicking My Computer on desktop-\u0026gt; properties -\u0026gt; Advanced System Setting\nNow in Advance System Setting you will have to click on Environment Variables and the following screen will appear.\nNow, here we need to add new user variable. So click on new and add both the variables.\nNow using the same code as above, we can access the environmental variables.\nimport os user_name = os.environ.get('USER') password = os.environ.get('password') print(user_name, password) # output my_user_name my_password   Written with StackEdit.\n "});index.add({'id':109,'href':'/library/tutorials/docs/articles/data-science/finance/stock-analysis-in-python/','title':"Stock Analysis in Python",'content':" Stock Analysis in Python Exploring financial data with object-oriented programming and additive models\nIt’s easy to get carried away with the wealth of data and free open-source tools available for data science. After spending a little bit of time with the quandl financial library and the prophet modeling library, I decided to try some simple stock data exploration. Several days and 1000 lines of Python later, I ended up with a complete stock analysis and prediction tool. Although I am not confident (or foolish) enough to use it to invest in individual stocks, I learned a ton of Python in the process and in the spirit of open-source, want to share my results and code so others can benefit.\nNow more than ever\nThis article will show how to use Stocker, a Python class-based tool for stock analysis and prediction (the name was originally arbitrary, but I decided after the fact it nicely stands for “stock explorer”). I had tried several times to conquer classes, the foundation of object-oriented programming in Python, but as with most programming topics, they never quite made sense to me when I read the books. It was only when I was deep in a project faced with a problem I had not solved before that the concept finally clicked, showing once again that experience beats theoretical explanations! In addition to an exploration of Stocker, we will touch on some important topics including the basics of a Python class and additive models. For anyone wanting to use Stocker, the complete code can be found on GitHub along with documentation for usage. Stocker was designed to be easy to use (even for those new to Python), and I encourage anyone reading to try it out. Now, let’s take a look at the analysis capabilities of Stocker!\nGetting Started with Stocker After installing the required libraries, the first thing we do is import the Stocker class into our Python session. We can do this from an interactive Python session or a Jupyter Notebook started in the directory with the script.\nfrom stocker import Stocker  We now have the Stocker class in our Python session, and we can use it to create an instance of the class. In Python, an instance of a class is called an object, and the act of creating an object is sometimes called instantiation or construction. In order to make a Stocker object we need to pass in the name of a valid stock ticker (bold indicates output).\nmicrosoft = Stocker('MSFT') MSFT Stocker Initialized. Data covers 1986-03-13 to 2018-01-16.  Now, we have a microsoftobject with all the properties of the Stocker class. Stocker is built on the quandl WIKI database which gives us access to over 3000 US stocks with years of daily price data (full list). For this example, we will stick to Microsoft data. Although Microsoft might be seen as the opposite of open-source, they have recently made some changes that make me optimist they are embracing the open-source community (including Python).\nA class in Python is comprised of two main parts: attributes and methods. Without going into too much detail, attributes are values or data associated either with the class as a whole or with specific instances (objects) of the class. Methods are functions contained in the class which can act on that data. One attribute of a Stocker object is stock data for a specific company that is attribute is associated with the object when we construct it. We can access the attribute and assign it to another variable for inspection:\n# Stock is an attribute of the microsoft object stock_history = microsoft.stock stock_history.head()  Microsoft Stock Data\nThe benefit of a Python class is that the methods (functions) and the data they act on are associated with the same object. We can use a method of the Stocker object to plot the entire history of the stock.\n# A method (function) requires parentheses microsoft.plot_stock() Maximum Adj. Close = 89.58 on 2018-01-12. Minimum Adj. Close = 0.06 on 1986-03-24. Current Adj. Close = 88.35.  The default value plotted is the Adjusted Closing price, which accounts for splits in the stock (when one stock is split into multiple stocks, say 2, with each new stock worth 1\u0026frasl;2 of the original price).\nThis is a pretty basic plot that we could have found from a Google Search, but there is something satisfying about doing it ourselves in a few lines of Python! The plot_stockfunction has a number of optional arguments. By default, this method plots the Adjusted Closing price for the entire date range, but we can choose the range, the stats to plot, and the type of plot. For example, if we want to compare the Daily Change in price with the Adjusted Volume (number of shares) traded, we can specify those in the function call.\nmicrosoft.plot_stock(start_date = '2000-01-03', end_date = '2018-01-16', stats = ['Daily Change', 'Adj. Volume'], plot_type='pct') Maximum Daily Change = 2.08 on 2008-10-13. Minimum Daily Change = -3.34 on 2017-12-04. Current Daily Change = -1.75. Maximum Adj. Volume = 591052200.00 on 2006-04-28. Minimum Adj. Volume = 7425503.00 on 2017-11-24. Current Adj. Volume = 35945428.00.  Notice the y-axis is in percentage change relative to the average value for the statistic. This scale is necessary because the daily volume is originally in shares, with a range in the hundreds of millions, while daily price change typically is a few dollars! By converting to percentage change we can look at both datasets on a similar scale. The plot shows there is no correlation between the number of shares traded and the daily change in price. This is surprising as we might have expected more shares to be traded on days with larger price changes as people rush to take advantage of the swings. However, the only real trend seems to be that the volume traded decreases over time. There is also a significant decrease in price on December 4, 2017 that we could try to correlate with news stories about Microsoft. A quick news search for December 3 yields the following:\nNot sure about the reliability of these sources Google\nThere certainly does not seem to be any indication that Microsoft stock is due for its largest price decrease in 10 years the next day! In fact, if we were playing the stock market based on news, we might have been tempted to buy stock because a deal with the NFL (second result) sounds like a positive!\nUsing plot_stock,we can investigate any of the quantities in the data across any date range and look for correlations with real-world events (if there are any). For now, we will move on to one of the more enjoyable parts of Stocker: making fake money!\nLet’s pretend for a moment we had the presence of mind to invest in 100 shares of Microsoft at the company’s Initial Public Offering (IPO). How much richer would we be now?\nmicrosoft.buy_and_hold(start_date='1986-03-13', end_date='2018-01-16', nshares=100) MSFT Total buy and hold profit from 1986-03-13 to 2018-01-16 for 100 shares = $8829.11  In addition to making us feel better, using these results will allow us to plan our trips back in time to maximize profits.\nIf we are feeling too confident, we can try to tweak the results to lose money:\nmicrosoft.buy_and_hold(start_date='1999-01-05', end_date='2002-01-03', nshares=100) MSFT Total buy and hold profit from 1999-01-05 to 2002-01-03 for 100 shares = $-56.92  Surprisingly, it is possible to lose money in the stock market!\nAdditive Models Additive models are a powerful tool for analyzing and predicting time series, one of the most common types of real world data. The concept is straightforward: represent a time series as a combination of patterns on different time scales and an overall trend. We know the long-term trend of Microsoft stock is a steady increase, but there could also be patterns on a yearly or daily basis, such as an increase every Tuesday, that would be economically beneficial to know. A great library for analyzing time series with daily observations (such as stocks) is Prophet, developed by Facebook. Stocker does all the modeling work with Prophet behind the scenes for us, so we can use a simple method call to create and inspect a model.\nmodel, model_data = microsoft.create_prophet_model()  The additive model smooths out the noise in the data, which is why the modeled line does not exactly line up with the observations. Prophet models also calculate uncertainty, an essential part of modeling as we can never be sure of our predictions when dealing with fluctuating real life processes. We can also use a prophet model to make predictions for the future, but for now we are more concerned with past data. Notice that this method call returned two objects, a model and some data, which we assigned to variables. We now use these variables to plot the time series components.\n# model and model_data are from previous method call model.plot_components(model_data) plt.show()  The overall trend is a definitive increase over the past three years. There also appears to be a noticeable yearly pattern (bottom graph), with prices bottoming out in September and October and reaching a peak in November and January. As the time-scale decreases, the data gets noisier. Over the course of a typical month, there is more signal than noise! If we believe there might be a weekly pattern, we can add that in to the prophet model by changing the weekly_seasonalityattribute of the Stocker object:\nprint(microsoft.weekly_seasonality) microsoft.weekly_seasonality = True print(microsoft.weekly_seasonality) # False # True  The default value for weekly_seasonalityis False, but we changed the value to include a weekly pattern in our model. We then make another call to create_prophet_modeland graph the resulting components. Below is the weekly seasonality from the new model.\nThere was no way I could make this graph look good\nWe can ignore the weekends because the price only changes over the week (in reality the price changes by a small amount during after-hours training but it does not affect our analysis). Unfortunately, there is not a trend over the week that we can use and before we continue modeling, we will turn off the weekly seasonality. This behavior is expected: with stock data, as the time scale decreases, the noise starts to wash out the signal. On a day-to-day basis, the movements of stocks are essentially random, and it is only by zooming out to the yearly scale that we can see trends. Hopefully this serves as a good reminder of why not to play the daily stock game!\nChangepoints Changepoints occur when a time-series goes from increasing to decreasing or vice versa (in a more rigorous sense, they are located where the change in the rate of the time series is greatest). These times are extremely important because knowing when a stock will reach a peak or is about to take off could have significant economic benefits. Identifying the causes of changepoints might let us predict future swings in the value of a stock. The Stocker object can automatically find the 10 largest changepoints for us.\nmicrosoft.changepoint_date_analysis() Changepoints sorted by slope rate of change (2nd derivative): Date Adj. Close delta 48 2015-03-30 38.238066 2.580296 337 2016-05-20 48.886934 2.231580 409 2016-09-01 55.966886 -2.053965 72 2015-05-04 45.034285 -2.040387 313 2016-04-18 54.141111 -1.936257**  The changepoints tend to line up with peaks and valleys in the stock price. Prophet only finds changepoints in the first 80% of the data, but nonetheless, these results are useful because we can attempt to correlate them with real-world events. We could repeat what we did earlier and manually search for Google News around these dates, but I thought it would be preferable if Stocker did that for us. You might have seen the Google Search Trends tool which allows you to see the popularity of any search term over time in Google searches. Stocker can automatically retrieve this data for any search term we specify and plot the result on the original data. To find and graph the frequency of a search term, we modify the previous method call.\n# same method but with a search term microsoft.changepoint_date_analysis(search = 'Microsoft profit')  Top Related Queries:\nquery value 0 microsoft non profit 100 1 microsoft office 55 2 apple 30 3 microsoft 365 30 4 microsoft office 365 20  Rising Related Queries:\nquery value 0 microsoft 365 120 1 microsoft office 365 90 2 microsoft profit 2014 70  In addition to graphing the relative search frequency, Stocker displays the top related queries and the top rising queries for the date range of the graph. On the graph, the y-axis is normalized between 0 and 1 by dividing the values by their maximums, allowing us to compare two variables with different scales. From the figure, there does not appear to be a correlation between searches for “Microsoft profit” and the stock price of Microsoft.\nHad we found a correlation, there would still be the question of causation. We would not know if searches or news caused the price to change, or if the change in price caused the searches. There might be some useful information to be found, but there are also many chance correlations. (For a humorous take on such random relationships, check out spurious correlations). Feel free to try out some different terms to see if you can find any interesting trends!\nmicrosoft.changepoint_date_analysis(search = 'Microsoft Office')  Looks like declining searches for Office leads to increasing stock prices. Maybe someone should let Microsoft know.\nPredictions We have only explored the first half of Stocker capabilities. The second half is designed for forecasting, or predicting future stock price. Although this might be a futile exercise (or at least will not pay off), there is still plenty to learn in the process! Stay tuned for a future article on prediction, or get started predicting with Stocker on your own (check out the documentation for details). For now, I’ll leave you with one more image.\n# specify number of days in future to make a prediction model, future = microsoft.create_prophet_model(days=180) Predicted Price on 2018-07-15 = $97.67  Although all the capabilities of Stocker might already be publically available, the process of creating this tool was enjoyable, and more importantly, taught me more about data science, Python, and the stock market than any college course could. We live in an incredible age of democratized knowledge where anyone can learn about programming or even state of the art fields like machine learning without formal instruction. If you have an idea for a project but think you do not know enough or find out it has been done before, don’t let that stop you. You might develop a better solution and even if you don’t, you’ll be better off and know more than if you had never started!\n Source:.\n "});index.add({'id':110,'href':'/library/tutorials/docs/articles/python/virtualenv/','title':"การใช้งาน Virtualenv",'content':" การใช้งาน Virtualenv Virtualenv คืออะไร Virtualenv(ironment) คือ environment ของ python เช่น คุณทำโปรแกรมอยู่ 2 ตัว A กับ B แล้วเวลาคุณจะติดตั้ง library ถ้าคุณ pip install ลงไปเลย\n library ที่คุณใช้กับงาน A กับปนมั่วกับงาน B  เช่น เวลาจะทำไฟล์ requirement เพื่อให้คนอื่น สามารถติดตั้ง library ที่ใช้กับงานเราได้สะดวกมากขึ้นก็กลับกลายเป็นว่า งาน A ใช้ 5 library งาน B ใช้ 10 Libray สรุป คนที่เอาโปรแกรมเราไม่ไปใช้ก็ไม่รู้ว่า โปรแกรมเราใช้ library อะไรบ้างก็ต้องติดตั้งทั้งหมด 15 library\n หรือแบบไม่สามารถแยก version ของ library กันได้  เช่น งาน A ใช้ OpenCV 3 แต่ งาน B ใช้ OpenCV 4 ทำไงให้ลง 2 version พร้อมกันได้ละ ก็ต้องให้เจ้า Virtualenv ช่วยเราไง\nโดยเจ้า Virtualenv จะสร้าง environment ใหม่ขึ้นมา ที่มีแต่ตัว Python เปล่าๆ แล้วเวลาเราติดตั้ง library อะไรไปมันก็จะเก็บไว้ใน Folder ของ environment แต่ละตัวไม่มาปนกัน\nตอนนี้อาจจะ งง เดี๋ยวไปลองติดตั้งแล้วใช้งานจริงกันเลยดีกว่าครับ\nการติดตั้ง Virtualenv เราจะติดตั้ง Virtualenv ผ่าน pip กันนะครับ โดยการพิมพ์ command\npip install virtualenv  การใช้งาน Virtualenv สมมติ ผมทำโปรเจค image_enhancement อยู่ผมก็จะเข้าไปใน folder โปรเจคของผม\nในทีนี้ผมจะสร้าง python environment ชื่อ env โดยสั่ง\nvirtualenv.exe venv  เวลาจะใช้งานก็สั่ง command\n.\\venv\\Scripts\\activate  \nNote: สำหรับใครที่ใช้ Virtualenv แล้วติดปัญหาเกี่ยวกับ execution policies แบบในรูปด้านล่าง\n\nก็ให้เปิด Powershell หรือ Command Prompt แบบ Admin แล้วสั่ง\nSet-ExecutionPolicy AllSigned  กับ\nSet-ExecutionPolicy RemoteSigned  โดยจะเลือกแบบ Yes หรือ Yes to All ก็ได้ ดูรายละเอียดได้จาก User Guid ของ virtualenv ครับ\nกลับมาเข้าเรื่องของเราต่อครับ เมื่อเราสั่ง activate แล้วจะมีชื่อ environment ของเราอยู่หน้าบรรทัดของ powershell หรือ command\nการใช้งาน Virtualenv (ต่อ) คราวนี้ถ้าเราอยากรู้ว่า environment ของเรามี library อะไรอยู่บ้างก็ให้ลองสั่ง\npip freeze  ซึ่งเราจะยังไม่เห็น library ใดๆ คราวนนี้เรามาลองติดตั้ง library OpenCV กัน\npip install opencv-python  แล้วลอง pip freeze อีกรอบ เราก็จะเห็นว่ามี library OpenCV เพิ่มเข้ามา\nnumpy==1.16.3 opencv-python==4.1.0.25  ทีนี้ก็มาลองทดสอบ library ที่เพิ่งลงกันครับ\n\nถ้าเราใช้งาน environment เสร็จแล้ว ก็ให้สั่ง\ndeactivate  เพื่อออกจาก environment นั้น\nประโยชน์ของ Virtualenv สมมติ ว่าเราทำโปรเจคเสร็จ แล้วคนอื่นอยากนำไปใช้งานต่อ ให้เราสั่ง\npip freeze \u0026gt; requirement.txt  เพื่อจะรวบรวม library ไว้ในไฟล์ requirement.txt เราอาจจะใช้ชื่อไฟล์อื่นก็ได้นะครับ\n\nเวลาคนอื่นเอาไปใช้ เค้าก็จะสั่ง\npip install -r \u0026lt;file requirement\u0026gt;  เจ้า pip ก็จะลง library ทุกตัวให้อัตโนมัติ ของเพียงแค่ version ของ python เหมือนกัน เพราะ บางทีถ้าเรา freeze library จาก python 3.7 แล้วไปลงใน python 3.6 version ของ library บางตัวอาจจะไม่มีก็ได้ครับ\nสรุป    Command Descriptions     virtualenv  สร้าง environment   /Scripts/activate ใช้งาน environment   deactivate ออกจาก environtment   pip install  ติดตั้ง library   pip freeze แสดงรายชื่อ library   สัญลักษณ์ \u0026gt;  เป็นการบอกให้เขียนใส่      ที่มาบทความ skconan.com.\n "});index.add({'id':111,'href':'/library/tutorials/docs/python/beginer/dictionary/python-dictionaries/','title':"Dictionaries",'content':" Python Dictionaries Data structures are basically containers that store data in predefined layouts, optimized for certain operations — like apples in a box, ready for picking😉.\nThe Python programming language natively implements a number of data structures. Lists, tuples, sets, dictionaries are but some of them. We will be looking at the dictionary data type in subsequent sections.\nWhat are dictionaries ? key-value mapping  A dictionary in python is a mapping object that maps keys to values, where the keys are unique within a collection and the values can hold any arbitrary value. In addition to being unique, keys are also required to be hashable.\nAn object is said to be hashable if it has a hash value (implemented by a __hash__() method) that does not change during the object’s lifetime. Most commonly, we use immutable data types such as strings, integers, and tuples (only if they contain similarly immutable types) as dictionary keys.\nA dictionary’s data is always enclosed by a pair of curly braces { }, and would normally look like this:\nmy_dict = {\u0026quot;first_name\u0026quot;: \u0026quot;John\u0026quot;, \u0026quot;last_name\u0026quot;:\u0026quot;Snow\u0026quot;, \u0026quot;age\u0026quot;:16, \u0026quot;gender\u0026quot;:\u0026quot;Male\u0026quot;}  We have created a dictionary named my_dict where each key-value pair is separated by a full colon, with the key-value pairs as:\nfirst_name - John last_name - Snow age - 16 gender - Male  Typically dictionaries store associative data, i.e data that is related. Examples of such data include the attributes of an object, SQL query results and csv-formatted information. Throughout this article, we will be using dictionaries to store job listing details from Kaggle.\nComparisons Dictionaries are an implementation of Associative Arrays. All Associative arrays have a structure of (key, value) pairs, where each key is unique for every collection. Other languages also have similar implementations, such as:\n- Maps in Go - std::map in C++ - Maps in Java - JavaScript objects  Unlike sequenced data types like lists and tuples, where indexing is achieved using positional indices, dictionaries are indexed using their keys. Therefore, individual values can be accessed using these keys.\nDictionary Operations 1. Creation  We initialize an empty dictionary using a pair of curly braces. This approach is often used when we expect to store some data at later stages of our operation.\nempty_dict = {}  In the line above, we have created an empty dictionary named empty_dict.\n For instances when we have our data beforehand, we use curly braces with the key-value pairs. We can now create a dictionary to represent the second row of data in the jobs.csv file.\njob1 = {\u0026quot;title\u0026quot;:\u0026quot;Production Manager\u0026quot;, \u0026quot;location\u0026quot;:\u0026quot;Rest of Kenya\u0026quot;, \u0026quot;job_type\u0026quot;:\u0026quot;Full Time\u0026quot;, \u0026quot;employer\u0026quot;:\u0026quot;The African Talent Company (TATC)\u0026quot;, \u0026quot;category\u0026quot;:\u0026quot;Farming\u0026quot;}  We just created a dictionary with the keys title,location, job_type, employer, category and assigned it to the variable job1.\n Dictionaries can also be created using the dict() constructor. To do this we pass the constructor a sequence of key-value pairs. We could also pass in named arguments.\nLet\u0026rsquo;s create a dictionary to represent the third row of data in the jobs.csv file, using both of these methods.\n# create an empty dictionary empty_property = dict() # create dictionary using a list of key-value tuples job2 = dict([ (\u0026quot;title\u0026quot;,\u0026quot;Marketing \u0026amp; Business Development Manager\u0026quot;),(\u0026quot;location\u0026quot;,\u0026quot;Mombasa\u0026quot;), (\u0026quot;job_type\u0026quot;,\u0026quot;Full Time\u0026quot;), (\u0026quot;employer\u0026quot;,\u0026quot;KUSCCO Limited (Kenya Union of Savings \u0026amp; Credit Co-operatives Limited)\u0026quot;), (\u0026quot;category\u0026quot;,\u0026quot;Marketing \u0026amp; Communications\u0026quot;) ])  Creating dictionary with list of key-value tuples\n  We passed a sequence, in this case a list of key-value tuples, to the dict() constructor to create our dictionary, and assigned it to the variable job2.\n# Using keyword arguments dict( title=\u0026quot;Marketing \u0026amp; Business Development Manager\u0026quot;, location=\u0026quot;Mombasa\u0026quot;,job_type=\u0026quot;Full Time\u0026quot;, employer=\u0026quot;KUSCCO Limited (Kenya Union of Savings \u0026amp; Credit Co-operatives Limited)\u0026quot;, category=\u0026quot;Marketing \u0026amp; Communications\u0026quot; )  Creating dictionary with dict( )\nHere, we created a dictionary using named arguments. The keys are the argument names, while the values are the argument values. It is however important to note that this method is only suitable when our keys are just simple strings.\n2. Accessing Items As we mentioned earlier on, dictionaries are indexed using their keys.\nTo access a particular value in a dictionary we use the indexing operator (key inside square brackets). However, to use this method, we need to make sure the key we intend to retrieve exists, lest we get a KeyError. Checking for availability of a key is as easy as using the in operator.\n# Check existence of title \u0026quot;title\u0026quot; in job2 # returns True \u0026quot;salary\u0026quot; in job2 # returns False # Using key indexing job2[\u0026quot;title\u0026quot;] # return 'Marketing \u0026amp; Business Development Manager'  Indexing\n In the example above we use indexing to access the title from job2 after making sure it is available using in. If you are like me, this is probably a lot of work. The good news, however, is that we have a better tool — the get() method. This method works by giving out a value if the key exists, or returning None. None sounds better than an error, right?\nWhat if we want to go even further, and return something, a placeholder of sorts? get() takes a second argument, a default value to be used in place of None. Now let\u0026rsquo;s use in to check if title exists in job2, then we can use indexing to retrieve its value. We\u0026rsquo;ll also go ahead and use get() to retrieve salary from job2.\n# Using keyword arguments dict( title=\u0026quot;Marketing \u0026amp; Business Development Manager\u0026quot;, location=\u0026quot;Mombasa\u0026quot;,job_type=\u0026quot;Full Time\u0026quot;, employer=\u0026quot;KUSCCO Limited (Kenya Union of Savings \u0026amp; Credit Co-operatives Limited)\u0026quot;, category=\u0026quot;Marketing \u0026amp; Communications\u0026quot; )  Accessing items\n  Here, we use get() to access the title and salary.\nHowever, job2 doesn\u0026rsquo;t have a salary key so the return value is None. Adding a second argument, to get() now gives us 5000 instead of None.\n3. Modification Dictionaries can be modified directly using the keys or using the update() method. update() takes in a dictionary with the key-value pairs to be modified or added. For our demonstration, let\u0026rsquo;s:\n Add a new item (salary) to job2 with a value of 10000. Modify the job_type to be \u0026ldquo;Part time\u0026rdquo;. Update the salary to 20000. Update the dictionary to include a new item (available) with a value of True.\n# Adding a new entry for salary using the index job2[\u0026quot;salary\u0026quot;] = 10000 # Modifying the entry for job_type using the index job2[\u0026quot;job_type\u0026quot;] = \u0026quot;Part time\u0026quot; # Modifying the salary entry using update job2.update({\u0026quot;salary\u0026quot;:20000}) # Adding the available entry using update job2.update({\u0026quot;available\u0026quot;:True})   Updating dictionaries\nTo add a new entry, we use syntax similar to indexing. If the key exists, then the value will be modified, however, if the key doesn’t exist, a new entry will be created with the specified key and value.\n Initially, we assigned a value of 10000 to the salary key, but since salary doesn\u0026rsquo;t exist, a new entry is created, with that value. For our second example, the job_type key exists, the value is modified to \u0026ldquo;Part time\u0026rdquo;. Next, we use the update() method to change the salary value to 20000, since salary is already a key in the dictionary. Finally, we apply update() to the dictionary, a new entry is created with a key of available and value of True.  A particularly nice use case for update() is when we need to merge two dictionaries. Say we have another dictionary extra_info containing extra fields for a job, and we would like to merge this with job2.\nextra_info = { \u0026quot;verified\u0026quot;:True, \u0026quot;qualification\u0026quot;:\u0026quot;Undergraduate Degree\u0026quot;, \u0026quot;taxable\u0026quot;:True} # Merge extra_info with job2 job2.update(extra_info)  Merging dictionaries\n4. Deletion We can now remove the just created salary entry from job2, and remove everything from job1.\ndel job2[\u0026quot;salary\u0026quot;] del job2[\u0026quot;available\u0026quot;] print(job2) #return a dictionary without 'salary' and 'available' entries job1.clear() print(job1) #return an empty dictionary del job1 print(job1) # return NameError  Deletion\nTo remove the entries associated with the salary and available keys from job2, we use the del keyword. Now if we go ahead and print job2, the salary and available entries are gone.\nRemoving all items from job1 entails using the clear() method, which leaves us with an empty dictionary. If we don\u0026rsquo;t need a dictionary anymore, say job1, we use the del keyword to delete it. Now if we try printing job1 we\u0026rsquo;ll get a NameErrorsince job1 is no longer defined.\n6. Iteration A dictionary by itself is an iterable of its keys. Moreover, we can iterate through dictionaries in 3 different ways:\n dict.values() - this returns an iterable of the dictionary\u0026rsquo;s values. dict.keys() - this returns an iterable of the dictionary\u0026rsquo;s keys. dict.items() - this returns an iterable of the dictionary\u0026rsquo;s (key,value) pairs.  But why would we need to iterate over a dictionary?\nOur dataset has about 860 listings, suppose we wanted to display the properties of all these on our website, it wouldn’t make sense to write the same markup 860 times. It would be efficient to dynamically render the data using a loop.\nLet’s iterate over job2 using a for-loop using all the three methods. Furthermore we\u0026rsquo;ll use the csv module to read our csv-formatted data in to a list of dictionaries, then we\u0026rsquo;ll iterate through all the dictionaries and print out the keys and values.\n# Iterating through the dictionary itself for x in job2: print(x) # prints the keys of job2 # Using keys() for key in job2.keys(): print(key) # prints the keys of job2 # Using values() for val in job2.values(): print(val) # prints the values of job2 # Dictionary iteration use case import csv with open('jobs.csv','r') as csv_file: reader = csv.DictReader(csv_file) for job in reader: # Using items() for key,val in job.items(): # Apply any additional processing print(key, val) #print the keys and values of each job  Dictionary Iteration\n First, we loop through the dictionary as it is. This is similar in output to stepping through the job2.keys() iterable. Secondly, we iterate through job2.values() while printing out the value. Finally, we step through the list of dictionaries, and for each one, loop through the keys and values simultaneously.\nWe include both key and value in the for-loop constructor since job.items() yields a tuple of key and value during each iteration. We can now apply any kind of operation to our data at this point. Our implementation simply prints out the pair at each step.  7. Sorting Borrowing from our description of dictionaries earlier, this data type is meant to be unordered, and doesn’t come with the sorting functionality baked in. Calling the sorted() function and passing it a dictionary only returns a list of the keys in a sorted order, since the dictionary is an iterable of its keys.\nIf we use the items() iterable we could sort the items of our dictionary as we please. However, this doesn\u0026rsquo;t give us our original dictionary, but a list of key-value tuples in a sorted order.\nSay we wanted to display the job details in the above example in alphabetical order, We would need to alter our iteration to give sorted results. Lets walk through the example again an see how we would achieve that functionality.\nith open('jobs.csv','r') as csv_file: reader = csv.DictReader(csv_file) for job in reader: # Using sorted() to sort a dictionary's items on the keys for key,val in sorted(job.items(),key=lambda item:item[0]): # Apply any additional processing print(key, val) #print the keys and values of each job  Iteration\n In this example we use python’s inbuilt sorted() function which takes in an iterable (our dictionary\u0026rsquo;s items). The key argument of the sorted()function instructs sorted() to use the value at index 0 for sorting. This named argument points to a lambda function which takes in an item, say (“a”, “b”) and returns the value at the item’s first index, in this case “a”.\nSimilarly, to sort by the values, we use index 1 instead of index 0.  Other Methods Dictionaries have other methods that could be used on demand. To read up further on these, please consult the python documentation. Here are some other useful methods:\n pop(key,default) - deletes the key key and returns it, or returns an optional default when the key doesn\u0026rsquo;t exist. copy() - returns a shallow copy of the original. This shallow copy has similar references to the original, and not copies of the original\u0026rsquo;s items. setdefault(key,default) - returns the value of key if in the dictionary, or sets the new key with an optional default as its value then returns the value.  Speeding Up your Code Dictionary unpacking can greatly speed up our code. It involves destructuring a dictionary into individual keyword arguments with values.\nThis is especially useful for cases that involve supplying multiple keyword arguments, for example in function calls.\nTo implement this functionality we use the iterable unpacking operator (**).\nWhat if we needed Job objects to work with, instead of dictionaries? We shouldn\u0026rsquo;t have to do some heavy lifting to get our data reorganized in to objects.\nLet\u0026rsquo;s see how we could translate our dictionaries into objects, by again tweaking our previous code.\nDefine a Job Class class Job: def __init__(self, title=\u0026quot;Job Title\u0026quot;, location=\u0026quot;Job Location\u0026quot;, job_type=\u0026quot;Job Type\u0026quot;, employer=\u0026quot;Job Employer\u0026quot;, category=\u0026quot;Job Category\u0026quot;,): self.title = title self.location = location self.job_type = job_type self.employer = employer self.category = category def __str__(self): return self.title # Creating a job object without unpacking Job(\u0026quot;Marketing \u0026amp; Business Development Manager\u0026quot;,\u0026quot;Mombasa\u0026quot;,\u0026quot;Full Time\u0026quot;, \u0026quot;KUSCCO Limited (Kenya Union of Savings \u0026amp; Credit Co-operatives Limited)\u0026quot;, \u0026quot;Marketing \u0026amp; Communications\u0026quot;) with open('jobs.csv','r') as csv_file: reader = csv.DictReader(csv_file) for job in reader: # Creating a job object with unpacking Job(**job)  Dictionary Unpacking\n To instantiate a new Job object, traditionally, we would need to pass in all the required arguments. However, with unpacking, we just pass in a dictionary with the ** operator before it.\nThe operator unpacks the dictionary in to an arbitrary number of named arguments. This approach is much cleaner and involves less code.  8. Anti-patterns: Wrong usage Compared to lists and tuples, dictionaries take up more space in memory, since they need to store both the key and value, as opposed to just values.\n Therefore, dictionaries should only be used in cases where we have associative data, that would lose meaning if stored in lists, or any other sequenced data type. Dictionaries are mutable, hence not suitable for storing data than shouldn’t be modified in place. Since dictionaries are unordered, it would not be sensible to store strictly arranged data in them.\nA possible candidate data type for this scenario would be the OrderedDict from the collections module. An OrderedDict is a subclass of the regular dict class, with the advantage of tracking the order in which keys were added. Dictionaries are well-designed to let us find a value instantly without necessarily having to search through the entire collection, hence we should not use loops for such an operation.\n# How not to search for a value and return it key_i_need = \u0026quot;location\u0026quot; target = \u0026quot;\u0026quot; for key in job2: if key == key_i_need: target = job2[key] # How to search efficiently target = job2.get(\u0026quot;location\u0026quot;)   Antipatterns\nWe have a variable key_i_need containing the key we want to search for. We have used a for loop to traverse the collection, comparing the key at each step with our variable. If we get a match, we assign that key\u0026rsquo;s value to the variable target.\nThis is the wrong approach. We should instead use get(), and pass it the desired key.\nPerformance Trade-offs Dictionary operations are heavily optimized in python, especially since they’re also extensively used within the language.\nFor instance, members of a class are internally stored in dictionaries.\nMost dictionary operations have a time complexity of O(1) — implying that the operations run in constant time relative to the size of the dictionary. This simply means that the operation only runs once irregardless of the dictionary size.\nCreating a dictionary runs in a linear time of O(N), where “N” is the number of key-value pairs.\nSimilarly, all iterations run in O(N) since the loop has to run N times.\nDictionary Operations — https://www.ics.uci.edu/~brgallar/week8_2.html\nConclusion Dictionaries come in very handy for regular python usage. They are suitable for use with unordered data that relies on relations. Caution should however be exercised to ensure we do not use dictionaries in the wrong way and end up slowing down execution of our code. For further reading please refer to the official python documentation on mapping types. \u0026gt; Written with StackEdit.\n"});index.add({'id':112,'href':'/library/tutorials/docs/python/beginer/dictionary/','title':"Dictionary(Dict)",'content':" Python Dictionary(Dict) "});index.add({'id':113,'href':'/library/tutorials/functions/','title':"Functions",'content':""});index.add({'id':114,'href':'/library/tutorials/functions/newfunction/','title':"Newfunction",'content':""});index.add({'id':115,'href':'/library/tutorials/posts/','title':"Posts",'content':""});index.add({'id':116,'href':'/library/tutorials/posts/goisforlovers/','title':"(Hu)go Template Primer",'content':" Hugo uses the excellent Go html/template library for its template engine. It is an extremely lightweight engine that provides a very small amount of logic. In our experience that it is just the right amount of logic to be able to create a good static website. If you have used other template systems from different languages or frameworks you will find a lot of similarities in Go templates.\nThis document is a brief primer on using Go templates. The Go docs provide more details.\nIntroduction to Go Templates Go templates provide an extremely simple template language. It adheres to the belief that only the most basic of logic belongs in the template or view layer. One consequence of this simplicity is that Go templates parse very quickly.\nA unique characteristic of Go templates is they are content aware. Variables and content will be sanitized depending on the context of where they are used. More details can be found in the Go docs.\nBasic Syntax Golang templates are HTML files with the addition of variables and functions.\nGo variables and functions are accessible within {{ }}\nAccessing a predefined variable \u0026ldquo;foo\u0026rdquo;:\n{{ foo }}  Parameters are separated using spaces\nCalling the add function with input of 1, 2:\n{{ add 1 2 }}  Methods and fields are accessed via dot notation\nAccessing the Page Parameter \u0026ldquo;bar\u0026rdquo;\n{{ .Params.bar }}  Parentheses can be used to group items together\n{{ if or (isset .Params \u0026quot;alt\u0026quot;) (isset .Params \u0026quot;caption\u0026quot;) }} Caption {{ end }}  Variables Each Go template has a struct (object) made available to it. In hugo each template is passed either a page or a node struct depending on which type of page you are rendering. More details are available on the variables page.\nA variable is accessed by referencing the variable name.\n\u0026lt;title\u0026gt;{{ .Title }}\u0026lt;/title\u0026gt;  Variables can also be defined and referenced.\n{{ $address := \u0026quot;123 Main St.\u0026quot;}} {{ $address }}  Functions Go template ship with a few functions which provide basic functionality. The Go template system also provides a mechanism for applications to extend the available functions with their own. Hugo template functions provide some additional functionality we believe are useful for building websites. Functions are called by using their name followed by the required parameters separated by spaces. Template functions cannot be added without recompiling hugo.\nExample:\n{{ add 1 2 }}  Includes When including another template you will pass to it the data it will be able to access. To pass along the current context please remember to include a trailing dot. The templates location will always be starting at the /layout/ directory within Hugo.\nExample:\n{{ template \u0026quot;chrome/header.html\u0026quot; . }}  Logic Go templates provide the most basic iteration and conditional logic.\nIteration Just like in Go, the Go templates make heavy use of range to iterate over a map, array or slice. The following are different examples of how to use range.\nExample 1: Using Context\n{{ range array }} {{ . }} {{ end }}  Example 2: Declaring value variable name\n{{range $element := array}} {{ $element }} {{ end }}  Example 2: Declaring key and value variable name\n{{range $index, $element := array}} {{ $index }} {{ $element }} {{ end }}  Conditionals If, else, with, or, \u0026amp; and provide the framework for handling conditional logic in Go Templates. Like range, each statement is closed with end.\nGo Templates treat the following values as false:\n false 0 any array, slice, map, or string of length zero  Example 1: If\n{{ if isset .Params \u0026quot;title\u0026quot; }}\u0026lt;h4\u0026gt;{{ index .Params \u0026quot;title\u0026quot; }}\u0026lt;/h4\u0026gt;{{ end }}  Example 2: If -\u0026gt; Else\n{{ if isset .Params \u0026quot;alt\u0026quot; }} {{ index .Params \u0026quot;alt\u0026quot; }} {{else}} {{ index .Params \u0026quot;caption\u0026quot; }} {{ end }}  Example 3: And \u0026amp; Or\n{{ if and (or (isset .Params \u0026quot;title\u0026quot;) (isset .Params \u0026quot;caption\u0026quot;)) (isset .Params \u0026quot;attr\u0026quot;)}}  Example 4: With\nAn alternative way of writing \u0026ldquo;if\u0026rdquo; and then referencing the same value is to use \u0026ldquo;with\u0026rdquo; instead. With rebinds the context . within its scope, and skips the block if the variable is absent.\nThe first example above could be simplified as:\n{{ with .Params.title }}\u0026lt;h4\u0026gt;{{ . }}\u0026lt;/h4\u0026gt;{{ end }}  Example 5: If -\u0026gt; Else If\n{{ if isset .Params \u0026quot;alt\u0026quot; }} {{ index .Params \u0026quot;alt\u0026quot; }} {{ else if isset .Params \u0026quot;caption\u0026quot; }} {{ index .Params \u0026quot;caption\u0026quot; }} {{ end }}  Pipes One of the most powerful components of Go templates is the ability to stack actions one after another. This is done by using pipes. Borrowed from unix pipes, the concept is simple, each pipeline\u0026rsquo;s output becomes the input of the following pipe.\nBecause of the very simple syntax of Go templates, the pipe is essential to being able to chain together function calls. One limitation of the pipes is that they only can work with a single value and that value becomes the last parameter of the next pipeline.\nA few simple examples should help convey how to use the pipe.\nExample 1 :\n{{ if eq 1 1 }} Same {{ end }}  is the same as\n{{ eq 1 1 | if }} Same {{ end }}  It does look odd to place the if at the end, but it does provide a good illustration of how to use the pipes.\nExample 2 :\n{{ index .Params \u0026quot;disqus_url\u0026quot; | html }}  Access the page parameter called \u0026ldquo;disqus_url\u0026rdquo; and escape the HTML.\nExample 3 :\n{{ if or (or (isset .Params \u0026quot;title\u0026quot;) (isset .Params \u0026quot;caption\u0026quot;)) (isset .Params \u0026quot;attr\u0026quot;)}} Stuff Here {{ end }}  Could be rewritten as\n{{ isset .Params \u0026quot;caption\u0026quot; | or isset .Params \u0026quot;title\u0026quot; | or isset .Params \u0026quot;attr\u0026quot; | if }} Stuff Here {{ end }}  Context (aka. the dot) The most easily overlooked concept to understand about Go templates is that {{ . }} always refers to the current context. In the top level of your template this will be the data set made available to it. Inside of a iteration it will have the value of the current item. When inside of a loop the context has changed. . will no longer refer to the data available to the entire page. If you need to access this from within the loop you will likely want to set it to a variable instead of depending on the context.\nExample:\n {{ $title := .Site.Title }} {{ range .Params.tags }} \u0026lt;li\u0026gt; \u0026lt;a href=\u0026quot;{{ $baseurl }}/tags/{{ . | urlize }}\u0026quot;\u0026gt;{{ . }}\u0026lt;/a\u0026gt; - {{ $title }} \u0026lt;/li\u0026gt; {{ end }}  Notice how once we have entered the loop the value of {{ . }} has changed. We have defined a variable outside of the loop so we have access to it from within the loop.\nHugo Parameters Hugo provides the option of passing values to the template language through the site configuration (for sitewide values), or through the meta data of each specific piece of content. You can define any values of any type (supported by your front matter/config format) and use them however you want to inside of your templates.\nUsing Content (page) Parameters In each piece of content you can provide variables to be used by the templates. This happens in the front matter.\nAn example of this is used in this documentation site. Most of the pages benefit from having the table of contents provided. Sometimes the TOC just doesn\u0026rsquo;t make a lot of sense. We\u0026rsquo;ve defined a variable in our front matter of some pages to turn off the TOC from being displayed.\nHere is the example front matter:\n--- title: \u0026quot;Permalinks\u0026quot; date: \u0026quot;2013-11-18\u0026quot; aliases: - \u0026quot;/doc/permalinks/\u0026quot; groups: [\u0026quot;extras\u0026quot;] groups_weight: 30 notoc: true ---  Here is the corresponding code inside of the template:\n {{ if not .Params.notoc }} \u0026lt;div id=\u0026quot;toc\u0026quot; class=\u0026quot;well col-md-4 col-sm-6\u0026quot;\u0026gt; {{ .TableOfContents }} \u0026lt;/div\u0026gt; {{ end }}  Using Site (config) Parameters In your top-level configuration file (eg, config.yaml) you can define site parameters, which are values which will be available to you in chrome.\nFor instance, you might declare:\nparams: CopyrightHTML: \u0026quot;Copyright \u0026amp;#xA9; 2013 John Doe. All Rights Reserved.\u0026quot; TwitterUser: \u0026quot;spf13\u0026quot; SidebarRecentLimit: 5  Within a footer layout, you might then declare a \u0026lt;footer\u0026gt; which is only provided if the CopyrightHTML parameter is provided, and if it is given, you would declare it to be HTML-safe, so that the HTML entity is not escaped again. This would let you easily update just your top-level config file each January 1st, instead of hunting through your templates.\n{{if .Site.Params.CopyrightHTML}}\u0026lt;footer\u0026gt; \u0026lt;div class=\u0026quot;text-center\u0026quot;\u0026gt;{{.Site.Params.CopyrightHTML | safeHtml}}\u0026lt;/div\u0026gt; \u0026lt;/footer\u0026gt;{{end}}  An alternative way of writing the \u0026ldquo;if\u0026rdquo; and then referencing the same value is to use \u0026ldquo;with\u0026rdquo; instead. With rebinds the context . within its scope, and skips the block if the variable is absent:\n{{with .Site.Params.TwitterUser}}\u0026lt;span class=\u0026quot;twitter\u0026quot;\u0026gt; \u0026lt;a href=\u0026quot;https://twitter.com/{{.}}\u0026quot; rel=\u0026quot;author\u0026quot;\u0026gt; \u0026lt;img src=\u0026quot;/images/twitter.png\u0026quot; width=\u0026quot;48\u0026quot; height=\u0026quot;48\u0026quot; title=\u0026quot;Twitter: {{.}}\u0026quot; alt=\u0026quot;Twitter\u0026quot;\u0026gt;\u0026lt;/a\u0026gt; \u0026lt;/span\u0026gt;{{end}}  Finally, if you want to pull \u0026ldquo;magic constants\u0026rdquo; out of your layouts, you can do so, such as in this example:\n\u0026lt;nav class=\u0026quot;recent\u0026quot;\u0026gt; \u0026lt;h1\u0026gt;Recent Posts\u0026lt;/h1\u0026gt; \u0026lt;ul\u0026gt;{{range first .Site.Params.SidebarRecentLimit .Site.Recent}} \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;{{.RelPermalink}}\u0026quot;\u0026gt;{{.Title}}\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; {{end}}\u0026lt;/ul\u0026gt; \u0026lt;/nav\u0026gt;  "});index.add({'id':117,'href':'/library/tutorials/posts/hugoisforlovers/','title':"Getting Started with Hugo",'content':" Step 1. Install Hugo Go to Hugo releases and download the appropriate version for your OS and architecture.\nSave it somewhere specific as we will be using it in the next step.\nMore complete instructions are available at Install Hugo\nStep 2. Build the Docs Hugo has its own example site which happens to also be the documentation site you are reading right now.\nFollow the following steps:\n Clone the Hugo repository Go into the repo Run hugo in server mode and build the docs Open your browser to http://localhost:1313  Corresponding pseudo commands:\ngit clone https://github.com/spf13/hugo cd hugo /path/to/where/you/installed/hugo server --source=./docs \u0026gt; 29 pages created \u0026gt; 0 tags index created \u0026gt; in 27 ms \u0026gt; Web Server is available at http://localhost:1313 \u0026gt; Press ctrl+c to stop  Once you\u0026rsquo;ve gotten here, follow along the rest of this page on your local build.\nStep 3. Change the docs site Stop the Hugo process by hitting Ctrl+C.\nNow we are going to run hugo again, but this time with hugo in watch mode.\n/path/to/hugo/from/step/1/hugo server --source=./docs --watch \u0026gt; 29 pages created \u0026gt; 0 tags index created \u0026gt; in 27 ms \u0026gt; Web Server is available at http://localhost:1313 \u0026gt; Watching for changes in /Users/spf13/Code/hugo/docs/content \u0026gt; Press ctrl+c to stop  Open your favorite editor and change one of the source content pages. How about changing this very file to fix the typo. How about changing this very file to fix the typo.\nContent files are found in docs/content/. Unless otherwise specified, files are located at the same relative location as the url, in our case docs/content/overview/quickstart.md.\nChange and save this file.. Notice what happened in your terminal.\n\u0026gt; Change detected, rebuilding site \u0026gt; 29 pages created \u0026gt; 0 tags index created \u0026gt; in 26 ms  Refresh the browser and observe that the typo is now fixed.\nNotice how quick that was. Try to refresh the site before it\u0026rsquo;s finished building. I double dare you. Having nearly instant feedback enables you to have your creativity flow without waiting for long builds.\nStep 4. Have fun The best way to learn something is to play with it.\n"});index.add({'id':118,'href':'/library/tutorials/docs/backup/example/2nd/3rd/4th/','title':"4th",'content':" 4th Level of Menu Caesorum illa tu sentit micat vestes papyriferi Inde aderam facti; Theseus vis de tauri illa peream. Oculos uberaque non regisque vobis cursuque, opus venit quam vulnera. Et maiora necemque, lege modo; gestanda nitidi, vero? Dum ne pectoraque testantur.\nVenasque repulsa Samos qui, exspectatum eram animosque hinc, aut manes, Assyrii. Cupiens auctoribus pariter rubet, profana magni super nocens. Vos ius sibilat inpar turba visae iusto! Sedes ante dum superest extrema.\n"});index.add({'id':119,'href':'/library/tutorials/docs/backup/example/2nd/3rd/','title':"Docs\\backup\\example\\2nd\\3rd\\",'content':" 3rd Level of Menu Nefas discordemque domino montes numen tum humili nexilibusque exit, Iove. Quae miror esse, scelerisque Melaneus viribus. Miseri laurus. Hoc est proposita me ante aliquid, aura inponere candidioribus quidque accendit bella, sumpta. Intravit quam erat figentem hunc, motus de fontes parvo tempestate.\niscsi_virus = pitch(json_in_on(eupViral), northbridge_services_troubleshooting, personal( firmware_rw.trash_rw_crm.device(interactive_gopher_personal, software, -1), megabit, ergonomicsSoftware(cmyk_usb_panel, mips_whitelist_duplex, cpa))); if (5) { managementNetwork += dma - boolean; kilohertz_token = 2; honeypot_affiliate_ergonomics = fiber; } mouseNorthbridge = byte(nybble_xmp_modem.horse_subnet( analogThroughputService * graphicPoint, drop(daw_bit, dnsIntranet), gateway_ospf), repository.domain_key.mouse(serverData(fileNetwork, trim_duplex_file), cellTapeDirect, token_tooltip_mashup( ripcordingMashup))); module_it = honeypot_driver(client_cold_dvr(593902, ripping_frequency) + coreLog.joystick(componentUdpLink), windows_expansion_touchscreen); bashGigabit.external.reality(2, server_hardware_codec.flops.ebookSampling( ciscNavigationBacklink, table + cleanDriver), indexProtocolIsp);  "});index.add({'id':120,'href':'/library/tutorials/docs/backup/example/hidden/','title':"Hidden",'content':" This page is hidden in menu Quondam non pater est dignior ille Eurotas Latent te facies Lorem markdownum arma ignoscas vocavit quoque ille texit mandata mentis ultimus, frementes, qui in vel. Hippotades Peleus pennas conscia cuiquam Caeneus quas.\n Pater demittere evincitque reddunt Maxime adhuc pressit huc Danaas quid freta Soror ego Luctus linguam saxa ultroque prior Tatiumque inquit Saepe liquitur subita superata dederat Anius sudor  Cum honorum Latona O fallor in sustinui iussorum equidem. Nymphae operi oris alii fronde parens dumque, in auro ait mox ingenti proxima iamdudum maius?\nreality(burnDocking(apache_nanometer), pad.property_data_programming.sectorBrowserPpga(dataMask, 37, recycleRup)); intellectualVaporwareUser += -5 * 4; traceroute_key_upnp /= lag_optical(android.smb(thyristorTftp)); surge_host_golden = mca_compact_device(dual_dpi_opengl, 33, commerce_add_ppc); if (lun_ipv) { verticalExtranet(1, thumbnail_ttl, 3); bar_graphics_jpeg(chipset - sector_xmp_beta); }  Fronde cetera dextrae sequens pennis voce muneris Acta cretus diem restet utque; move integer, oscula non inspirat, noctisque scelus! Nantemque in suas vobis quamvis, et labori!\nvar runtimeDiskCompiler = home - array_ad_software; if (internic \u0026gt; disk) { emoticonLockCron += 37 + bps - 4; wan_ansi_honeypot.cardGigaflops = artificialStorageCgi; simplex -= downloadAccess; } var volumeHardeningAndroid = pixel + tftp + onProcessorUnmount; sector(memory(firewire + interlaced, wired));  "});index.add({'id':121,'href':'/library/tutorials/docs/backup/shortcodes/','title':"Docs\\backup\\shortcodes\\",'content':""});index.add({'id':122,'href':'/library/tutorials/docs/backup/shortcodes/buttons/','title':"Buttons",'content':" Buttons Buttons are styled links that can lead to local page or external link.\n{{\u0026lt; button relref=\u0026quot;/\u0026quot; [class=\u0026quot;...\u0026quot;] \u0026gt;}}Get Home{{\u0026lt; /button \u0026gt;}} {{\u0026lt; button href=\u0026quot;https://github.com/alex-shpak/hugo-book\u0026quot; \u0026gt;}}Contribute{{\u0026lt; /button \u0026gt;}}  Example \rGet Home\r\rContribute\r\r"});index.add({'id':123,'href':'/library/tutorials/docs/backup/shortcodes/columns/','title':"Columns",'content':" Columns Columns help organize shorter pieces of content horizontally for readability.\n{{\u0026lt; columns \u0026gt;}} \u0026lt;!-- begin columns block --\u0026gt; # Left Content Lorem markdownum insigne... \u0026lt;---\u0026gt; \u0026lt;!-- magic sparator, between columns --\u0026gt; # Mid Content Lorem markdownum insigne... \u0026lt;---\u0026gt; \u0026lt;!-- magic sparator, between columns --\u0026gt; # Right Content Lorem markdownum insigne... {{\u0026lt; /columns \u0026gt;}}  Example Left Content Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.\r\rMid Content Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter!\r\rRight Content Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.\r\r\r"});index.add({'id':124,'href':'/library/tutorials/docs/backup/shortcodes/expand/','title':"Expand",'content':" Expand Expand shortcode can help to decrease clutter on screen by hiding part of text. Expand content by clicking on it.\nExample Default {{\u0026lt; expand \u0026gt;}} ## Markdown content Lorem markdownum insigne... {{\u0026lt; /expand \u0026gt;}}  \rExpand\r↕\r\rMarkdown content Lorem markdownum insigne\u0026hellip;\r\r\r\rWith Custom Label {{\u0026lt; expand \u0026quot;Custom Label\u0026quot; \u0026quot;...\u0026quot; \u0026gt;}} ## Markdown content Lorem markdownum insigne... {{\u0026lt; /expand \u0026gt;}}  \rCustom Label\r...\r\rMarkdown content Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.\r\r\r\r"});index.add({'id':125,'href':'/library/tutorials/docs/backup/shortcodes/hints/','title':"Hints",'content':" Hints Hint shortcode can be used as hint/alerts/notification block.\nThere are 3 colors to choose: info, warning and danger.\n{{\u0026lt; hint [info|warning|danger] \u0026gt;}} **Markdown content** Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa {{\u0026lt; /hint \u0026gt;}}  Example Markdown content\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa\r\rMarkdown content\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa\r\rMarkdown content\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa\r\r"});index.add({'id':126,'href':'/library/tutorials/docs/backup/shortcodes/katex/','title':"Katex",'content':" KaTeX KaTeX shortcode let you render math typesetting in markdown document. See KaTeX\nExample {{\u0026lt; katex [class=\u0026quot;text-center\u0026quot;] \u0026gt;}} x = \\begin{cases} a \u0026amp;\\text{if } b \\\\ c \u0026amp;\\text{if } d \\end{cases} {{\u0026lt; /katex \u0026gt;}} \r\r \n$$ x = \\begin{cases} a \u0026\\text{if } b \\\\ c \u0026\\text{if } d \\end{cases} $$ \r\r"});index.add({'id':127,'href':'/library/tutorials/docs/backup/shortcodes/mermaid/','title':"Mermaid",'content':" Mermaid Chart Mermaid is library for generating svg charts and diagrams from text.\nExample {{\u0026lt; mermaid [class=\u0026quot;text-center\u0026quot;]\u0026gt;}} sequenceDiagram Alice-\u0026gt;\u0026gt;Bob: Hello Bob, how are you? alt is sick Bob-\u0026gt;\u0026gt;Alice: Not so good :( else is well Bob-\u0026gt;\u0026gt;Alice: Feeling fresh like a daisy end opt Extra response Bob-\u0026gt;\u0026gt;Alice: Thanks for asking end {{\u0026lt; /mermaid \u0026gt;}} \r\r sequenceDiagram Alice-Bob: Hello Bob, how are you? alt is sick Bob-Alice: Not so good :( else is well Bob-Alice: Feeling fresh like a daisy end opt Extra response Bob-Alice: Thanks for asking end\r\r\r"});index.add({'id':128,'href':'/library/tutorials/docs/backup/shortcodes/tabs/','title':"Tabs",'content':" Tabs Tabs let you organize content by context, for example installation instructions for each supported platform.\n{{\u0026lt; tabs \u0026quot;uniqueid\u0026quot; \u0026gt;}} {{\u0026lt; tab \u0026quot;MacOS\u0026quot; \u0026gt;}} # MacOS Content {{\u0026lt; /tab \u0026gt;}} {{\u0026lt; tab \u0026quot;Linux\u0026quot; \u0026gt;}} # Linux Content {{\u0026lt; /tab \u0026gt;}} {{\u0026lt; tab \u0026quot;Windows\u0026quot; \u0026gt;}} # Windows Content {{\u0026lt; /tab \u0026gt;}} {{\u0026lt; /tabs \u0026gt;}}  Example MacOS\r\rMacOS This is tab MacOS content.\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.\n\rLinux\r\rLinux This is tab Linux content.\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.\n\rWindows\r\rWindows This is tab Windows content.\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.\n\r\r"});index.add({'id':129,'href':'/library/tutorials/docs/articles/webapp/javascript/10-knowledge-javascript/','title':"10 เรื่องน่ารู้ตอบข้อสงสัย JavaScript",'content':" 10 เรื่องน่ารู้ตอบข้อสงสัย JavaScript ในการเขียนภาษา JavaScript นั้นมีทั้งสิ่งที่เหมือนและแตกต่างกับภาษาโปรแกรมอื่นๆ สำหรับคนที่ใช้งาน JavaScript ไม่ว่าจะเพิ่งเริ่มศึกษาหรือใช้มานานแล้ว ก็อาจจะยังมีบางเรื่องที่สงสัยหรือยังไม่รู้เกี่ยวกับ JavaScript อยู่ เราจึงรวบรวม 10 เรื่องน่ารู้เกี่ยวกับ JavaScriptมาให้ได้ลองอ่านกัน\n1. การประกาศตัวแปร Var, Let, Const ใช้แบบไหน ในการเขียนโค้ด การประกาศตัวแปรก็เป็นสิ่งแรกๆ ที่น่าจะเจอในการเริ่มต้นศึกษาภาษานั้นๆ ใน JavaScript ก็เช่นกัน สำหรับคนที่เริ่มศึกษา JavaSctipt น่าจะเคยเห็นผ่านตามาบ้างก็คือ var, let และ const เพื่อการนำไปใช้งานอย่างถูกต้อง ลองมาดูกันว่าการประกาศแต่ละแบบนั้นต่างกันอย่างไรบ้าง\nfunction run() { const myNum = 191; var one = \u0026quot;One\u0026quot;; let two = \u0026quot;Two\u0026quot;; { var three = \u0026quot;Three\u0026quot;; let four = \u0026quot;Four\u0026quot;; } console.log(one); //Output: One console.log(two); //Output: Two console.log(three); //Output: Three console.log(four); //Uncaught ReferenceError } run();   var – สำหรับการประกาศค่าด้วย var นั้น น่าจะเป็นแบบที่ทุกเคยเห็นกันแน่นอน ซึ่งการใช้ var นั้นเคยเป็นหลักในการประกาศตัวแปรมาก่อนที่ ES6 จะออกมา ซึ่งการประกาศด้วย var นั้นจะเป็นแบบ function scope เมื่อประกาศตัวแปรแล้วจะสมารถนำไปใช้ได้ภายในฟังก์ชันนั้นได้ทั้งหมด let – เป็นการประกาศตัวแปรที่ออกมาพร้อมกันกับ const ซึ่งมาพร้อมกับอัพเดต ES6 เพื่อช่วยให้การเขียน JavaScript นั้นง่ายขึ้น โดย let เมื่อประกาศแล้วตัวแปรจะมีค่าอยู่แค่ภายใน block scope คือแค่ภายในเครื่องหมาย { และ } ทำให้ไม่เกิดปัญหาการอ้างอิงตัวแปรเก่า เช่น การใช้ตัวแปรใน loop ค่างๆ ที่ต้องการประกาศค่าขึ้นมาใหม่ const – ใช้สำหรับประกาศค่าตัวแปรที่ไม่ต้องการให้เปลี่ยนแปลงค่าได้ เพราะเมื่อประกาศค่าไปแล้วจะไม่สามรถแก้ไขค่านั้นซ้ำได้ โดย const นั้นทำงานภายใน block scope เหมือนกันกับ let  2. ชนิดของตัวแปร JavaScript เป็น dynamic data type คือตัวแปรหนึ่งตัวนั้น สามารถกำหนดค่าที่ชนิดแตกต่างกันให้กับตัวแปรนั้นๆได้\nvar x = 10; console.log(x); //Output: 10 x = \u0026quot;hello\u0026quot;; console.log(x); //Output: hello x = [1, 2, 3]; console.log(x); //Output: [1,2,3]  จะเห็นว่าในตอนแรกนั้นตัวแปร x นั้นถูกกำหนดค่า string ไว้ แต่ภายหลังก็สามารถกำหนดค่าด้วย number หรือ array ให้กับตัวแปร x ได้เช่นกัน ในด้านหนึ่งนึงนี่คือความง่ายในการเขียนโค้ด แต่เมื่อโค้ดมีความซับซ้อนขึ้น หรือในการนำไปใช้ในโปรเจ็กใหญ่ๆ การที่ไม่ระบุชนิดของตัวแปรก็อาจจะกลายเป็นความยุ่งยากในการพัฒนาได้ ซึ่งถ้าอยู่ในจุดนั้นคงต้องหาทางเลือกอื่น เช่นการเปลี่ยนไปใช้ TypeScript ในการพัฒนาแทน\n3. เครื่องหมาย == กับ === ต่างกันยังไง ? การสร้างอัลกอริทึมขึ้นมา operator สำหรับการเปรียบเทียบค่าพื้นฐานย่อมเป็นสิ่งจำเป็นที่มีอยู่ในโค้ด เช่น มากกว่า, น้อยกว่า, เท่ากัน หรือ ไม่เท่ากัน สำหรับเครื่องหมายที่ใช้ในการเปรียบเทียบความเท่ากันนั้น อาจจะเคยเห็นหรือเคยใช้ทั้ง == และ === มาแล้ว แต่อาจจะยังไม่เข้าใจว่ามันมีอะไรที่ต่างกัน\nvar a = 10; var b = '10'; a == b // Output: true a === b // Output: false   == จะใช้สำหรับเปรียบเทียบความเท่ากัน (equality) === ใช้ในการเปรียบเทียบความเหมือนกัน/เป็นอย่างเดียวกัน (identically)  ในการใช้งาน == นั้นจะทำการแปลงชนิดของตัวแปรเพื่อเปรียบเทียบกัน ในขณะที่ === จะไม่ทำการแปลงชนิดของข้อมูล แต่จะเปรียบเทียบทั้ง ชนิดของตัวแปร และค่าของตัวแปร โดยตรง\n4. What Is ‘This’ ? ในภาษาอื่นๆเช่น Java นั้น this จะใช้เพื่ออ้างอิงถึง Object ที่กำลังใช้งานอยู่ อย่างเช่น method ภายในคลาสที่ต้องการเรียกค่าตัวแปรภายในคลาสนั้น ก็สามารถระบุได้ด้วยการใช้ this แต่ในส่วนของ JavaScript นั้นจะต่างออกไป โดยจะเปลี่ยนไปตามบริบทที่ใช้งาน เช่น\n// สร้าง Object var pet = { name: \u0026quot;Foo\u0026quot;, weight: 15, info: function() { return \u0026quot;Name: \u0026quot; + this.name+ \u0026quot;, Weight: \u0026quot; + this.weight; } };   this ใน method จะอ้างอิงถึง Object ที่เป็นเจ้าของ เช่นเดียวกันกับภาษา OOP อื่น\nvar x = 10; function run() { var x = 20; console.log(x); //Output: 20 console.log(this.x); //Output: 10 } run();  this ใน function จะอ้างอิงถึง Window Object\n\u0026lt;button onclick=\u0026quot;console.log(this.tagName);\u0026quot;\u0026gt; Click Me \u0026lt;/button\u0026gt; //Output: BUTTON  this ใน event handler จะอ้างอิงถึง HTML Element ที่เป็นตัวทำให้เกิด event นั้นๆ\n  5. Null กับ Undefined ต่างกันยังไง ? สำหรับคนที่เคยเขียน JavaJcript น่าจะเคยเจอ error เกี่ยวกับ null และ undefined มาบ้าง ซึ่งทั้งสองอย่างก็ล้วนแต่เป็นปัญหาเกี่ยวกับตัวแปรเวลาเขียนโค้ดเหมือนๆกัน แล้วสองอย่างนี้แตกต่างกันตรงไหน?\nvar myVarA; console.log(myVarA); //Output: undefined var myVarB = null; console.log(myVarB); //Output: null   Undefined นั้นหมายถึงว่าตัวแปรนั้นถูกประกาศเรียบร้อยแล้วแต่ยังไม่ได้กำหนดค่าให้ตัวแปร Null นั้นเป็นค่าที่ใช้กำหนดให้กับตัวแปรเพื่อสื่อความหมายว่า ตัวแปรนั้นไม่มีค่าอะไร  นอกจากความหมายของทั้งสองตัวจะต่างกันแล้ว ยังมีข้อสังเกตอีกว่า undefined นั้นจะเป็นค่าเริ่มต้นที่โปรแกรมจะกำหนดให้ตัวแปรที่ถูกสร้างขึ้นแต่ยังไม่ได้กำหนดค่าเสมอ ส่วน null นั้นจะเป็นค่าที่โปรแกรมเมอร์เป็นคนกำหนดให้กับตัวแปร (รูปแกนทิชชู)\n6. For / ForEach / For-In / For-Of แบบไหนใช้ยังไง ? ในการเขียนโปรแกรมยังไงก็คงหนีไม่พ้นการใช้ for loop เพราะใช้ในการทำซ้ำงานต่างๆ โดยหลักๆที่ภาษาโปรแกรมอื่นๆมีกันก็น่าจะเป็น for และ for each ที่แต่ละคนคงจะเคยคุ้นเคยกันแล้ว พอมาเป็น javascript ก็มีเช่นกัน แต่ถ้าใครได้ลองหาข้อมูลดูอาจจะได้เจอกับ for-in และ for-of ที่การใช้งานก็ดูคล้ายกันไปหมด แล้วทีนี้เราจะเลือกใช้ for แบบไหนตอนไหนดี\nlet myArray = [1, 2, 3] for (let index = 0; index \u0026lt; myArray.length; index++) { const element = myArray[index]; console.log(element); }  //Output 1 2 3   for – เริ่มที่ตัวพื้นฐาน สำหรับ for ตัวนี้ทุกคนต้องเคยใช้กันแน่นอน โดยจะเป็นการวนลูปตามค่า index ที่กำหนดไว้\nlet myArray = [1, 2, 3] myArray.forEach(element =\u0026gt; { console.log(element); });  //Output 1 2 3  forEach – มาถึงตัวนี้ก็น่าจะรู้จักการทำงานของมันที่เหมือนกันกับภาษาอื่นๆ คือใช้เพื่อเข้าถึงข้อมูลใน Array ต่างๆ โดยที่เราไม่ต้องประกาศค่า index ในการวนลูปเอง แต่ forEach จะเข้าถึงข้อมูลใน Array ตั้งแต่ตำแหน่งแรกจนถึงสุดท้ายให้เรา\nvar dog = { name: \u0026quot;Yoyo\u0026quot;, color: \u0026quot;black\u0026quot;, age: 2 } for (const key in dog) { if (dog.hasOwnProperty(key)) { const element = dog[key]; console.log(key + \u0026quot; : \u0026quot; + element); } }  //Output name : Yoyo color : black age : 2  for…in – สำหรับ for-in ของ javascript นั้นใช้สำหรับวนลูป Object ซึ่งจะได้เป็นชื่อ properties ของ Object นั้นๆ หรือก็คือ key นั่นเอง\n// Array var myArray = [1, 2, 3]; for (const iterator of myArray) { console.log(iterator); }  //Output 1 2 3  // String var str = \u0026quot;hello\u0026quot;; for (const iterator of str) { console.log(iterator); }  //Output h e l l o  for…of – ตัวสุดท้ายกับ for…of ตัวนี้จะใช้งานได้กับ iterable object หมายความว่าอะไรก็ตามที่สามารถวนลูปได้ จะสามารถใช้ for…of ได้นั่นเอง เช่น array, set หรือแม้แต่ string ก็สามารถใช้ได้\n  นี่เป็นเพียงแค่การวนลูปด้วย for ต่างๆเท่านั้น ยังไม่นับรวม while อีก จึงขึ้นอยู่กับการใช้งาน ว่าจะเลือกใช้อันไหนให้เหมาะสมกับความต้องการของเรา\n7. Use Strict คืออะไร ? หลายคนที่เคยได้อ่านโค้ด JavaScript น่าจะเคยผ่านตากับ use strict ที่อยู่บรรทัดแรกของโค้ดมากันบ้าง แต่อาจจะไม่รู้ว่ามันมีไว้เพื่ออะไร use strict มีไว้เพื่อระบุว่าโค้ดในส่วนนั้นจะทำงานใน strict mode ซึ่งจะทำให้ใช้ตัวแปรที่ยังไม่ได้ประกาศไม่ได้ เนื่องจากใน javascript นั้นหากเรียกใช้ตัวแปรโดยไม่ได้ประกาศ var/let/const นำหน้าชื่อตัวแปร ตัวแปรนั้นจะถูกกำหนดเป็น global variables ดังนั้นเพื่อป้องกันความผิดพลาดในการประกาศค่าตัวแปรเราจึงสามารถใช้ use strict ได้\nfunction myFunction1 () { x = 6; console.log(x); //Output: 6 } myFunction1()  function myFunction2 () { \u0026quot;use strict\u0026quot;; y = 7; console.log(y); //Uncaught ReferenceError: y is not defined } myFunction2()  8. Arrow Function ( =\u0026gt; ) คืออะไร ? สำหรับคนที่เพิ่งเริ่มศึกษา JavaScript เวลาค้นหาข้อมูลอาจจะเจอกับเครื่องหมาย =\u0026gt; ที่มีคนมาตอบตามกระทู้คำถามต่างๆเช่นใน Stack Overflow แล้วงงว่ามันคืออะไร ชื่อของเครื่องหมายนี้ก็ตามหัวข้อนี้เลยคือ Arrow Function เป็นสิ่งที่มาพร้อมกับ ES6 เพื่อให้สามารถเขียนฟังก์ชันได้สั้นลง\n// แบบปกติ sayHi = function() { return \u0026quot;Hi Human\u0026quot;; }  // แบบใช้ Arrow Function sayHi = () =\u0026gt; { return \u0026quot;Hi Human\u0026quot;; }  9. String จะใช้ ‘ ’ , “ ” หรือ ? การประกาศค่าให้กับตัวแปรชนิด string ใน JavaScript เราน่าจะเคยเห็นหรือใช้ทั้ง ‘ ’ (single quote) และ “ ” (double quote) ซึ่งทำงานได้เหมือนกันทุกประการ ขึ้นอยู่กับความชอบของแต่ละคน โดยจุดที่แตกต่างกันคือ\nvar str = 'Hello it\\'s me'; console.log(str); //Output: Hello it's me   single quote – ต้องใช้ Escape character สำหรับพิมพ์ single quote\nvar str = \u0026quot;Hello from the \\\u0026quot;other\\\u0026quot; side\u0026quot;; console.log(str); //Output: Hello from the \u0026quot;other\u0026quot; side  double quote – ต้องใช้ Escape character สำหรับพิมพ์ double quote\n  จากสองแบบข้างต้นก็จะทำให้ความยากง่ายในการประกาศค่าตัวแปร string ต่างกันออกไปขึ้นอยู่กับว่าเป็นประโยคแบบไหน เราก็สามารถเลือกใช้ตามความเหมาะสมได้ แต่ยังมีอีกเครื่องหมายนึงที่ใช้ประกาศค่า string ได้ ก็คือ (backtick) ก็คือเครื่องหมายที่อยู่ปุ่มเดียวกันกับปุ่มตัวหนอนที่มักใช้สำหรับเปลี่ยนภาษากันนั่นเอง ส่วนการนำไปใช้งานนั้น\nstr = `Hello it's me from the \u0026quot;other\u0026quot; side`; console.log(str); //Output: Hello it's me from the \u0026quot;other\u0026quot; side   backtick – ไม่ต้องใช้ Escape character ในเวลาที่พิมพ์ทั้ง single quote และ double quote  จะเห็นได้ว่าการใช้ backtick นั้นช่วยให้การประกาศค่า string นั้นทำได้ง่ายขึ้น และโค้ดอ่านได้ง่าย แต่ท้ายที่สุกแล้วก็วนกลับไปที่ความถนัดของแต่ละคนหรือสไตล์ที่คนในทีมเลือกใช้กัน ที่จะเป็นตัวตัดสินว่าเราจะเลือกใช้รูปแบบไหนในการเขียนโค้ดของเราออกมา\n10. Boolean ใน Javascript อะไรบ้างที่เป็น True หรือเป็น False ใน javascript นั้นค่าความจริงหรือ Boolean นั้นมี 2 ค่าด้วยกันนั่นคือ true และ false แต่นอกจากสองอย่างนี้แล้วสิ่งอื่นๆก็ล้วนนำมาเป็นค่าความจริงได้ โดยหลักการมีง่ายๆคือ\nconsole.log(Boolean(\u0026quot;hello\u0026quot;)); // true console.log(Boolean(5)); // true console.log(Boolean(9.99)); // true console.log(Boolean(1 + 2 + 3 + 4 + 5)); // true   อะไรก็ตามที่ “มีค่า” จะนับเป็น true เช่น “hello”, 5, 9.99, 1+2+3+4+5\nconsole.log(Boolean(\u0026quot;\u0026quot;)); // false console.log(Boolean(0)); // false console.log(Boolean(-0)); // false console.log(Boolean(null)); // false console.log(Boolean(undefined)); // false  ส่วนอะไรก็ตามที่ “ไม่มีค่า” จะนับเป็น false เช่น “”, 0, -0, null, undefined\n  อ้างอิง\nJavaScript Tutorial, available in https://www.w3schools.com/js/ 2020. JavaScript reference, available in https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference 2020. เรื่องของ this ใน JavaScript และวิธีการใช้ bind, call, apply, available in https://www.tamemo.com/post/118/what-is-js-this-bind-call-apply/   Written with StackEdit.\n "});index.add({'id':130,'href':'/library/tutorials/docs/book/automate-the-boring-stuff/chapter-13/','title':"13. Working With Excel",'content':" 13 Working With Excel Spreadsheets Although we don’t often think of spreadsheets as programming tools, almost everyone uses them to organize information into two-dimensional data structures, perform calculations with formulas, and produce output as charts. In the next two chapters, we’ll integrate Python into two popular spreadsheet applications: Microsoft Excel and Google Sheets.\nExcel is a popular and powerful spreadsheet application for Windows. The openpyxl module allows your Python programs to read and modify Excel spreadsheet files. For example, you might have the boring task of copying certain data from one spreadsheet and pasting it into another one. Or you might have to go through thousands of rows and pick out just a handful of them to make small edits based on some criteria. Or you might have to look through hundreds of spreadsheets of department budgets, searching for any that are in the red. These are exactly the sort of boring, mindless spreadsheet tasks that Python can do for you.\nAlthough Excel is proprietary software from Microsoft, there are free alternatives that run on Windows, macOS, and Linux. Both LibreOffice Calc and OpenOffice Calc work with Excel’s .xlsx file format for spreadsheets, which means the openpyxl module can work on spreadsheets from these applications as well. You can download the software from https://www.libreoffice.org/ and https://www.openoffice.org/, respectively. Even if you already have Excel installed on your computer, you may find these programs easier to use. The screenshots in this chapter, however, are all from Excel 2010 on Windows 10.\nExcel Documents First, let’s go over some basic definitions: an Excel spreadsheet document is called a workbook. A single workbook is saved in a file with the .xlsx extension. Each workbook can contain multiple sheets (also called worksheets). The sheet the user is currently viewing (or last viewed before closing Excel) is called the active sheet.\nEach sheet has columns (addressed by letters starting at A) and rows (addressed by numbers starting at 1). A box at a particular column and row is called a cell. Each cell can contain a number or text value. The grid of cells with data makes up a sheet.\nInstalling the openpyxl Module Python does not come with OpenPyXL, so you’ll have to install it. Follow the instructions for installing third-party modules in Appendix A; the name of the module is openpyxl.\nThis book uses version 2.6.2 of OpenPyXL. It’s important that you install this version by running pip install \u0026ndash;user -U openpyxl==2.6.2 because newer versions of OpenPyXL are incompatible with the information in this book. To test whether it is installed correctly, enter the following into the interactive shell:\nimport openpyxl  If the module was correctly installed, this should produce no error messages. Remember to import the openpyxl module before running the interactive shell examples in this chapter, or you’ll get a NameError: name \u0026lsquo;openpyxl\u0026rsquo; is not defined error.\nYou can find the full documentation for OpenPyXL at https://openpyxl.readthedocs.org/.\nReading Excel Documents The examples in this chapter will use a spreadsheet named example.xlsx stored in the root folder. You can either create the spreadsheet yourself or download it from https://nostarch.com/automatestuff2/. Figure 13-1 shows the tabs for the three default sheets named Sheet1, Sheet2, and Sheet3 that Excel automatically provides for new workbooks. (The number of default sheets created may vary between operating systems and spreadsheet programs.)\nFigure 13-1: The tabs for a workbook’s sheets are in the lower-left corner of Excel.\nSheet 1 in the example file should look like Table 13-1. (If you didn’t download example.xlsx from the website, you should enter this data into the sheet yourself.)\nTable 13-1: The example.xlsx Spreadsheet\n   No. A B C     1 4/5/2015 1:34:02 PM Apples 73   2 4/5/2015 3:41:23 AM Cherries 85   3 4/6/2015 12:46:51 PM Pears 14   4 4/8/2015 8:59:43 AM Oranges 52   5 4/10/2015 2:07:00 AM Apples 152   6 4/10/2015 6:10:37 PM Bananas 23   7 4/10/2015 2:40:46 AM Strawberries 98    Now that we have our example spreadsheet, let’s see how we can manipulate it with the openpyxl module.\nOpening Excel Documents with OpenPyXL Once you’ve imported the openpyxl module, you’ll be able to use the openpyxl.load_workbook() function. Enter the following into the interactive shell:\nimport openpyxl wb = openpyxl.load_workbook('example.xlsx') type(wb) # \u0026lt;class 'openpyxl.workbook.workbook.Workbook'\u0026gt;  The openpyxl.load_workbook() function takes in the filename and returns a value of the workbook data type. This Workbook object represents the Excel file, a bit like how a File object represents an opened text file.\nRemember that example.xlsx needs to be in the current working directory in order for you to work with it. You can find out what the current working directory is by importing os and using os.getcwd(), and you can change the current working directory using os.chdir().\nGetting Sheets from the Workbook You can get a list of all the sheet names in the workbook by accessing the sheetnames attribute. Enter the following into the interactive shell:\nimport openpyxl wb = openpyxl.load_workbook('example.xlsx') wb.sheetnames # The workbook's sheets' names. ['Sheet1', 'Sheet2', 'Sheet3'] sheet = wb['Sheet3'] # Get a sheet from the workbook. sheet \u0026lt;Worksheet \u0026quot;Sheet3\u0026quot;\u0026gt; type(sheet) \u0026lt;class 'openpyxl.worksheet.worksheet.Worksheet'\u0026gt; sheet.title # Get the sheet's title as a string. 'Sheet3' anotherSheet = wb.active # Get the active sheet. anotherSheet \u0026lt;Worksheet \u0026quot;Sheet1\u0026quot;\u0026gt;  Each sheet is represented by a Worksheet object, which you can obtain by using the square brackets with the sheet name string like a dictionary key. Finally, you can use the active attribute of a Workbook object to get the workbook’s active sheet. The active sheet is the sheet that’s on top when the workbook is opened in Excel. Once you have the Worksheet object, you can get its name from the title attribute.\nGetting Cells from the Sheets Once you have a Worksheet object, you can access a Cell object by its name. Enter the following into the interactive shell:\nimport openpyxl wb = openpyxl.load_workbook('example.xlsx') sheet = wb['Sheet1'] # Get a sheet from the workbook. sheet['A1'] # Get a cell from the sheet. \u0026lt;Cell 'Sheet1'.A1\u0026gt; sheet['A1'].value # Get the value from the cell. datetime.datetime(2015, 4, 5, 13, 34, 2) c = sheet['B1'] # Get another cell from the sheet. c.value 'Apples' # Get the row, column, and value from the cell. 'Row %s, Column %s is %s' % (c.row, c.column, c.value) 'Row 1, Column B is Apples' 'Cell %s is %s' % (c.coordinate, c.value) 'Cell B1 is Apples' sheet['C1'].value 73  The Cell object has a value attribute that contains, unsurprisingly, the value stored in that cell. Cell objects also have row, column, and coordinate attributes that provide location information for the cell.\nHere, accessing the value attribute of our Cell object for cell B1 gives us the string \u0026lsquo;Apples\u0026rsquo;. The row attribute gives us the integer 1, the column attribute gives us \u0026lsquo;B\u0026rsquo;, and the coordinate attribute gives us \u0026lsquo;B1\u0026rsquo;.\nOpenPyXL will automatically interpret the dates in column A and return them as datetime values rather than strings. The datetime data type is explained further in Chapter 17.\nSpecifying a column by letter can be tricky to program, especially because after column Z, the columns start by using two letters: AA, AB, AC, and so on. As an alternative, you can also get a cell using the sheet’s cell() method and passing integers for its row and column keyword arguments. The first row or column integer is 1, not 0. Continue the interactive shell example by entering the following:\nsheet.cell(row=1, column=2) \u0026lt;Cell 'Sheet1'.B1\u0026gt; sheet.cell(row=1, column=2).value 'Apples' for i in range(1, 8, 2): # Go through every other row: ... print(i, sheet.cell(row=i, column=2).value) ... 1 Apples 3 Pears 5 Apples 7 Strawberries  As you can see, using the sheet’s cell() method and passing it row=1 and column=2 gets you a Cell object for cell B1, just like specifying sheet[\u0026lsquo;B1\u0026rsquo;] did. Then, using the cell() method and its keyword arguments, you can write a for loop to print the values of a series of cells.\nSay you want to go down column B and print the value in every cell with an odd row number. By passing 2 for the range() function’s “step” parameter, you can get cells from every second row (in this case, all the odd-numbered rows). The for loop’s i variable is passed for the row keyword argument to the cell() method, while 2 is always passed for the column keyword argument. Note that the integer 2, not the string \u0026lsquo;B\u0026rsquo;, is passed.\nYou can determine the size of the sheet with the Worksheet object’s max_row and max_column attributes. Enter the following into the interactive shell:\nimport openpyxl wb = openpyxl.load_workbook('example.xlsx') sheet = wb['Sheet1'] sheet.max_row # Get the highest row number. 7 sheet.max_column # Get the highest column number. 3  Note that the max_column attribute is an integer rather than the letter that appears in Excel.\nConverting Between Column Letters and Numbers To convert from letters to numbers, call the openpyxl.utils.column_index_from_string() function. To convert from numbers to letters, call the openpyxl.utils.get_column_letter() function. Enter the following into the interactive shell:\nimport openpyxl from openpyxl.utils import get_column_letter, column_index_from_string get_column_letter(1) # Translate column 1 to a letter. 'A' get_column_letter(2) 'B' get_column_letter(27) 'AA' get_column_letter(900) 'AHP' wb = openpyxl.load_workbook('example.xlsx') sheet = wb['Sheet1'] get_column_letter(sheet.max_column) 'C' column_index_from_string('A') # Get A's number. 1 column_index_from_string('AA') 27  After you import these two functions from the openpyxl.utils module, you can call get_column_letter() and pass it an integer like 27 to figure out what the letter name of the 27th column is. The function column_index_string() does the reverse: you pass it the letter name of a column, and it tells you what number that column is. You don’t need to have a workbook loaded to use these functions. If you want, you can load a workbook, get a Worksheet object, and use a Worksheet attribute like max_column to get an integer. Then, you can pass that integer to get_column_letter().\nGetting Rows and Columns from the Sheets You can slice Worksheet objects to get all the Cell objects in a row, column, or rectangular area of the spreadsheet. Then you can loop over all the cells in the slice. Enter the following into the interactive shell:\nimport openpyxl wb = openpyxl.load_workbook('example.xlsx') sheet = wb['Sheet1'] tuple(sheet['A1':'C3']) # Get all cells from A1 to C3. ((\u0026lt;Cell 'Sheet1'.A1\u0026gt;, \u0026lt;Cell 'Sheet1'.B1\u0026gt;, \u0026lt;Cell 'Sheet1'.C1\u0026gt;), (\u0026lt;Cell 'Sheet1'.A2\u0026gt;, \u0026lt;Cell 'Sheet1'.B2\u0026gt;, \u0026lt;Cell 'Sheet1'.C2\u0026gt;), (\u0026lt;Cell 'Sheet1'.A3\u0026gt;, \u0026lt;Cell 'Sheet1'.B3\u0026gt;, \u0026lt;Cell 'Sheet1'.C3\u0026gt;)) ➊ for rowOfCellObjects in sheet['A1':'C3']: ➋ ... for cellObj in rowOfCellObjects: ... print(cellObj.coordinate, cellObj.value) ... print('--- END OF ROW ---') A1 2015-04-05 13:34:02 B1 Apples C1 73 --- END OF ROW --- A2 2015-04-05 03:41:23 B2 Cherries C2 85 --- END OF ROW --- A3 2015-04-06 12:46:51 B3 Pears C3 14 --- END OF ROW ---  Here, we specify that we want the Cell objects in the rectangular area from A1 to C3, and we get a Generator object containing the Cell objects in that area. To help us visualize this Generator object, we can use tuple() on it to display its Cell objects in a tuple.\nThis tuple contains three tuples: one for each row, from the top of the desired area to the bottom. Each of these three inner tuples contains the Cell objects in one row of our desired area, from the leftmost cell to the right. So overall, our slice of the sheet contains all the Cell objects in the area from A1 to C3, starting from the top-left cell and ending with the bottom-right cell.\nTo print the values of each cell in the area, we use two for loops. The outer for loop goes over each row in the slice ➊. Then, for each row, the nested for loop goes through each cell in that row ➋.\nTo access the values of cells in a particular row or column, you can also use a Worksheet object’s rows and columns attribute. These attributes must be converted to lists with the list() function before you can use the square brackets and an index with them. Enter the following into the interactive shell:\nimport openpyxl wb = openpyxl.load_workbook('example.xlsx') sheet = wb.active list(sheet.columns)[1] # Get second column's cells. (\u0026lt;Cell 'Sheet1'.B1\u0026gt;, \u0026lt;Cell 'Sheet1'.B2\u0026gt;, \u0026lt;Cell 'Sheet1'.B3\u0026gt;, \u0026lt;Cell 'Sheet1'. B4\u0026gt;, \u0026lt;Cell 'Sheet1'.B5\u0026gt;, \u0026lt;Cell 'Sheet1'.B6\u0026gt;, \u0026lt;Cell 'Sheet1'.B7\u0026gt;) for cellObj in list(sheet.columns)[1]: print(cellObj.value) # Apples # Cherries # Pears # Oranges # Apples # Bananas # Strawberries  Using the rows attribute on a Worksheet object will give you a tuple of tuples. Each of these inner tuples represents a row, and contains the Cell objects in that row. The columns attribute also gives you a tuple of tuples, with each of the inner tuples containing the Cell objects in a particular column. For example.xlsx, since there are 7 rows and 3 columns, rows gives us a tuple of 7 tuples (each containing 3 Cell objects), and columns gives us a tuple of 3 tuples (each containing 7 Cell objects).\nTo access one particular tuple, you can refer to it by its index in the larger tuple. For example, to get the tuple that represents column B, you use list(sheet.columns)[1]. To get the tuple containing the Cell objects in column A, you’d use list(sheet.columns)[0]. Once you have a tuple representing one row or column, you can loop through its Cell objects and print their values.\nWorkbooks, Sheets, Cells As a quick review, here’s a rundown of all the functions, methods, and data types involved in reading a cell out of a spreadsheet file:\n Import the openpyxl module. Call the openpyxl.load_workbook() function. Get a Workbook object. Use the active or sheetnames attributes. Get a Worksheet object. Use indexing or the cell() sheet method with row and column keyword arguments. Get a Cell object. Read the Cell object’s value attribute.  Project: Reading Data from a Spreadsheet Say you have a spreadsheet of data from the 2010 US Census and you have the boring task of going through its thousands of rows to count both the total population and the number of census tracts for each county. (A census tract is simply a geographic area defined for the purposes of the census.) Each row represents a single census tract. We’ll name the spreadsheet file censuspopdata.xlsx, and you can download it from https://nostarch.com/automatestuff2/. Its contents look like Figure 13-2.\nFigure 13-2: The censuspopdata.xlsx spreadsheet\nEven though Excel can calculate the sum of multiple selected cells, you’d still have to select the cells for each of the 3,000-plus counties. Even if it takes just a few seconds to calculate a county’s population by hand, this would take hours to do for the whole spreadsheet.\nIn this project, you’ll write a script that can read from the census spreadsheet file and calculate statistics for each county in a matter of seconds.\nThis is what your program does:\n Reads the data from the Excel spreadsheet Counts the number of census tracts in each county Counts the total population of each county Prints the results This means your code will need to do the following:\n Open and read the cells of an Excel document with the openpyxl module.\n Calculate all the tract and population data and store it in a data structure.\n Write the data structure to a text file with the .py extension using the pprint module.\n  Step 1: Read the Spreadsheet Data There is just one sheet in the censuspopdata.xlsx spreadsheet, named \u0026lsquo;Population by Census Tract\u0026rsquo;, and each row holds the data for a single census tract. The columns are the tract number (A), the state abbreviation (B), the county name \u0026copy;, and the population of the tract (D).\nOpen a new file editor tab and enter the following code. Save the file as readCensusExcel.py.\n#! python3 # readCensusExcel.py - Tabulates population and number of census tracts for # each county. ➊ import openpyxl, pprint print('Opening workbook...') ➋ wb = openpyxl.load_workbook('censuspopdata.xlsx') ➌ sheet = wb['Population by Census Tract'] countyData = {} # TODO: Fill in countyData with each county's population and tracts. print('Reading rows...') ➍ for row in range(2, sheet.max_row + 1): # Each row in the spreadsheet has data for one census tract. state = sheet['B' + str(row)].value county = sheet['C' + str(row)].value pop = sheet['D' + str(row)].value # TODO: Open a new text file and write the contents of countyData to it.  This code imports the openpyxl module, as well as the pprint module that you’ll use to print the final county data ➊. Then it opens the censuspopdata.xlsx file ➋, gets the sheet with the census data ➌, and begins iterating over its rows ➍.\nNote that you’ve also created a variable named countyData, which will contain the populations and number of tracts you calculate for each county. Before you can store anything in it, though, you should determine exactly how you’ll structure the data inside it.\nStep 2: Populate the Data Structure The data structure stored in countyData will be a dictionary with state abbreviations as its keys. Each state abbreviation will map to another dictionary, whose keys are strings of the county names in that state. Each county name will in turn map to a dictionary with just two keys, \u0026lsquo;tracts\u0026rsquo; and \u0026lsquo;pop\u0026rsquo;. These keys map to the number of census tracts and population for the county. For example, the dictionary will look similar to this:\n{'AK': {'Aleutians East': {'pop': 3141, 'tracts': 1}, 'Aleutians West': {'pop': 5561, 'tracts': 2}, 'Anchorage': {'pop': 291826, 'tracts': 55}, 'Bethel': {'pop': 17013, 'tracts': 3}, 'Bristol Bay': {'pop': 997, 'tracts': 1}, --snip--  If the previous dictionary were stored in countyData, the following expressions would evaluate like this:\ncountyData['AK']['Anchorage']['pop'] 291826 countyData['AK']['Anchorage']['tracts'] 55  More generally, the countyData dictionary’s keys will look like this:\ncountyData[state abbrev][county]['tracts'] countyData[state abbrev][county]['pop']  Now that you know how countyData will be structured, you can write the code that will fill it with the county data. Add the following code to the bottom of your program:\n#! python 3 # readCensusExcel.py - Tabulates population and number of census tracts for # each county. --snip-- for row in range(2, sheet.max_row + 1): # Each row in the spreadsheet has data for one census tract. state = sheet['B' + str(row)].value county = sheet['C' + str(row)].value pop = sheet['D' + str(row)].value # Make sure the key for this state exists. ➊ countyData.setdefault(state, {}) # Make sure the key for this county in this state exists. ➋ countyData[state].setdefault(county, {'tracts': 0, 'pop': 0}) # Each row represents one census tract, so increment by one. ➌ countyData[state][county]['tracts'] += 1 # Increase the county pop by the pop in this census tract. ➍ countyData[state][county]['pop'] += int(pop) # TODO: Open a new text file and write the contents of countyData to it.  The last two lines of code perform the actual calculation work, incrementing the value for tracts ➌ and increasing the value for pop ➍ for the current county on each iteration of the for loop.\nThe other code is there because you cannot add a county dictionary as the value for a state abbreviation key until the key itself exists in countyData. (That is, countyData[\u0026lsquo;AK\u0026rsquo;][\u0026lsquo;Anchorage\u0026rsquo;][\u0026lsquo;tracts\u0026rsquo;] += 1 will cause an error if the \u0026lsquo;AK\u0026rsquo; key doesn’t exist yet.) To make sure the state abbreviation key exists in your data structure, you need to call the setdefault() method to set a value if one does not already exist for state ➊.\nJust as the countyData dictionary needs a dictionary as the value for each state abbreviation key, each of those dictionaries will need its own dictionary as the value for each county key ➋. And each of those dictionaries in turn will need keys \u0026lsquo;tracts\u0026rsquo; and \u0026lsquo;pop\u0026rsquo; that start with the integer value 0. (If you ever lose track of the dictionary structure, look back at the example dictionary at the start of this section.)\nSince setdefault() will do nothing if the key already exists, you can call it on every iteration of the for loop without a problem.\nStep 3: Write the Results to a File After the for loop has finished, the countyData dictionary will contain all of the population and tract information keyed by county and state. At this point, you could program more code to write this to a text file or another Excel spreadsheet. For now, let’s just use the pprint.pformat() function to write the countyData dictionary value as a massive string to a file named census2010.py. Add the following code to the bottom of your program (making sure to keep it unindented so that it stays outside the for loop):\n#! python 3 # readCensusExcel.py - Tabulates population and number of census tracts for # each county. --snip-- for row in range(2, sheet.max_row + 1): --snip-- # Open a new text file and write the contents of countyData to it. print('Writing results...') resultFile = open('census2010.py', 'w') resultFile.write('allData = ' + pprint.pformat(countyData)) resultFile.close() print('Done.')  The pprint.pformat() function produces a string that itself is formatted as valid Python code. By outputting it to a text file named census2010.py, you’ve generated a Python program from your Python program! This may seem complicated, but the advantage is that you can now import census2010.py just like any other Python module. In the interactive shell, change the current working directory to the folder with your newly created census2010.py file and then import it:\nimport os import census2010 census2010.allData['AK']['Anchorage'] {'pop': 291826, 'tracts': 55} anchoragePop = census2010.allData['AK']['Anchorage']['pop'] print('The 2010 population of Anchorage was ' + str(anchoragePop)) The 2010 population of Anchorage was 291826  The readCensusExcel.py program was throwaway code: once you have its results saved to census2010.py, you won’t need to run the program again. Whenever you need the county data, you can just run import census2010.\nCalculating this data by hand would have taken hours; this program did it in a few seconds. Using OpenPyXL, you will have no trouble extracting information that is saved to an Excel spreadsheet and performing calculations on it. You can download the complete program from https://nostarch.com/automatestuff2/.\nIdeas for Similar Programs Many businesses and offices use Excel to store various types of data, and it’s not uncommon for spreadsheets to become large and unwieldy. Any program that parses an Excel spreadsheet has a similar structure: it loads the spreadsheet file, preps some variables or data structures, and then loops through each of the rows in the spreadsheet. Such a program could do the following:\n Compare data across multiple rows in a spreadsheet. Open multiple Excel files and compare data between spreadsheets. Check whether a spreadsheet has blank rows or invalid data in any cells and alert the user if it does. Read data from a spreadsheet and use it as the input for your Python programs.  Writing Excel Documents OpenPyXL also provides ways of writing data, meaning that your programs can create and edit spreadsheet files. With Python, it’s simple to create spreadsheets with thousands of rows of data.\nCreating and Saving Excel Documents Call the openpyxl.Workbook() function to create a new, blank Workbook object. Enter the following into the interactive shell:\nimport openpyxl wb = openpyxl.Workbook() # Create a blank workbook. wb.sheetnames # It starts with one sheet. ['Sheet'] sheet = wb.active sheet.title 'Sheet' sheet.title = 'Spam Bacon Eggs Sheet' # Change title. wb.sheetnames ['Spam Bacon Eggs Sheet']  The workbook will start off with a single sheet named Sheet. You can change the name of the sheet by storing a new string in its title attribute.\nAny time you modify the Workbook object or its sheets and cells, the spreadsheet file will not be saved until you call the save() workbook method. Enter the following into the interactive shell (with example.xlsx in the current working directory):\nimport openpyxl wb = openpyxl.load_workbook('example.xlsx') sheet = wb.active sheet.title = 'Spam Spam Spam' wb.save('example_copy.xlsx') # Save the workbook.  Here, we change the name of our sheet. To save our changes, we pass a filename as a string to the save() method. Passing a different filename than the original, such as \u0026lsquo;example_copy.xlsx\u0026rsquo;, saves the changes to a copy of the spreadsheet.\nWhenever you edit a spreadsheet you’ve loaded from a file, you should always save the new, edited spreadsheet to a different filename than the original. That way, you’ll still have the original spreadsheet file to work with in case a bug in your code caused the new, saved file to have incorrect or corrupt data.\nCreating and Removing Sheets Sheets can be added to and removed from a workbook with the create_sheet() method and del operator. Enter the following into the interactive shell:\nimport openpyxl wb = openpyxl.Workbook() wb.sheetnames ['Sheet'] wb.create_sheet() # Add a new sheet. \u0026lt;Worksheet \u0026quot;Sheet1\u0026quot;\u0026gt; wb.sheetnames ['Sheet', 'Sheet1'] # Create a new sheet at index 0. wb.create_sheet(index=0, title='First Sheet') \u0026lt;Worksheet \u0026quot;First Sheet\u0026quot;\u0026gt; wb.sheetnames ['First Sheet', 'Sheet', 'Sheet1'] wb.create_sheet(index=2, title='Middle Sheet') \u0026lt;Worksheet \u0026quot;Middle Sheet\u0026quot;\u0026gt; wb.sheetnames ['First Sheet', 'Sheet', 'Middle Sheet', 'Sheet1']  The create_sheet() method returns a new Worksheet object named SheetX, which by default is set to be the last sheet in the workbook. Optionally, the index and name of the new sheet can be specified with the index and title keyword arguments.\nContinue the previous example by entering the following:\nwb.sheetnames ['First Sheet', 'Sheet', 'Middle Sheet', 'Sheet1'] del wb['Middle Sheet'] del wb['Sheet1'] wb.sheetnames ['First Sheet', 'Sheet']  You can use the del operator to delete a sheet from a workbook, just like you can use it to delete a key-value pair from a dictionary.\nRemember to call the save() method to save the changes after adding sheets to or removing sheets from the workbook.\nWriting Values to Cells Writing values to cells is much like writing values to keys in a dictionary. Enter this into the interactive shell:\nimport openpyxl wb = openpyxl.Workbook() sheet = wb['Sheet'] sheet['A1'] = 'Hello, world!' # Edit the cell's value. sheet['A1'].value 'Hello, world!'  If you have the cell’s coordinate as a string, you can use it just like a dictionary key on the Worksheet object to specify which cell to write to.\nProject: Updating a Spreadsheet In this project, you’ll write a program to update cells in a spreadsheet of produce sales. Your program will look through the spreadsheet, find specific kinds of produce, and update their prices. Download this spreadsheet from https://nostarch.com/automatestuff2/. Figure 13-3 shows what the spreadsheet looks like.\nFigure 13-3: A spreadsheet of produce sales\nEach row represents an individual sale. The columns are the type of produce sold (A), the cost per pound of that produce (B), the number of pounds sold \u0026copy;, and the total revenue from the sale (D). The TOTAL column is set to the Excel formula =ROUND(B3*C3, 2), which multiplies the cost per pound by the number of pounds sold and rounds the result to the nearest cent. With this formula, the cells in the TOTAL column will automatically update themselves if there is a change in column B or C.\nNow imagine that the prices of garlic, celery, and lemons were entered incorrectly, leaving you with the boring task of going through thousands of rows in this spreadsheet to update the cost per pound for any garlic, celery, and lemon rows. You can’t do a simple find-and-replace for the price, because there might be other items with the same price that you don’t want to mistakenly “correct.” For thousands of rows, this would take hours to do by hand. But you can write a program that can accomplish this in seconds.\nYour program does the following:\n Loops over all the rows If the row is for garlic, celery, or lemons, changes the price  This means your code will need to do the following:\n Open the spreadsheet file. For each row, check whether the value in column A is Celery, Garlic, or Lemon. If it is, update the price in column B. Save the spreadsheet to a new file (so that you don’t lose the old spreadsheet, just in case).  Step 1: Set Up a Data Structure with the Update Information The prices that you need to update are as follows:\nCelery 1.19 Garlic 3.07 Lemon 1.27  You could write code like this:\nif produceName == 'Celery': cellObj = 1.19 if produceName == 'Garlic': cellObj = 3.07 if produceName == 'Lemon': cellObj = 1.27  Having the produce and updated price data hardcoded like this is a bit inelegant. If you needed to update the spreadsheet again with different prices or different produce, you would have to change a lot of the code. Every time you change code, you risk introducing bugs.\nA more flexible solution is to store the corrected price information in a dictionary and write your code to use this data structure. In a new file editor tab, enter the following code:\n#! python3 # updateProduce.py - Corrects costs in produce sales spreadsheet. import openpyxl wb = openpyxl.load_workbook('produceSales.xlsx') sheet = wb['Sheet'] # The produce types and their updated prices PRICE_UPDATES = {'Garlic': 3.07, 'Celery': 1.19, 'Lemon': 1.27} # TODO: Loop through the rows and update the prices.  Save this as updateProduce.py. If you need to update the spreadsheet again, you’ll need to update only the PRICE_UPDATES dictionary, not any other code.\nStep 2: Check All Rows and Update Incorrect Prices The next part of the program will loop through all the rows in the spreadsheet. Add the following code to the bottom of updateProduce.py:\n#! python3 # updateProduce.py - Corrects costs in produce sales spreadsheet. --snip-- # Loop through the rows and update the prices. ➊ for rowNum in range(2, sheet.max_row): # skip the first row ➋ produceName = sheet.cell(row=rowNum, column=1).value ➌ if produceName in PRICE_UPDATES: sheet.cell(row=rowNum, column=2).value = PRICE_UPDATES[produceName] ➍ wb.save('updatedProduceSales.xlsx')  We loop through the rows starting at row 2, since row 1 is just the header ➊. The cell in column 1 (that is, column A) will be stored in the variable produceName ➋. If produceName exists as a key in the PRICE_UPDATES dictionary ➌, then you know this is a row that must have its price corrected. The correct price will be in PRICE_UPDATES[produceName].\nNotice how clean using PRICE_UPDATES makes the code. Only one if statement, rather than code like if produceName == \u0026lsquo;Garlic\u0026rsquo;: , is necessary for every type of produce to update. And since the code uses the PRICE_UPDATES dictionary instead of hardcoding the produce names and updated costs into the for loop, you modify only the PRICE_UPDATES dictionary and not the code if the produce sales spreadsheet needs additional changes.\nAfter going through the entire spreadsheet and making changes, the code saves the Workbook object to updatedProduceSales.xlsx ➍. It doesn’t overwrite the old spreadsheet just in case there’s a bug in your program and the updated spreadsheet is wrong. After checking that the updated spreadsheet looks right, you can delete the old spreadsheet.\nYou can download the complete source code for this program from https://nostarch.com/automatestuff2/.\nIdeas for Similar Programs Since many office workers use Excel spreadsheets all the time, a program that can automatically edit and write Excel files could be really useful. Such a program could do the following:\nRead data from one spreadsheet and write it to parts of other spreadsheets. Read data from websites, text files, or the clipboard and write it to a spreadsheet.\nAutomatically “clean up” data in spreadsheets. For example, it could use regular expressions to read multiple formats of phone numbers and edit them to a single, standard format.\nSetting the Font Style of Cells Styling certain cells, rows, or columns can help you emphasize important areas in your spreadsheet. In the produce spreadsheet, for example, your program could apply bold text to the potato, garlic, and parsnip rows. Or perhaps you want to italicize every row with a cost per pound greater than $5. Styling parts of a large spreadsheet by hand would be tedious, but your programs can do it instantly.\nTo customize font styles in cells, important, import the Font() function from the openpyxl.styles module.\nfrom openpyxl.styles import Font  This allows you to type Font() instead of openpyxl.styles.Font(). (See “Importing Modules” on page 47 to review this style of import statement.)\nHere’s an example that creates a new workbook and sets cell A1 to have a 24-point, italicized font. Enter the following into the interactive shell:\nimport openpyxl from openpyxl.styles import Font wb = openpyxl.Workbook() sheet = wb['Sheet'] ➊ italic24Font = Font(size=24, italic=True) # Create a font. ➋ sheet['A1'].font = italic24Font # Apply the font to A1. sheet['A1'] = 'Hello, world!' wb.save('styles.xlsx')  In this example, Font(size=24, italic=True) returns a Font object, which is stored in italic24Font ➊. The keyword arguments to Font(), size and italic, configure the Font object’s styling information. And when sheet[\u0026lsquo;A1\u0026rsquo;].font is assigned the italic24Font object ➋, all that font styling information gets applied to cell A1.\nFont Objects To set font attributes, you pass keyword arguments to Font(). Table 13-2 shows the possible keyword arguments for the Font() function.\nTable 13-2: Keyword Arguments for Font Objects\n   Keyword argument Data type Description     name String The font name, such as \u0026lsquo;Calibri\u0026rsquo; or \u0026lsquo;Times New Roman\u0026rsquo;   size Integer The point size   bold Boolean True, for bold font   italic Boolean True, for italic font    You can call Font() to create a Font object and store that Font object in a variable. You then assign that variable to a Cell object’s font attribute. For example, this code creates various font styles:\nimport openpyxl from openpyxl.styles import Font wb = openpyxl.Workbook() sheet = wb['Sheet'] fontObj1 = Font(name='Times New Roman', bold=True) sheet['A1'].font = fontObj1 sheet['A1'] = 'Bold Times New Roman' fontObj2 = Font(size=24, italic=True) sheet['B3'].font = fontObj2 sheet['B3'] = '24 pt Italic' wb.save('styles.xlsx')  Here, we store a Font object in fontObj1 and then set the A1 Cell object’s font attribute to fontObj1. We repeat the process with another Font object to set the font of a second cell. After you run this code, the styles of the A1 and B3 cells in the spreadsheet will be set to custom font styles, as shown in Figure 13-4.\nFigure 13-4: A spreadsheet with custom font styles\nFor cell A1, we set the font name to \u0026lsquo;Times New Roman\u0026rsquo; and set bold to true, so our text appears in bold Times New Roman. We didn’t specify a size, so the openpyxl default, 11, is used. In cell B3, our text is italic, with a size of 24; we didn’t specify a font name, so the openpyxl default, Calibri, is used.\nFormulas Excel formulas, which begin with an equal sign, can configure cells to contain values calculated from other cells. In this section, you’ll use the openpyxl module to programmatically add formulas to cells, just like any normal value. For example:\nsheet['B9'] = '=SUM(B1:B8)'  This will store =SUM(B1:B8) as the value in cell B9. This sets the B9 cell to a formula that calculates the sum of values in cells B1 to B8. You can see this in action in Figure 13-5.\nFigure 13-5: Cell B9 contains the formula =SUM(B1:B8), which adds the cells B1 to B8.\nAn Excel formula is set just like any other text value in a cell. Enter the following into the interactive shell:\nimport openpyxl wb = openpyxl.Workbook() sheet = wb.active sheet['A1'] = 200 sheet['A2'] = 300 sheet['A3'] = '=SUM(A1:A2)' # Set the formula. wb.save('writeFormula.xlsx')  The cells in A1 and A2 are set to 200 and 300, respectively. The value in cell A3 is set to a formula that sums the values in A1 and A2. When the spreadsheet is opened in Excel, A3 will display its value as 500.\nExcel formulas offer a level of programmability for spreadsheets but can quickly become unmanageable for complicated tasks. For example, even if you’re deeply familiar with Excel formulas, it’s a headache to try to decipher what =IFERROR(TRIM(IF(LEN(VLOOKUP(F7, Sheet2!$A$1:$B$10000, 2, FALSE))\u0026gt;0,SUBSTITUTE(VLOOKUP(F7, Sheet2!$A$1:$B$10000, 2, FALSE), \u0026quot; \u0026quot;, \u0026quot;\u0026quot;),\u0026quot;\u0026quot;)), \u0026quot;\u0026quot;)actually does. Python code is much more readable.\nAdjusting Rows and Columns In Excel, adjusting the sizes of rows and columns is as easy as clicking and dragging the edges of a row or column header. But if you need to set a row or column’s size based on its cells’ contents or if you want to set sizes in a large number of spreadsheet files, it will be much quicker to write a Python program to do it.\nRows and columns can also be hidden entirely from view. Or they can be “frozen” in place so that they are always visible on the screen and appear on every page when the spreadsheet is printed (which is handy for headers).\nSetting Row Height and Column Width Worksheet objects have row_dimensions and column_dimensions attributes that control row heights and column widths. Enter this into the interactive shell:\nimport openpyxl wb = openpyxl.Workbook() sheet = wb.active sheet['A1'] = 'Tall row' sheet['B2'] = 'Wide column' # Set the height and width: sheet.row_dimensions[1].height = 70 sheet.column_dimensions['B'].width = 20 wb.save('dimensions.xlsx')  A sheet’s row_dimensions and column_dimensions are dictionary-like values; row_dimensions contains RowDimension objects and column_dimensions contains ColumnDimension objects. In row_dimensions, you can access one of the objects using the number of the row (in this case, 1 or 2). In column_dimensions, you can access one of the objects using the letter of the column (in this case, A or B).\nThe dimensions.xlsx spreadsheet looks like Figure 13-6.\nFigure 13-6: Row 1 and column B set to larger heights and widths\nOnce you have the RowDimension object, you can set its height. Once you have the ColumnDimension object, you can set its width. The row height can be set to an integer or float value between 0 and 409. This value represents the height measured in points, where one point equals 1\u0026frasl;72 of an inch. The default row height is 12.75. The column width can be set to an integer or float value between 0 and 255. This value represents the number of characters at the default font size (11 point) that can be displayed in the cell. The default column width is 8.43 characters. Columns with widths of 0 or rows with heights of 0 are hidden from the user.\nMerging and Unmerging Cells A rectangular area of cells can be merged into a single cell with the merge_cells() sheet method. Enter the following into the interactive shell:\nimport openpyxl wb = openpyxl.Workbook() sheet = wb.active sheet.merge_cells('A1:D3') # Merge all these cells. sheet['A1'] = 'Twelve cells merged together.' sheet.merge_cells('C5:D5') # Merge these two cells. sheet['C5'] = 'Two merged cells.' wb.save('merged.xlsx')  The argument to merge_cells() is a single string of the top-left and bottom-right cells of the rectangular area to be merged: \u0026lsquo;A1:D3\u0026rsquo; merges 12 cells into a single cell. To set the value of these merged cells, simply set the value of the top-left cell of the merged group.\nWhen you run this code, merged.xlsx will look like Figure 13-7.\nFigure 13-7: Merged cells in a spreadsheet\nTo unmerge cells, call the unmerge_cells() sheet method. Enter this into the interactive shell:\nimport openpyxl wb = openpyxl.load_workbook('merged.xlsx') sheet = wb.active sheet.unmerge_cells('A1:D3') # Split these cells up. sheet.unmerge_cells('C5:D5') wb.save('merged.xlsx')  If you save your changes and then take a look at the spreadsheet, you’ll see that the merged cells have gone back to being individual cells.\nFreezing Panes For spreadsheets too large to be displayed all at once, it’s helpful to “freeze” a few of the top rows or leftmost columns onscreen. Frozen column or row headers, for example, are always visible to the user even as they scroll through the spreadsheet. These are known as freeze panes. In OpenPyXL, each Worksheet object has a freeze_panes attribute that can be set to a Cell object or a string of a cell’s coordinates. Note that all rows above and all columns to the left of this cell will be frozen, but the row and column of the cell itself will not be frozen.\nTo unfreeze all panes, set freeze_panes to None or \u0026lsquo;A1\u0026rsquo;. Table 13-3 shows which rows and columns will be frozen for some example settings of freeze_panes.\nTable 13-3: Frozen Pane Examples\n   freeze_panes setting Rows and columns frozen     sheet.freeze_panes = \u0026lsquo;A2\u0026rsquo; Row 1   sheet.freeze_panes = \u0026lsquo;B1\u0026rsquo; Column A   sheet.freeze_panes = \u0026lsquo;C1\u0026rsquo; Columns A and B   sheet.freeze_panes = \u0026lsquo;C2\u0026rsquo; Row 1 and columns A and B   sheet.freeze_panes = \u0026lsquo;A1\u0026rsquo; or sheet.freeze_panes = None No frozen panes    Make sure you have the produce sales spreadsheet from https://nostarch.com/automatestuff2/. Then enter the following into the interactive shell:\nimport openpyxl wb = openpyxl.load_workbook('produceSales.xlsx') sheet = wb.active sheet.freeze_panes = 'A2' # Freeze the rows above A2. wb.save('freezeExample.xlsx')  If you set the freeze_panes attribute to \u0026lsquo;A2\u0026rsquo;, row 1 will always be viewable, no matter where the user scrolls in the spreadsheet. You can see this in Figure 13-8.\nFigure 13-8: With freeze_panes set to \u0026lsquo;A2\u0026rsquo;, row 1 is always visible, even as the user scrolls down.\nCharts OpenPyXL supports creating bar, line, scatter, and pie charts using the data in a sheet’s cells. To make a chart, you need to do the following:\nCreate a Reference object from a rectangular selection of cells. Create a Series object by passing in the Reference object. Create a Chart object. Append the Series object to the Chart object. Add the Chart object to the Worksheet object, optionally specifying which cell should be the top-left corner of the chart. The Reference object requires some explaining. You create Reference objects by calling the openpyxl.chart.Reference() function and passing three arguments:\nThe Worksheet object containing your chart data. A tuple of two integers, representing the top-left cell of the rectangular selection of cells containing your chart data: the first integer in the tuple is the row, and the second is the column. Note that 1 is the first row, not 0. A tuple of two integers, representing the bottom-right cell of the rectangular selection of cells containing your chart data: the first integer in the tuple is the row, and the second is the column. Figure 13-9 shows some sample coordinate arguments.\nFigure 13-9: From left to right: (1, 1), (10, 1); (3, 2), (6, 4); (5, 3), (5, 3)\nEnter this interactive shell example to create a bar chart and add it to the spreadsheet:\nimport openpyxl wb = openpyxl.Workbook() sheet = wb.active for i in range(1, 11): # create some data in column A ... sheet['A' + str(i)] = i ... refObj = openpyxl.chart.Reference(sheet, min_col=1, min_row=1, max_col=1, max_row=10) seriesObj = openpyxl.chart.Series(refObj, title='First series') chartObj = openpyxl.chart.BarChart() chartObj.title = 'My Chart' chartObj.append(seriesObj) sheet.add_chart(chartObj, 'C5') wb.save('sampleChart.xlsx')  This produces a spreadsheet that looks like Figure 13-10.\nFigure 13-10: A spreadsheet with a chart added\nWe’ve created a bar chart by calling openpyxl.chart.BarChart(). You can also create line charts, scatter charts, and pie charts by calling openpyxl.charts.LineChart(), openpyxl.chart.ScatterChart(), and openpyxl.chart.PieChart().\nSummary Often the hard part of processing information isn’t the processing itself but simply getting the data in the right format for your program. But once you have your spreadsheet loaded into Python, you can extract and manipulate its data much faster than you could by hand.\nYou can also generate spreadsheets as output from your programs. So if colleagues need your text file or PDF of thousands of sales contacts transferred to a spreadsheet file, you won’t have to tediously copy and paste it all into Excel.\nEquipped with the openpyxl module and some programming knowledge, you’ll find processing even the biggest spreadsheets a piece of cake.\nIn the next chapter, we’ll take a look at using Python to interact with another spreadsheet program: the popular online Google Sheets application.\nPractice Questions For the following questions, imagine you have a Workbook object in the variable wb, a Worksheet object in sheet, a Cell object in cell, a Comment object in comm, and an Image object in img.\n What does the openpyxl.load_workbook() function return?\n What does the wb.sheetnames workbook attribute contain?\n How would you retrieve the Worksheet object for a sheet named \u0026lsquo;Sheet1\u0026rsquo;?\n How would you retrieve the Worksheet object for the workbook’s active sheet?\n How would you retrieve the value in the cell C5?\n How would you set the value in the cell C5 to \u0026ldquo;Hello\u0026rdquo;?\n How would you retrieve the cell’s row and column as integers?\n What do the sheet.max_column and sheet.max_row sheet attributes hold, and what is the data type of these attributes?\n If you needed to get the integer index for column \u0026rsquo;M\u0026rsquo;, what function would you need to call?\n If you needed to get the string name for column 14, what function would you need to call?\n How can you retrieve a tuple of all the Cell objects from A1 to F1?\n How would you save the workbook to the filename example.xlsx?\n How do you set a formula in a cell?\n If you want to retrieve the result of a cell’s formula instead of the cell’s formula itself, what must you do first?\n How would you set the height of row 5 to 100?\n How would you hide column C?\n What is a freeze pane?\n What five functions and methods do you have to call to create a bar chart?\n  Practice Projects For practice, write programs that perform the following tasks.\nMultiplication Table Maker Create a program multiplicationTable.py that takes a number N from the command line and creates an N×N multiplication table in an Excel 1. 1. spreadsheet. For example, when the program is run like this:\npy multiplicationTable.py 6  \u0026hellip; it should create a spreadsheet that looks like Figure 13-11.\nFigure 13-11: A multiplication table generated in a spreadsheet\nRow 1 and column A should be used for labels and should be in bold.\nBlank Row Inserter Create a program blankRowInserter.py that takes two integers and a filename string as command line arguments. Let’s call the first integer N and the second integer M. Starting at row N, the program should insert M blank rows into the spreadsheet. For example, when the program is run like this:\npython blankRowInserter.py 3 2 myProduce.xlsx  \u0026hellip; the “before” and “after” spreadsheets should look like Figure 13-12.\nFigure 13-12: Before (left) and after (right) the two blank rows are inserted at row 3\nYou can write this program by reading in the contents of the spreadsheet. Then, when writing out the new spreadsheet, use a for loop to copy the first N lines. For the remaining lines, add M to the row number in the output spreadsheet.\nSpreadsheet Cell Inverter Write a program to invert the row and column of the cells in the spreadsheet. For example, the value at row 5, column 3 will be at row 3, column 5 (and vice versa). This should be done for all cells in the spreadsheet. For example, the “before” and “after” spreadsheets would look something like Figure 13-13.\nFigure 13-13: The spreadsheet before (top) and after (bottom) inversion\nYou can write this program by using nested for loops to read the spreadsheet’s data into a list of lists data structure. This data structure could have sheetData[x][y] for the cell at column x and row y. Then, when writing out the new spreadsheet, use sheetData[y][x] for the cell at column x and row y.\nText Files to Spreadsheet Write a program to read in the contents of several text files (you can make the text files yourself) and insert those contents into a spreadsheet, with one line of text per row. The lines of the first text file will be in the cells of column A, the lines of the second text file will be in the cells of column B, and so on.\nUse the readlines() File object method to return a list of strings, one string per line in the file. For the first file, output the first line to column 1, row 1. The second line should be written to column 1, row 2, and so on. The next file that is read with readlines() will be written to column 2, the next file to column 3, and so on.\nSpreadsheet to Text Files Write a program that performs the tasks of the previous program in reverse order: the program should open a spreadsheet and write the cells of column A into one text file, the cells of column B into another text file, and so on.\n Written with Source :.\n "});index.add({'id':131,'href':'/library/tutorials/docs/book/automate-the-boring-stuff/chapter-14/','title':"14 Working With Google Sheets",'content':" 14 Working With Google Sheets Source : \nGoogle Sheets, the free, web-based spreadsheet application available to anyone with a Google account or Gmail address, has become a useful, feature-rich competitor to Excel. Google Sheets has its own API, but this API can be confusing to learn and use. This chapter covers the EZSheets third-party module, documented at https://ezsheets.readthedocs.io/. While not as full featured as the official Google Sheets API, EZSheets makes common spreadsheet tasks easy to perform.\nInstalling and Setting Up EZSheets You can install EZSheets by opening a new terminal window and running pip install \u0026ndash;user ezsheets. As part of this installation, EZSheets will also install the google-api-python-client, google-auth-httplib2, and google-auth-oauthlib modules. These modules allow your program to log in to Google’s servers and make API requests. EZSheets handles the interaction with these modules, so you don’t need to concern yourself with how they work.\nObtaining Credentials and Token Files Before you can use EZSheets, you need to enable the Google Sheets and Google Drive APIs for your Google account. Visit the following web pages and click the Enable API buttons at the top of each:\n ttps://console.developers.google.com/apis/library/sheets.googleapis.com/ https://console.developers.google.com/apis/library/drive.googleapis.com/  You’ll also need to obtain three files, which you should save in the same folder as your .py Python script that uses EZSheets:\n A credentials file named credentials-sheets.json\n A token for Google Sheets named token-sheets.pickle\n A token for Google Drive named token-drive.pickle\n  The credentials file will generate the token files. The easiest way to obtain a credentials file is to go to the Google Sheets Python Quickstart page at https://developers.google.com/sheets/api/quickstart/python/ and click the blue Enable the Google Sheets API button, as shown in Figure 14-1. You’ll need to log in to your Google account to view this page.\nFigure 14-1: Obtaining a credentials.json file.\nClicking this button will bring up a window with a Download Client Configuration link that lets you download a credentials.json file. Rename this file to credentials-sheets.json and place it in the same folder as your Python scripts.\nOnce you have a credentials-sheets.json file, run the import ezsheets module. The first time you import the EZSheets module, it will open a new browser window for you to log in to your Google account. Click Allow, as shown in Figure 14-2.\nFigure 14-2: Allowing Quickstart to access your Google account\nThe message about Quickstart comes from the fact that you downloaded the credentials file from the Google Sheets Python Quickstart page. Note that this window will open twice: first for Google Sheets access and second for Google Drive access. EZSheets uses Google Drive access to upload, download, and delete spreadsheets.\nAfter you log in, the browser window will prompt you to close it, and the token-sheets.pickle and token-drive.pickle files will appear in the same folder as credentials-sheets.json. You only need to go through this process the first time you run import ezsheets.\nIf you encounter an error after clicking Allow and the page seems to hang, make sure you have first enabled the Google Sheets and Drive APIs from the links at the start of this section. It may take a few minutes for Google’s servers to register this change, so you may have to wait before you can use EZSheets.\nDon’t share the credential or token files with anyone—treat them like passwords.\nRevoking the Credentials File If you accidentally share the credential or token files with someone, they won’t be able to change your Google account password, but they will have access to your spreadsheets. You can revoke these files by going to the Google Cloud Platform developer’s console page at https://console.developers.google.com/. You’ll need to log in to your Google account to view this page. Click the Credentials link on the sidebar. Then click the trash can icon next to the credentials file you’ve accidentally shared, as shown in Figure 14-3.\nFigure 14-3: The Credentials page in the Google Cloud Platform developer’s console\nTo generate a new credentials file from this page, click the Create Credentials button and select OAuth client ID, also shown in Figure 14-3. Next, for Application Type, select Other and give the file any name you like. This new credentials file will then be listed on the page, and you can click on the download icon to download it. The downloaded file will have a long, complicated filename, so you should rename it to the default filename that EZSheets attempts to load: credentials-sheets.json. You can also generate a new credential file by clicking the Enable the Google Sheets API button mentioned in the previous section.\nSpreadsheet Objects In Google Sheets, a spreadsheet can contain multiple sheets (also called worksheets), and each sheet contains columns and rows of values. Figure 14-4 shows a spreadsheet titled “Education Data” containing three sheets titled “Students,” “Classes,” and “Resources.” The first column of each sheet is labeled A, and the first row is labeled 1.\nFigure 14-4: A spreadsheet titled “Education Data” with three sheets\nWhile most of your work will involve modifying the Sheet objects, you can also modify Spreadsheet objects, as you’ll see in the next section.\nCreating, Uploading, and Listing Spreadsheets You can make a new Spreadsheet object from an existing spreadsheet, a blank spreadsheet, or an uploaded spreadsheet. To make a Spreadsheet object from an existing Google Sheets spreadsheet, you’ll need the spreadsheet’s ID string. The unique ID for a Google Sheets spreadsheet can be found in the URL, after the spreadsheets/d/ part and before the /edit part. For example, the spreadsheet featured in Figure 14-4 is located at the URL https://docs.google.com/spreadsheets/d/1J-Jx6Ne2K_vqI9J2SO-TAXOFbxx_9tUjwnkPC22LjeU/edit#gid=151537240/, so its ID is 1J-Jx6Ne2K_vqI9J2SO-TAXOFbxx_9tUjwnkPC22LjeU.\nNOTE The specific spreadsheet IDs used in this chapter are for my Google account’s spreadsheets. They won’t work if you enter them into your interactive shell. Go to https://sheets.google.com/ to create spreadsheets under your account and then get the IDs from the address bar.\nPass your spreadsheet’s ID as a string to the ezsheets.Spreadsheet() function to obtain a Spreadsheet object for its spreadsheet:\n\u0026gt;\u0026gt;\u0026gt; import ezsheets \u0026gt;\u0026gt;\u0026gt; ss = ezsheets.Spreadsheet('1J-Jx6Ne2K_vqI9J2SO-TAXOFbxx_9tUjwnkPC22LjeU') \u0026gt;\u0026gt;\u0026gt; ss Spreadsheet(spreadsheetId='1J-Jx6Ne2K_vqI9J2SO-TAXOFbxx_9tUjwnkPC22LjeU') \u0026gt;\u0026gt;\u0026gt; ss.title 'Education Data'  For convenience, you can also obtain a Spreadsheet object of an existing spreadsheet by passing the spreadsheet’s full URL to the function. Or, if there is only one spreadsheet in your Google account with that title, you can pass the title of the spreadsheet as a string.\nTo make a new, blank spreadsheet, call the ezsheets.createSpreadsheet() function and pass it a string for the new spreadsheet’s title. For example, enter the following into the interactive shell:\n\u0026gt;\u0026gt;\u0026gt; import ezsheets \u0026gt;\u0026gt;\u0026gt; ss = ezsheets.createSpreadsheet('Title of My New Spreadsheet') \u0026gt;\u0026gt;\u0026gt; ss.title 'Title of My New Spreadsheet'  To upload an existing Excel, OpenOffice, CSV, or TSV spreadsheet to Google Sheets, pass the filename of the spreadsheet to ezsheets.upload(). Enter the following into the interactive shell, replacing my_spreadsheet.xlsx with a spreadsheet file of your own:\n\u0026gt;\u0026gt;\u0026gt; import ezsheets \u0026gt;\u0026gt;\u0026gt; ss = ezsheets.upload('my_spreadsheet.xlsx') \u0026gt;\u0026gt;\u0026gt; ss.title 'my_spreadsheet'  You can list the spreadsheets in your Google account by calling the listSpreadsheets() function. Enter the following into the interactive shell after uploading a spreadsheet:\n\u0026gt;\u0026gt;\u0026gt; ezsheets.listSpreadsheets() {'1J-Jx6Ne2K_vqI9J2SO-TAXOFbxx_9tUjwnkPC22LjeU': 'Education Data'}  The listSpreadsheets() function returns a dictionary where the keys are spreadsheet IDs and the values are the titles of each spreadsheet.\nOnce you’ve obtained a Spreadsheet object, you can use its attributes and methods to manipulate the online spreadsheet hosted on Google Sheets.\nSpreadsheet Attributes While the actual data lives in a spreadsheet’s individual sheets, the Spreadsheet object has the following attributes for manipulating the spreadsheet itself: title, spreadsheetId, url, sheetTitles, and sheets. Enter the following into the interactive shell:\n\u0026gt;\u0026gt;\u0026gt; import ezsheets \u0026gt;\u0026gt;\u0026gt; ss = ezsheets.Spreadsheet('1J-Jx6Ne2K_vqI9J2SO-TAXOFbxx_9tUjwnkPC22LjeU') \u0026gt;\u0026gt;\u0026gt; ss.title # The title of the spreadsheet. 'Education Data' \u0026gt;\u0026gt;\u0026gt; ss.title = 'Class Data' # Change the title. \u0026gt;\u0026gt;\u0026gt; ss.spreadsheetId # The unique ID (this is a read-only attribute). '1J-Jx6Ne2K_vqI9J2SO-TAXOFbxx_9tUjwnkPC22LjeU' \u0026gt;\u0026gt;\u0026gt; ss.url # The original URL (this is a read-only attribute). 'https://docs.google.com/spreadsheets/d/1J-Jx6Ne2K_vqI9J2SO- TAXOFbxx_9tUjwnkPC22LjeU/' \u0026gt;\u0026gt;\u0026gt; ss.sheetTitles # The titles of all the Sheet objects ('Students', 'Classes', 'Resources') \u0026gt;\u0026gt;\u0026gt; ss.sheets # The Sheet objects in this Spreadsheet, in order. (\u0026lt;Sheet sheetId=0, title='Students', rowCount=1000, columnCount=26\u0026gt;, \u0026lt;Sheet sheetId=1669384683, title='Classes', rowCount=1000, columnCount=26\u0026gt;, \u0026lt;Sheet sheetId=151537240, title='Resources', rowCount=1000, columnCount=26\u0026gt;) \u0026gt;\u0026gt;\u0026gt; ss[0] # The first Sheet object in this Spreadsheet. \u0026lt;Sheet sheetId=0, title='Students', rowCount=1000, columnCount=26\u0026gt; \u0026gt;\u0026gt;\u0026gt; ss['Students'] # Sheets can also be accessed by title. \u0026lt;Sheet sheetId=0, title='Students', rowCount=1000, columnCount=26\u0026gt; \u0026gt;\u0026gt;\u0026gt; del ss[0] # Delete the first Sheet object in this Spreadsheet. \u0026gt;\u0026gt;\u0026gt; ss.sheetTitles # The \u0026quot;Students\u0026quot; Sheet object has been deleted: ('Classes', 'Resources')  If someone changes the spreadsheet through the Google Sheets website, your script can update the Spreadsheet object to match the online data by calling the refresh() method:\n\u0026gt;\u0026gt;\u0026gt; ss.refresh()  This will refresh not only the Spreadsheet object’s attributes but also the data in the Sheet objects it contains. The changes you make to the Spreadsheet object will be reflected in the online spreadsheet in real time.\nDownloading and Uploading Spreadsheets You can download a Google Sheets spreadsheet in a number of formats: Excel, OpenOffice, CSV, TSV, and PDF. You can also download it as a ZIP file containing HTML files of the spreadsheet’s data. EZSheets contains functions for each of these options:\n\u0026gt;\u0026gt;\u0026gt; import ezsheets \u0026gt;\u0026gt;\u0026gt; ss = ezsheets.Spreadsheet('1J-Jx6Ne2K_vqI9J2SO-TAXOFbxx_9tUjwnkPC22LjeU') \u0026gt;\u0026gt;\u0026gt; ss.title 'Class Data' \u0026gt;\u0026gt;\u0026gt; ss.downloadAsExcel() # Downloads the spreadsheet as an Excel file. 'Class_Data.xlsx' \u0026gt;\u0026gt;\u0026gt; ss.downloadAsODS() # Downloads the spreadsheet as an OpenOffice file. 'Class_Data.ods' \u0026gt;\u0026gt;\u0026gt; ss.downloadAsCSV() # Only downloads the first sheet as a CSV file. 'Class_Data.csv' \u0026gt;\u0026gt;\u0026gt; ss.downloadAsTSV() # Only downloads the first sheet as a TSV file. 'Class_Data.tsv' \u0026gt;\u0026gt;\u0026gt; ss.downloadAsPDF() # Downloads the spreadsheet as a PDF. 'Class_Data.pdf' \u0026gt;\u0026gt;\u0026gt; ss.downloadAsHTML() # Downloads the spreadsheet as a ZIP of HTML files. 'Class_Data.zip'  Note that files in the CSV and TSV formats can contain only one sheet; therefore, if you download a Google Sheets spreadsheet in this format, you will get the first sheet only. To download other sheets, you’ll need to change the Sheet object’s index attribute to 0. See “Creating and Deleting Sheets” on page 341 for information on how to do this.\nThe download functions all return a string of the downloaded file’s filename. You can also specify your own filename for the spreadsheet by passing the new filename to the download function:\n\u0026gt;\u0026gt;\u0026gt; ss.downloadAsExcel('a_different_filename.xlsx') 'a_different_filename.xlsx'  The function should return the updated filename.\nDeleting Spreadsheets To delete a spreadsheet, call the delete() method:\n\u0026gt;\u0026gt;\u0026gt; import ezsheets \u0026gt;\u0026gt;\u0026gt; ss = ezsheets.createSpreadsheet('Delete me') # Create the spreadsheet. \u0026gt;\u0026gt;\u0026gt; ezsheets.listSpreadsheets() # Confirm that we've created a spreadsheet. {'1aCw2NNJSZblDbhygVv77kPsL3djmgV5zJZllSOZ_mRk': 'Delete me'} \u0026gt;\u0026gt;\u0026gt; ss.delete() # Delete the spreadsheet. \u0026gt;\u0026gt;\u0026gt; ezsheets.listSpreadsheets() {}  The delete() method will move your spreadsheet to the Trash folder on your Google Drive. You can view the contents of your Trash folder at https://drive.google.com/drive/trash. To permanently delete your spreadsheet, pass True for the permanent keyword argument:\n\u0026gt;\u0026gt;\u0026gt; ss.delete(permanent=True)  In general, permanently deleting your spreadsheets is not a good idea, because it would be impossible to recover a spreadsheet that a bug in your script accidentally deleted. Even free Google Drive accounts have gigabytes of storage available, so you most likely don’t need to worry about freeing up space.\nSheet Objects A Spreadsheet object will have one or more Sheet objects. The Sheet objects represent the rows and columns of data in each sheet. You can access these sheets using the square brackets operator and an integer index. The Spreadsheet object’s sheets attribute holds a tuple of Sheet objects in the order in which they appear in the spreadsheet. To access the Sheet objects in a spreadsheet, enter the following into the interactive shell:\n\u0026gt;\u0026gt;\u0026gt; import ezsheets \u0026gt;\u0026gt;\u0026gt; ss = ezsheets.Spreadsheet('1J-Jx6Ne2K_vqI9J2SO-TAXOFbxx_9tUjwnkPC22LjeU') \u0026gt;\u0026gt;\u0026gt; ss.sheets # The Sheet objects in this Spreadsheet, in order. (\u0026lt;Sheet sheetId=1669384683, title='Classes', rowCount=1000, columnCount=26\u0026gt;, \u0026lt;Sheet sheetId=151537240, title='Resources', rowCount=1000, columnCount=26\u0026gt;) \u0026gt;\u0026gt;\u0026gt; ss.sheets[0] # Gets the first Sheet object in this Spreadsheet. \u0026lt;Sheet sheetId=1669384683, title='Classes', rowCount=1000, columnCount=26\u0026gt; \u0026gt;\u0026gt;\u0026gt; ss[0] # Also gets the first Sheet object in this Spreadsheet. \u0026lt;Sheet sheetId=1669384683, title='Classes', rowCount=1000, columnCount=26\u0026gt;  You can also obtain a Sheet object with the square brackets operator and a string of the sheet’s name. The Spreadsheet object’s sheetTitles attribute holds a tuple of all the sheet titles. For example, enter the following into the interactive shell:\n\u0026gt;\u0026gt;\u0026gt; ss.sheetTitles # The titles of all the Sheet objects in this Spreadsheet. ('Classes', 'Resources') \u0026gt;\u0026gt;\u0026gt; ss['Classes'] # Sheets can also be accessed by title. \u0026lt;Sheet sheetId=1669384683, title='Classes', rowCount=1000, columnCount=26\u0026gt;  Once you have a Sheet object, you can read data from and write data to it using the Sheet object’s methods, as explained in the next section.\nReading and Writing Data Just as in Excel, Google Sheets worksheets have columns and rows of cells containing data. You can use the square brackets operator to read and write data from and to these cells. For example, to create a new spreadsheet and add data to it, enter the following into the interactive shell:\n\u0026gt;\u0026gt;\u0026gt; import ezsheets \u0026gt;\u0026gt;\u0026gt; ss = ezsheets.createSpreadsheet('My Spreadsheet') \u0026gt;\u0026gt;\u0026gt; sheet = ss[0] # Get the first sheet in this spreadsheet. \u0026gt;\u0026gt;\u0026gt; sheet.title 'Sheet1' \u0026gt;\u0026gt;\u0026gt; sheet = ss[0] \u0026gt;\u0026gt;\u0026gt; sheet['A1'] = 'Name' # Set the value in cell A1. \u0026gt;\u0026gt;\u0026gt; sheet['B1'] = 'Age' \u0026gt;\u0026gt;\u0026gt; sheet['C1'] = 'Favorite Movie' \u0026gt;\u0026gt;\u0026gt; sheet['A1'] # Read the value in cell A1. 'Name' \u0026gt;\u0026gt;\u0026gt; sheet['A2'] # Empty cells return a blank string. '' \u0026gt;\u0026gt;\u0026gt; sheet[2, 1] # Column 2, Row 1 is the same address as B1. 'Age' \u0026gt;\u0026gt;\u0026gt; sheet['A2'] = 'Alice' \u0026gt;\u0026gt;\u0026gt; sheet['B2'] = 30 \u0026gt;\u0026gt;\u0026gt; sheet['C2'] = 'RoboCop'  These instructions should produce a Google Sheets spreadsheet that looks like Figure 14-5.\nFigure 14-5: The spreadsheet created with the example instructions\nMultiple users can update a sheet simultaneously. To refresh the local data in the Sheet object, call its refresh() method:\n\u0026gt;\u0026gt;\u0026gt; sheet.refresh()  All of the data in the Sheet object is loaded when the Spreadsheet object is first loaded, so the data is read instantly. However, writing values to the online spreadsheet requires a network connection and can take about a second. If you have thousands of cells to update, updating them one at a time might be quite slow.\nColumn and Row Addressing Cell addressing works in Google Sheets just like in Excel. The only difference is that, unlike Python’s 0-based list indexes, Google Sheets have 1-based columns and rows: the first column or row is at index 1, not 0. You can convert the \u0026lsquo;A2\u0026rsquo; string-style address to the (column, row) tuple-style address (and vice versa) with the convertAddress() function. The getColumnLetterOf() and getColumnNumberOf() functions will also convert a column address between letters and numbers. Enter the following into the interactive shell:\n\u0026gt;\u0026gt;\u0026gt; import ezsheets \u0026gt;\u0026gt;\u0026gt; ezsheets.convertAddress('A2') # Converts addresses... (1, 2) \u0026gt;\u0026gt;\u0026gt; ezsheets.convertAddress(1, 2) # ...and converts them back, too. 'A2' \u0026gt;\u0026gt;\u0026gt; ezsheets.getColumnLetterOf(2) 'B' \u0026gt;\u0026gt;\u0026gt; ezsheets.getColumnNumberOf('B') 2 \u0026gt;\u0026gt;\u0026gt; ezsheets.getColumnLetterOf(999) 'ALK' \u0026gt;\u0026gt;\u0026gt; ezsheets.getColumnNumberOf('ZZZ') 18278  The \u0026lsquo;A2\u0026rsquo; string-style addresses are convenient if you’re typing addresses into your source code. But the (column, row) tuple-style addresses are convenient if you’re looping over a range of addresses and need a numeric form for the column. The convertAddress(), getColumnLetterOf(), and getColumnNumberOf() functions are helpful when you need to convert between the two formats.\nReading and Writing Entire Columns and Rows As mentioned, writing data one cell at a time can often take too long. Fortunately, EZSheets has Sheet methods for reading and writing entire columns and rows at the same time. The getColumn(), getRow(), updateColumn(), and updateRow() methods will, respectively, read and write columns and rows. These methods make requests to the Google Sheets servers to update the spreadsheet, so they require that you be connected to the internet. In this section’s example, we’ll upload produceSales.xlsx from the last chapter to Google Sheets. The first eight rows look like Table 14-1.\nTable 14-1: The First Eight Rows of the produceSales.xlsx Spreadsheet\n   No. A B C D     1 PRODUCE COST PER POUND POUNDS SOLD TOTAL   2 Potatoes 0.86 21.6 18.58   3 Okra 2.26 38.6 87.24   4 Fava beans 2.69 32.8 88.23   5 Watermelon 0.66 27.3 18.02   6 Garlic 1.19 4.9 5.83   7 Parsnips 2.27 1.1 2.5   8 Asparagus 2.49 37.9 94.37    To upload this spreadsheet, enter the following into the interactive shell:\n\u0026gt;\u0026gt;\u0026gt; import ezsheets \u0026gt;\u0026gt;\u0026gt; ss = ezsheets.upload('produceSales.xlsx') \u0026gt;\u0026gt;\u0026gt; sheet = ss[0] \u0026gt;\u0026gt;\u0026gt; sheet.getRow(1) # The first row is row 1, not row 0. ['PRODUCE', 'COST PER POUND', 'POUNDS SOLD', 'TOTAL', '', ''] \u0026gt;\u0026gt;\u0026gt; sheet.getRow(2) ['Potatoes', '0.86', '21.6', '18.58', '', ''] \u0026gt;\u0026gt;\u0026gt; columnOne = sheet.getColumn(1) \u0026gt;\u0026gt;\u0026gt; sheet.getColumn(1) ['PRODUCE', 'Potatoes', 'Okra', 'Fava beans', 'Watermelon', 'Garlic', --snip-- \u0026gt;\u0026gt;\u0026gt; sheet.getColumn('A') # Same result as getColumn(1) ['PRODUCE', 'Potatoes', 'Okra', 'Fava beans', 'Watermelon', 'Garlic', --snip-- \u0026gt;\u0026gt;\u0026gt; sheet.getRow(3) ['Okra', '2.26', '38.6', '87.24', '', ''] \u0026gt;\u0026gt;\u0026gt; sheet.updateRow(3, ['Pumpkin', '11.50', '20', '230']) \u0026gt;\u0026gt;\u0026gt; sheet.getRow(3) ['Pumpkin', '11.50', '20', '230', '', ''] \u0026gt;\u0026gt;\u0026gt; columnOne = sheet.getColumn(1) \u0026gt;\u0026gt;\u0026gt; for i, value in enumerate(columnOne): ... # Make the Python list contain uppercase strings: ... columnOne[i] = value.upper() ... \u0026gt;\u0026gt;\u0026gt; sheet.updateColumn(1, columnOne) # Update the entire column in one request.  The getRow() and getColumn() functions retrieve the data from every cell in a specific row or column as a list of values. Note that empty cells become blank string values in the list. You can pass getColumn() either a column number or letter to tell it to retrieve a specific column’s data. The previous example shows that getColumn(1) and getColumn(\u0026lsquo;A\u0026rsquo;) return the same list.\nThe updateRow() and updateColumn() functions will overwrite all the data in the row or column, respectively, with the list of values passed to the function. In this example, the third row initially contains information about okra, but the updateRow() call replaces it with data about pumpkin. Call sheet.getRow(3) again to view the new values in the third row.\nNext, let’s update the “produceSales” spreadsheet. Updating cells one at a time is slow if you have many cells to update. Getting a column or row as a list, updating the list, and then updating the entire column or row with the list is much faster, since all the changes can be made in one request.\nTo get all of the rows at once, call the getRows() method to return a list of lists. The inner lists inside the outer list each represent a single row of the sheet. You can modify the values in this data structure to change the produce name, pounds sold, and total cost of some of the rows. Then you pass it to the updateRows() method by entering the following into the interactive shell:\n\u0026gt;\u0026gt;\u0026gt; rows = sheet.getRows() # Get every row in the spreadsheet. \u0026gt;\u0026gt;\u0026gt; rows[0] # Examine the values in the first row. ['PRODUCE', 'COST PER POUND', 'POUNDS SOLD', 'TOTAL', '', ''] \u0026gt;\u0026gt;\u0026gt; rows[1] ['POTATOES', '0.86', '21.6', '18.58', '', ''] \u0026gt;\u0026gt;\u0026gt; rows[1][0] = 'PUMPKIN' # Change the produce name. \u0026gt;\u0026gt;\u0026gt; rows[1] ['PUMPKIN', '0.86', '21.6', '18.58', '', ''] \u0026gt;\u0026gt;\u0026gt; rows[10] ['OKRA', '2.26', '40', '90.4', '', ''] \u0026gt;\u0026gt;\u0026gt; rows[10][2] = '400' # Change the pounds sold. \u0026gt;\u0026gt;\u0026gt; rows[10][3] = '904' # Change the total. \u0026gt;\u0026gt;\u0026gt; rows[10] ['OKRA', '2.26', '400', '904', '', ''] \u0026gt;\u0026gt;\u0026gt; sheet.updateRows(rows) # Update the online spreadsheet with the changes. You can update the entire sheet in a single request by passing updateRows() the list of lists returned from getRows(), amended with the changes made to rows 1 and 10. Note that the rows in the Google Sheet have empty strings at the end. This is because the uploaded sheet has a column count of 6, but we have only 4 columns of data. You can read the number of rows and columns in a sheet with the rowCount and columnCount attributes. Then by setting these values, you can change the size of the sheet. \u0026gt;\u0026gt;\u0026gt; sheet.rowCount # The number of rows in the sheet. 23758 \u0026gt;\u0026gt;\u0026gt; sheet.columnCount # The number of columns in the sheet. 6 \u0026gt;\u0026gt;\u0026gt; sheet.columnCount = 4 # Change the number of columns to 4. \u0026gt;\u0026gt;\u0026gt; sheet.columnCount # Now the number of columns in the sheet is 4. 4  These instructions should delete the fifth and sixth columns of the “produceSales” spreadsheet, as shown in Figure 14-6.\nFigure 14-6: The sheet before (left) and after (right) changing the column count to 4\nAccording to https://support.google.com/drive/answer/37603?hl=en/, Google Sheets spreadsheets can have up to 5 million cells in them. However, it’s a good idea to make sheets only as big as you need to minimize the time it takes to update and refresh the data.\nCreating and Deleting Sheets All Google Sheets spreadsheets start with a single sheet named “Sheet1.” You can add additional sheets to the end of the list of sheets with the createSheet() method, to which you pass a string to use as the new sheet’s title. An optional second argument can specify the integer index of the new sheet. To create a spreadsheet and then add new sheets to it, enter the following into the interactive shell:\n\u0026gt;\u0026gt;\u0026gt; import ezsheets \u0026gt;\u0026gt;\u0026gt; ss = ezsheets.createSpreadsheet('Multiple Sheets') \u0026gt;\u0026gt;\u0026gt; ss.sheetTitles ('Sheet1',) \u0026gt;\u0026gt;\u0026gt; ss.createSheet('Spam') # Create a new sheet at the end of the list of sheets. \u0026lt;Sheet sheetId=2032744541, title='Spam', rowCount=1000, columnCount=26\u0026gt; \u0026gt;\u0026gt;\u0026gt; ss.createSheet('Eggs') # Create another new sheet. \u0026lt;Sheet sheetId=417452987, title='Eggs', rowCount=1000, columnCount=26\u0026gt; \u0026gt;\u0026gt;\u0026gt; ss.sheetTitles ('Sheet1', 'Spam', 'Eggs') \u0026gt;\u0026gt;\u0026gt; ss.createSheet('Bacon', 0) code\u0026gt;# Create a sheet at index 0 in the list of sheets. \u0026lt;Sheet sheetId=814694991, title='Bacon', rowCount=1000, columnCount=26\u0026gt; \u0026gt;\u0026gt;\u0026gt; ss.sheetTitles ('Bacon', 'Sheet1', 'Spam', 'Eggs')  These instructions add three new sheets to the spreadsheet: “Bacon,” “Spam,” and “Eggs” (in addition to the default “Sheet1”). The sheets in a spreadsheet are ordered, and new sheets go to the end of the list unless you pass a second argument to createSheet() specifying the sheet’s index. Here, you create the sheet titled “Bacon” at index 0, making “Bacon” the first sheet in the spreadsheet and displacing the other three sheets by one position. This is similar to the behavior of the insert() list method.\nYou can see the new sheets on the tabs at the bottom of the screen, as shown in Figure 14-7.\nFigure 14-7: The “Multiple Sheets” spreadsheet after adding sheets “Spam,” “Eggs,” and “Bacon”\nThe Sheet object’s delete() method will delete the sheet from the spreadsheet. If you want to keep the sheet but delete the data it contains, call the clear() method to clear all the cells and make it a blank sheet. Enter the following into the interactive shell:\n\u0026gt;\u0026gt;\u0026gt; ss.sheetTitles ('Bacon', 'Sheet1', 'Spam', 'Eggs') \u0026gt;\u0026gt;\u0026gt; ss[0].delete() # Delete the sheet at index 0: the \u0026quot;Bacon\u0026quot; sheet. \u0026gt;\u0026gt;\u0026gt; ss.sheetTitles ('Sheet1', 'Spam', 'Eggs') \u0026gt;\u0026gt;\u0026gt; ss['Spam'].delete() # Delete the \u0026quot;Spam\u0026quot; sheet. \u0026gt;\u0026gt;\u0026gt; ss.sheetTitles ('Sheet1', 'Eggs') \u0026gt;\u0026gt;\u0026gt; sheet = ss['Eggs'] # Assign a variable to the \u0026quot;Eggs\u0026quot; sheet. \u0026gt;\u0026gt;\u0026gt; sheet.delete() # Delete the \u0026quot;Eggs\u0026quot; sheet. \u0026gt;\u0026gt;\u0026gt; ss.sheetTitles ('Sheet1',) \u0026gt;\u0026gt;\u0026gt; ss[0].clear() # Clear all the cells on the \u0026quot;Sheet1\u0026quot; sheet. \u0026gt;\u0026gt;\u0026gt; ss.sheetTitles # The \u0026quot;Sheet1\u0026quot; sheet is empty but still exists. ('Sheet1',)  Deleting sheets is permanent; there’s no way to recover the data. However, you can back up sheets by copying them to another spreadsheet with the copyTo() method, as explained in the next section.\nCopying Sheets Every Spreadsheet object has an ordered list of the Sheet objects it contains, and you can use this list to reorder the sheets (as shown in the previous section) or copy them to other spreadsheets. To copy a Sheet object to another Spreadsheet object, call the copyTo() method. Pass it the destination Spreadsheet object as an argument. To create two spreadsheets and copy the first spreadsheet’s data to the other sheet, enter the following into the interactive shell:\n\u0026gt;\u0026gt;\u0026gt; import ezsheets \u0026gt;\u0026gt;\u0026gt; ss1 = ezsheets.createSpreadsheet('First Spreadsheet') \u0026gt;\u0026gt;\u0026gt; ss2 = ezsheets.createSpreadsheet('Second Spreadsheet') \u0026gt;\u0026gt;\u0026gt; ss1[0] \u0026lt;Sheet sheetId=0, title='Sheet1', rowCount=1000, columnCount=26\u0026gt; \u0026gt;\u0026gt;\u0026gt; ss1[0].updateRow(1, ['Some', 'data', 'in', 'the', 'first', 'row']) \u0026gt;\u0026gt;\u0026gt; ss1[0].copyTo(ss2) # Copy the ss1's Sheet1 to the ss2 spreadsheet. \u0026gt;\u0026gt;\u0026gt; ss2.sheetTitles # ss2 now contains a copy of ss1's Sheet1. ('Sheet1', 'Copy of Sheet1')  Note that since the destination spreadsheet (ss2 in the previous example) already had a sheet named Sheet1, the copied sheet will be named Copy of Sheet1. Copied sheets appear at the end of the list of the destination spreadsheet’s sheets. If you wish, you can change their index attribute to reorder them in the new spreadsheet.\nWorking with Google Sheets Quotas Because Google Sheets is online, it’s easy to share sheets among multiple users who can all access the sheets simultaneously. However, this also means that reading and updating the sheets will be slower than reading and updating Excel files stored locally on your hard drive. In addition, Google Sheets has limits on how many read and write operations you can perform.\nAccording to Google’s developer guidelines, users are restricted to creating 250 new spreadsheets a day, and free Google accounts can perform 100 read and 100 write requests per 100 seconds. Attempting to exceed this quota will raise the googleapiclient.errors.HttpError “Quota exceeded for quota group” exception. EZSheets will automatically catch this exception and retry the request. When this happens, the function calls to read or write data will take several seconds (or even a full minute or two) before they return. If the request continues to fail (which is possible if another script using the same credentials is also making requests), EZSheets will re-raise this exception.\nThis means that, on occasion, your EZSheets method calls may take several seconds before they return. If you want to view your API usage or increase your quota, go to the IAM \u0026amp; Admin Quotas page at https://console.developers.google.com/quotas/ to learn about paying for increased usage. If you’d rather just deal with the HttpError exceptions yourself, you can set ezsheets.IGNORE_QUOTA to True, and EZSheet’s methods will raise these exceptions when it encounters them.\nSummary Google Sheets is a popular online spreadsheet application that runs in your browser. Using the EZSheets third-party module, you can download, create, read, and modify spreadsheets. EZSheets represents spreadsheets as Spreadsheet objects, each of which contains an ordered list of Sheet objects. Each sheet has columns and rows of data that you can read and update in several ways.\nWhile Google Sheets makes sharing data and cooperative editing easy, its main disadvantage is speed: you must update spreadsheets with web requests, which can take a few seconds to execute. But for most purposes, this speed restriction won’t affect Python scripts using EZSheets. Google Sheets also limits how often you can make changes.\nFor complete documentation of EZSheet’s features, visit https://ezsheets.readthedocs.io/.\nPractice Questions  What three files do you need for EZSheets to access Google Sheets?\n What two types of objects does EZSheets have?\n How can you create an Excel file from a Google Sheet spreadsheet?\n How can you create a Google Sheet spreadsheet from an Excel file?\n The ss variable contains a Spreadsheet object. What code will read data from the cell B2 in a sheet titled “Students”?\n How can you find the column letters for column 999?\n How can you find out how many rows and columns a sheet has?\n How do you delete a spreadsheet? Is this deletion permanent?\n What functions will create a new Spreadsheet object and a new Sheet object, respectively?\n What will happen if, by making frequent read and write requests with EZSheets, you exceed your Google account’s quota?\n  Practice Projects For practice, write programs to do the following tasks.\nDownloading Google Forms Data Google Forms allows you to create simple online forms that make it easy to collect information from people. The information they enter into the form is stored in a Google Sheet. For this project, write a program that can automatically download the form information that users have submitted. Go to https://docs.google.com/forms/ and start a new form; it will be blank. Add fields to the form that ask the user for a name and email address. Then click the Send button in the upper right to get a link to your new form, such as https://goo.gl/forms/QZsq5sC2Qe4fYO592/. Try to enter a few example responses into this form.\nOn the “Responses” tab of your form, click the green Create Spreadsheet button to create a Google Sheets spreadsheet that will hold the responses that users submit. You should see your example responses in the first rows of this spreadsheet. Then write a Python script using EZSheets to collect a list of the email addresses on this spreadsheet.\nConverting Spreadsheets to Other Formats You can use Google Sheets to convert a spreadsheet file into other formats. Write a script that passes a submitted file to upload(). Once the spreadsheet has uploaded to Google Sheets, download it using downloadAsExcel(), downloadAsODS(), and other such functions to create a copy of the spreadsheet in these other formats.\nFinding Mistakes in a Spreadsheet After a long day at the bean-counting office, I’ve finished a spreadsheet with all the bean totals and uploaded them to Google Sheets. The spreadsheet is publicly viewable (but not editable). You can get this spreadsheet with the following code:\n\u0026gt;\u0026gt;\u0026gt; import ezsheets \u0026gt;\u0026gt;\u0026gt; ss = ezsheets.Spreadsheet('1jDZEdvSIh4TmZxccyy0ZXrH-ELlrwq8_YYiZrEOB4jg')  You can look at this spreadsheet in your browser by going to https://docs.google.com/spreadsheets/d/1jDZEdvSIh4TmZxccyy0ZXrH-ELlrwq8_YYiZrEOB4jg/edit?usp=sharing/. The columns of the first sheet in this spreadsheet are “Beans per Jar,” “Jars,” and “Total Beans.” The “Total Beans” column is the product of the numbers in the “Beans per Jar” and “Jars” columns. However, there is a mistake in one of the 15,000 rows in this sheet. That’s too many rows to check by hand. Luckily, you can write a script that checks the totals.\nAs a hint, you can access the individual cells in a row with ss[0].getRow(rowNum), where ss is the Spreadsheet object and rowNum is the row number. Remember that row numbers in Google Sheets begin at 1, not 0. The cell values will be strings, so you’ll need to convert them to integers so your program can work with them. The expression int(ss[0].getRow(2)[0]) * int(ss[0].getRow(2)[1]) == int(ss[0].getRow(2)[2]) evaluates to True if the row has the correct total. Put this code in a loop to identify which row in the sheet has the incorrect total.\n"});index.add({'id':132,'href':'/library/tutorials/docs/python/snippets/all_equal/','title':"all_equal()",'content':" all_equal() Checks if all elements in a list are equal.\nUse [1:] and [:-1] to compare all the values in the given list.\ndef all_equal(lst): return lst[1:] == lst[:-1]  all_equal([1, 2, 3, 4, 5, 6]) # False all_equal([1, 1, 1, 1]) # True  "});index.add({'id':133,'href':'/library/tutorials/docs/python/snippets/all_unique/','title':"all_unique()",'content':" all_unique() Returns True if all the values in a list are unique, False otherwise.\nUse set() on the given list to remove duplicates, use len() to compare its length with the length of the list.\ndef all_unique(lst): return len(lst) == len(set(lst))  x = [1, 2, 3, 4, 5, 6] y = [1, 2, 2, 3, 4, 5] all_unique(x) # True all_unique(y) # False  "});index.add({'id':134,'href':'/library/tutorials/docs/articles/','title':"Articles",'content':" Articles Welcome "});index.add({'id':135,'href':'/library/tutorials/docs/book/automate-the-boring-stuff/','title':"Automate the Boring Stuff",'content':" Automate the Boring Stuff with Python "});index.add({'id':136,'href':'/library/tutorials/docs/python/snippets/average/','title':"average()",'content':" average() Returns the average of two or more numbers.\nUse sum() to sum all of the args provided, divide by len(args).\ndef average(*args): return sum(args, 0.0) / len(args)  average(*[1, 2, 3]) # 2.0 average(1, 2, 3) # 2.0  "});index.add({'id':137,'href':'/library/tutorials/docs/python/snippets/average_by/','title':"average_by()",'content':" average_by() Returns the average of a list, after mapping each element to a value using the provided function.\nUse map() to map each element to the value returned by fn. Use sum() to sum all of the mapped values, divide by len(lst).\ndef average_by(lst, fn=lambda x: x): return sum(map(fn, lst), 0.0) / len(lst)  average_by([{ 'n': 4 }, { 'n': 2 }, { 'n': 8 }, { 'n': 6 }], lambda x: x['n']) # 5.0  "});index.add({'id':138,'href':'/library/tutorials/docs/python/snippets/bifurcate/','title':"bifurcate()",'content':" bifurcate() Splits values into two groups. If an element in filter is True, the corresponding element in the collection belongs to the first group; otherwise, it belongs to the second group.\nUse list comprehension and enumerate() to add elements to groups, based on filter.\ndef bifurcate(lst, filter): return [ [x for i, x in enumerate(lst) if filter[i] == True], [x for i, x in enumerate(lst) if filter[i] == False] ]  bifurcate(['beep', 'boop', 'foo', 'bar'], [True, True, False, True]) # [ ['beep', 'boop', 'bar'], ['foo'] ]  "});index.add({'id':139,'href':'/library/tutorials/docs/python/snippets/bifurcate_by/','title':"bifurcate_by()",'content':" bifurcate_by() Splits values into two groups according to a function, which specifies which group an element in the input list belongs to. If the function returns True, the element belongs to the first group; otherwise, it belongs to the second group.\nUse list comprehension to add elements to groups, based on fn.\ndef bifurcate_by(lst, fn): return [ [x for x in lst if fn(x)], [x for x in lst if not fn(x)] ]  bifurcate_by( ['beep', 'boop', 'foo', 'bar'], lambda x: x[0] == 'b' ) # [ ['beep', 'boop', 'bar'], ['foo'] ]  "});index.add({'id':140,'href':'/library/tutorials/docs/book/','title':"Book",'content':" Book "});index.add({'id':141,'href':'/library/tutorials/docs/front-end/bootstrap/basic-bootstap/boostrap-4-flex-grid/','title':"Bootstrap 4 Grid",'content':" Bootstrap 4 Grid Download Source Code\nBootstrap 4 brings many changes and new features to the grid system we are all so familiar with from version 3. The new grid is now powered by flexbox, lots of utility classes have been renamed, and a new XL breakpoint has been added.\n When we first wrote this article, Bootstrap 4 was supposed to have two separate grids. Shortly after we published it, a new Alpha was released, making flexbox the only layout mode of the framework as well as introducing some new features. We have updated the article to reflect those changes.\n 1. Basic Grid By now everyone knows how the Bootstrap grid works. We\u0026rsquo;ve got rows separated into 12 equal pieces, and columns that go inside the rows. Each column can take anywhere from 1 to 12 spaces:\n\u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col-xs-2\u0026quot;\u0026gt;.col-xs-2\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;col-xs-4\u0026quot;\u0026gt;.col-xs-4\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;col-xs-6\u0026quot;\u0026gt;.col-xs-6\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt;  Structurally nothing has changed, the grid still has rows and 12 columns. However, there are changes in the width of containers, as well as other small stuff like the lowest breakpoint tier being renamed from .col-xs- to simply .col-\n\u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col-2\u0026quot;\u0026gt;.col-2\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;col-4\u0026quot;\u0026gt;.col-4\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;col-6\u0026quot;\u0026gt;.col-6\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt;  To help you better visualize the changes, we\u0026rsquo;ve prepared side-by-side demos of both new flex and old non-flex grids. You can check them out below:\nA Basic Bootstrap Grid\n2. Automatic Layout A cool new feature of the Bootstrap 4 grid is the auto-layout mode. It lets developers leave out the size of columns, making them automatically distribute the space in that row.\n\u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col\u0026quot;\u0026gt;.col\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;col\u0026quot;\u0026gt;.col\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;col\u0026quot;\u0026gt;.col\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt;  Sizeless columns share the available space equally, always filling up the entire row. If we want a column to be bigger or smaller, we can still do that with a .col-size class.\nAutomatic Layout\n3. Column Wrapping When the sum of all columns in a row is over 12, the first extra column will move to the next line. This is known as column wrapping and works the same way it did in non-flexbox bootstrap.\n\u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col-6\u0026quot;\u0026gt;.col-6\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;col-6\u0026quot;\u0026gt;.col-6\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;col-3\u0026quot;\u0026gt;.col-3, This column will move to the next line.\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt;  The only thing to note here is that when using the auto layout, a sizeless column that took up only a couple of spaces, can take up the entire row once it wraps.\nColumn Wrapping\n4. Responsive Grid As we mentioned in the intro, Bootstrap 4 has a new XL grid tier on top of the old ones. Now the grid media queries look like this:\n Extra small (xs) - below 576px Small (sm) - between 576px and 768px Medium (md) - between 768px and 992px Large (lg) - between 992px and 1200px Extra Large (xl) - over 1200px  Other than that, there haven\u0026rsquo;t been any changes to the way responsiveness works.\nResponsive Grid\n5. Column Height The old grid system was built on floated elements and because of that every column has a different height, depending on the content it holds.\nColumn Height In Bootstrap 3\nIn flexbox layouts all cells in a row are aligned to be as tall as the column with most content.\nColumn Height in Bootstrap 4\n6. Horizontal Alignment In old Bootstrap, positioning columns horizontally is done via an offset system. Offsets work like empty columns and allow us to move elements to the right (e.g an .col-xs-offset-3 moves the column 3 spaces to the right). This can be a little annoying as we need to manually adjust the amount of spaces needed.\n\u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col-xs-6 col-xs-offset-3\u0026quot;\u0026gt;This column is now centered.\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt;  Thanks to the justify-content property, horizontal positioning in flex-strap is as easy as adding the correct class.\n\u0026lt;div class=\u0026quot;row justify-content-center\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col-6\u0026quot;\u0026gt;All columns in that row will be automatically centered.\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt;  Also, if you want to use offsets, you can still do that as well! Just keep in mind that the classes are now shortened to .offset-xs-*.\nHorizontal Alignment\n7. Vertical Alignment There are no options for vertical alignment in the Bootstrap 3 grid. The only way to do any sort of vertical positioning is using custom CSS and it is often messy.\nFlexbox, on the other hand, is great at layout alignment and gives us not one, but two ways to vertically position columns:\nVertically align the whole row:\n\u0026lt;div class=\u0026quot;row align-items-center\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col\u0026quot;\u0026gt;Middle\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;row align-items-end\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col\u0026quot;\u0026gt;Bottom\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;row align-items-start\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col\u0026quot;\u0026gt;Top\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt;  Align individual columns within the row:\n\u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col align-self-start\u0026quot;\u0026gt;Top\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;col align-self-center\u0026quot;\u0026gt;Middle\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;col align-self-end\u0026quot;\u0026gt;Bottom\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt;  Vertical Alignment\n8. Reordering Columns With the old grid system, if we wanted to swap around the order of columns we needed to use push and pull while manually adjusting the correct amount of places to move left and right.\n\u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col-xs-4 col-xs-push-8\u0026quot;\u0026gt; This column will move 8 spaces to the right. \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;col-xs-8 col-xs-pull-4\u0026quot;\u0026gt; This column will move 4 spaces to the left.\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt;  Anyone who has used flexbox before knows that it has a built-in order property. The way Bootstrap devs have implemented it is via three ordering classes:\n .flex-first - Displayed first. .flex-last - Displayed last. .flex-unordered - Displayed between first and last.  No manual calculations are required. If you need to order more than 3 columns (which rarely happens) you can use push\u0026amp;pull or the order property via CSS.\nReordering Columns\nConclusion Looking back at the points covered in the article, its pretty clear that going full flexbox brings a lot of great features and makes the grid system much more advanced and versatile. The only real drawback is the lack of support for IE9 and older browsers (all modern clients have full flexbox compatibility), if you don\u0026rsquo;t have to support those you\u0026rsquo;re good to go.\nThis wraps up our introduction to the new Bootstrap 4 grid system. Feel free to bookmark the demo page for quick future reference. We hope we\u0026rsquo;ve been helpful! Happy coding :)\n Source : .\n "});index.add({'id':142,'href':'/library/tutorials/docs/articles/webapp/vue/build-web-app-with-vue/','title':"Build a web app with Vue",'content':" How to build a web app with Vue, Vuetify and Axios Source:\nIntroduction In this article, we will be building a Vue.js Application supported by Vuetify and Axios. The aim of this article is to implement a movie application which will be calling on an API. The user will be able to search for movies. The API will retrieve movies with all the search details. When a user clicks on a movie, it will give more details of each movie. It’s a fairly simple App, but it will explain the use case of calling the API from the Vue.js App.\nContents  Why Axios? Why Vuetify? A brief about the movie API Calling and testing API and Test. Create an App Requirement and structure of the App Add Vuetify to the Project Add vue-router to the project Add axios to the project Remove the currently scaffolded component Create LatestMovies component Implement Movie Component Display the ratings Add Search Movie component An issue with search movie and how we can rectify it Add a warning message if there is no search data in the API Creating a central file for axios/refactoring Wrapping Up and source code  1. Why Axios? In Vue.js App, we can display the data from an external API. This can be done by vue-resource and axios. Axios is a 3rd part library and it is a popular one. Here is the official link for using Axios with Vue.js.\nThe important point to be noted here is that in the official docs there are no details about installing axios to the Vue.js app. We will cover this in Section 9: Add axios to the project.\n2. Why Vuetify? Vuetify is a material design framework built on top of Vue.js. It has nice UI components and which can be readily available to use on Vue.js.\n3. A brief about the movie API http://www.omdbapi.com/\nThe omdbapi is an open and free movie database API which will provide the movie details and images too. The main drawback is that most images are not very clear, but it will do the trick. Also API support is there.\nIn order to use this API, first of all, need to signup and they will provide an API key sent to you via mail. This can be used for each query result.\nPassing key and also the special string is needed. s stands for search when passing s=”Indiana”, API will retrieve all data contains Indiana. Also, i stands for a movie with imbd id will be returned, so only one is returned since it is unique. We are using “s” and “i” here for the demo.\n4. Calling and testing API and Test In order to check what we will receive when calling the omdbapi is by testing with postman tool or any API test mechanism. Here I am using the postman for this.\nAs you see in the image, need to pass the apikey=XXXX and the s=”movie-name”\nSo the URL becomes\n http://www.omdbapi.com/?s=movie-name\u0026amp;apikey=XXXX\u0026amp;page=1\u0026amp;type=movie\u0026amp;Content-Type=application/json\n Awesome, we are good, now we can proceed to create an app and work on the axios as well.\n5. Create an App Create a Vue js application is done by a simple command\nvue create movie-app  movie-app is our app name.\n6. Requirement and structure of the App The structure of the app have 3 components.\n LatestMovie component. Movie Component. SearchMovie component.  LatestMovie component will have the current home page and I will display the movies related to my favorite movie “indiana”\nOn clicking on each movie, will display details of every single movie, Which can be done by using the Movie component.\nProvided an option to search and display those movies, which can be handled by SearchMovie component.\n7. Add Vuetify to the Project As already discussed, we are using the Vuetify for the desgin of the App. Need to do some groundwork for that. on the terminal, type\nvue add vuetify  After installation, our front end will look like this:\nAwesome right, they provide a nav bar also. Then will proceed.\n8. Add vue-router to the project Will explain why we needed the vue-router, it will do the routing functionalities and component switching without hassle. Installing the vue-router is by\nnpm install vue-router  now, need to link the router to the application and create a routes file.\n Create a router file Add content to the router file Link the router to the app  1.Create a router file\nI am following a pattern by which create a folder called router in the src path and in that, will create an index.js file\n2. Add content to the router file\nSo far, we created a router/index.js file now need to import the Vue instance and vue-router to that file also, need to export the default router file.\nEach router path will have 3 components: path, name, component.\nimport Vue from 'vue' import VueRouter from 'vue-router' Vue.use(VueRouter) export default new VueRouter({ routes: [ { } ] })  3. Link the router to the app\nFirst, need to import the router from the path, and use that in the Vue instance. All these are done in the src/main.js file\nimport router from ‘./router’  Current main.js file will look like this:\nimport Vue from 'vue' import './plugins/vuetify' import App from './App.vue' import router from './router'Vue.config.productionTip = false new Vue({ render: h =\u0026gt; h(App), router }).$mount('#app')  9. Add axios to the project Axios is our point of contact to call the API services in this app. Now we need to install axios to our project.\nnpm install axios --save  10. Remove the currently scaffolded component By default, we are having a component in place, will remove that and will create the components we needed.\nHelloWorld.vue is the default component, will remove that from our app.\n11. Create LatestMovie component Need to do some steps here\n Create the LatestMovie.vue. Add the axios to the LatestMovie component. Link the router to LatestMovie. Add a progress bar for LatestMovie. Create the LatestMovie.vue.  Create a file called LatestMovie.vue in components folder.\n2. Add the axios to the LatestMovie component.\nHere, we are using the mounted() life cycle for this, added the code to get the result from the omdbapi with the indiana movie data.\nmounted () { axios .get('http://www.omdbapi.com/?s=mummy\u0026amp;apikey=XXXXX\u0026amp;page=1\u0026amp;type=movie\u0026amp;Content-Type=application/json') .then(response =\u0026gt; { this.wholeResponse = response.data.Search }) .catch(error =\u0026gt; { console.log(error) }) }  3. Link the router to LatestMovie.\nNow, we need to link the LatestMovie to the router file.\nin the src/router/index.js:\nimport LatestMovie from \u0026lsquo;@/components/LatestMovie\u0026rsquo;\nadd the links to the router/index.js:\nexport default new VueRouter({ routes: [ { path: '/', name: 'LatestMovie', component: LatestMovie } ] })  4. Add a progress bar for LatestMovie\nIf the API will take time to retrieve, we will need to display a progress bar. This can be achieved by using the “ \u0026lt;v-progress-circular” from vuetify.\nCreated a data property which will be set to true initially, then after the API response will be set to false.\nAlso another data property called wholeResponse will take care of the data.\nSo totally our LatestMovie.vue becomes:\n\u0026lt;template\u0026gt;\u0026lt;v-container v-if=\u0026quot;loading\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;text-xs-center\u0026quot;\u0026gt; \u0026lt;v-progress-circular indeterminate :size=\u0026quot;150\u0026quot; :width=\u0026quot;8\u0026quot; color=\u0026quot;green\u0026quot;\u0026gt; \u0026lt;/v-progress-circular\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/v-container\u0026gt;\u0026lt;v-container v-else grid-list-xl\u0026gt; \u0026lt;v-layout wrap\u0026gt; \u0026lt;v-flex xs4 v-for=\u0026quot;(item, index) in wholeResponse\u0026quot; :key=\u0026quot;index\u0026quot; mb-2\u0026gt; \u0026lt;v-card\u0026gt; \u0026lt;v-img :src=\u0026quot;item.Poster\u0026quot; aspect-ratio=\u0026quot;1\u0026quot; \u0026gt;\u0026lt;/v-img\u0026gt;\u0026lt;v-card-title primary-title\u0026gt; \u0026lt;div\u0026gt; \u0026lt;h2\u0026gt;{{item.Title}}\u0026lt;/h2\u0026gt; \u0026lt;div\u0026gt;Year: {{item.Year}}\u0026lt;/div\u0026gt; \u0026lt;div\u0026gt;Type: {{item.Type}}\u0026lt;/div\u0026gt; \u0026lt;div\u0026gt;IMDB-id: {{item.imdbID}}\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/v-card-title\u0026gt;\u0026lt;v-card-actions class=\u0026quot;justify-center\u0026quot;\u0026gt; \u0026lt;v-btn flat color=\u0026quot;green\u0026quot; [@click](http://twitter.com/click)=\u0026quot;singleMovie(item.imdbID)\u0026quot; \u0026gt;View\u0026lt;/v-btn\u0026gt; \u0026lt;/v-card-actions\u0026gt;\u0026lt;/v-card\u0026gt; \u0026lt;/v-flex\u0026gt; \u0026lt;/v-layout\u0026gt; \u0026lt;/v-container\u0026gt; \u0026lt;/template\u0026gt;\u0026lt;script\u0026gt; import axios from 'axios' export default { data () { return { wholeResponse: [], loading: true } }, mounted () { axios .get('http://www.omdbapi.com/?s=indiana\u0026amp;apikey=XXXX\u0026amp;page=1\u0026amp;type=movie\u0026amp;Content-Type=application/json') .then(response =\u0026gt; { this.wholeResponse = response.data.Search this.loading = false }) .catch(error =\u0026gt; { console.log(error) }) } } \u0026lt;/script\u0026gt;\u0026lt;style lang=\u0026quot;stylus\u0026quot; scoped\u0026gt; .v-progress-circular margin: 1rem \u0026lt;/style\u0026gt; Now, add the router-view to the App.vue to display the component: \u0026lt;router-view\u0026gt;\u0026lt;/router-view\u0026gt;  12. Implement Movie Component Now, it is the time for the single movie part. This can be achieved by using the Movie.vue file.\n Add the Movie.vue file Add the router Add the mode Pass the props in a router. Pass the props in latest component. Work on the props data in the movie component.  Add the Movie.vue file\nAdd the file in components/Movie.vue\nAdd the router\nRegister the Movie.vue to the router/index.js file\nimport Movie from @/components/Movie\nAdd the mode\nThere is “#” is there in the URL, we can remove those using the\nmode: history\nIn the router/index.js file.\nPass the props in a router.\nCreate a path for the Movie.vue component, using the below code in the router/index.js\n{ path: '/movie/:id', name: 'Movie', props: true, component: Movie },  We are giving props: true because we are passing the imdb_id to the Movie.vue component then that value is used to call the API for that single movie.\nPass the props in latest component\nNow up on clicking on the view in the LatestMovie, will call the method which will, in turn, pass the imdb_id as a props to the Movie.vue.\n\u0026lt;v-btn round color=\u0026quot;green\u0026quot; [@click](http://twitter.com/click)=\u0026quot;singleMovie(item.imdbID)\u0026quot; \u0026gt;View\u0026lt;/v-btn\u0026gt;  and the singleMovie method is\nmethods: { singleMovie (id) { this.$router.push('/movie/' + id) } }  Work on the props data in the movie component\nNow, the data is passed from the LatestMovie. That value is received as prop in the Movie.vue component. This value can be used by this.id\nAlso, added a data property called singleMovie to handle the response.\nThe code in the Movie.vue becomes,\n\u0026lt;template\u0026gt; \u0026lt;v-container\u0026gt; \u0026lt;v-layout row wrap\u0026gt; \u0026lt;v-flex xs12\u0026gt; \u0026lt;h2\u0026gt;welcome to single movie component\u0026lt;/h2\u0026gt; \u0026lt;div\u0026gt;{{singleMovie}}\u0026lt;/div\u0026gt; \u0026lt;/v-flex\u0026gt; \u0026lt;/v-layout\u0026gt; \u0026lt;/v-container\u0026gt; \u0026lt;/template\u0026gt;\u0026lt;script\u0026gt; import axios from 'axios' export default { props: ['id'], data () { return { singleMovie: '' } }, mounted () { axios .get('[http://www.omdbapi.com/?apikey=b76b385c\u0026amp;i=XXXXX\u0026amp;Content-Type=application/json'](http://www.omdbapi.com/?apikey=b76b385c\u0026amp;i=tt0209163\u0026amp;Content-Type=application/json%27)) .then(response =\u0026gt; { this.singleMovie = response.data }) .catch(error =\u0026gt; { console.log(error) }) } } \u0026lt;/script\u0026gt;\u0026lt;style\u0026gt; \u0026lt;/style\u0026gt;  13. Display the ratings The omdbapi will provide us the current ratings for the movie. We will display that value in the table,\nFor that, will display using a modal, which will be invoked on clicking the view rating button.\n\u0026lt;template\u0026gt; \u0026lt;v-layout row wrap\u0026gt; \u0026lt;v-flex xs12\u0026gt; \u0026lt;div class=\u0026quot;text-xs-center\u0026quot;\u0026gt; \u0026lt;v-dialog v-model=\u0026quot;dialog\u0026quot; width=\u0026quot;500\u0026quot;\u0026gt; \u0026lt;v-btn slot=\u0026quot;activator\u0026quot; color=\u0026quot;green\u0026quot; dark\u0026gt; View Ratings \u0026lt;/v-btn\u0026gt; \u0026lt;v-card\u0026gt; \u0026lt;v-card-title class=\u0026quot;headline grey lighten-2\u0026quot; primary-title \u0026gt; Ratings \u0026lt;/v-card-title\u0026gt; \u0026lt;v-card-text\u0026gt; \u0026lt;table style=\u0026quot;width:100%\u0026quot; border=\u0026quot;1\u0026quot; \u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th\u0026gt;Source\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;Ratings\u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr v-for=\u0026quot;(rating,index) in this.ratings\u0026quot; :key=\u0026quot;index\u0026quot;\u0026gt; \u0026lt;td align=\u0026quot;center\u0026quot;\u0026gt;{{ratings[index].Source}}\u0026lt;/td\u0026gt; \u0026lt;td align=\u0026quot;center\u0026quot;\u0026gt;{{ratings[index].Value}}\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;/v-card-text\u0026gt; \u0026lt;v-divider\u0026gt;\u0026lt;/v-divider\u0026gt; \u0026lt;v-card-actions\u0026gt; \u0026lt;v-spacer\u0026gt;\u0026lt;/v-spacer\u0026gt; \u0026lt;v-btn color=\u0026quot;primary\u0026quot; flat [@click](http://twitter.com/click)=\u0026quot;dialog = false\u0026quot; \u0026gt; OK \u0026lt;/v-btn\u0026gt; \u0026lt;/v-card-actions\u0026gt; \u0026lt;/v-card\u0026gt; \u0026lt;/v-dialog\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/v-flex\u0026gt; \u0026lt;/v-layout\u0026gt; \u0026lt;/template\u0026gt;  We are iterating a data value called ratings. This data property is from a response from API ie response.data.Ratings.\n14. Add Search Movie component For this, we need to create the following:\n Create a SearchMovie.vue file Create a text field in the App.vue. On clicking the search button, will pass the data from the text field to the SearchMovie.vue file as prop. In SearchMovie.vue file, we will receive the value and call the API to get the data.  commit link for this\n15. An issue with search movie and how we can rectify it Currently mounted lifecycle hook is called only one time, when we search for one time, it displays the data, ie when searched with iron man, it shows the data. but After searching with “titan”, It shows the same data. This can be fixed by using the watch property on the props of the data called name(from the App.vue) and updated the mounted property as a method. As a result, the system will call 2 times, ie when the first loaded by the mounted lifecycle hook and again search will be handled by the watcher action for the props(name) value.\nthe issue, we are searching for Titan, but we got iron man\ncommit link for the fix\n16. Add a warning message if there is no search data in the API Suppose, when we are calling for the API with invalid movie or movie that is not available in our omdbapi . In that case, need to display a message.\nWe are creating a data property by default which is false, when searched data is not returning anything, will set as true and it will display the message.\ncommit link for the code change\n17. Creating a central file for axios/refactoring Still, our axios and API calling codes are scattered everywhere in the component. It will good if we place those all in a single place like services in angular.\nFor that\n Create a folder named services in src/ and create a file MovieApi.js Import the axios in the main.js Create a default URL in the main.js Export the MovieApi.js file Import the MovieApi.js in the components. Remove the axios code from the components and place in the MovieApi.js file. Call the appropriate methods from components.  commit link for the code change\n18. Wrapping Up and source code Our final output will be this:\nLatestMovie component.\nsearchMovie.vue\nMovie.vue\nGitHub URL\nAnd there we have it! I hope you have enjoyed following along. Please leave claps and comments if you liked the content and would like to discuss further!\n"});index.add({'id':143,'href':'/library/tutorials/docs/articles/data-science/web-scraping/beautiful-soup-web-scraper/','title':"Build a Web Scraper",'content':" Beautiful Soup: Build a Web Scraper With Python The incredible amount of data on the Internet is a rich resource for any field of research or personal interest. To effectively harvest that data, you’ll need to become skilled at web scraping. The Python libraries requests and Beautiful Soup are powerful tools for the job. If you like to learn with hands-on examples and you have a basic understanding of Python and HTML, then this tutorial is for you.\nIn this tutorial, you’ll learn how to:\n Use requests and Beautiful Soup for scraping and parsing data from the Web Walk through a web scraping pipeline from start to finish Build a script that fetches job offers from the Web and displays relevant information in your console  This is a powerful project because you’ll be able to apply the same process and the same tools to any static website out there on the World Wide Web. You can download the source code for the project and all examples in this tutorial by clicking on the link below:\n Get Sample Code: Click here to get the sample code you\u0026rsquo;ll use for the project and examples in this tutorial.\n Let’s get started!\nWhat Is Web Scraping? Web scraping is the process of gathering information from the Internet. Even copy-pasting the lyrics of your favorite song is a form of web scraping! However, the words “web scraping” usually refer to a process that involves automation. Some websites don’t like it when automatic scrapers gather their data, while others don’t mind.\nIf you’re scraping a page respectfully for educational purposes, then you’re unlikely to have any problems. Still, it’s a good idea to do some research on your own and make sure that you’re not violating any Terms of Service before you start a large-scale project. To learn more about the legal aspects of web scraping, check out Legal Perspectives on Scraping Data From The Modern Web.\nWhy Scrape the Web? Say you’re a surfer (both online and in real life) and you’re looking for employment. However, you’re not looking for just any job. With a surfer’s mindset, you’re waiting for the perfect opportunity to roll your way!\nThere’s a job site that you like that offers exactly the kinds of jobs you’re looking for. Unfortunately, a new position only pops up once in a blue moon. You think about checking up on it every day, but that doesn’t sound like the most fun and productive way to spend your time.\nThankfully, the world offers other ways to apply that surfer’s mindset! Instead of looking at the job site every day, you can use Python to help automate the repetitive parts of your job search. Automated web scraping can be a solution to speed up the data collection process. You write your code once and it will get the information you want many times and from many pages.\nIn contrast, when you try to get the information you want manually, you might spend a lot of time clicking, scrolling, and searching. This is especially true if you need large amounts of data from websites that are regularly updated with new content. Manual web scraping can take a lot of time and repetition.\nThere’s so much information on the Web, and new information is constantly added. Something among all that data is likely of interest to you, and much of it is just out there for the taking. Whether you’re actually on the job hunt, gathering data to support your grassroots organization, or are finally looking to get all the lyrics from your favorite artist downloaded to your computer, automated web scraping can help you accomplish your goals.\nChallenges of Web Scraping The Web has grown organically out of many sources. It combines a ton of different technologies, styles, and personalities, and it continues to grow to this day. In other words, the Web is kind of a hot mess! This can lead to a few challenges you’ll see when you try web scraping.\nOne challenge is variety. Every website is different. While you’ll encounter general structures that tend to repeat themselves, each website is unique and will need its own personal treatment if you want to extract the information that’s relevant to you.\nAnother challenge is durability. Websites constantly change. Say you’ve built a shiny new web scraper that automatically cherry-picks precisely what you want from your resource of interest. The first time you run your script, it works flawlessly. But when you run the same script only a short while later, you run into a discouraging and lengthy stack of tracebacks!\nThis is a realistic scenario, as many websites are in active development. Once the site’s structure has changed, your scraper might not be able to navigate the sitemap correctly or find the relevant information. The good news is that many changes to websites are small and incremental, so you’ll likely be able to update your scraper with only minimal adjustments.\nHowever, keep in mind that because the internet is dynamic, the scrapers you’ll build will probably require constant maintenance. You can set up continuous integration to run scraping tests periodically to ensure that your main script doesn’t break without your knowledge.\nAPIs: An Alternative to Web Scraping Some website providers offer Application Programming Interfaces (APIs) that allow you to access their data in a predefined manner. With APIs, you can avoid parsing HTML and instead access the data directly using formats like JSON and XML. HTML is primarily a way to visually present content to users.\nWhen you use an API, the process is generally more stable than gathering the data through web scraping. That’s because APIs are made to be consumed by programs, rather than by human eyes. If the design of a website changes, then it doesn’t mean that the structure of the API has changed.\nHowever, APIs can change as well. Both the challenges of variety and durability apply to APIs just as they do to websites. Additionally, it’s much harder to inspect the structure of an API by yourself if the provided documentation is lacking in quality.\nThe approach and tools you need to gather information using APIs are outside the scope of this tutorial. To learn more about it, check out API Integration in Python.\nScraping the Monster Job Site In this tutorial, you’ll build a web scraper that fetches Software Developer job listings from the Monster job aggregator site. Your web scraper will parse the HTML to pick out the relevant pieces of information and filter that content for specific words.\nYou can scrape any site on the Internet that you can look at, but the difficulty of doing so depends on the site. This tutorial offers you an introduction to web scraping to help you understand the overall process. Then, you can apply this same process for every website you’ll want to scrape.\nPart 1: Inspect Your Data Source The first step is to head over to the site you want to scrape using your favorite browser. You’ll need to understand the site structure to extract the information you’re interested in.\nExplore the Website Click through the site and interact with it just like any normal user would. For example, you could search for Software Developer jobs in Australia using the site’s native search interface:\n\nYou can see that there’s a list of jobs returned on the left side, and there are more detailed descriptions about the selected job on the right side. When you click on any of the jobs on the left, the content on the right changes. You can also see that when you interact with the website, the URL in your browser’s address bar also changes.\nDecipher the Information in URLs A lot of information can be encoded in a URL. Your web scraping journey will be much easier if you first become familiar with how URLs work and what they’re made of. Try to pick apart the URL of the site you’re currently on:\nhttps://www.monster.com/jobs/search/?q=Software-Developer\u0026amp;where=Australia  You can deconstruct the above URL into two main parts:\n The base URL represents the path to the search functionality of the website. In the example above, the base URL is https://www.monster.com/jobs/search/. The query parameters represent additional values that can be declared on the page. In the example above, the query parameters are ?q=Software-Developer\u0026amp;where=Australia.  Any job you’ll search for on this website will use the same base URL. However, the query parameters will change depending on what you’re looking for. You can think of them as query strings that get sent to the database to retrieve specific records.\nQuery parameters generally consist of three things:\n Start: The beginning of the query parameters is denoted by a question mark (?). Information: The pieces of information constituting one query parameter are encoded in key-value pairs, where related keys and values are joined together by an equals sign (key=value). Separator: Every URL can have multiple query parameters, which are separated from each other by an ampersand (\u0026amp;).  Equipped with this information, you can pick apart the URL’s query parameters into two key-value pairs:\n q=Software-Developer selects the type of job you’re looking for. where=Australia selects the location you’re looking for.  Try to change the search parameters and observe how that affects your URL. Go ahead and enter new values in the search bar up top:\nChange these values to observe the changes in the URL.\nNext, try to change the values directly in your URL. See what happens when you paste the following URL into your browser’s address bar:\nhttps://www.monster.com/jobs/search/?q=Programmer\u0026amp;where=New-York  You’ll notice that changes in the search box of the site are directly reflected in the URL’s query parameters and vice versa. If you change either of them, then you’ll see different results on the website. When you explore URLs, you can get information on how to retrieve data from the website’s server.\nInspect the Site Using Developer Tools Next, you’ll want to learn more about how the data is structured for display. You’ll need to understand the page structure to pick what you want from the HTML response that you’ll collect in one of the upcoming steps.\nDeveloper tools can help you understand the structure of a website. All modern browsers come with developer tools installed. In this tutorial, you’ll see how to work with the developer tools in Chrome. The process will be very similar to other modern browsers.\nIn Chrome, you can open up the developer tools through the menu View → Developer → Developer Tools. You can also access them by right-clicking on the page and selecting the Inspect option, or by using a keyboard shortcut.\nDeveloper tools allow you to interactively explore the site’s DOM to better understand the source that you’re working with. To dig into your page’s DOM, select the Elements tab in developer tools. You’ll see a structure with clickable HTML elements. You can expand, collapse, and even edit elements right in your browser:\n\nThe HTML on the right represents the structure of the page you can see on the left.\nYou can think of the text displayed in your browser as the HTML structure of that page. If you’re interested, then you can read more about the difference between the DOM and HTML on CSS-TRICKS.\nWhen you right-click elements on the page, you can select Inspect to zoom to their location in the DOM. You can also hover over the HTML text on your right and see the corresponding elements light up on the page.\nTask: Find a single job posting. What HTML element is it wrapped in, and what other HTML elements does it contain?\nPlay around and explore! The more you get to know the page you’re working with, the easier it will be to scrape it. However, don’t get too overwhelmed with all that HTML text. You’ll use the power of programming to step through this maze and cherry-pick only the interesting parts with Beautiful Soup.\nPart 2: Scrape HTML Content From a Page Now that you have an idea of what you’re working with, it’s time to get started using Python. First, you’ll want to get the site’s HTML code into your Python script so that you can interact with it. For this task, you’ll use Python’s requests library. Type the following in your terminal to install it:\n$ pip3 install requests  Then open up a new file in your favorite text editor. All you need to retrieve the HTML are a few lines of code:\nimport requests URL = 'https://www.monster.com/jobs/search/?q=Software-Developer\u0026amp;where=Australia' page = requests.get(URL)`  This code performs an HTTP request to the given URL. It retrieves the HTML data that the server sends back and stores that data in a Python object.\nIf you take a look at the downloaded content, then you’ll notice that it looks very similar to the HTML you were inspecting earlier with developer tools. To improve the structure of how the HTML is displayed in your console output, you can print the object’s .content attribute with pprint().\nStatic Websites The website you’re scraping in this tutorial serves static HTML content. In this scenario, the server that hosts the site sends back HTML documents that already contain all the data you’ll get to see as a user.\nWhen you inspected the page with developer tools earlier on, you discovered that a job posting consists of the following long and messy-looking HTML:\n\u0026lt;section class=\u0026quot;card-content\u0026quot; data-jobid=\u0026quot;4755ec59-d0db-4ce9-8385-b4df7c1e9f7c\u0026quot; onclick=\u0026quot;MKImpressionTrackingMouseDownHijack(this, event)\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;flex-row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;mux-company-logo thumbnail\u0026quot;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;summary\u0026quot;\u0026gt; \u0026lt;header class=\u0026quot;card-header\u0026quot;\u0026gt; \u0026lt;h2 class=\u0026quot;title\u0026quot;\u0026gt;\u0026lt;a data-bypass=\u0026quot;true\u0026quot; data-m_impr_a_placement_id=\u0026quot;JSR2CW\u0026quot; data-m_impr_j_cid=\u0026quot;4\u0026quot; data-m_impr_j_coc=\u0026quot;\u0026quot; data-m_impr_j_jawsid=\u0026quot;371676273\u0026quot; data-m_impr_j_jobid=\u0026quot;0\u0026quot; data-m_impr_j_jpm=\u0026quot;2\u0026quot; data-m_impr_j_jpt=\u0026quot;3\u0026quot; data-m_impr_j_lat=\u0026quot;30.1882\u0026quot; data-m_impr_j_lid=\u0026quot;619\u0026quot; data-m_impr_j_long=\u0026quot;-95.6732\u0026quot; data-m_impr_j_occid=\u0026quot;11838\u0026quot; data-m_impr_j_p=\u0026quot;3\u0026quot; data-m_impr_j_postingid=\u0026quot;4755ec59-d0db-4ce9-8385-b4df7c1e9f7c\u0026quot; data-m_impr_j_pvc=\u0026quot;4496dab8-a60c-4f02-a2d1-6213320e7213\u0026quot; data-m_impr_s_t=\u0026quot;t\u0026quot; data-m_impr_uuid=\u0026quot;0b620778-73c7-4550-9db5-df4efad23538\u0026quot; href=\u0026quot;https://job-openings.monster.com/python-developer-woodlands-wa-us-lancesoft-inc/4755ec59-d0db-4ce9-8385-b4df7c1e9f7c\u0026quot; onclick=\u0026quot;clickJobTitle('plid=619\u0026amp;amp;pcid=4\u0026amp;amp;poccid=11838','Software Developer',''); clickJobTitleSiteCat('{\u0026amp;quot;events.event48\u0026amp;quot;:\u0026amp;quot;true\u0026amp;quot;,\u0026amp;quot;eVar25\u0026amp;quot;:\u0026amp;quot;Python Developer\u0026amp;quot;,\u0026amp;quot;eVar66\u0026amp;quot;:\u0026amp;quot;Monster\u0026amp;quot;,\u0026amp;quot;eVar67\u0026amp;quot;:\u0026amp;quot;JSR2CW\u0026amp;quot;,\u0026amp;quot;eVar26\u0026amp;quot;:\u0026amp;quot;_LanceSoft Inc\u0026amp;quot;,\u0026amp;quot;eVar31\u0026amp;quot;:\u0026amp;quot;Woodlands_WA_\u0026amp;quot;,\u0026amp;quot;prop24\u0026amp;quot;:\u0026amp;quot;2019-07-02T12:00\u0026amp;quot;,\u0026amp;quot;eVar53\u0026amp;quot;:\u0026amp;quot;1500127001001\u0026amp;quot;,\u0026amp;quot;eVar50\u0026amp;quot;:\u0026amp;quot;Aggregated\u0026amp;quot;,\u0026amp;quot;eVar74\u0026amp;quot;:\u0026amp;quot;regular\u0026amp;quot;}')\u0026quot;\u0026gt;Python Developer \u0026lt;/a\u0026gt;\u0026lt;/h2\u0026gt; \u0026lt;/header\u0026gt; \u0026lt;div class=\u0026quot;company\u0026quot;\u0026gt; \u0026lt;span class=\u0026quot;name\u0026quot;\u0026gt;LanceSoft Inc\u0026lt;/span\u0026gt; \u0026lt;ul class=\u0026quot;list-inline\u0026quot;\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;location\u0026quot;\u0026gt; \u0026lt;span class=\u0026quot;name\u0026quot;\u0026gt; Woodlands, WA \u0026lt;/span\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;meta flex-col\u0026quot;\u0026gt; \u0026lt;time datetime=\u0026quot;2017-05-26T12:00\u0026quot;\u0026gt;2 days ago\u0026lt;/time\u0026gt; \u0026lt;span class=\u0026quot;mux-tooltip applied-only\u0026quot; data-mux=\u0026quot;tooltip\u0026quot; title=\u0026quot;Applied\u0026quot;\u0026gt; \u0026lt;i aria-hidden=\u0026quot;true\u0026quot; class=\u0026quot;icon icon-applied\u0026quot;\u0026gt;\u0026lt;/i\u0026gt; \u0026lt;span class=\u0026quot;sr-only\u0026quot;\u0026gt;Applied\u0026lt;/span\u0026gt; \u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;mux-tooltip saved-only\u0026quot; data-mux=\u0026quot;tooltip\u0026quot; title=\u0026quot;Saved\u0026quot;\u0026gt; \u0026lt;i aria-hidden=\u0026quot;true\u0026quot; class=\u0026quot;icon icon-saved\u0026quot;\u0026gt;\u0026lt;/i\u0026gt; \u0026lt;span class=\u0026quot;sr-only\u0026quot;\u0026gt;Saved\u0026lt;/span\u0026gt; \u0026lt;/span\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/section\u0026gt;  It can be difficult to wrap your head around such a long block of HTML code. To make it easier to read, you can use an HTML formatter to automatically clean it up a little more. Good readability helps you better understand the structure of any code block. While it may or may not help to improve the formatting of the HTML, it’s always worth a try.\n Note: Keep in mind that every website will look different. That’s why it’s necessary to inspect and understand the structure of the site you’re currently working with before moving forward.\n The HTML above definitely has a few confusing parts in it. For example, you can scroll to the right to see the large number of attributes that the \u0026lt;a\u0026gt; element has. Luckily, the class names on the elements that you’re interested in are relatively straightforward:\n class=\u0026quot;title\u0026quot;: the title of the job posting class=\u0026quot;company\u0026quot;: the company that offers the position class=\u0026quot;location\u0026quot;: the location where you’d be working  In case you ever get lost in a large pile of HTML, remember that you can always go back to your browser and use developer tools to further explore the HTML structure interactively.\nBy now, you’ve successfully harnessed the power and user-friendly design of Python’s requests library. With only a few lines of code, you managed to scrape the static HTML content from the web and make it available for further processing.\nHowever, there are a few more challenging situations you might encounter when you’re scraping websites. Before you begin using Beautiful Soup to pick the relevant information from the HTML that you just scraped, take a quick look at two of these situations.\nHidden Websites Some pages contain information that’s hidden behind a login. That means you’ll need an account to be able to see (and scrape) anything from the page. The process to make an HTTP request from your Python script is different than how you access a page from your browser. That means that just because you can log in to the page through your browser, that doesn’t mean you’ll be able to scrape it with your Python script.\nHowever, there are some advanced techniques that you can use with the requests to access the content behind logins. These techniques will allow you to log in to websites while making the HTTP request from within your script.\nDynamic Websites Static sites are easier to work with because the server sends you an HTML page that already contains all the information as a response. You can parse an HTML response with Beautiful Soup and begin to pick out the relevant data.\nOn the other hand, with a dynamic website the server might not send back any HTML at all. Instead, you’ll receive JavaScript code as a response. This will look completely different from what you saw when you inspected the page with your browser’s developer tools.\n Note: To offload work from the server to the clients’ machines, many modern websites avoid crunching numbers on their servers whenever possible. Instead, they’ll send JavaScript code that your browser will execute locally to produce the desired HTML.\n As mentioned before, what happens in the browser is not related to what happens in your script. Your browser will diligently execute the JavaScript code it receives back from a server and create the DOM and HTML for you locally. However, doing a request to a dynamic website in your Python script will not provide you with the HTML page content.\nWhen you use requests, you’ll only receive what the server sends back. In the case of a dynamic website, you’ll end up with some JavaScript code, which you won’t be able to parse using Beautiful Soup. The only way to go from the JavaScript code to the content you’re interested in is to execute the code, just like your browser does. The requests library can’t do that for you, but there are other solutions that can.\nFor example, requests-html is a project created by the author of the requests library that allows you to easily render JavaScript using syntax that’s similar to the syntax in requests. It also includes capabilities for parsing the data by using Beautiful Soup under the hood.\n Note: Another popular choice for scraping dynamic content is Selenium. You can think of Selenium as a slimmed-down browser that executes the JavaScript code for you before passing on the rendered HTML response to your script.\n You won’t go deeper into scraping dynamically-generated content in this tutorial. For now, it’s enough for you to remember that you’ll need to look into the above-mentioned options if the page you’re interested in is generated in your browser dynamically.\nPart 3: Parse HTML Code With Beautiful Soup You’ve successfully scraped some HTML from the Internet, but when you look at it now, it just seems like a huge mess. There are tons of HTML elements here and there, thousands of attributes scattered around—and wasn’t there some JavaScript mixed in as well? It’s time to parse this lengthy code response with Beautiful Soup to make it more accessible and pick out the data that you’re interested in.\nBeautiful Soup is a Python library for parsing structured data. It allows you to interact with HTML in a similar way to how you would interact with a web page using developer tools. Beautiful Soup exposes a couple of intuitive functions you can use to explore the HTML you received. To get started, use your terminal to install the Beautiful Soup library:\n$ pip3 install beautifulsoup4  Then, import the library and create a Beautiful Soup object:\nimport requests from bs4 import BeautifulSoup URL = 'https://www.monster.com/jobs/search/?q=Software-Developer\u0026amp;where=Australia' page = requests.get(URL) soup = BeautifulSoup(page.content, 'html.parser')  When you add the two highlighted lines of code, you’re creating a Beautiful Soup object that takes the HTML content you scraped earlier as its input. When you instantiate the object, you also instruct Beautiful Soup to use the appropriate parser.\nFind Elements by ID In an HTML web page, every element can have an id attribute assigned. As the name already suggests, that id attribute makes the element uniquely identifiable on the page. You can begin to parse your page by selecting a specific element by its ID.\nSwitch back to developer tools and identify the HTML object that contains all of the job postings. Explore by hovering over parts of the page and using right-click to Inspect.\n Note: Keep in mind that it’s helpful to periodically switch back to your browser and interactively explore the page using developer tools. This helps you learn how to find the exact elements you’re looking for.\n At the time of this writing, the element you’re looking for is a \u0026lt;div\u0026gt; with an id attribute that has the value \u0026quot;ResultsContainer\u0026quot;. It has a couple of other attributes as well, but below is the gist of what you’re looking for:\n\u0026lt;div id=\u0026quot;ResultsContainer\u0026quot;\u0026gt; \u0026lt;!-- all the job listings --\u0026gt; \u0026lt;/div\u0026gt;  Beautiful Soup allows you to find that specific element easily by its ID:\nresults = soup.find(id='ResultsContainer')  For easier viewing, you can .prettify() any Beautiful Soup object when you print it out. If you call this method on the results variable that you just assigned above, then you should see all the HTML contained within the \u0026lt;div\u0026gt;:\nprint(results.prettify())  When you use the element’s ID, you’re able to pick one element out from among the rest of the HTML. This allows you to work with only this specific part of the page’s HTML. It looks like the soup just got a little thinner! However, it’s still quite dense.\nFind Elements by HTML Class Name You’ve seen that every job posting is wrapped in a \u0026lt;section\u0026gt; element with the class card-content. Now you can work with your new Beautiful Soup object called results and select only the job postings. These are, after all, the parts of the HTML that you’re interested in! You can do this in one line of code:\njob_elems = results.find_all('section', class_='card-content')  Here, you call .find_all() on a Beautiful Soup object, which returns an iterable containing all the HTML for all the job listings displayed on that page.\nTake a look at all of them:\nfor job_elem in job_elems: print(job_elem, end='\\n'*2)  That’s already pretty neat, but there’s still a lot of HTML! You’ve seen earlier that your page has descriptive class names on some elements. Let’s pick out only those:\nfor job_elem in job_elems: # Each job_elem is a new BeautifulSoup object. # You can use the same methods on it as you did before. title_elem = job_elem.find('h2', class_='title') company_elem = job_elem.find('div', class_='company') location_elem = job_elem.find('div', class_='location') print(title_elem) print(company_elem) print(location_elem) print()  Great! You’re getting closer and closer to the data you’re actually interested in. Still, there’s a lot going on with all those HTML tags and attributes floating around:\n\u0026lt;h2 class=\u0026quot;title\u0026quot;\u0026gt;\u0026lt;a data-bypass=\u0026quot;true\u0026quot; data-m_impr_a_placement_id=\u0026quot;JSR2CW\u0026quot; data-m_impr_j_cid=\u0026quot;4\u0026quot; data-m_impr_j_coc=\u0026quot;\u0026quot; data-m_impr_j_jawsid=\u0026quot;371676273\u0026quot; data-m_impr_j_jobid=\u0026quot;0\u0026quot; data-m_impr_j_jpm=\u0026quot;2\u0026quot; data-m_impr_j_jpt=\u0026quot;3\u0026quot; data-m_impr_j_lat=\u0026quot;30.1882\u0026quot; data-m_impr_j_lid=\u0026quot;619\u0026quot; data-m_impr_j_long=\u0026quot;-95.6732\u0026quot; data-m_impr_j_occid=\u0026quot;11838\u0026quot; data-m_impr_j_p=\u0026quot;3\u0026quot; data-m_impr_j_postingid=\u0026quot;4755ec59-d0db-4ce9-8385-b4df7c1e9f7c\u0026quot; data-m_impr_j_pvc=\u0026quot;4496dab8-a60c-4f02-a2d1-6213320e7213\u0026quot; data-m_impr_s_t=\u0026quot;t\u0026quot; data-m_impr_uuid=\u0026quot;0b620778-73c7-4550-9db5-df4efad23538\u0026quot; href=\u0026quot;https://job-openings.monster.com/python-developer-woodlands-wa-us-lancesoft-inc/4755ec59-d0db-4ce9-8385-b4df7c1e9f7c\u0026quot; onclick=\u0026quot;clickJobTitle('plid=619\u0026amp;amp;pcid=4\u0026amp;amp;poccid=11838','Software Developer',''); clickJobTitleSiteCat('{\u0026amp;quot;events.event48\u0026amp;quot;:\u0026amp;quot;true\u0026amp;quot;,\u0026amp;quot;eVar25\u0026amp;quot;:\u0026amp;quot;Python Developer\u0026amp;quot;,\u0026amp;quot;eVar66\u0026amp;quot;:\u0026amp;quot;Monster\u0026amp;quot;,\u0026amp;quot;eVar67\u0026amp;quot;:\u0026amp;quot;JSR2CW\u0026amp;quot;,\u0026amp;quot;eVar26\u0026amp;quot;:\u0026amp;quot;_LanceSoft Inc\u0026amp;quot;,\u0026amp;quot;eVar31\u0026amp;quot;:\u0026amp;quot;Woodlands_WA_\u0026amp;quot;,\u0026amp;quot;prop24\u0026amp;quot;:\u0026amp;quot;2019-07-02T12:00\u0026amp;quot;,\u0026amp;quot;eVar53\u0026amp;quot;:\u0026amp;quot;1500127001001\u0026amp;quot;,\u0026amp;quot;eVar50\u0026amp;quot;:\u0026amp;quot;Aggregated\u0026amp;quot;,\u0026amp;quot;eVar74\u0026amp;quot;:\u0026amp;quot;regular\u0026amp;quot;}')\u0026quot;\u0026gt;Python Developer \u0026lt;/a\u0026gt;\u0026lt;/h2\u0026gt; \u0026lt;div class=\u0026quot;company\u0026quot;\u0026gt; \u0026lt;span class=\u0026quot;name\u0026quot;\u0026gt;LanceSoft Inc\u0026lt;/span\u0026gt; \u0026lt;ul class=\u0026quot;list-inline\u0026quot;\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;location\u0026quot;\u0026gt; \u0026lt;span class=\u0026quot;name\u0026quot;\u0026gt; Woodlands, WA \u0026lt;/span\u0026gt; \u0026lt;/div\u0026gt;  You’ll see how to narrow down this output in the next section.\nExtract Text From HTML Elements For now, you only want to see the title, company, and location of each job posting. And behold! Beautiful Soup has got you covered. You can add .text to a Beautiful Soup object to return only the text content of the HTML elements that the object contains:\nfor job_elem in job_elems: title_elem = job_elem.find('h2', class_='title') company_elem = job_elem.find('div', class_='company') location_elem = job_elem.find('div', class_='location') print(title_elem.text) print(company_elem.text) print(location_elem.text) print()  Run the above code snippet and you’ll see the text content displayed. However, you’ll also get a lot of whitespace. Since you’re now working with Python strings, you can .strip() the superfluous whitespace. You can also apply any other familiar Python string methods to further clean up your text.\n Note: The web is messy and you can’t rely on a page structure to be consistent throughout. Therefore, you’ll more often than not run into errors while parsing HTML.\n When you run the above code, you might encounter an AttributeError:\nAttributeError: 'NoneType' object has no attribute 'text'  If that’s the case, then take a step back and inspect your previous results. Were there any items with a value of None? You might have noticed that the structure of the page is not entirely uniform. There could be an advertisement in there that displays in a different way than the normal job postings, which may return different results. For this tutorial, you can safely disregard the problematic element and skip over it while parsing the HTML:\nfor job_elem in job_elems: title_elem = job_elem.find('h2', class_='title') company_elem = job_elem.find('div', class_='company') location_elem = job_elem.find('div', class_='location') if None in (title_elem, company_elem, location_elem): continue print(title_elem.text.strip()) print(company_elem.text.strip()) print(location_elem.text.strip()) print()  Feel free to explore why one of the elements is returned as None. You can use the conditional statement you wrote above to print() out and inspect the relevant element in more detail. What do you think is going on there?\nAfter you complete the above steps try running your script again. The results finally look much better:\nPython Developer LanceSoft Inc Woodlands, WA Senior Engagement Manager Zuora Sydney, NSW  Find Elements by Class Name and Text Content By now, you’ve cleaned up the list of jobs that you saw on the website. While that’s pretty neat already, you can make your script more useful. However, not all of the job listings seem to be developer jobs that you’d be interested in as a Python developer. So instead of printing out all of the jobs from the page, you’ll first filter them for some keywords.\nYou know that job titles in the page are kept within \u0026lt;h2\u0026gt; elements. To filter only for specific ones, you can use the string argument:\npython_jobs = results.find_all('h2', string='Python Developer')`  This code finds all \u0026lt;h2\u0026gt; elements where the contained string matches 'Python Developer' exactly. Note that you’re directly calling the method on your first results variable. If you go ahead and print() the output of the above code snippet to your console, then you might be disappointed because it will probably be empty:\n[]  There was definitely a job with that title in the search results, so why is it not showing up? When you use string= like you did above, your program looks for exactly that string. Any differences in capitalization or whitespace will prevent the element from matching. In the next section, you’ll find a way to make the string more general.\nPass a Function to a Beautiful Soup Method In addition to strings, you can often pass functions as arguments to Beautiful Soup methods. You can change the previous line of code to use a function instead:\npython_jobs = results.find_all('h2', string=lambda text: 'python' in text.lower())  Now you’re passing an anonymous function to the string= argument. The lambda function looks at the text of each \u0026lt;h2\u0026gt; element, converts it to lowercase, and checks whether the substring 'python' is found anywhere in there. Now you’ve got a match:\nprint(len(python_jobs)) # 1  Your program has found a match!\n Note: In case you still don’t get a match, try adapting your search string. The job offers on this page are constantly changing and there might not be a job listed that includes the substring 'python' in its title at the time that you’re working through this tutorial.\n The process of finding specific elements depending on their text content is a powerful way to filter your HTML response for the information that you’re looking for. Beautiful Soup allows you to use either exact strings or functions as arguments for filtering text in Beautiful Soup objects.\nExtract Attributes From HTML Elements At this point, your Python script already scrapes the site and filters its HTML for relevant job postings. Well done! However, one thing that’s still missing is the link to apply for a job.\nWhile you were inspecting the page, you found that the link is part of the element that has the title HTML class. The current code strips away the entire link when accessing the .text attribute of its parent element. As you’ve seen before, .text only contains the visible text content of an HTML element. Tags and attributes are not part of that. To get the actual URL, you want to extract one of those attributes instead of discarding it.\nLook at the list of filtered results python_jobs that you created above. The URL is contained in the href attribute of the nested \u0026lt;a\u0026gt; tag. Start by fetching the \u0026lt;a\u0026gt; element. Then, extract the value of its href attribute using square-bracket notation:\npython_jobs = results.find_all('h2', string=lambda text: \u0026quot;python\u0026quot; in text.lower()) for p_job in python_jobs: link = p_job.find('a')['href'] print(p_job.text.strip()) print(f\u0026quot;Apply here: {link}\\n\u0026quot;)  The filtered results will only show links to job opportunities that include python in their title. You can use the same square-bracket notation to extract other HTML attributes as well. A common use case is to fetch the URL of a link, as you did above.\nBuilding the Job Search Tool If you’ve written the code alongside this tutorial, then you can already run your script as-is. To wrap up your journey into web scraping, you could give the code a final makeover and create a command line interface app that looks for Software Developer jobs in any location you define.\nYou can check out a command line app version of the code you built in this tutorial at the link below:\nGet Sample Code: Click here to get the sample code you\u0026rsquo;ll use for the project and examples in this tutorial.\nIf you’re interested in learning how to adapt your script as a command line interface, then check out How to Build Command Line Interfaces in Python With argparse.\nAdditional Practice Below is a list of other job boards. These linked pages also return their search results as static HTML responses. To keep practicing your new skills, you can revisit the web scraping process using any or all of the following sites:\n PythonJobs Remote(dot)co Indeed  Go through this tutorial again from the top using one of these other sites. You’ll see that the structure of each website is different and that you’ll need to re-build the code in a slightly different way to fetch the data you want. This is a great way to practice the concepts that you just learned. While it might make you sweat every so often, your coding skills will be stronger for it!\nDuring your second attempt, you can also explore additional features of Beautiful Soup. Use the documentation as your guidebook and inspiration. Additional practice will help you become more proficient at web scraping using Python, requests, and Beautiful Soup.\nConclusion Beautiful Soup is packed with useful functionality to parse HTML data. It’s a trusted and helpful companion for your web scraping adventures. Its documentation is comprehensive and relatively user-friendly to get started with. You’ll find that Beautiful Soup will cater to most of your parsing needs, from navigating to advanced searching through the results.\nIn this tutorial, you’ve learned how to scrape data from the Web using Python, requests, and Beautiful Soup. You built a script that fetches job postings from the Internet and went through the full web scraping process from start to finish.\nYou learned how to:\n Inspect the HTML structure of your target site with your browser’s developer tools Gain insight into how to decipher the data encoded in URLs Download the page’s HTML content using Python’s requests library Parse the downloaded HTML with Beautiful Soup to extract relevant information  With this general pipeline in mind and powerful libraries in your toolkit, you can go out and see what other websites you can scrape! Have fun, and remember to always be respectful and use your programming skills responsibly.\nYou can download the source code for the sample script that you built in this tutorial by clicking on the link below:\nGet Sample Code: Click here to get the sample code you\u0026rsquo;ll use for the project and examples in this tutorial.\n Source : .\n "});index.add({'id':144,'href':'/library/tutorials/docs/articles/webapp/falsk/build-web-app-using-flask/','title':"Building a Simple Web APP using Flask and MongoDB",'content':" Building a Simple Python Web APP using Flask framework and MongoDB Introduction We are going to create a simple Python web application using Flask framework and MongoDB. It is very easy to work with Flask as well as MongoDB.\nYou can select the customized installation choice for adding Python environment variables. If you choose default installation, please set these variables manually.\nPlease click Add Python 3.7 to PATH option. It will add one entry in the environment variable.\nIf needed you can modify the installation path. Please check the Python environment variables.\nAfter successful installation, if you check the system environment variable you can see the below two entries are added in the system.\nWe installed the Python 3.7 version, so it added as Python 37-32.\n\\Scripts folder is used for handling additional packages needed for Python.\nNow you can check the Python and PIP version in the command prompt. PIP is the abbreviation for Python package index which is used for installing, upgrading or removing the additional Python libraries from our system.\npython --version and pip -- version  By default, the pip version may not be 18. This is the latest version as of today. If your pip version is older than that, please upgrade it.\npython -m pip install -__U pip_Now  we are going to install Flask. Flask is a web framework for Python. Flask provides you with tools, libraries and technologies that allow you to build a web application in Python.\nIts dependencies are,\n Werkzeug a WSGI utility library jinja2 which is its template engine  WSGI is basically a protocol defined so that the Python application can communicate with a web-server and thus be used as web-application outside of CGI.\nJinja2 is used for creating views in flask application. It holds all the static files like html, CSS and JavaScript files.\nFirst install Flask using pip command in command prompt.\npip install Flask_It will install the latest version of flask library from its global repository and in Windows machines it saves the below file location\nC:\\Program Files (x86)\\Python\\Python37-32\\Lib\\site-packages\nOur sample application uses MongoDB as database. So, we are going to install Mongo DB from below URL.\nhttps://www.mongodb.com/download-center#community\nIt is a free community version. After successful installation it is all set to run MongoDB instance.\nBefore running the MongoDB instance, we must create a data folder and run below command in command prompt.\n\u0026quot;C:\\Program Files\\MongoDB\\Server\\4.0\\bin\\mongod.exe\u0026quot; --dbpath=\u0026quot;C:\\mongo-data\u0026quot;\nHere C:\\mongo-data folder is used for saving mongodb files.\nWhile installing the MongoDB in windows system, you can choose the compass community edition also.\nThis is a free edition and will help to handle our MongoDB databases, collections (tables in MongoDB) and documents (records) graphically\nBy default, MongoDB is running in localhost 27017 port.\nWe can see there are 3 databases, (admin, config and local) created automatically in the installation time.\nNow we are going to install PyMongolibrary in python. PyMongo is a simple but powerful Python distribution containing tools for working with MongoDB and is the recommended way to work with MongoDB from Python. It\u0026rsquo;s a kind of ODM (object document mapper). There is mongoengine and so many libraries also available as ODM for Python.\npip install pymongo  We need to install another Python library, bson, too. It is used for getting objectId property of mongodb document.\npip install bson  Now we are all set and ready to start our python program.Create a folder named FlaskwithMongo and add two sub folders, static and templates, inside it. There is a convention to name static and templates used in jinja2 framework. Please open the folder in any of the code editors. I am using Visual Studio code as an IDE. Create a new file named app.py. This is the only Python file we are using in this application. First, we are going to import the required libraries into our application.\nfrom flask import Flask, render_template,request,redirect,url_for from bson import ObjectId from pymongo import MongoClient import os  Now we are going to declare the app variable in our program.\napp = Flask(**name**)_  This app variable is used in the entire application.\nNow we are going to declare twovariable titles and headings which are later used in jinja2 template.\ntitle = \u0026quot;TODO sample application with Flask and MongoDB\u0026quot; heading = \u0026quot;TODO Reminder with Flask and MongoDB\u0026quot;  We must declare the connection string for MongoDB and select a database. Also, we are going to select our collection name to a variable.\nclient = MongoClient(\u0026quot;mongodb://127.0.0.1:27017\u0026quot;) #host uri db = client.mymongodb #Select the database todos = db.todo #Select the collection name  As I mentioned earlier mongodb is running in the port 27017 by default. Please note that we have selected mymongodb as database and todo as collection name. When we create our first transaction, pymongo will generate the database and collection automatically. Unlike SQL server or any other RDBMS mongodb doesn’t require predefined schemas.\nIn flask, it is easy to implement routing unlike any other programming language.\nFor that, we are using _rendertemplate, request, redirect and url_for. All these methods help us to establish redirection and show html templates in the browser\ndef redirect_url(): return request.args.get('next') or \\ request.referrer or \\ url_for('index')  In the above code we defined a method named _redirect_url _and it is used to redirect page to index page.\n@app.route(\u0026quot;/\u0026quot;) @app.route(\u0026quot;/uncompleted\u0026quot;) def tasks (): #Display the Uncompleted Tasks todos_l = todos.find({\u0026quot;done\u0026quot;:\u0026quot;no\u0026quot;}) a2=\u0026quot;active\u0026quot; return render_template('index.html',a2=a2,todos=todos_l,t=title,h=heading)  In the above code, we defined a method named tasks and it is used for two routes. One for default “/” route and another for “/uncompleted” route. In this code we defined a variable todos_l and it gets the documents from mongodb filter by condition done equal to no. We defined one more variable named a2 and it is used for controlling active records. Both todos_land a2 variables passed with the other two variables, title, and heading, and passed to the jinja2 template index.html which we must create in the template folder.\nNow we are going to finish all the remaining route definitions for adding and deleting the documents to mongodb\napp.py\nfrom flask import Flask, render_template,request,redirect,url_for # For flask implementation from bson import ObjectId # For ObjectId to work from pymongo import MongoClient import os app = Flask(__name__) title = \u0026quot;TODO sample application with Flask and MongoDB\u0026quot; heading = \u0026quot;TODO Reminder with Flask and MongoDB\u0026quot; client = MongoClient(\u0026quot;mongodb://127.0.0.1:27017\u0026quot;) #host uri db = client.mymongodb #Select the database todos = db.todo #Select the collection name def redirect_url(): return request.args.get('next') or \\ request.referrer or \\ url_for('index') @app.route(\u0026quot;/list\u0026quot;) def lists (): #Display the all Tasks todos_l = todos.find() a1=\u0026quot;active\u0026quot; return render_template('index.html',a1=a1,todos=todos_l,t=title,h=heading) @app.route(\u0026quot;/\u0026quot;) @app.route(\u0026quot;/uncompleted\u0026quot;) def tasks (): #Display the Uncompleted Tasks todos_l = todos.find({\u0026quot;done\u0026quot;:\u0026quot;no\u0026quot;}) a2=\u0026quot;active\u0026quot; return render_template('index.html',a2=a2,todos=todos_l,t=title,h=heading) @app.route(\u0026quot;/completed\u0026quot;) def completed (): #Display the Completed Tasks todos_l = todos.find({\u0026quot;done\u0026quot;:\u0026quot;yes\u0026quot;}) a3=\u0026quot;active\u0026quot; return render_template('index.html',a3=a3,todos=todos_l,t=title,h=heading) @app.route(\u0026quot;/done\u0026quot;) def done (): #Done-or-not ICON id=request.values.get(\u0026quot;_id\u0026quot;) task=todos.find({\u0026quot;_id\u0026quot;:ObjectId(id)}) if(task[0][\u0026quot;done\u0026quot;]==\u0026quot;yes\u0026quot;): todos.update({\u0026quot;_id\u0026quot;:ObjectId(id)}, {\u0026quot;$set\u0026quot;: {\u0026quot;done\u0026quot;:\u0026quot;no\u0026quot;}}) else: todos.update({\u0026quot;_id\u0026quot;:ObjectId(id)}, {\u0026quot;$set\u0026quot;: {\u0026quot;done\u0026quot;:\u0026quot;yes\u0026quot;}}) redir=redirect_url() return redirect(redir) @app.route(\u0026quot;/action\u0026quot;, methods=['POST']) def action (): #Adding a Task name=request.values.get(\u0026quot;name\u0026quot;) desc=request.values.get(\u0026quot;desc\u0026quot;) date=request.values.get(\u0026quot;date\u0026quot;) pr=request.values.get(\u0026quot;pr\u0026quot;) todos.insert({ \u0026quot;name\u0026quot;:name, \u0026quot;desc\u0026quot;:desc, \u0026quot;date\u0026quot;:date, \u0026quot;pr\u0026quot;:pr, \u0026quot;done\u0026quot;:\u0026quot;no\u0026quot;}) return redirect(\u0026quot;/list\u0026quot;) @app.route(\u0026quot;/remove\u0026quot;) def remove (): #Deleting a Task with various references key=request.values.get(\u0026quot;_id\u0026quot;) todos.remove({\u0026quot;_id\u0026quot;:ObjectId(key)}) return redirect(\u0026quot;/\u0026quot;) @app.route(\u0026quot;/update\u0026quot;) def update (): id=request.values.get(\u0026quot;_id\u0026quot;) task=todos.find({\u0026quot;_id\u0026quot;:ObjectId(id)}) return render_template('update.html',tasks=task,h=heading,t=title) @app.route(\u0026quot;/action3\u0026quot;, methods=['POST']) def action3 (): #Updating a Task with various references name=request.values.get(\u0026quot;name\u0026quot;) desc=request.values.get(\u0026quot;desc\u0026quot;) date=request.values.get(\u0026quot;date\u0026quot;) pr=request.values.get(\u0026quot;pr\u0026quot;) id=request.values.get(\u0026quot;_id\u0026quot;) todos.update({\u0026quot;_id\u0026quot;:ObjectId(id)}, {'$set':{ \u0026quot;name\u0026quot;:name, \u0026quot;desc\u0026quot;:desc, \u0026quot;date\u0026quot;:date, \u0026quot;pr\u0026quot;:pr }}) return redirect(\u0026quot;/\u0026quot;) @app.route(\u0026quot;/search\u0026quot;, methods=['GET']) def search(): #Searching a Task with various references key=request.values.get(\u0026quot;key\u0026quot;) refer=request.values.get(\u0026quot;refer\u0026quot;) if(key==\u0026quot;_id\u0026quot;): todos_l = todos.find({refer:ObjectId(key)}) else: todos_l = todos.find({refer:key}) return render_template('searchlist.html',todos=todos_l,t=title,h=heading) if __name__ == \u0026quot;__main__\u0026quot;: app.run()  We must add the below three HTML files in the templates folder. (index.html, searchlist.html and update.html)\nindex.html\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;{{t}}\u0026lt;/title\u0026gt; \u0026lt;!-- href=\u0026quot;/static/assets/style.css\u0026quot;--\u0026gt; \u0026lt;link rel=\u0026quot;stylesheet\u0026quot; type=\u0026quot;text/css\u0026quot; href=\u0026quot;{{ url_for('static',filename='assets/style.css')}}\u0026quot; \u0026gt; \u0026lt;link rel=\u0026quot;stylesheet\u0026quot; type=\u0026quot;text/css\u0026quot; href=\u0026quot;{{ url_for('static',filename='assets/emoji.css')}}\u0026quot; \u0026gt; \u0026lt;script src=\u0026quot;{{ url_for('static',filename='assets/twemoji.min.js')}}\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026quot;{{ url_for('static',filename='assets/emoji.js')}}\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;{{ h }}\u0026lt;/h1\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;/list\u0026quot; class=\u0026quot;{{ a1 }}\u0026quot;\u0026gt;ALL\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;/\u0026quot; class=\u0026quot;{{ a2 }}\u0026quot;\u0026gt;Uncompleted\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;/completed\u0026quot; class=\u0026quot;{{ a3 }}\u0026quot;\u0026gt;Completed\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;hr\u0026gt; {% if todos[0] %} \u0026lt;div span=\u0026quot;right\u0026quot;\u0026gt; \u0026lt;form action=\u0026quot;/search\u0026quot; method=\u0026quot;GET\u0026quot; \u0026gt; \u0026lt;table class=\u0026quot;none\u0026quot; id=\u0026quot;close\u0026quot;\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;big\u0026gt;\u0026lt;b\u0026gt;Search Reference:\u0026lt;/b\u0026gt;\u0026lt;/big\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;select name=\u0026quot;refer\u0026quot; required\u0026gt; \u0026lt;option value=\u0026quot;name\u0026quot;\u0026gt;Task Name\u0026lt;/option\u0026gt; \u0026lt;option value=\u0026quot;desc\u0026quot;\u0026gt;Description\u0026lt;/option\u0026gt; \u0026lt;option value=\u0026quot;date\u0026quot;\u0026gt;Date\u0026lt;/option\u0026gt; \u0026lt;option value=\u0026quot;pr\u0026quot;\u0026gt;Priority\u0026lt;/option\u0026gt; \u0026lt;/select\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;input type=\u0026quot;text\u0026quot; name=\u0026quot;key\u0026quot; placeholder=\u0026quot;Search Task\u0026quot; size=\u0026quot;15\u0026quot; /\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;button type=\u0026quot;submit\u0026quot;\u0026gt;Search\u0026lt;/button\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;b\u0026gt;\u0026lt;big\u0026gt;To-Do LIST :\u0026lt;/big\u0026gt;\u0026lt;/b\u0026gt; \u0026lt;table\u0026gt; \u0026lt;tr id=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;th class=\u0026quot;status\u0026quot;\u0026gt;Status\u0026lt;/th\u0026gt; \u0026lt;th class=\u0026quot;name\u0026quot;\u0026gt;Task Name\u0026lt;/th\u0026gt; \u0026lt;th class=\u0026quot;desc\u0026quot;\u0026gt;Description Name\u0026lt;/th\u0026gt; \u0026lt;th class=\u0026quot;date\u0026quot;\u0026gt;Date\u0026lt;/th\u0026gt; \u0026lt;th class=\u0026quot;pr\u0026quot;\u0026gt;Priority\u0026lt;/th\u0026gt; \u0026lt;th class=\u0026quot;func1\u0026quot;\u0026gt;Remove\u0026lt;/th\u0026gt; \u0026lt;th class=\u0026quot;func2\u0026quot;\u0026gt;Modify\u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; {% for todo in todos %} \u0026lt;tr class=\u0026quot;datas\u0026quot;\u0026gt; \u0026lt;td\u0026gt;\u0026lt;a href=\u0026quot;./done?_id={{ todo['_id'] }}\u0026quot;\u0026gt;\u0026lt;input type=\u0026quot;image\u0026quot; src=\u0026quot;static/images/{{todo['done']}}.png\u0026quot; alt=\u0026quot;Submit ME\u0026quot;\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;td class=\u0026quot;name\u0026quot;\u0026gt;{{ todo[\u0026quot;name\u0026quot;] }}\u0026lt;/td\u0026gt; \u0026lt;td class=\u0026quot;desc\u0026quot;\u0026gt;{{ todo[\u0026quot;desc\u0026quot;] }}\u0026lt;/td\u0026gt; \u0026lt;td class=\u0026quot;date\u0026quot;\u0026gt;{{ todo[\u0026quot;date\u0026quot;] }}\u0026lt;/td\u0026gt; \u0026lt;td class=\u0026quot;pr\u0026quot;\u0026gt;{{ todo[\u0026quot;pr\u0026quot;] }}\u0026lt;/td\u0026gt; \u0026lt;td class=\u0026quot;func1\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;./remove?_id={{ todo['_id'] }}\u0026quot;\u0026gt;\u0026lt;button type=\u0026quot;submit\u0026quot;\u0026gt;DELETE\u0026lt;/button\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;td class=\u0026quot;func1\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;./update?_id={{ todo['_id'] }}\u0026quot;\u0026gt;\u0026lt;button type=\u0026quot;submit\u0026quot;\u0026gt;EDIT\u0026lt;/button\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; {% endfor %} \u0026lt;/table\u0026gt; {% else %} \u0026lt;h4\u0026gt;No Tasks in the List !!\u0026lt;/h4\u0026gt; {% endif %} \u0026lt;hr/\u0026gt; \u0026lt;form action=\u0026quot;/action\u0026quot; method=\u0026quot;POST\u0026quot;\u0026gt; \u0026lt;table class=\u0026quot;none\u0026quot;\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;\u0026lt;b\u0026gt;\u0026lt;big\u0026gt;\u0026lt;label\u0026gt;Add a Task : \u0026lt;/label\u0026gt;\u0026lt;/big\u0026gt;\u0026lt;/b\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;\u0026lt;input type=\u0026quot;text\u0026quot; name=\u0026quot;name\u0026quot; placeholder=\u0026quot;Taskname\u0026quot; \u0026gt;\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;textarea name=\u0026quot;desc\u0026quot; rows=\u0026quot;1\u0026quot; cols=\u0026quot;30\u0026quot; placeholder=\u0026quot;Enter Description here...\u0026quot; required\u0026gt;\u0026lt;/textarea\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;input type=\u0026quot;text\u0026quot; name=\u0026quot;date\u0026quot; placeholder=\u0026quot;Date\u0026quot; /\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;input type=\u0026quot;text\u0026quot; name=\u0026quot;pr\u0026quot; placeholder=\u0026quot;Priority\u0026quot; /\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;button type=\u0026quot;submit\u0026quot;\u0026gt; Create \u0026lt;/button\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;script\u0026gt; \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  searchlist.html\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;{{t}}\u0026lt;/title\u0026gt; \u0026lt;link rel=\u0026quot;stylesheet\u0026quot; type=\u0026quot;text/css\u0026quot; href=\u0026quot;{{ url_for('static',filename='assets/style.css')}}\u0026quot; \u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;{{h}}\u0026lt;/h1\u0026gt; \u0026lt;hr\u0026gt; {% if todos[0] %} \u0026lt;h3\u0026gt;Result of the Search : ToDO List\u0026lt;/h3\u0026gt; \u0026lt;table\u0026gt; \u0026lt;tr id=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;td class=\u0026quot;status\u0026quot;\u0026gt;Status\u0026lt;/td\u0026gt; \u0026lt;td class=\u0026quot;name\u0026quot;\u0026gt;Task Name\u0026lt;/td\u0026gt; \u0026lt;td class=\u0026quot;desc\u0026quot;\u0026gt;Task Description\u0026lt;/td\u0026gt; \u0026lt;td class=\u0026quot;date\u0026quot;\u0026gt;Date\u0026lt;/td\u0026gt; \u0026lt;td class=\u0026quot;pr\u0026quot;\u0026gt;Project\u0026lt;/td\u0026gt; \u0026lt;td class=\u0026quot;func\u0026quot;\u0026gt;Delete\u0026lt;/td\u0026gt; \u0026lt;td class=\u0026quot;func\u0026quot;\u0026gt;Modify\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; {% for todo in todos %} \u0026lt;tr class=\u0026quot;datas\u0026quot;\u0026gt; \u0026lt;td\u0026gt;\u0026lt;a href=\u0026quot;./done?_id={{ todo['_id'] }}\u0026quot;\u0026gt;\u0026lt;input type=\u0026quot;image\u0026quot; src=\u0026quot;static/images/{{todo['done']}}.png\u0026quot; alt=\u0026quot;Submit ME\u0026quot;\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;td class=\u0026quot;name\u0026quot;\u0026gt;{{ todo[\u0026quot;name\u0026quot;] }}\u0026lt;/td\u0026gt; \u0026lt;td class=\u0026quot;desc\u0026quot;\u0026gt;{{ todo[\u0026quot;desc\u0026quot;] }}\u0026lt;/td\u0026gt; \u0026lt;td class=\u0026quot;date\u0026quot;\u0026gt;{{ todo[\u0026quot;date\u0026quot;] }}\u0026lt;/td\u0026gt; \u0026lt;td class=\u0026quot;pr\u0026quot;\u0026gt;{{ todo[\u0026quot;pr\u0026quot;] }}\u0026lt;/td\u0026gt; \u0026lt;td class=\u0026quot;func1\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;./remove?_id={{ todo['_id'] }}\u0026quot;\u0026gt;\u0026lt;button type=\u0026quot;submit\u0026quot;\u0026gt;DELETE\u0026lt;/button\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;td class=\u0026quot;func1\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;./update?_id={{ todo['_id'] }}\u0026quot;\u0026gt;\u0026lt;button type=\u0026quot;submit\u0026quot;\u0026gt;EDIT\u0026lt;/button\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; {% endfor %} {% else %} \u0026lt;h4\u0026gt;No Result Found !!\u0026lt;/h4\u0026gt; {% endif %} \u0026lt;/table\u0026gt; \u0026lt;a href=\u0026quot;/\u0026quot;\u0026gt;Return to TaskList\u0026lt;/a\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  update.html\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;{{t}}\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;style\u0026gt; h1{ font-family:\u0026quot;Arial Black\u0026quot;, Gadget, sans-serif; } body{ background-color:white; } \u0026lt;/style\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;{{h}}\u0026lt;/h1\u0026gt; \u0026lt;hr\u0026gt; \u0026lt;h3\u0026gt;Update tasks with a reference\u0026lt;/h3\u0026gt; \u0026lt;form action=\u0026quot;/action3\u0026quot; method=\u0026quot;POST\u0026quot;\u0026gt; {% for task in tasks %} Unique Object ID : {{ task['_id'] }}\u0026lt;br/\u0026gt; \u0026lt;input type=\u0026quot;text\u0026quot; name=\u0026quot;_id\u0026quot; value=\u0026quot;{{ task['_id'] }}\u0026quot; hidden\u0026gt; \u0026lt;table\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;Task Name\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt; : \u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;\u0026lt;input type=\u0026quot;text\u0026quot; name=\u0026quot;name\u0026quot; value=\u0026quot;{{ task['name'] }}\u0026quot; placeholder=\u0026quot;{{ task['name'] }}\u0026quot;\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;Description\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt; : \u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;\u0026lt;textarea type=\u0026quot;text\u0026quot; name=\u0026quot;desc\u0026quot; rows=3 cols=30 placeholder=\u0026quot;{{ task['desc'] }}\u0026quot;\u0026gt; {{ task['desc'] }} \u0026lt;/textarea\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;Date\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt; : \u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;\u0026lt;input type=\u0026quot;text\u0026quot; name=\u0026quot;date\u0026quot; value=\u0026quot;{{ task['date'] }}\u0026quot; placeholder=\u0026quot;{{ task['date'] }}\u0026quot;\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;Priority\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt; : \u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;\u0026lt;input type=\u0026quot;text\u0026quot; name=\u0026quot;pr\u0026quot; value=\u0026quot;{{ task['pr'] }}\u0026quot; placeholder=\u0026quot;{{ task['pr'] }}\u0026quot;\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/table\u0026gt; {% endfor %} \u0026lt;button type=\u0026quot;submit\u0026quot;\u0026gt; Update Task \u0026lt;/button\u0026gt; \u0026lt;br/\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;a href=\u0026quot;/\u0026quot;\u0026gt;Return to TaskList\u0026lt;/a\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  All three of these files used the features of jinja2 framework to render the model values from app.py.\nIn addition, we must add emoji.css, emoji.js, style.css and twemoji.min.js files in the static\\assets folder\nemoji.css\nimg.emoji { // Override any img styles to ensure Emojis are displayed inline margin: 0px !important; display: inline !important; }  emoji.js\nwindow.onload = function() { // Set the size of the rendered Emojis // This can be set to 16x16, 36x36, or 72x72 twemoji.size = '16x16'; // Parse the document body and // insert \u0026lt;img\u0026gt; tags in place of Unicode Emojis twemoji.parse(document.body); }  style.css\nh1{ /* font-family:\u0026quot;Arial Black\u0026quot;, Gadget, sans-serif;*/ font-family:\u0026quot;Times New Romans\u0026quot;, Gadget, sans-serif; } body{ color:black; background-color:white; left-margin:10px; right-margin:10px; } table{ width:95%; border-collapse:collapse; table-layout:fixed; } td { border: rgba(224, 119, 70, 1) 2px solid; word-wrap:break-word; } table#close{ table-layout:default; border-collapse:seperate; border-spacing: 5px 5px; border:none; vertical-align:top; } table.none { border:none; vertical-align:top; } table.none td { border: none; } tr.row td{ text-decoration:italic; } th.status{ width:5%; } th.name{ width:20%; } th.des{ width:40%; padding:5px 5px 5px 5px; } th.date{ width:8%; } th.pr{ width:7%; } th.func1{ width:6%; } th.func2{ width:5%; } input[type=submit] { width: 20em; height: 2em; } ul { list-style-type: none; margin: 0; padding: 0; overflow: hidden; background-color: #333; } li { float: left; } li a { display: block; color: white; text-align: center; padding: 14px 16px; text-decoration: none; } a.active { background-color: #4CAF50; } /* Change the link color to #111 (black) on hover */ li a:hover { background-color: #111; }  There are two images, _no.png_, and _yes.png,_ in static\\images folder.\nWe are ready to run our sample application.\nPlease start our mongodb instance with the below command\n\u0026ldquo;C:\\Program Files\\MongoDB\\Server\\4.0\\bin\\mongod.exe\u0026rdquo; \u0026ndash;dbpath=\u0026ldquo;C:\\mongo-data\u0026rdquo;\nPlease note that mongodb now runs with data folder C:\\mongo-data\nBy default, it is listening the port 27017.\nPlease open another command prompt window in the same Python application folder and run Python with the below command.\nFor example:\nD:\\Python\\FlaskWithMongo\u0026gt;python app.py\nOur local server is running in the port 5000 by default.\nThe application is now running successfully.\nYou can now add a sample task as task name “Test task for mongo with flask application”, description “Sample description”, date “05-08-2018\u0026rdquo; and priority “High”\nAfter clicking the Create button we can immediately view the task details in the grid.\nPlease note that there is a new database named mymongodb and collection todo is created now. Using this application, you can edit and remove the existing documents easily.\nYou can check the document details in the mongodb compass community too.\nHappy coding with Flask and MongoDB!!!\nYou can download the source code from Github.\nThank you!\n Source : .\n "});index.add({'id':145,'href':'/library/tutorials/docs/articles/data-science/web-scraping/building-stock-screener-1/','title':"Building a Stock Screener - Part 1",'content':" Building a Stock Screener in Python- Part 1  ที่มาบทความ .\n In this post, I’ll share how to create a stock screener — a program which can filter stocks based on user preferences — from scratch (and for free) using python. This project will be broken into 3 parts-\n Scraping data Storing data Screening data  Before we dive into programming, let’s start by asking why anyone would want to build a stock screener.\nWhy Let’s think about personal finance and investments for a second: why would someone strategically pick healthy stocks which provide a high return-on-investment while maintaining relatively low levels of risk?\nDifference between growing your money at 6%, 8% and 10%\nBecause your choice of stocks directly impacts your portfolio’s returns and can be the difference between becoming a Millionaire at age 35 vs 55. Even a few bad stocks in your portfolio can greatly decrease performance, so it’s important to carefully analyze and filter companies.\nHow So now that you know why, let’s talk about how someone could strategically pick healthy stocks which provide a high return-on-investment while maintaining relatively low levels of risk? There’s a few methods out there for people wondering, but one of the most common analysis strategies for picking companies is Technical Analysis.\nTechnical Analysis is a method by which analysts use data to find patterns and trends to generate predictions about company performance. The key word in the previous statement is data. Sources like Yahoo Finance, Bloomberg, Market Watch etc. act like central hubs for stock data. They collect, visualize and share this information with the rest of the world. Investors use these websites to analyse companies and pick the ones they see fit; thus the terminology, filtering. While individually looking through hundreds of web-pages and picking companies is a perfectly acceptable method of building a portfolio, computer scientists know better. This is a where a stock screener comes into play.\nStock Screeners A stock screener is a program which can filter stocks based on certain criteria. It can be used to analyze a large volume of companies in a relatively short period of time. Keep in mind that a stock screener is not a program that can (or should) replace religious analysis of a company’s performance before any personal investment decision is made, but rather is a way to effectively decrease the number of companies which need to be analyzed. A trivial, but important example is shown below-\nWithout any filter\nApproximately 13,547 companies are listed on Yahoo Finance. This is a huge number of companies to filter through for individual examination\nScreen without any filters\nWith a basic filter\nEven a basic screen (companies which have seen a percent change in price greater than 10%, thus have a highly positive price change) decreases the number of companies by over 90%, making individual examination a possibility.\nScreen with a basic filter\nWith a selective filter\nThe following filter is fairly selective: it is only looking at Mega Cap companies (Market Cap over $100B), with a current ratio greater than 1 (indicating good liquidity health), and an expected PEG ratio greater than 2 (indicating very good expected growth over 5 years). The list of companies is down to 9, which is a very manageable number to individually inspect.\nScreen with a fairly selective filter\nBy now I’m sure you understand the importance of having a stock screener and hope you’re excited to build one from scratch! While there are a few paid and free stock screeners available online, building one from scratch enables you to really customize your screens, implement more complicated/personalized methods and take your filtering abilities to the next level. Now let’s get down to business.\nPart 1: Scraping Data Part 1, and arguably the most important part of building a stock screener, is the ability to get your hands on the data. There are many stock data API’s available out there, but do not be fooled, most of them are fairly expensive or limit the number of requests, making them severely infeasible for a stock screener. That is why I will show you how to scrape stock information in this part. You can use the framework discussed below on different websites/data based on your needs.\nThe following are the main steps taken to scrape the data.\n Find a reliable source Determine data to be scraped Create scraping methodology Build algorithm  Find a reliable source\nThis is a website that publishes the stock information that you’re trying to scrape. Be sure to check the website’s terms and conditions regarding data scraping to avoid unnecessary problems. In this case, I’m collecting the data for educational and research purposes only, and do not wish to sell this information elsewhere. I decided to use Yahoo Finance, as it is a very reliable source of data. Additionally, they also keep their information well organized as we’ll discuss below.\nDetermine Data to be scraped\nThis step is very important, as it constraints the data that the scraper will be collecting. In order to do this, we’ll be taking a look at the typical Yahoo Finance page of a company and decide what data is relevant to us. Here’s what the main Yahoo page of Apple Inc. looks like (as of December 30, 2018):\nYahoo Finance page for Apple Inc. (AAPL)\nWhile the summary tab contains some very useful information about this stock, we’re interested in indicators which tell us more about the health of this company. For this, we’ll turn to the statistics tab, which looks like so-\nStatistics page of Yahoo Finance for Apple Inc. (AAPL)\nAs you can see, this page contains a myriad of data and is neatly arranged into tables, making it perfect for our program. We note the URL (which is shown below) and move on to the scraping methodology. You can check out the web page for Apple yourself using the link too.\nhttp://finance.yahoo.com/q/ks?s=aapl\nCreate Scraping Methodology\nBefore we can talk about the scraping methodology, you need to understand Beautiful Soup. If you already know the basics feel free to move on, but if you need a refresher, check out this article.\nThe scraping methodology refers to the method by which beautiful soup finds the relevant \u0026lt;div\u0026gt;'s \u0026lt;table\u0026gt;'s etc. inside the web page’s HTML source code. This is usually achieved by inspecting the different elements (right click -\u0026gt; inspect element) inside a web page, till you can find a consistent class, attribute etc. which captures all the data you want. Here’s some photos of me inspecting elements in the Yahoo Finance pages to further show this point.\nInspecting elements on the Yahoo Finance web page for Apple Inc. (AAPL)\nAs you can (barely) tell from the above photo, each of the name-value pairs, like Market Cap (intraday), 741.37B are displayed using \u0026lt;span\u0026gt; and \u0026lt;td\u0026gt; tags inside the same \u0026lt;tr\u0026gt; tag. Further, all of these \u0026lt;tr\u0026gt; are within the same \u0026lt;table\u0026gt; tag with a special class: table-qsp-stats. This class gives us a way to distinguish the data-tables from all other elements on the web page. On further inspection, you can also see that the class is attached to every table tag that contains relevant data.\nThis is perfect for us, as we can easily use Beautiful Soup to navigate to the table (which contains our special class name), iterate through the rows and capture relevant information. Now, we can start coding this algorithm.\nBuild Algorithm\nNow we start with our actual python program. Here’s our algorithm, laid out step-by-step-\n Create URL for given stock Extract HTML from web page Find all tables that contain class table-qsp-stats For each table, iterate through rows For each row store \u0026lt;span\u0026gt;text as key and \u0026lt;td\u0026gt; text as corresponding value in dictionary  Here’s the syntax of the function, which accepts a stock symbol (for reference):\ndef scrape_yahoo(stock):  Now building on this, we need to create the URL (using the stock symbol) and extract the HTML from the web page using urllib2 and Beautiful Soup-\nurl = ('http://finance.yahoo.com/q/ks?s=' + stock) page = urllib2.urlopen(url) soup = BeautifulSoup(page, 'html.parser')  Now we move on to finding the relevant tables and processing each of the rows.\nNote: technicals is an empty dictionary initialized earlier.\ntables = soup.findAll('table', {\u0026quot;class\u0026quot; : 'table-qsp-stats'}) for table in tables: table_body = table.find('tbody') rows = table_body.find_all('tr') for row in rows: # span tags contain the indicator name col_name = row.find_all('span') col_name = [cell.text.strip() for cell in col_name] # td tags contain the indicator values col_val = row.find_all('td') col_val = [cell.text.strip() for cell in col_val] technicals[col_name[0]] = col_val[1]  The full code for this data scraper can be found on this github repository.\nWrap up and what next? So now you have it! A way to scrape stock data off of Yahoo Finance for use in your very own stock screener. If you want to continue on in this series, feel free to check out Part 2. In part 2 we build upon this algorithm to store the data collected and then we’ll be ready to create filtering queries to wrap up the stock screener.\nIf you have any questions, feedback or comments, feel free to get in touch with me through LinkedIn, or my website.\n"});index.add({'id':146,'href':'/library/tutorials/docs/articles/data-science/web-scraping/building-stock-screener-2/','title':"Building a Stock Screener - Part 2",'content':" Building a Stock Screener in Python- Part 2 In this series, I’ll share how to create a stock screener — a program which can filter stocks based on user preferences — from scratch (and for free) using python. This project will be broken into 3 parts-\n Scraping data Storing data Screening data  If you haven’t already, check out Part 1 where I talk about scraping stock information from Yahoo Finance in under 10 minutes! In this part, we’ll focus on storing the data we’ve collected and preparing it for screening.\nRecap- Scraping In the last part, we built a web scraper to crawl through yahoo finance and collect information about companies we’re interested in. We utilized BeautifulSoup library to create the scraper and were successfully able to scrape data.\nExample from the first part scraping information about Apple, Tesla and GE\nPieces We’ll be storing the information from the stock scraper in a format which is user-friendly and ready for screening. To do this, we’ll need two things-\n List of companies to get data for List of indicators to collect data for  We eventually want to use this stored data to screen companies to invest in, so we first want a list of companies that we’re interested in. For me, I found the constituents of the S\u0026amp;P 500, which consists of 500 of the largest U.S. publicly traded companies. You can chose to use your own list, but if you want to use the S\u0026amp;P 500 as well, here’s a link.\nWe also need a list of indicators to collect data. Indicators are metrics used to predict the direction of major financial indexes or groups of securities. In my case, here’s the list of indicators which I chose-\n ‘Market Cap (intraday)’, ‘Return on Equity’, ‘Revenue’, ‘Quarterly Revenue Growth’, ‘Operating Cash Flow’, ‘Total Cash’, ‘Total Debt’, ‘Current Ratio’, ‘52-Week Change’, ‘Avg Vol (3 month)’, ‘Avg Vol (10 day)’, ‘% Held by Insiders’\n You can find the full list of indicators on the Yahoo Finance page for a security.\nCode We’re going to utilize the scraper we built in the last part, along with the list of companies and indicators as discussed above. The code for storing this data is fairly straightforward and I explain it thoroughly below.\nThe first part of the code create a list of companies to look at from a .csv file in the folder, which contains symbols, names and industries of companies we’re interested in. We then create an array of strings with the names of all the indicators we’re interested in.\nAfter this, we’ll be creating an empty pandas data frame with the columns set to the indicators to store the information about the companies. Now, similar to the previous part, we’ll iterate through the list of companies, and each indicator. For each company we’ll scrape data using our scrape_yahoo method. We’ll store the data collected in our data frame and at the end print out a message when the data is stored to keep track of our progress. Our job is not done yet though, we still need to clean the data!\nWe’ll clean the data in 3 steps. We’ll rename the first column in the data frame to “Symbol” as it contains the ticker symbol for each of our companies. Then, we’ll join our new data frame with the old symbols data frame to ensure we keep the full name and industry of the company as well. Last, we’ll drop rows with excessive NaN values. When web scraping, there’s a fair possibility to have some missing data and dropping rows with excessive missing values(\u0026lt;10 non-NaN values) will be helpful later. After this, we can save our pandas data frame to a .csv file.\nThe full code for this data storage program can be found on this github repository.\nWrap up and what next? So now you have it! A way to store scraped stock data off of Yahoo Finance for use in your very own stock screener. If you want to continue on in this series, feel free to check out Part 3 (coming in Mar. 2019). In part 3 we’ll build upon this algorithm and create a screening pipeline to select companies which match our criteria.\n ที่มาบทความ : Medium.com.\n "});index.add({'id':147,'href':'/library/tutorials/docs/python/snippets/byte_size/','title':"byte_size()",'content':" byte_size() Returns the length of a string in bytes.\nUse s.encode('utf-8') to encode the given string and return its length.\ndef byte_size(s): return len(s.encode('utf-8'))  byte_size('😀') # 4 byte_size('Hello World') # 11  "});index.add({'id':148,'href':'/library/tutorials/docs/articles/data-science/finance/cal-stock-return/','title':"Calculate Stock Returns",'content':" How to calculate stock returns in Python  4/3/2018 Written by DD\nSource.\n Calculating financial returns in Python One of the most important tasks in financial markets is to analyze historical returns on various investments. To perform this analysis we need historical data for the assets. There are many data providers, some are free most are paid. In this chapter we will use the data from Yahoo’s finance website. In python we can do this using the pandas-datareader module.\nIn this post we will:\n Download prices Calculate Returns Calculate mean and standard deviation of returns  Lets load the modules first.\nimport pandas as pd import numpy as np import matplotlib.pyplot as plt import pandas_datareader as web  Individual Stock Downloading the stock price for Netflix Netflix has seen phenomenal growth since 2009. It was responsible for producing a new category of business - subscription based online streaming. It has changed the industry landscape and pushed Blockbuster our of business. Old media companies like CBS, Fox, Viacom, Disney etc are under threat from the new way of consuming media. Netflix started as a content delivery platform, but today its responsible for content creation as well. Its original programs have won several Emmy awards. Today Netflix seems like an unstoppable force in the media landscape.\nTo see just how well Netflix’s stock has performed, we will start by downloading the historical price for Netflix and then perform the return calculations.\nnetflix = web.get_data_yahoo(\u0026quot;NFLX\u0026quot;, start = \u0026quot;2009-01-01\u0026quot;, end = \u0026quot;2018-03-01\u0026quot;)  print(netflix.head())  ## High Low ... Volume Adj Close ## Date ... ## 2009-01-02 4.357143 4.200000 ... 6605200.0 4.267143 ## 2009-01-05 4.562857 4.302857 ... 13044500.0 4.562857 ## 2009-01-06 4.750000 4.590000 ... 12065900.0 4.705714 ## 2009-01-07 4.734286 4.571429 ... 10133900.0 4.672857 ## 2009-01-08 4.797143 4.485714 ... 8175300.0 4.735714 ## ## [5 rows x 6 columns]  Next we will chart the Netflix’s adjusted closing price.\nnetflix['Adj Close'].plot() plt.xlabel(\u0026quot;Date\u0026quot;) plt.ylabel(\u0026quot;Adjusted\u0026quot;) plt.title(\u0026quot;Netflix Price data\u0026quot;) plt.show()  Calculating the daily and monthly returns for individual stock Once we downloaded the stock prices from yahoo finance, the next thing to do is to calculate the returns. We will again use pandas package to do the calculations. We have already downloaded the price data for Netflix above, if you haven’t done that then see the above section. We will calculate the monthly and daily price returns.\nnetflix_daily_returns = netflix['Adj Close'].pct_change() netflix_monthly_returns = netflix['Adj Close'].resample('M').ffill().pct_change()  Looking at the head of the daily returns.\nprint(netflix_daily_returns.head())  ## Date ## 2009-01-02 NaN ## 2009-01-05 0.069300 ## 2009-01-06 0.031309 ## 2009-01-07 -0.006982 ## 2009-01-08 0.013452 ## Name: Adj Close, dtype: float64  Looking at the head of the monthly returns.\nprint(netflix_monthly_returns.head())  ## Date ## 2009-01-31 NaN ## 2009-02-28 0.002767 ## 2009-03-31 0.184327 ## 2009-04-30 0.055685 ## 2009-05-31 -0.129993 ## Freq: M, Name: Adj Close, dtype: float64  Charting the daily and monthly for Netflix fig = plt.figure() ax1 = fig.add_axes([0.1,0.1,0.8,0.8]) ax1.plot(netflix_daily_returns) ax1.set_xlabel(\u0026quot;Date\u0026quot;) ax1.set_ylabel(\u0026quot;Percent\u0026quot;) ax1.set_title(\u0026quot;Netflix daily returns data\u0026quot;) plt.show()  fig = plt.figure() ax1 = fig.add_axes([0.1,0.1,0.8,0.8]) ax1.plot(netflix_monthly_returns) ax1.set_xlabel(\u0026quot;Date\u0026quot;) ax1.set_ylabel(\u0026quot;Percent\u0026quot;) ax1.set_title(\u0026quot;Netflix monthly returns data\u0026quot;) plt.show()  After looking at the daily returns chart for Netflix we can conclude that the returns are quite volatile and the stock can move +/- 5% on any given day. To get a sense of how extreme the returns can be we can plot a histogram.\nfig = plt.figure() ax1 = fig.add_axes([0.1,0.1,0.8,0.8]) netflix_daily_returns.plot.hist(bins = 60) ax1.set_xlabel(\u0026quot;Daily returns %\u0026quot;) ax1.set_ylabel(\u0026quot;Percent\u0026quot;) ax1.set_title(\u0026quot;Netflix daily returns data\u0026quot;) ax1.text(-0.35,200,\u0026quot;Extreme Low\\nreturns\u0026quot;) ax1.text(0.25,200,\u0026quot;Extreme High\\nreturns\u0026quot;) plt.show()  Calculating the cumulative returns for the Netflix stock Plotting the daily and monthly returns are useful for understanding the daily and monthly volatility of the investment. To calculate the growth of our investment or in other word, calculating the total returns from our investment, we need to calculate the cumulative returns from that investment. To calculate the cumulative returns we will use the cumprod() function.\nnetflix_cum_returns = (netflix_daily_returns + 1).cumprod()  Next we can chart the cumulative returns of Netflix.\nfig = plt.figure() ax1 = fig.add_axes([0.1,0.1,0.8,0.8]) netflix_cum_returns.plot() ax1.set_xlabel(\u0026quot;Date\u0026quot;) ax1.set_ylabel(\u0026quot;Growth of $1 investment\u0026quot;) ax1.set_title(\u0026quot;Netflix daily cumulative returns data\u0026quot;) plt.show()  This chart shows the cumulative returns since 2009 for Netflix. With the power of hindsight, one could have made $70 on a $1 investment since 2009. That is quite a remarkable performance. But as we know its easier said then done. During the 10 year or so period there were times when the investment lost 50% of its value during the Qwickster fiasco. Very few investors can hold onto investments through such periods.\nfig = plt.figure() ax1 = fig.add_axes([0.1,0.1,0.8,0.8]) netflix_cum_returns = (netflix_monthly_returns + 1).cumprod() ax1.plot(netflix_cum_returns) ax1.set_xlabel(\u0026quot;Date\u0026quot;) ax1.set_ylabel(\u0026quot;Growth of $1 investment\u0026quot;) ax1.set_title(\u0026quot;Netflix Monthly cumulative returns data\u0026quot;) plt.show()  We can visualize that the monthly returns chart is much more smoother than the daily chart.\nMultiple stocks Downloading stock market data for multiple stocks. We can download the financial data for multiple stocks. We first assign the stock symbols to a variable named “tickers”\u0026rdquo;, and use that to download the stock prices.\ntickers = [\u0026quot;FB\u0026quot;, \u0026quot;AMZN\u0026quot;, \u0026quot;AAPL\u0026quot;, \u0026quot;NFLX\u0026quot;, \u0026quot;GOOG\u0026quot;] multpl_stocks = web.get_data_yahoo(tickers, start = \u0026quot;2013-01-01\u0026quot;, end = \u0026quot;2018-03-01\u0026quot;)  Charting the stock prices for multiple stocks Next we will chart the stock prices for multiple stocks\nfig = plt.figure() ax1 = fig.add_subplot(321) ax2 = fig.add_subplot(322) ax3 = fig.add_subplot(323) ax4 = fig.add_subplot(324) ax5 = fig.add_subplot(325) ax1.plot(multpl_stocks['Adj Close']['AMZN']) ax1.set_title(\u0026quot;Amazon\u0026quot;) ax2.plot(multpl_stocks['Adj Close']['AAPL']) ax2.set_title(\u0026quot;Apple\u0026quot;) ax3.plot(multpl_stocks['Adj Close']['FB']) ax3.set_title(\u0026quot;Facebook\u0026quot;) ax4.plot(multpl_stocks['Adj Close']['NFLX']) ax4.set_title(\u0026quot;Netflix\u0026quot;) ax5.plot(multpl_stocks['Adj Close']['GOOG']) ax5.set_title(\u0026quot;Google\u0026quot;) plt.tight_layout() plt.show()  Calculating the returns for multiple stocks Calculating the the returns for multiple stocks is just as easy as the single stock.\nmultpl_stock_daily_returns = multpl_stocks['Adj Close'].pct_change() multpl_stock_monthly_returns = multpl_stocks['Adj Close'].resample('M').ffill().pct_change()  fig = plt.figure() (multpl_stock_monthly_returns + 1).cumprod().plot() plt.show()  Not surprisingly, Netflix had the best returns since 2013. Amazon and Facebook come in distant second and third. The most surprising result is Google. It has severely under performed the other stocks in the FAANG group. Maybe the market participants are worried about its spending on the moon shot projects (Google glass, X Labs, Waymo etc). Whether these projects can produce results is yet to be seen.\nA contrarian could argue that given the investments in the future projects, Google is currently undervalued an could be the better investment among the FAANG stocks.\nStatistical Data Calculating the Mean, standard deviation and other stats We already have the daily and monthly returns data for Netflix. Now we we will calculate the daily and monthly mean and standard deviations of the returns. We will use mean() and std() functions for our purpose.\nprint(multpl_stock_monthly_returns.mean())  ## Symbols ## AAPL 0.023860 ## AMZN 0.031329 ## FB 0.031989 ## GOOG 0.018693 ## NFLX 0.049129 ## dtype: float64  print(multpl_stock_monthly_returns.std())  ## Symbols ## AAPL 0.068283 ## AMZN 0.080158 ## FB 0.089625 ## GOOG 0.056989 ## NFLX 0.125132 ## dtype: float64  Calculating the correlation and covariance using pandas print(multpl_stock_monthly_returns.corr())  ## Symbols AAPL AMZN FB GOOG NFLX ## Symbols ## AAPL 1.000000 0.276006 0.156129 0.217476 0.273787 ## AMZN 0.276006 1.000000 0.201276 0.630632 0.475268 ## FB 0.156129 0.201276 1.000000 0.265375 0.230154 ## GOOG 0.217476 0.630632 0.265375 1.000000 0.453463 ## NFLX 0.273787 0.475268 0.230154 0.453463 1.000000  print(multpl_stock_monthly_returns.cov())  ## Symbols AAPL AMZN FB GOOG NFLX ## Symbols ## AAPL 0.004663 0.001511 0.000955 0.000846 0.002339 ## AMZN 0.001511 0.006425 0.001446 0.002881 0.004767 ## FB 0.000955 0.001446 0.008033 0.001355 0.002581 ## GOOG 0.000846 0.002881 0.001355 0.003248 0.003234 ## NFLX 0.002339 0.004767 0.002581 0.003234 0.015658  Summary We did a lot in this port.\n Download prices Calculate returns calculate mean and standard deviations calculate the correlation and covariance of stocks.  "});index.add({'id':149,'href':'/library/tutorials/docs/python/snippets/camel/','title':"camel()",'content':" camel() Converts a string to camelcase.\nUse re.sub() to replace any - or _ with a space, using the regexp r\u0026quot;(_|-)+\u0026quot;. Use title() to capitalize the first letter of each word convert the rest to lowercase. Finally, use replace() to remove spaces between words.\nfrom re import sub def camel(s): s = sub(r\u0026quot;(_|-)+\u0026quot;, \u0026quot; \u0026quot;, s).title().replace(\u0026quot; \u0026quot;, \u0026quot;\u0026quot;) return s[0].lower() + s[1:]  camel('some_database_field_name') # 'someDatabaseFieldName' camel('Some label that needs to be camelized') # 'someLabelThatNeedsToBeCamelized' camel('some-javascript-property') # 'someJavascriptProperty' camel('some-mixed_string with spaces_underscores-and-hyphens') # 'someMixedStringWithSpacesUnderscoresAndHyphens'  "});index.add({'id':150,'href':'/library/tutorials/docs/python/snippets/capitalize/','title':"capitalize()",'content':" capitalize() Capitalizes the first letter of a string.\nCapitalize the first letter of the string and then add it with rest of the string. Omit the lower_rest parameter to keep the rest of the string intact, or set it to True to convert to lowercase.\ndef capitalize(s, lower_rest=False): return s[:1].upper() + (s[1:].lower() if lower_rest else s[1:])  capitalize('fooBar') # 'FooBar' capitalize('fooBar', True) # 'Foobar'  "});index.add({'id':151,'href':'/library/tutorials/docs/python/snippets/capitalize_every_word/','title':"capitalize_every_word()",'content':" capitalize_every_word() Capitalizes the first letter of every word in a string.\nUse s.title() to capitalize first letter of every word in the string.\ndef capitalize_every_word(s): return s.title()  capitalize_every_word('hello world!') # 'Hello World!'  "});index.add({'id':152,'href':'/library/tutorials/docs/python/snippets/cast_list/','title':"cast_list()",'content':" cast_list() Casts the provided value as a list if it\u0026rsquo;s not one.\nUse isinstance() to check if the given value is enumerable and return it by using list() or encapsulated in a list accordingly.\ndef cast_list(val): return list(val) if isinstance(val, (tuple, list, set, dict)) else [val]  cast_list('foo') # ['foo'] cast_list([1]) # [1] cast_list(('foo', 'bar')) # ['foo', 'bar']  "});index.add({'id':153,'href':'/library/tutorials/docs/python/snippets/check_prop/','title':"check_prop()",'content':" check_prop() Given a predicate function, fn, and a prop string, this curried function will then take an object to inspect by calling the property and passing it to the predicate.\nReturn a lambda function that takes an object and applies the predicate function, fn to the specified property.\ndef check_prop(fn, prop): return lambda obj: fn(obj[prop])  check_age = check_prop(lambda x: x \u0026gt;= 18, 'age') user = {'name': 'Mark', 'age': 18} check_age(user) # True  "});index.add({'id':154,'href':'/library/tutorials/docs/python/snippets/chunk/','title':"chunk()",'content':" chunk() Chunks a list into smaller lists of a specified size.\nUse list() and range() to create a list of the desired size. Use map() on the list and fill it with splices of the given list. Finally, return the created list.\nfrom math import ceil def chunk(lst, size): return list( map(lambda x: lst[x * size:x * size + size], list(range(0, ceil(len(lst) / size)))))  chunk([1, 2, 3, 4, 5], 2) # [[1,2],[3,4],5]  "});index.add({'id':155,'href':'/library/tutorials/docs/articles/webapp/javascript/circle-progress/','title':"Circle Progress",'content':" Circle Progress  Responsive, accessible, animated, stylable with CSS circular progress bar available as plain (vanilla) JavaScript and jQuery plugin.\n See examples or go to the project site\nGetting Started As plain JavaScript Download the minified [production version][vanilla-min]\nIn your web page:\n\u0026lt;div class=\u0026quot;progress\u0026quot;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;script src=\u0026quot;dist/circle-progress.min.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script\u0026gt; new CircleProgress('.progress'); \u0026lt;/script\u0026gt;  As jQuery plugin Download the minified jQuery production version\nIn your web page:\n\u0026lt;div class=\u0026quot;progress\u0026quot;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;script src=\u0026quot;https://code.jquery.com/jquery-3.3.1.min.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026quot;dist/jquery.circle-progress.min.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script\u0026gt; jQuery(function($) { $('.progress').circleProgress(); }); \u0026lt;/script\u0026gt;  A note about jQuery file jQuery version of Circle Progress is built on top of plain JavaScript version. It uses jQuery Widget Factory. Two files are available: one that contains the Widget Factory code, and one that doesn\u0026rsquo;t. 1. You can use the smaller jquery.circle-progress.bare.min.js, if you have already included the jQuery Widget Factory or another native jQuery widget in your page. 1. Otherwise you must use jquery.circle-progress.min.js, which includes the jQuery Widget Factory code.\nUsage Initiate Circle Progress Plain JavaScript const circleProgress = new CircleProgress(element, options, doc);  where\nelement is HTML element or selector to be converted into a progress circle (required),\noptions - object map of options (optional),\ndoc - the document we are acting upon (optional).\njQuery $('.progress').circleProgress(options);  where options is object map of options (optional).\nOptions You can customize Circle Progress with these options by either passing options object at initiation, or setting them later, e. g.:\nIn plain js Set options as properties on a CircleProgress instance:\ncircleProgress.max = 100; circleProgress.value = 20;  or using the chainable attr method by passing it option key and value:\ncircleProgress .attr('max', 100) .attr('value', 20);  or options object\ncircleProgress.attr({ max: 100, value: 20, });  In jQuery $('.progress').circleProgress('value', 20);  or\n$('.progress').circleProgress({ max: 100, value: 20, });  All available options    Option Type Default Description     value Number Indeterminate Current value   min Number 0 Minimum value   max Number 1 Maximum value   startAngle Number 0 Starting angle in degrees. Angle of 0 points straight up. Direction depends on clockwise.   clockwise Boolean true Whether to rotate clockwise (true) or anti-clockwise (false)   constrain Boolean true Whether the value should be constrained between min and max. If true, values over max will be truncated to max and values under min will be set to min.   indeterminateText String \u0026rsquo;?\u0026rsquo; Text to display as the value when it is indeterminate   textFormat String or Function \u0026lsquo;horizontal\u0026rsquo; Text layout for value, min, max. You can pass either one of the possible keywords: horizontal - value/max vertical - value is shown over max percent - value% value - only value is shown valueOnCircle - the value is painted on top of the filled region on the circle none - no text is shown. Alternatively you can provide your own function, which will be called each time progress is updated with value and max as arguments and is expected to return a string to insert in the center of the progress circle   animation String \u0026lsquo;easeInOutCubic\u0026rsquo; Animation easing function. One of linear, easeInCubic, easeOutCubic, easeInOutCubic, easeInQuadr, easeOutQuadr, easeInOutQuadr or none   animationDuration Number 600 Animation duration in milliseconds    To customize widget\u0026rsquo;s appearance, you can style its underlying SVG elements with CSS. The elements are:\n   Class Description     circle-progress The svg image. You can use this selector to scale the widget. E. g.: .circle-progress {width: 200px; height: auto;}   circle-progress-circle The entire circle (SVG circle element)   circle-progress-value The arc representing currently filled progress (SVG path element)   circle-progress-text Text controlled by textFormat option (SVG text element)   circle-progress-text-value Current value text (SVG tspan element). Appears only for textFormat values of horizontal, vertical, valueOnCircle   circle-progress-text-max Maximum value text (SVG tspan element). Appears only for textFormat values of horizontal, vertical, valueOnCircle    You can use any SVG presentation attributes on these elements. Particularly useful are: fill, stroke, stroke-width, stroke-linecap properties. (See examples)\nThe default options are stored in CircleProgress.defaults or jQuery.fn.circleProgress.defaults. The two are references to the same object. You can override them, so that all instances will be created with the overridden options.\n vanilla-min : https://github.com/tigrr/circle-progress/raw/master/dist/circle-progress.js jquery-min: https://github.com/tigrr/circle-progress/raw/master/dist/jquery.circle-progress.js site: https://tigrr.github.io/circle-progress/ examples: https://tigrr.github.io/circle-progress/examples.html license: https://github.com/tigrr/circle-progress/blob/master/LICENSE  Browser Support Chrome, Firefox, Safari, Edge and IE 11 are supported.\nLicense © 2018 Tigran Sargsyan\nLicensed under (the MIT License)\n[vanilla-min] : https://github.com/tigrr/circle-progress/raw/master/dist/circle-progress.js\n"});index.add({'id':156,'href':'/library/tutorials/docs/python/snippets/clamp_number/','title':"clamp_number()",'content':" clamp_number() Clamps num within the inclusive range specified by the boundary values a and b.\nIf num falls within the range, return num. Otherwise, return the nearest number in the range.\ndef clamp_number(num,a,b): return max(min(num, max(a, b)), min(a, b))  clamp_number(2, 3, 5) # 3 clamp_number(1, -1, -5) # -1  "});index.add({'id':157,'href':'/library/tutorials/docs/python/snippets/compact/','title':"compact()",'content':" compact() Removes falsey values from a list.\nUse filter() to filter out falsey values (False, None, 0, and \u0026quot;\u0026quot;).\ndef compact(lst): return list(filter(bool, lst))  compact([0, 1, False, 2, '', 3, 'a', 's', 34]) # [ 1, 2, 3, 'a', 's', 34 ]  "});index.add({'id':158,'href':'/library/tutorials/docs/python/snippets/compose/','title':"compose()",'content':" compose() Performs right-to-left function composition.\nUse functools.reduce() to perform right-to-left function composition. The last (rightmost) function can accept one or more arguments; the remaining functions must be unary.\nfrom functools import reduce def compose(*fns): return reduce(lambda f, g: lambda *args: f(g(*args)), fns)  add5 = lambda x: x + 5 multiply = lambda x, y: x * y multiply_and_add_5 = compose(add5, multiply) multiply_and_add_5(5, 2) # 15  "});index.add({'id':159,'href':'/library/tutorials/docs/python/snippets/compose_right/','title':"compose_right()",'content':" compose_right() Performs left-to-right function composition.\nUse functools.reduce() to perform left-to-right function composition. The first (leftmost) function can accept one or more arguments; the remaining functions must be unary.\nfrom functools import reduce def compose_right(*fns): return reduce(lambda f, g: lambda *args: g(f(*args)), fns)  add = lambda x, y: x + y square = lambda x: x * x add_and_square = compose_right(add,square) add_and_square(1, 2) # 9  "});index.add({'id':160,'href':'/library/tutorials/docs/python/snippets/count_by/','title':"count_by()",'content':" count_by() Groups the elements of a list based on the given function and returns the count of elements in each group.\nUse map() to map the values of the given list using the given function. Iterate over the map and increase the element count each time it occurs.\ndef count_by(arr, fn=lambda x: x): key = {} for el in map(fn, arr): key[el] = 1 if el not in key else key[el] + 1 return key  from math import floor count_by([6.1, 4.2, 6.3], floor) # {6: 2, 4: 1} count_by(['one', 'two', 'three'], len) # {3: 2, 5: 1}  "});index.add({'id':161,'href':'/library/tutorials/docs/python/snippets/count_occurences/','title':"count_occurences()",'content':" count_occurences() Counts the occurrences of a value in a list.\nIncrement a counter for every item in the list that has the given value and is of the same type.\ndef count_occurrences(lst, val): return len([x for x in lst if x == val and type(x) == type(val)])  count_occurrences([1, 1, 2, 1, 2, 3], 1) # 3  "});index.add({'id':162,'href':'/library/tutorials/docs/articles/webapp/html/creating-the-layout/','title':"Creating the Layout in HTML",'content':" Website Design: Creating the Layout in HTML For this you need to be aware of the different layout options available in HTML/CSS and which of those is the right fit for your website design. Let us go through the options one by one.\nPhoto by Pankaj Patel on Unsplash\nTables — Do Not Do This! This was used earlier when the web was still in its infancy, and there wasn’t much you could do with a website except display text. The developers had got used to designing websites using \u0026lt;table\u0026gt; element and stuck to it even when new things (CSS, images, animations, small screens) came into the picture.\n\u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;table width=\u0026quot;600px\u0026quot; cellspacing=\u0026quot;0\u0026quot; cellpadding=\u0026quot;0\u0026quot; align=\u0026quot;center\u0026quot;\u0026gt; \u0026lt;tbody\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt; \u0026lt;table width=\u0026quot;600px\u0026quot; bgcolor=\u0026quot;red\u0026quot; cellspacing=\u0026quot;0\u0026quot; cellpadding=\u0026quot;0\u0026quot;\u0026gt; \u0026lt;tbody\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td height=\u0026quot;130px\u0026quot;\u0026gt; \u0026lt;h1\u0026gt;Header\u0026lt;/h1\u0026gt; \u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/tbody\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt; \u0026lt;table width=\u0026quot;600px\u0026quot; cellspacing=\u0026quot;0\u0026quot; cellpadding=\u0026quot;0\u0026quot;\u0026gt; \u0026lt;tbody\u0026gt; \u0026lt;tr\u0026gt;\u0026lt;td height=\u0026quot;10px\u0026quot;\u0026gt;\u0026lt;/td\u0026gt;\u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td bgcolor=\u0026quot;yellow\u0026quot; width=\u0026quot;400px\u0026quot; height=\u0026quot;450px\u0026quot;\u0026gt; \u0026lt;h1\u0026gt;Main\u0026lt;/h1\u0026gt; \u0026lt;/td\u0026gt; \u0026lt;td width=\u0026quot;5px\u0026quot;\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;td bgcolor=\u0026quot;orange\u0026quot; width=\u0026quot;195px\u0026quot; height=\u0026quot;450px\u0026quot;\u0026gt; \u0026lt;h1\u0026gt;Aside\u0026lt;/h1\u0026gt; \u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt;\u0026lt;td height=\u0026quot;10px\u0026quot;\u0026gt;\u0026lt;/td\u0026gt;\u0026lt;/tr\u0026gt; \u0026lt;/tbody\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt; \u0026lt;table width=\u0026quot;600px\u0026quot; height=\u0026quot;80px\u0026quot; bgcolor=\u0026quot;green\u0026quot; cellspacing=\u0026quot;0\u0026quot; cellpadding=\u0026quot;0\u0026quot;\u0026gt; \u0026lt;tbody\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt; \u0026lt;h1\u0026gt;Footer\u0026lt;/h1\u0026gt; \u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/tbody\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/tbody\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  Websites designed using \u0026lt;table\u0026gt; element are fixed in nature. They can’t be redesigned to handle new changes, everything will have to be rewritten completely. This is because the \u0026lt;table\u0026gt; element is meant to display only tabular data, and nothing more. So do not use it for website layout!\nWhen we look at the other options available, you will realise why it’s so bad to use the Table-based layout. Especially when you are trying to create responsive websites.\nA bit of history: When the CSS standard arrived in 1996, it helped alleviate the problems created by table-based layout. The \u0026lt;div\u0026gt; element ruled the layout design for a long time, until the CSS 2.1 standard was finally published in 2011 and float walked in to claim the throne!\nFloat — The Classical Way The CSS Float property is used to float elements in a website. For example, you can float an image next to a body of text. This is \u0026lt;float\u0026gt; in its simplest usage. The same concept can be used to design an entire website.\nimg { float: right; }  For designing an entire website, the basic idea to understand is that the \u0026lt;float\u0026gt; element can be used to design an n-column layout. We can combine this with the \u0026lt;div\u0026gt; element to create a layout as given below.\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div class=\u0026quot;header\u0026quot;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;topmenu\u0026quot;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;content\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;sidebar\u0026quot;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;mainbar\u0026quot;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;footer\u0026quot;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  /* Create two columns that floats next to each other */ .sidebar { float: left; width: 30%; } .mainbar { float: left; width: 70%; } /* Clear floats after the columns */ .content:after { content: \u0026quot;\u0026quot;; display: block; clear: both; }  Today, a website can be accessed from so many different devices — mobiles, tablets, laptops, PCs. So, how would you ensure that your website looks good on any device? The answer is Responsive Web Design. It has only one guiding principle: A web page should look good on any device!\nw3schools has a rather neat definition: “_Responsive Web Design is about using HTML and CSS to automatically resize, hide, shrink, or enlarge, a website, to make it look good on all devices (desktops, tablets, and phones)._”\nNow, if you want to make sure that your website is responsive and looks good on all kinds of devices then you can do something like the code below.\nAdd the following \u0026lt;meta\u0026gt; element to all your web pages:\n\u0026lt;meta name=\u0026quot;viewport\u0026quot; content=\u0026quot;width=device-width, initial-scale=1.0\u0026quot;\u0026gt;  Modify the CSS to add a media query:\n/* Create two columns that floats next to each other */ .sidebar { float: left; width: 30%; } .mainbar { float: left; width: 70%; } /* Use a media query to add a breakpoint at 800px: */ @media screen and (max-width: 800px) { .sidebar, .mainbar { width: 100%; /* The width is 100%, when the viewport is 800px or smaller */ } } /* Clear floats after the columns */ .content:after { content: \u0026quot;\u0026quot;; display: block; clear: both; }  This basically makes the website display as a single column for devices with resolution smaller than 800px (most tablets and all smartphones). Why do this you ask? Imagine looking at a two-column website on your mobile device and trying to read the content. It’s not appealing, is it?!\nFlex — The Responsive Way CSS Flexbox makes it quite simple to design flexible responsive layout for websites. It takes the concept behind float and streamlines it for easy adoption. The above code can be rewritten as follows:\n/* Flexbox Layout */ .content { display: flex; flex-direction: row; } /* Use a media query to add a breakpoint at 800px: */ @media screen and (max-width: 800px) { .sidebar, .mainbar { width: 100%; /* The width is 100%, when the viewport is 800px or smaller */ } }  It’s that simple.\nYou can imagine your website to be a hierarchy of Flexbox elements, starting with the body element, and diving down into the depths till you reach the individual components on each page. Once you start adding \u0026lt;flex\u0026gt; elements to your website, it will become second nature to think of your layout in terms of \u0026lt;flex\u0026gt; properties. That’s how powerful Flexbox is!\nI won’t add anything more here, because there is a beautiful website which already explains Flexbox and its properties in detail. This CSS Tricks page is my go-to reference for all things flex!\nGrid — The Future By now you should be able to spot the issue with using \u0026lt;flex\u0026gt; to design an entire layout. It is a one-dimensional tool (a row/column layout), and as such has to be adapted to be used for designing a website layout which is two-dimensional. This is why you will end up with a hierarchy of nested Flexbox elements in your layout design.\nGrid solves this by providing a two-dimensional layout that can be designed as per your requirements. The below code creates a 3-column layout of 8 items.\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div class=\u0026quot;grid-container\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;grid-item\u0026quot;\u0026gt;1\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;grid-item\u0026quot;\u0026gt;2\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;grid-item\u0026quot;\u0026gt;3\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;grid-item\u0026quot;\u0026gt;4\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;grid-item\u0026quot;\u0026gt;5\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;grid-item\u0026quot;\u0026gt;6\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;grid-item\u0026quot;\u0026gt;7\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;grid-item\u0026quot;\u0026gt;8\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  .grid-container { display: grid; grid-template-columns: auto auto auto; } .grid-item { text-align: center; }  Going by the example above, you can design a layout of your website using the CSS Grid as follows.\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div class=\u0026quot;grid-container\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;item1\u0026quot;\u0026gt;Header\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;item2\u0026quot;\u0026gt;Menu\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;item3\u0026quot;\u0026gt;Main\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;item4\u0026quot;\u0026gt;Right\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;item5\u0026quot;\u0026gt;Footer\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  .item1 { grid-area: header; } .item2 { grid-area: menu; } .item3 { grid-area: main; } .item4 { grid-area: right; } .item5 { grid-area: footer; } .grid-container { display: grid; grid-template-areas: 'header header header header header header' 'menu main main main right right' 'menu footer footer footer footer footer'; grid-gap: 10px; } .grid-container \u0026gt; div { text-align: center; }  The grid-template-areas is a great way to structure your layout. It’s represented visually in code and is easily understandable. Comparing this with the earlier ways (the rigid structure of the tables, the cumbersome floats and the multi-level hierarchy of the flexbox), we can see how easy the CSS Grid has made designing a layout!\nAfter going through each of the above, you can see that a pattern has emerged.\n The CSS Grid is best suited for designing entire layout of the website. The CSS Flexbox is optimal for designing individual rows or columns of components. Responsive Web Design should be considered in the beginning stages of website design. You should have a pretty good idea about how your website will look on every kind of device. And finally, DO NOT use Tables for layout design.  I hope this post has been easy to understand and has added to your CSS/HTML knowledge. Please don’t hesitate to ask any questions that you may have!\nUntil the next bog post..\nOriginally published at www.amithraravi.com on December 29, 2018.\n Written with StackEdit.\n "});index.add({'id':163,'href':'/library/tutorials/docs/articles/webapp/css/guide-to-css-animation-part-1/','title':"CSS Animation — Part 1",'content':" A Guide to CSS Animation — Part 1 This post assumes you’ve never created a CSS animation before. But even if you have, there may be things you were not aware of. It does assume you have some familiarity with HTML and CSS. We’ll explore creating your first animation through to things like chaining animations.\nCSS animation can be a quick concept to grasp but a big topic to cover once we really dig in. Therefore, this post is split over parts.\n Part 1: Introduces CSS animation looking at things like performance and how to inspect animations. We will also create a basic animation and look at @keyframes composition. Part 2: With the basics grasped, we dig into the different things we can do with the animation properties. This includes tips on things like using fill-mode and chaining animations.\n Part 3: We wrap things up with some bonus topics like using CSS variables and hooking in from JavaScript. We also discuss whether you should even use CSS animation at all. That’s right, it’s not always the best option. But there’s benefit to understanding the foundations and alternatives.\n  This enables you to edit and fork live examples 👍\nYou can also grab the code on GitHub Demo code for \u0026ldquo;A Guide to CSS Animation\u0026rdquo; \nFor all animations we are using a single div element unless stated otherwise. The basic markup comprises of something like the following\nThe goal of this guide is to make you comfortable with creating your own CSS animations from scratch! 💪\nSo, why animate? To improve usability and general user experience. But that does not mean animation should be everywhere in your sites. There’s a time and a place.\nWith animation, we can do things such as draw a users attention to something or direct them through a flow. Consider loading animations or page transition effects for example.\nWhat can we animate? Before we start creating animations, we need to know which properties we can animate. We can’t animate every property. The following MDN article lists properties that we can animate. - Animatable CSS properties - Animatable: One property, two values, endless possibilities\r\rProperty performance Of the properties we can animate we may choose to animate some over others due to performance.\nFor example, animating element position will be better handled using transform. This is because the GPU can handle the heavy lifting when animating that property. Animating some properties will trigger layouts to take place 👎\nThe following article is great for understanding animation performance 👍 High Performance Animations - HTML5 Rocks\r\rWith all that out of the way, let’s get started 💪\nOur first animation Let’s dig right in and create our first animation ⛏\nFor this animation we will make an element spin 360 degrees. Riveting stuff I know 😅 But we need to start somewhere!\nFirst, we create our animation using the @keyframes rule. The @keyframes rule takes the following structure.\nanimation-name is the name we give to our animation. You can have one or many keyframe selectors 👍\nWe will name our animation spin. To spin our element we can use the transform property and rotate from 0deg to 360deg. We use two keyframe selectors. One to define the start of our animation(from) and one for the end of our animation(to). from and to keywords are equivalent to 0% and 100%.\nWe can take this a little further. The styles under the from keyframe selector don’t make any difference to our element. So, the from keyframe selector is redundant. We can remove it.\nNow, we need to apply that animation to our element. We use the animation-name and animation-duration properties 👍\nHere we are telling our element to use the animation spin with a duration of 2 seconds. Duration can be set in either milliseconds(ms) or seconds(s).\nLoading that up in a browser should give us something like\nOur first animation 🎉\nFrom that first animation, you have enough to go off and start creating cool animations 😎 But stick around and we will get a full grasp of what we can achieve.\nAnimations inspector We have created our first animation. Now seems like a great time to introduce the Animations inspector in Google Chrome.\nOpen up your animation in Google Chrome and open up the Developer Tools. Open up the Animations panel by going into More Tools. If the Animations panel says “Listening for animations…”, refresh the page.\nAfter refreshing, you should see something in the Animations panel, that’s our animation!\nClick the animation and we are able to inspect it. Now as our animation isn’t particularly complex, there isn’t much to inspect. But with the Animations inspector we can do various things. We can experiment with durations and delays as well as altering playback speed. Most importantly, we can replay our animations without having to refresh the entire page 😅\nThis becomes particularly useful when we have many animations. Whether it be for different elements or on one element.\nYou can read more about the Animations inspector in the following article. Inspect animations | Tools for Web Developers | Google Developers\r\rThroughout this guide I recommend using the inspector when checking out the demos. This will allow you to replay animations and tweak them without having the reload the page 👍\n@keyframes We put together our first @keyframes rule in our spin animation.\nThere isn’t much to @keyframes. After specifying an animation name, we specify animation within keyframe selectors. The keyframe selector specifies a percentage of the animation duration. Or, as mentioned before, we can use the from and to keywords that are the equal to 0% and 100%.\nEach selector defines styles that should apply at that point of the animation. If we have selectors that specify the same CSS styles, we can group them together.\nLet’s start with a simple example. Consider the effect of an element moving around the path of a square.\nWe will call our animation squarePath, very creative I know 😅\nFor this example, there will be four positions for our element. For every side of the square, we use a quarter of the animation. Because our start and finish position will be the same, we can group those keyframe selectors 👍\nApply the animation and a duration to our element 🎉\nAnd that’s it! We have an element moving along the path of a square 🎉\nThat’s it for Part 1 🤓 We’ve taken a look at the basics of creating and applying animations to our elements. Also we can inspect our animations and tweak them in the browser 💪\nAlthough that will be enough to get you up and running with CSS animation, there’s a lot more to it! I hope you’ll join me in Part 2 where we dig deeper into applying animations and the associated tips and tricks.\n Written with StackEdit.\n "});index.add({'id':164,'href':'/library/tutorials/docs/articles/webapp/css/guide-to-css-animation-part-2/','title':"CSS Animation — Part 2",'content':" A Guide to CSS Animation — Part 2 animation-iteration-count Let’s pick up from where we left off with by modifying our first animation. If you need a little refresher, this is what we had.\nBut the animation only ran once. What if we wanted the animation to run many times or not even stop? In the case of loading animations, we may want the animation to be infinite. This is where animation-iteration-count comes into play.\nLet’s say we wanted the animation to run five times.\nIt’s as easy as that. Let’s turn our spinning square into a loading spinner. To do this, animation-iteration-count also accepts the keyword infinite 👍\nWhich gives us the following 🎉\nanimation-timing-function Let’s take another look at that spinning square. The square does keep on spinning. But not without a little break after every spin. This is due to the animation-timing-function.\nThe animation-timing-function property defines the speed characteristics of an animation. It accepts a few different values.\n cubic-bezier(x1, y1, x2, y2) - provides ability to define custom speed ease - start and end slowly but speedier in the middle(default) ease-in- start slowly ease-in-out - start and end slowly but not the same as ease ease-out - end slowly linear - maintain speed throughout steps(number, direction \u0026lt;optional\u0026gt;) - provides a way to split the animation into equal steps. direction values can either be start or end. start means that the first step happens at the start of the animation. end means that the last step happens at the end of the animation. end is the default value.  So which one do you choose? Different scenarios will call for different easing. The following is a nice short resource about the basics of easing. The Basics of Easing | Web Fundamentals | Google Developers\r\rYou can experiment with different easings to find what feels right in your applications. This pen shows how animation-timing-function can affect the same animation.\nThe only ease that might be trickier to grasp is cubic-bezier. Cubic Bézier curves - Wikipedia\r\rIn essence the cubic-bezier function defines a cubic bezier curve. There is a good explanation about the cubic-bezier function in this article Single Transition Timing Function | MDN\r\rOr, you may prefer to play with the cubic-bezier function and compare it to the other easing values. cubic-bezier.com has you covered 👍\nSo returning to our spinning square. How do we remove that little break? We can apply a linear timing. This replaces the default ease timing.\nThis would give us\nSweet 🍭\nanimation-play-state Play state is pretty simple. You can pause animations or have them running. You do this with the animation-play-state property. For our spinning square we could introduce a checkbox that toggles the play state. Using the sibling selector, we can toggle the play state 👍\nWhen it’s :checked we set the play state to running 👟\nanimation-delay Next up is delaying animations. Like animation-duration, animation-delay takes a time value in milliseconds or seconds.\nLet’s add some extra squares and have them all spin side by side once. Note we’ve changed the animation-timing-function value to ease-out.\nIf we add a delay to each square could we create a staggered effect?\nThe answer is yes! 👍\nBut, if we then wanted the squares to keep spinning we would lose the staggered effect. This is because animation-delay is only applied once before an animation begins 👎 It does not apply to every iteration of an animation. At this point we have two choices. We could experiment with different delays using the Animations Inspector. Or we could try stalling the first half of the animation by delaying the spin.\nanimation-fill-mode Next up is animation-fill-mode. This one’s magic 🎩\nBy default, when we apply an animation to an element, it has no affect before or after it has ran. animation-fill-mode changes that.\nThe values for animation-fill-mode that will interest us are;\n forwards - element retains animation styling backwards- element retains style from first keyframe during animation-delay both - element retains styling in both directions  Let’s consider an animation where we shrink an element to half its size.\nWithout using animation-fill-mode the element returns to normal size at the end of the animation. But using animation-fill-mode means we can keep the element at half size once the animation ends.\nNow a more common scenario for using animation-fill-mode is when showing and hiding elements. Consider a scenario where we have three elements that we want to fade in.\nWe’d prefer a staggered effect so we give each element a different animation-delay.\nBut the outcome is not quite as desired because we didn’t use animation-fill-mode 👎 Applying animation-fill-mode: backwards will fix it!\nFor another demo consider this walk sign using animation-fill-mode 🚶\nanimation-direction Last but not least is animation-direction. No surprises that this property allows you to define the direction of your animation. There are four main keywords;\n alternate- the direction of the animation alternates on each iteration alternate-reverse- same as alternate but starts in reverse normal - self explanatory reverse - the animation is played in reverse  For an example we could use alternate for something that opens and closes.\nHow about a clapper board?\nUsing an animation-iteration-count of 2 with animation-direction alternate saves us writing separate animations.\nanimation shorthand If you’ve got this far, that’s all the animation properties 🎉 You know them all now 🤓 There’s now an opportunity to tidy up your animation code by using the shorthand property. That’s right, you don’t need to write out all the properties each time.\nThis\nIs equivalent to this\nSweet 🍭\nThose properties are also optional so you can use whichever combination you need 👍\nBut that’s not all. Using the animation property makes it a little easier to apply many animations to an element.\nConsider an element that we make come in from below and then rotate by 45 degrees.\nYou can use comma separated values for your animation properties. But you could also do this\n Written with StackEdit.\n "});index.add({'id':165,'href':'/library/tutorials/docs/articles/webapp/css/guide-to-css-animation-part-3/','title':"CSS Animation — Part 3",'content':" A Guide to CSS Animation — Part 3 CSS Variables CSS variables are awesome. But you can’t animate them just yet. So what can we do with them? We can use their values to create dynamic animations.\nConsider an example where we have three squares. We want to animate them all growing to different scales. Do we need three different animations for this? We could use animation-fill-mode backwards and scale them all from the same start size? But do we know their start size? With CSS variables we can make the animation dynamic.\nHow about the following code\nUnfortunately, I’ve not seen a way for the animation to take any notice of CSS variables changing value at run time 👎 😭 Maybe in the future.\nBut not all is lost, we can just flip the animation on it’s head 🤕 Consider this example where we update an elements scale to effect the animation.\n**UPDATE 💡\n**It seems that you can actually update variables for animations on the fly now 💪 Consider this example I recently put together:\nCurved animation path So we can animate an element from point to point but how do we add curve to our animation path?\nLet’s start with a simple example where we want an element to travel from one point to another but get some air time.\nLooks good. But won’t work. We will get something like this\nSo how do we combat that? We need two animations and two elements. The wrapper element will handle the X axis. The actual element will handle the Y axis.\nSweet 🍭\nAnd here’s a little loader you could put together with this technique 🐛\nJavaScript hooks So what if we need to know when an animation has ended in our scripts? Don’t worry. There are some events for you to hook into.\n animationiteration - triggered after each animation iteration animationend - triggered after an animation completes animationstart - triggered at the start of an animation  These hooks are pretty powerful and allow us to do some pretty cool things. Consider an infinitely spinning element. Using animationiteration we can keep a track of how many times the element has span for example.\nThere are many possibilities when you start hooking into the animation events. You could also make an animation infinite but with random delays.\nDo you even need CSS animation? If you’ve got this far, you pretty much know everything there is to know about CSS animation 🙌\nIt might seem like an odd topic to end on but do you even need CSS animation? 😕\nHear me out. CSS animation is great. But once your animations start becoming complex, things get harder to maintain. Especially if you’re not using a CSS preprocessor like SASS.\nYou can make use of the JavaScript hooks to manage things a little better. But if you start developing complex timelines, don’t start reinventing the wheel. There are great tools out there to aid with animation. I can’t vouch for GSAP enough. It’s brilliant for gaining complete control over your animations from the JavaScript side. GSAP, the standard for JavaScript HTML5 animation | GreenSock\r\rSo why learn CSS animation at all?! CSS animation still has it’s place. There are plenty of things you can do with it. And you might not always be able to rely on JavaScript. Especially if a user has it disabled in their browser. Consider simpler things that you might animate such as loading spinners. These still contribute to user experience.\nThat’s it! 🎉 If you’ve got this far, thank you so much for sticking around!\nYou should be all set now to go off and get things moving 📽 If there’s something you are not quite sure about or feel could be explained better, don’t hesitate to reach out.\nAll of the demos are available in the following CodePen collection\n Written with StackEdit.\n "});index.add({'id':166,'href':'/library/tutorials/docs/python/snippets/curry/','title':"curry()",'content':" curry() Curries a function.\nUse functools.partial() to return a new partial object which behaves like fn with the given arguments, args, partially applied.\nfrom functools import partial def curry(fn, *args): return partial(fn,*args)  add = lambda x, y: x + y add10 = curry(add, 10) add10(20) # 30  "});index.add({'id':167,'href':'/library/tutorials/docs/articles/data-science/finance/stock-portfolio-analyses-2/','title':"Dash by Plotly",'content':" Python for Finance: Dash by Plotly  Source.\n Part 2 of Leveraging Python for Stock Portfolio Analyses. In part 1 of this series I discussed how, since I’ve become more accustomed to using pandas, that I have signficantly increased my use of Python for financial analyses. During the part 1 post, we reviewed how to largely automate the tracking and benchmarking of a stock portfolio’s performance leveraging pandas and the Yahoo Finance API. At the end of that post you had generated a rich dataset, enabling calculations such as the relative percentage and dollar value returns for portfolio positions versus equally-sized S\u0026amp;P 500 positions during the same holding periods. You could also determine how much each position contributed to your overall portfolio return and, perhaps most importantly, if you would have been better off investing in an S\u0026amp;P 500 ETF or index fund. Finally, you used Plotly for visualizations, which made it much easier to understand which positions drove the most value, what their YTD momentum looked like relative to the S\u0026amp;P 500, and if any had traded down and you might want to consider divesting, aka hit a “Trailing Stop”.\nI learned a lot as part of building this initial process in Jupyter notebook, and I also found it very helpful to write a post which walked through the notebook, explained the code and related my thinking behind each of the visualizations. This follow-up post will be shorter than the prior one and more direct in its purpose. While I’ve continued to find the notebook that I created helpul to track my stock portfolio, it had always been my intention to learn and incorporate a Python framework for building analytical dashboards / web applications. One of the most important use cases for me is having the ability to select specific positions and a time frame, and then dynamically evaluate the relative performances of each position. In the future, I will most likely expand this evaluation case to positions I do not own but am considering acquiring. For the rest of this year, I’m looking to further develop my understanding of building web applications by also learning Flask, deploying apps with Heroku, and ideally developing some type of a data pipeline to automate the extracting and loading of new data for the end web application. While I’m still rather early on in this process, in this post I will discuss the extension of the notebook I discussed last time with my initial development using Dash by Plotly, aka Dash.\nDash by Plotly. If you have read or reference part 1, you will see that once you created the master dataframe, you used Plotly to generate the visualizations which evaluate portfolio performance relative to the S\u0026amp;P 500. Plotly is a very rich library and I prefer to create visualizations using Plotly relative to other Python visualization libraries such as Seaborn and Matplotlib. Building on this, my end goal is to have an interactive dashboard / web app for my portfolio analysis. I’m continuing to search for the optimal solution for this, and in the meantime I’ve begun exploring the use of Dash. Plotly defines Dash as a Python framework for building web applications with the added benefit that no JavaScript is required. As indicated on the landing page which I link to, it’s built on top of Plotly.js, React, and Flask.\nThe initial benefit that I’ve seen thus far is that, once you’re familiar and comfortable with Plotly, Dash is a natural extension into dashboard development. Rather than simply house your visualizations within the Jupyter notebook where you conduct your analysis, I definitely see value in creating a stand-alone and interactive web app. Dash provides increased interactivity and the ability to manipulate data with “modern UI elements like dropdowns, sliders and graphs”. This functionality directionally supports my ultimate goal for my stock portfolio analyses, including the ability to conduct ‘what if analyses’, as well as interactively research potential opportunities and quickly understand key drivers and scenarios. With all of this considered, the learning curve with Dash, at least for me, is not insignificant.\nJose Portilla’s “Interactive Python Dashboards with Plotly and Dash” To short circuit the time that it would have taken for me to read through and extensively troubleshoot Dash’s documentation, I enrolled in Jose Portilla’s Plotly and Dash course on Udemy. The detail page for that course can be found here. I have taken a few of Jose’s courses and am currently taking his Flask course. I view him as a very sound and helpful instructor – while he generally does not presume extensive programming experience as prerequisites for his courses, in this Dash course he does recommend at least a strong familiarity with Python. In particular, having a solid understanding of Plotly's syntax for visualization, including using pandas, are highly recommended. After taking the course, you will still be scratching the surface in terms of what you can build with Dash. However, I found the course to be a very helpful jump start, particularly because Jose uses datareader and financial data and examples, including dynamically pulling stock price charts.\nPorting Data from Jupyter Notebook to Interact with it in Dash. Getting Started Similar to part 1, I created another repo on GitHub with all of the files and code required to create the final Dash dashboard.\nBelow is a summary of what is included and how to get started:\n Investment Portfolio Python Notebook_Dash_blog_example.ipynb — this is very similar to the Jupyter notebook from part 1; the additions include the final two sections: a ‘Stock Return Comparisons’ section, which I built as a proof-of-concept prior to using Dash, and ‘Data Outputs’, where I create csv files of the data the analyses generate; these serve as the data sources used in the Dash dashboard. Sample stocks acquisition dates_costs.xlsx — this is the toy portfolio file, which you will use or modify for your portfolio assessments. requirements.txt — this should have all of the libraries you will need. I recommend creating a virtual environment in Anaconda, discussed further below. Mock_Portfolio_Dash.py — this has the code for the Dash dashboard which we’ll cover below.  As per my repo’s README file, I recommend creating a virtual environment using Anaconda. Here’s a quick explanation and a link to more detail on Anaconda virtual environments:\nI recommend Python 3.6 or greater so that you can run the Dash dashboard locally with the provided csv files. Here is a very thorough explanation on how to set up virtual environments in Anaconda.\nLast, as mentioned in part 1, once your environment is set up, in addition to the libraries in the requirements file, if you want the Yahoo Finance datareader piece to run in the notebook, you will also need to pip install fix-yahoo-finance within your virtual environment.\nWorking with Dash If you have followed along thus far in setting up a virtual environment using Python 3.6, and have installed the necessary libraries, you should be able to run the Python file with the Dash dashboard code.\nFor those who are less familiar: once in your virtual environment, you will need to change directory, cd, to where you have the repo’s files saved. As a quick example, if you open Anaconda Prompt and you are in your Documents folder, and the files are saved on your Desktop, you could do the following:\ncd .. # This will take you up one folder in the directory. cd Desktop # this will take you to your Desktop. dir # This is the windows command to display all files in the directory. You should see the Mock_Portfolio_Dash.py file listed. python Mock_Portfolio_Dash.py # this will run the Dash file # You will then go to your browser and input the URL where Python says your dashboard is running on localhost.  If you would like the full explanation on the Jupyter notebook and generating the portfolio data set, please refer to part 1. At the end of the Jupyter notebook, you will see the below code in the ‘Data Outputs’ section. These minor additions will send CSV files into your local directory. The first is the full portfolio dataset, from which you can generate all of the visualizations, and the second provides the list of tickers you will use in the first, new stock chart’s dropdown selection.\n# Generate the base file that will be used for Dash dashboard. merged_portfolio_sp_latest_YTD_sp_closing_high.to_csv('analyzed_portfolio.csv')  I’ll highlight some key aspects of the Mock Portfolio Python file and share how to run the dashboard locally.\nFor reference while we breakdown the .py file, below is a screen grab of the first three charts that you should see when running this Dash dashboard.\nFirst three charts in Dash Stock Portfolio Analyses dashboard.\nAt the beginning of the .py file, you import the libraries included in the requirements.txt file, and then write\napp = dash.Dash()  in order to instantiate the Dash app. You then create two dataframe objects, tickers and data. Tickers will be used for the stock tickers in one of the chart’s dropdowns, and the data dataframe is the final data set which is used for all of the visualization evaluations.\nYou wrap the entire dashboard in a Div, and then begin adding the charting components within this main Div. Lines 35–72 in the .py file produce the ‘Relative Returns Comparison’ chart, including the stock symbol dropdown, the start/end date range, the Submit button, and the chart’s output. For brevity, I’ll break down the first of the three sections within this portion of the .py file.\nhtml.H1('Relative Returns Comparison'), html.Div([html.H3('Enter a stock symbol:', style={'paddingRight': '30px'}), dcc.Dropdown( id='my_ticker_symbol', options = options, value = ['SPY'], multi = True # style={'fontSize': 24, 'width': 75} )\t]  As mentioned, using Dash means that you do not need to add JavaScript to your application. In the above code block, we label the output with an H1 tag, create another Div, and then make use of a dropdown from the dash_core_components library. You set the id to ‘my_ticker_symbol’, we’ll review where this comes in to play shortly, set a default value of ‘SPY’ from the options list (generated from tickers dataframe), and then set multi-select to be True. There is a bit of a learning curve here, at least for me, and this is where a course such as Jose Portilla’s can short circuit your learning by providing tangible examples which summarize Dash documentation – Jose actually uses a similar example to this stock list dropdown and date range picker in his course.\nBelow this, in rows 75–93, you’ll see the code for the bottom left chart on the dashboard. This chart is the same as what was provided in the Jupyter Notebook in part 1, but I find using Dash for all of these outputs in a dashboard layout to be a better user experience and easier to work with than within Jupyter notebook (I continue to prefer notebooks for conducting analysis to anything else I’ve used to-date).\n# YTD Returns versus S\u0026amp;P 500 section html.H1('YTD and Total Position Returns versus S\u0026amp;P 500'), dcc.Graph(id='ytd1', figure = {'data':[ go.Bar( x = data['Ticker'][0:20], y = data['Share YTD'][0:20], name = 'Ticker YTD'), go.Scatter( x = data['Ticker'][0:20], y = data['SP 500 YTD'][0:20], name = 'SP500 YTD') ], 'layout':go.Layout(title='YTD Return vs S\u0026amp;P 500 YTD', barmode='group', xaxis = {'title':'Ticker'}, yaxis = {'title':'Returns', 'tickformat':\u0026quot;.2%\u0026quot;} )}, style={'width': '50%', 'display':'inline-block'} )  For those comfortable using Plotly, the syntax should be familiar in terms of creating the data and layout objects required to plot the Plotly figure. This syntax included above is different than that used for the charts in the notebook, as I prefer to create traces, generate the data object based on these traces, and use the dict syntax within the layout object. In taking Jose’s course and reviewing the Dash documentation, I’ve just found it easier to conform to this syntax in Dash – it can sometimes get unwieldy when troubleshooting closing tags, parentheses, curly braces, et al, so I’ve focused on getting accustomed to this structure.\n@app.callback(Output('my_graph', 'figure'), [Input('submit-button', 'n_clicks')], [State('my_ticker_symbol', 'value'), State('my_date_picker', 'start_date'), State('my_date_picker', 'end_date') ]) def update_graph(n_clicks, stock_ticker, start_date, end_date): start = datetime.strptime(start_date[:10], '%Y-%m-%d') end = datetime.strptime(end_date[:10], '%Y-%m-%d') traces = [] for tic in stock_ticker: df = web.DataReader(tic, 'iex', start, end) traces.append({'x':df.index, 'y':(df['close']/df['close'].iloc[0])-1, 'name': tic}) fig = { 'data': traces, 'layout': {'title':stock_ticker} } return fig if __name__ == '__main__': app.run_server()  Lines 229–252 (provided above) drive the interactivity for the first ‘Relative Returns Comparison’ chart. Below is a quick overview of what this code is doing:\n In order to create interactive charts, Dash uses a callback decorator: “The “inputs” and “outputs” of our application interface are described declaratively through the app.callback decorator.” In the app callback, we output the dcc.Graph specified earlier with an id of ‘my_graph’. You use the Submit button as the input, and we have three default states, ‘my_ticker_symbol’ with the default ‘SPY’ value declared in the dcc.Dropdown discussed earlier, as well as a default start date of 1/1/2018 and end date of today. Below the callback is the function the callback decorator wraps. As described in Dashdocumentation, when an input property changes, the function the decorator wraps is called automatically. “Dash provides the function with the new value of the input property as an input argument and Dash updates the property of the output component with whatever was returned by the function.” Within the for loop, for the y-values I divide the closing price on any given day, df['close'], by the first closing price in the series generated by the date range provided (df['close'].iloc[0]). I do this to look at the relative performance of two or more stocks indexed at 0, the start of the date range. Given the large differences in share price, this makes it much easier to compare the relative performance of a stock trading over $1,800 (e.g., AMZN) versus another trading below $100 (e.g., WMT). I’d quickly mention that there is sometimes a misconception that a stock is “cheap” if it trades at a lower price and “expensive” if it trades where AMZN currently does. Given this misconception, companies will sometimes split their stock in order to make the share price appear more affordable to small investors even though the company’s value / market cap remain the same. Regardless, the benefit of this chart is that it allows you to quickly spot over / under-performance of a stock relative to the S\u0026amp;P 500 using dynamic date ranges. This provides useful information regarding value contribution to your overall portfolio, and also when it might be time to consider divesting an under-performing holding.  Conclusion and Future considerations. This concludes my initial review of Dash for stock portfolio analyses. As before, you have an extensible Jupyter notebook and portfolio dataset, which you can now read out as a csv file and review in an interactive Dash dashboard. As discussed before in Part 1, this approach continues to have some areas for improvement, including the need to incorporate dividends as part of total shareholder return and the need to be able to evaluate both active and all (including divested) positions.\nThe most significant benefits I’ve found with this approach include the additional interactivity, and my preference for the dashboard layout of all of the charts versus in separate cells in Jupyter notebook. In the future, I’m planning to incorporate greater interactivity, including more ‘what-if-analyses’ to assess individual stock’s contribution to overall performance.\nThe additional options that I’m currently considering to deliver an end-to-end web application with a data pipeline include:\n Mode Analytics with Google BigQuery: I’ve written before about how much I enjoyed using Mode Analytics at my former company. The benefits of Mode include the fact that it already supports rich visualizations (no coding required), including a built in Python notebook. However, I do not believe there’s a way in Mode to extract data from a finance API, including Yahoo Finance and IEX. The data from those API sources could be read in to a private database, e.g., using Google BigQuery, which you could connect to Mode. However, for now this seems like a limitation as I believe more of my future charts and use cases will require data pulled from APIs (as opposed to stored in a database). Heroku with Postgres and Pipeline: As part of Jose’s course, he shows you how to deploy a Dashapp to Heroku (another benefit of his course). As of now, I believe that leveraging Heroku’s app functionality is a potential long-term solution. This is another reason why I’m taking Jose’s Flaskcourse; I’ve never built a web app, and he shows how to use SQLAlchemy as the database for the Flask app. Furthering my understanding of deploying an app with a database on Heroku, my focus will be determining the best way to pull in finance-API data to be analyzed within an interactive web app which I can refresh with new data on a specified schedule.  The long-term solution requires a lot more learning for me, but it’s definitely a challenge that I want to take on the rest of this year. I hope that you found this post useful, and I welcome any feedback in the comments, including additional options which I have not mentioned and you believe would be better suited for this application and its analyses.\nIf you enjoyed this post, it would be awesome if you would click the “claps” icon to let me know and to help increase circulation of my work.\nFeel free to also reach out to me on twitter, @kevinboller, and my personal blog can be found here. Thanks for reading!\n"});index.add({'id':168,'href':'/library/tutorials/docs/python/beginer/date-and-time/','title':"Date\u0026Time",'content':" Python DateTime "});index.add({'id':169,'href':'/library/tutorials/docs/python/beginer/date-and-time/python-datetime-tutorial/','title':"Datetime Tutorial",'content':" Python Datetime Tutorial: Manipulate Times, Dates, and Time Spans Table of Contents  Python datetime Classes Creating Date Objects Extract Year and Month from the Date  - Handling Date and Time Strings with strptime() and strftime()  Getting Day of the Month and Day of the Week from a Date Getting Hours and Minutes From a Python Datetime Object Getting Week of the Year from a Datetime Object Converting a Date Object into Unix Timestamp and Vice Versa Measuring Time Span with Timedelta Objects Find the Difference Between Two Dates and Times Formatting Dates: More on strftime() and strptime() Handling Timezones Working with pandas Datetime Objects  - Get Year, Month, Day, Hour, Minute in pandas  Get Weekday and Day of Year  Convert Date Object into DataFrame Index  Conclusion  Dealing with dates and times in Python can be a hassle. Thankfully, there’s a built-in way of making it easier: the Python datetime module.\ndatetime helps us identify and process time-related elements like dates, hours, minutes, seconds, days of the week, months, years, etc. It offers various services like managing time zones and daylight savings time. It can work with timestamp data. It can extract the day of the week, day of the month, and other date and time formats from strings.\nIn short, it’s a really powerful way of handling anything date and time related in Python. So let’s get into it!\nIn this tutorial, we’ll learn about python datetime functions in detail, including:\n Creating Date Objects Getting year and month from the date Getting month day and Weekday from date Getting hour and minutes from the date Getting Week number of the year from date Converting date object into timestamp Converting UNIX timestamp string to date object Handling timedelta objects Getting the difference between two dates and times Formatting dates: strftime() and strptime() Handling timezones Working with Pandas datetime objects\n Getting year, month, day, hour, and minute Getting weekday and day of year Converting date objects into a DataFrame index   As you work through this tutorial, we’d encourage you to run the code on your own machine. Alternatively, if you’d like to run code in your browser and learn in an interactive fashion with answer-checking to be sure you’re getting it right, our free Python intermediate course has a lesson on datetime in Python that we recommend. All it requires is signing up for a free user account.\nPython datetime Classes Before jumping into writing code, it’s worth looking at the five main object classes that are used in the datetime module. Depending on what we’re trying to do, we’ll likely need to make use of one or more of these distinct classes:\n datetime – Allows us to manipulate times and dates together (month, day, year, hour, second, microsecond).\n date – Allows us to manipulate dates independent of time (month, day, year).\n time – Allows us to manipulate time independent of date (hour, minute, second, microsecond).\n timedelta— A duration of time used for manipulating dates and measuring.\n tzinfo— An abstract class for dealing with time zones.\n  If those distinctions don’t make sense yet, don’t worry! Let’s dive into datetime and start working with it to better understand how these are applied.\nCreating Date Objects First, let’s take a closer look at a datetime object. Since datetime is both a module and a class within that module, we’ll start by importing the datetime class from the datetime module.\nThen, we’ll print the current date and time to take a closer look at what’s contained in a datetime object. We can do this using datetime‘s .now() function. We’ll print our datetime object, and then also print its type using type() so we can take a closer look.\n# import datetime class from datetime module from datetime import datetime # get current date datetime_object = datetime.now() print(datetime_object) print('Type :- ',type(datetime_object)) ## output 2019-10-25 10:24:01.521881 Type :- \u0026lt;class 'datetime.datetime'\u0026gt;  We can see from the results above that datetime_object is indeed a datetime object of the datetime class. This includes the year, month, day, hour, minute, second, and microsecond.\nExtract Year and Month from the Date Now we’ve seen what makes up a datetime object, we can probably guess how date and time objects look, because we know that date objects are just like datetime without the time data, and time objects are just like datetime without the date data.\nWe can also antipate some problems. For example, in most data sets, date and time information is stored in string format! Also, we may not want all of this date and time data — if we’re doing something like a monthly sales analysis, breaking things down by microsecond isn’t going to be very useful.\nSo now, let’s start digging into a common task in data science: extracting only the elements that we actually want from a string using datetime.\nTo do this, we need to do a few things.\nHandling Date and Time Strings with strptime() and strftime() Thankfully, datetime includes two methods, strptime() and strftime(), for converting objects from strings to datetime objects and vice versa. strptime() can read strings with date and time information and convert them to datetime objects, and strftime() converts datetime objects back into strings.\nOf course, strptime() isn’t magic — it can’t turn any string into a date and time, and it will need a little help from us to interpret what it’s seeing! But it’s capable of reading most conventional string formats for date and time data (see the documentation for more details). Let’s give it a date string in YYYY-MM-DD format and see what it can do!\nmy_string = '2019-10-31' # Create date object in given time format yyyy-mm-dd my_date = datetime.strptime(my_string, \u0026quot;%Y-%m-%d\u0026quot;) print(my_date) print('Type: ',type(my_date)) ## output 2019-10-31 00:00:00 Type: \u0026lt;class 'datetime.datetime'\u0026gt;  Note that strptime() took two arguments: the string (my_string) and \u0026quot;%Y-%m-%d\u0026quot;, another string that tells strptime() how to interpret the input string my_string. %Y, for example, tells it to expect the first four characters of the string to be the year.\nA full list of these patterns is available in the documentation, and we’ll go into these methods in more depth later in this tutorial.\nYou may also have noticed that a time of 00:00:00 has been added to the date. That’s because we created a datetime object, which must include a date and a time. 00:00:00 is the default time that will be assigned if no time is designated in the string we’re inputting.\nAnyway, we were hoping to separate out specific elements of the date for our analysis. One way can do that using the built-in class attributes of a datetime object, like .month or .year:\nprint('Month: ', my_date.month) # To Get month from date print('Year: ', my_date.year) # To Get month from year ## output Month: 10 Year: 2019  Getting Day of the Month and Day of the Week from a Date Let’s do some more extraction, because that’s a really common task. This time, we’ll try to get the day of the month and the day of the week from my_date. Datetime will give us the day of the week as a number using its .weekday() function, but we can convert this to a text format (i.e. Monday, Tuesday, Wednesday…) using the calendar module and a method called day_name.\nWe’ll start by importing calendar, and then using .day and .weekday() on my_date. From there, we can get the day of the week in text format like so:\n# import calendar module import calendar print('Day of Month:', my_date.day) # to get name of day(in number) from date print('Day of Week (number): ', my_date.weekday()) # to get name of day from date ## output Day of Month: 31 Day of Week (number): 3 Day of Week (name): Thursday  Wait a minute, that looks a bit odd! The third day of the week should be Wednesday, not Thursday, right?\nLet’s take a closer look at that day_name variable using a for loop:\nj = 0 for i in calendar.day_name: print(j,'-',i) j+=1 ## output 0 - Monday 1 - Tuesday 2 - Wednesday 3 - Thursday 4 - Friday 5 - Saturday 6 - Sunday  Now we can see that Python starts weeks on Monday and counts from the index 0 rather than starting at 1. So it makes sense that the number 3 is converted to “Thursday” as we saw above.\nGetting Hours and Minutes From a Python Datetime Object Now let’s dig into time and extract the hours and minutes from datetime object. Much like what we did above with month and year, we can use class attributes .hour and .minute to get the hours and minutes of the day.\nLet’s set a new date and time using the .now() function. As of this writing, it’s October 25, 2019 at 10:25 AM. You’ll get different results depending on when you choose to run this code, of course!\nfrom datetime import datetime todays_date = datetime.now() # to get hour from datetime print('Hour: ', todays_date.hour) # to get minute from datetime print('Minute: ', todays_date.minute) ## output Hour: 10 Minute: 25  Getting Week of the Year from a Datetime Object We can also do fancier things with datetime. For example, what if we want to know what week of the year it is?\nWe can get the year, week of the year, and day of the week from a datetime object with the .isocalendar() function.\nSpecifically, isocalendar() returns a tuple with ISO year, week number and weekday. The ISO calendar is a widely-used standard calendar based on the Gregorian calendar. You can read about it in more detail at that link, but for our purposes, all we need to know is that it works as a regular calendar, starting each week on Monday.\n# Return a 3-tuple, (ISO year, ISO week number, ISO weekday). todays_date.isocalendar() # (2019, 43, 5)  Note that in the ISO calendar, the week starts counting from 1, so here 5 represents the correct day of the week: Friday.\nWe can see from the above that this is the 43rd week of the year, but if we wanted to isolate that number, we could do so with indexing just as we might for any other Python list or tuple:\ntodays_date.isocalendar()[1] # 43  Converting a Date Object into Unix Timestamp and Vice Versa In programming, it’s not uncommon to encounter time and date data that’s stored as a timestamp, or to want to store your own data in Unix timestamp format.\nWe can do that using datetime’s built-in timestamp() function, which takes a datetime object as an argument and returns that date and time in timestamp format:\n#import datetime from datetime import datetime # get current date now = datetime.now() # convert current date into timestamp timestamp = datetime.timestamp(now) print(\u0026quot;Date and Time :\u0026quot;, now) print(\u0026quot;Timestamp:\u0026quot;, timestamp) # Date and Time : 2019-10-25 10:36:32.827300 # Timestamp: 1572014192.8273  Similarly, we can do the reverse conversion using fromtimestamp(). This is a datetime function that takes a timestamp (in float format) as an argument and returns a datetime object, as below:\n#import datetime from datetime import datetime timestamp = 1572014192.8273 #convert timestamp to datetime object dt_object = datetime.fromtimestamp(timestamp) print(\u0026quot;dt_object:\u0026quot;, dt_object) print(\u0026quot;type(dt_object): \u0026quot;, type(dt_object))  dt_object: 2019-10-25 10:36:32.827300 type(dt_object): \u0026lt;class 'datetime.datetime'\u0026gt;  Measuring Time Span with Timedelta Objects Often, we may want to measure a span of time, or a duration, using Python datetime. We can do this with its built-in timedelta class. A timedelta object represents the amount of time between two dates or times. We can use this to measure time spans, or manipulate dates or times by adding and subtracting from them, etc.\nBy default a timedelta object has all parameters set to zero. Let’s create a new timedelta object that’s two weeks long and see how that looks:\n#import datetime from datetime import timedelta # create timedelta object with difference of 2 weeks d = timedelta(weeks=2) print(d) print(type(d)) print(d.days)  14 days, 0:00:00 \u0026lt;class 'datetime.timedelta'\u0026gt; 14  Note that we can get our time duration in days by using the timedelta class attribute .days. As we can see in its documentation, we can also get this time duration in seconds or microseconds.\nLet’s create another timedelta duration to get a bit more practice:\nyear = timedelta(days=365) print(year) # 365 days, 0:00:00  Now let’s start doing using timedelta objects together with datetime objects to do some math! Specifically, let’s add a few diffeent time durations to the current time and date to see what date it will be after 15 days, what date it was two weeks ago.\nTo do this, we can use the + or - operators to add or subtract the timedelta object to/from a datetime object. The result will be the datetime object plus or minus the duration of time specified in our timedelta object. Cool, right?\n(Note: in the code below, it’s October 25 at 11:12 AM; your results will differ depending on when you run the code since we’re getting our datetime object using the .now() function).\n#import datetime from datetime import datetime, timedelta # get current time now = datetime.now() print (\u0026quot;Today's date: \u0026quot;, str(now)) #add 15 days to current date future_date_after_15days = now + timedelta(days = 15) print('Date after 15 days: ', future_date_after_15days) #subtract 2 weeks from current date two_weeks_ago = now - timedelta(weeks = 2) print('Date two weeks ago: ', two_weeks_ago) print('two_weeks_ago object type: ', type(two_weeks_ago))  Today's date: 2019-10-25 11:12:24.863308 Date after 15 days: 2019-11-09 11:12:24.863308 Date two weeks ago: 2019-10-11 11:12:24.863308 two_weeks_ago object type: \u0026lt;class 'datetime.datetime'\u0026gt;  Note that the output of these mathematical operations is still a datetime object.\nFind the Difference Between Two Dates and Times Similar to what we did above, we can also subtract one date from another date to find the timespan between them using datetime.\nBecause the result of this math is a duration, the object produced when we subtract one date from another will be a timedelta object.\nHere, we’ll create two date objects (remeber, these work the same as datetime objects, they just don’t include time data) and subtract one from the other to find the duration:\n# import datetime from datetime import date # Create two dates date1 = date(2008, 8, 18) date2 = date(2008, 8, 10) # Difference between two dates delta = date2 - date1 print(\u0026quot;Difference: \u0026quot;, delta.days) print('delta object type: ', type(delta))  Difference: -8 delta object type: \u0026lt;class 'datetime.timedelta'\u0026gt;  Above, we used only dates for the sake of clarity, but we can do the same thing with datetime objects to get a more precise measurement that includes hours, minutes, and seconds as well:\n# import datetime from datetime import datetime # create two dates with year, month, day, hour, minute, and second date1 = datetime(2017, 6, 21, 18, 25, 30) date2 = datetime(2017, 5, 16, 8, 21, 10) # Difference between two dates diff = date1-date2 print(\u0026quot;Difference: \u0026quot;, diff) # Difference: 36 days, 10:04:20  Formatting Dates: More on strftime() and strptime() We touched briefly on strftime() and strptime() earlier, but let’s take a closer look at these methods, as they’re often important for data analysis work in Python.\nstrptime() is the method we used before, and you’ll recall that it can turn a date and time that’s formatted as a text string into a datetime object, in the following format:\ntime.strptime(string, format)  Note that it takes two arguments:\n string − the time in string format that we want to convert\n format − the specific formatting of the time in the string, so that strptime() can parse it correctly\n  Let’s try converting a different kind of date string this time. This site is a really useful reference for finding the formatting codes needed to help strptime() interpret our string input.\n# import datetime from datetime import datetime date_string = \u0026quot;1 August, 2019\u0026quot; # format date date_object = datetime.strptime(date_string, \u0026quot;%d %B, %Y\u0026quot;) print(\u0026quot;date_object: \u0026quot;, date_object) # date_object: 2019-08-01 00:00:00  Now let’s do something a bit more advanced to practice everything we’ve learned so far! We’ll start with a date in string format, convert it to a datetime object, and look at a couple different ways of formatting it (dd/mm and mm/dd).\nThen, sticking with the mm/dd formatting, we’ll convert it into a Unix timestamp. Then we’ll convert it back into a datetime object, and convert that back into strings using a few different strftime patterns to control the output:\n# import datetime from datetime import datetime dt_string = \u0026quot;12/11/2018 09:15:32\u0026quot; # Considering date is in dd/mm/yyyy format dt_object1 = datetime.strptime(dt_string, \u0026quot;%d/%m/%Y %H:%M:%S\u0026quot;) print(\u0026quot;dt_object1:\u0026quot;, dt_object1) # Considering date is in mm/dd/yyyy format dt_object2 = datetime.strptime(dt_string, \u0026quot;%m/%d/%Y %H:%M:%S\u0026quot;) print(\u0026quot;dt_object2:\u0026quot;, dt_object2) # Convert dt_object2 to Unix Timestamp timestamp = datetime.timestamp(dt_object2) print('Unix Timestamp: ', timestamp) # Convert back into datetime date_time = datetime.fromtimestamp(timestamp) d = date_time.strftime(\u0026quot;%c\u0026quot;) print(\u0026quot;Output 1:\u0026quot;, d) d = date_time.strftime(\u0026quot;%x\u0026quot;) print(\u0026quot;Output 2:\u0026quot;, d) d = date_time.strftime(\u0026quot;%X\u0026quot;) print(\u0026quot;Output 3:\u0026quot;, d)  dt_object1: 2018-11-12 09:15:32 dt_object2: 2018-12-11 09:15:32 Unix Timestamp: 1544537732.0 Output 1: Tue Dec 11 09:15:32 2018 Output 2: 12/11/18 Output 3: 09:15:32  Here’s an image you can save with a cheat sheet for common, useful strptime and strftime patterns:\nLet’s get a little more practice using these:\n# current date and time now = datetime.now() # get year from date year = now.strftime(\u0026quot;%Y\u0026quot;) print(\u0026quot;Year:\u0026quot;, year) # get month from date month = now.strftime(\u0026quot;%m\u0026quot;) print(\u0026quot;Month;\u0026quot;, month) # get day from date day = now.strftime(\u0026quot;%d\u0026quot;) print(\u0026quot;Day:\u0026quot;, day) # format time in HH:MM:SS time = now.strftime(\u0026quot;%H:%M:%S\u0026quot;) print(\u0026quot;Time:\u0026quot;, time) # format date date_time = now.strftime(\u0026quot;%m/%d/%Y, %H:%M:%S\u0026quot;) print(\u0026quot;Date and Time:\u0026quot;,date_time)  Year: 2019 Month; 10 Day: 25 Time: 11:56:41 Date and Time: 10/25/2019, 11:56:41\nHandling Timezones Working with dates and times in Pythin can get even more complicated when timezones get involved. Thankfully, the pytz module exists to help us deal with cross-timezone conversions. It also handles the daylight savings time in locations that use that.\nWe can use the localize function to add a time zone location to a Python datetime object. Then we can use the function astimezone() to convert the existing local time zone into any other time zone we specify (it takes the time zone we want to convert into as an argument).\nFor example:\n# import timezone from pytz module from pytz import timezone # Create timezone US/Eastern east = timezone('US/Eastern') # Localize date loc_dt = east.localize(datetime(2011, 11, 2, 7, 27, 0)) print(loc_dt) # Convert localized date into Asia/Kolkata timezone kolkata = timezone(\u0026quot;Asia/Kolkata\u0026quot;) print(loc_dt.astimezone(kolkata)) # Convert localized date into Australia/Sydney timezone au_tz = timezone('Australia/Sydney') print(loc_dt.astimezone(au_tz))  2011-11-02 07:27:00-04:00 2011-11-02 16:57:00+05:30 2011-11-02 22:27:00+11:00  This module can help make life simpler when working with data sets that include multiple different time zones.\nWorking with pandas Datetime Objects Data scientists love pandas for many reasons. One of them is that it contains extensive capabilities and features for working with time series data. Much like datetime itself, pandas has both datetime and timedelta objects for specifying dates and times and durations, respectively.\nWe can convert date, time, and duration text strings into pandas Datetime objects using these functions:\n to_datetime(): Converts string dates and times into Python datetime objects. to_timedelta(): Finds differences in times in terms of days, hours, minutes, and seconds.  And as we’ll see, these functions are actually quite good at converting strings to Python datetime objects by detecting their format automatically, without needing us to define it using strftime patterns.\nLet’s look at a quick example:\n# import pandas module as pd import pandas as pd # create date object using to_datetime() function date = pd.to_datetime(\u0026quot;8th of sep, 2019\u0026quot;) print(date)  2019-09-08 00:00:00  Note that even though we gave it a string with some complicating factors like a “th” and “sep” rather than “Sep.” or “September”, pandas was able to correctly parse the string and return a formatted date.\nWe can also use pandas (and some of its affiliated numpy functionality) to create date ranges automatically as pandas Series. Below, for example, we create a series of twelve dates starting from the day we defined above. Then we create a different series of dates starting from a predefined date using pd.date_range():\n# Create date series using numpy and to_timedelta() function date_series = date + pd.to_timedelta(np.arange(12), 'D') print(date_series) # Create date series using date_range() function date_series = pd.date_range('08/10/2019', periods = 12, freq ='D') print(date_series)  DatetimeIndex(['2019-09-08', '2019-09-09', '2019-09-10', '2019-09-11', '2019-09-12', '2019-09-13', '2019-09-14', '2019-09-15', '2019-09-16', '2019-09-17', '2019-09-18', '2019-09-19'], dtype='datetime64[ns]', freq=None) DatetimeIndex(['2019-08-10', '2019-08-11', '2019-08-12', '2019-08-13', '2019-08-14', '2019-08-15', '2019-08-16', '2019-08-17', '2019-08-18', '2019-08-19', '2019-08-20', '2019-08-21'], dtype='datetime64[ns]', freq='D')  Get Year, Month, Day, Hour, Minute in pandas We can easily get year, month, day, hour, or minute from dates in a column of a pandas dataframe using dt attributes for all columns. For example, we can use df['date'].dt.year to extract only the year from a pandas column that includes the full date.\nTo explore this, let’s make a quick DataFrame using one of the Series we created above:\n# Create a DataFrame with one column date df = pd.DataFrame() df['date'] = date_series df.head()  \tdate 0\t2019-08-10 1\t2019-08-11 2\t2019-08-12 3\t2019-08-13 4\t2019-08-14  Now, let’s create separate columns for each element of the date by using the relevant Python datetime (accessed with dt) attributes:\n# Extract year, month, day, hour, and minute. Assign all these date component to new column. df['year'] = df['date'].dt.year df['month'] = df['date'].dt.month df['day'] = df['date'].dt.day df['hour'] = df['date'].dt.hour df['minute'] = df['date'].dt.minute df.head()     date year month day hour minute     2019-08-10 2019 8 10 0 0   2019-08-11 2019 8 11 0 0   2019-08-12 2019 8 12 0 0   2019-08-13 2019 8 13 0 0   2019-08-14 2019 8 14 0 0    Get Weekday and Day of Year Pandas is also capable of getting other elements, like the day of the week and the day of the year, from its datetime objects. Again, we can use dt attributes to do this. Note that here, as in Python generally, the week starts on Monday at index 0, so day of the week 5 is Saturday.\n# get Weekday and Day of Year. Assign all these date component to new column. df['weekday'] = df['date'].dt.weekday df['day_name'] = df['date'].dt.weekday_name df['dayofyear'] = df['date'].dt.dayofyear df.head()     date year month day hour minute weekday day_name dayofyear     2019-08-10 2019 8 10 0 0 5 Saturday 222   2019-08-11 2019 8 11 0 0 6 Sunday 223   2019-08-12 2019 8 12 0 0 0 Monday 224   2019-08-13 2019 8 13 0 0 1 Tuesday 225   2019-08-14 2019 8 14 0 0 2 Wednesday 226    Convert Date Object into DataFrame Index We can also use pandas to make a datetime column into the index of our DataFrame. This can be very helpful for tasks like exploratory data visualization, because matplotlib will recognize that the DataFrame index is a time series and plot the data accordingly.\nTo do this, all we have to do is redefine df.index:\n# Assign date column to dataframe index df.index = df.date df.head()     date.1 year month day hour minute weekday day_name dayofyear     2019-08-10 2019 8 10 0 0 5 Saturday 222   2019-08-11 2019 8 11 0 0 6 Sunday 223   2019-08-12 2019 8 12 0 0 0 Monday 224   2019-08-13 2019 8 13 0 0 1 Tuesday 225   2019-08-14 2019 8 14 0 0 2 Wednesday 226    Conclusion In this tutorial, we’ve taken a deep dive into Python datetime, and also done some work with pandas and the calendar module. We’ve covered a lot, but remember: the best way to learn something is by actually writing code yourself! If you’d like to practice writing datetime code with interactive answer-checking, check out our free Python intermediate course for a lesson on datetime in Python with interative answer-checking and in-browser code-running.\n Source : .\n "});index.add({'id':170,'href':'/library/tutorials/docs/python/beginer/date-and-time/datetime-timedelta-strftime/','title':"DateTime, TimeDelta, Strftime with Examples",'content':" Python DateTime, TimeDelta, Strftime(Format) with Examples In Python, date, time and datetime classes provides a number of function to deal with dates, times and time intervals. Date and datetime are an object in Python, so when you manipulate them, you are actually manipulating objects and not string or timestamps. Whenever you manipulate dates or time, you need to import datetime function.\nThe datetime classes in Python are categorized into main 5 classes.\n date – Manipulate just date ( Month, day, year) time – Time independent of the day (Hour, minute, second, microsecond) datetime – Combination of time and date (Month, day, year, hour, second, microsecond) timedelta— A duration of time used for manipulating dates tzinfo— An abstract class for dealing with time zones  Table of Contents  Python DateTime, TimeDelta, Strftime(Format) with Examples\n How to Use Date \u0026amp; DateTime Class\n Print Date using date.today()\n Today’s Weekday Number  Python Current Date and Time: now() today()\n How to Format Date and Time Output with Strftime()\n How to use Timedelta Objects\n Python 2 Example\n Summary   How to Use Date \u0026amp; DateTime Class Step 1) Before you run the code for datetime, it is important that you import the date time modules as shown in the screenshot below.\n\nThese import statements are pre-defined pieces of functionality in the Python library that let you manipulates dates and times, without writing any code.\nConsider the following points before executing the datetime code\nfrom datetime import date  This line tells the Python interpreter that from the datetime module import the date class We are not writing the code for this date functionality alas just importing it for our use\nStep 2) Next, we create an instance of the date object.\n\nStep 3) Next, we print the date and run the code.\n\nThe output is as expected.\nPrint Date using date.today() date.today function has several properties associated with it. We can print individual day/month/year and many other things\nLet\u0026rsquo;s see an example\n\nToday\u0026rsquo;s Weekday Number The date.today() function also gives you the weekday number. Here is the Weekday Table which start with Monday as 0 and Sunday as 6\n   Day WeekDay Number     Monday 0   Tuesday 1   Wednesday 2   Thursday 3   Friday 4   Saturday 5   Sunday 6    Weekday Number is useful for arrays whose index is dependent on the Day of the week.\n\nPython Current Date and Time: now() today() Step 1) Like Date Objects, we can also use \u0026ldquo;DATETIME OBJECTS\u0026rdquo; in Python. It gives date along with time in hours, minutes, seconds and milliseconds.\n\nWhen we execute the code for datetime, it gives the output with current date and time.\nStep 2) With \u0026ldquo;DATETIME OBJECT\u0026rdquo;, you can also call time class.\nSuppose we want to print just the current time without the date.\nt = datetime.time(datetime.now())   We had imported the time class. We will be assigning it the current value of time using datetime.now() We are assigning the value of the current time to the variable t.  And this will give me just the time. So let\u0026rsquo;s run this program.\n\nOkay, so you can see that here I got the date and time. And then the next line, I\u0026rsquo;ve got just the time by itself\nStep 3) We will apply our weekday indexer to our weekday\u0026rsquo;s arrayList to know which day is today\n Weekdays operator (wd) is assigned the number from (0-6) number depending on what the current weekday is. Here we declared the array of the list for days (Mon, Tue, Wed…Sun). Use that index value to know which day it is. In our case, it is #2, and it represents Wednesday, so in the output it will print out \u0026ldquo;Which is a Wednesday.\u0026rdquo;  \nHere is the complete code to get current date and time using datetime now\nHere is the complete code to get current date and time using datetime now\nfrom datetime import date from datetime import time from datetime import datetime def main(): ##DATETIME OBJECTS #Get today's date from datetime class today=datetime.now() #print (today) # Get the current time #t = datetime.time(datetime.now()) #print \u0026quot;The current time is\u0026quot;, t #weekday returns 0 (monday) through 6 (sunday) wd=date.weekday(today) #Days start at 0 for monday days= [\u0026quot;monday\u0026quot;,\u0026quot;tuesday\u0026quot;,\u0026quot;wednesday\u0026quot;,\u0026quot;thursday\u0026quot;,\u0026quot;friday\u0026quot;,\u0026quot;saturday\u0026quot;,\u0026quot;sunday\u0026quot;] print(\u0026quot;Today is day number %d\u0026quot; % wd) print(\u0026quot;which is a \u0026quot; + days[wd]) if __name__== \u0026quot;__main__\u0026quot;: main()  How to Format Date and Time Output with Strftime() As of now we have learned, how to use datetime and date object in Python. We will advance a step further and learn how to use a formatting function to format Time and Date.\nStep 1) First we will see a simple step of how to format the year. It is better to understand with an example.\n\n We used the \u0026ldquo;strftime function\u0026rdquo; for formatting. This function uses different control code to give an output. Each control code resembles different parameters like year,month, weekday and date [(%y/%Y – Year), (%a/%A- weekday), (%b/%B- month), (%d - day of month)] . In our case, it is (\u0026ldquo;%Y\u0026rdquo;) which resembles year, it prints out the full year with the century (e.g., 2018).  Step 2) Now if you replace (\u0026ldquo;%Y\u0026rdquo;) with lowercase, i.e., ( \u0026ldquo;%y) and execute the code the output will display only (18) and not (2018). The century of the year will not display as shown in the screenshot below\n\nStep 3) Strf function can declare the date, day, month and year separately. Also with small changes in the control code in strftime function you can format the style of the text.\n\nInside the strftime function if you replace (%a) with capital A, i.e., (%A) the output will print out as \u0026ldquo;Firday\u0026rdquo; instead of just an abbreviation \u0026ldquo;Fri\u0026rdquo;.\n\nStep 4) With the help of \u0026ldquo;Strftime\u0026rdquo; function we can also retrieve local system time, date or both.\n %C- indicates the local date and time %x- indicates the local date %X- indicates the local time  \nIn the output, you can see the result as expected\nStep 5) The \u0026ldquo;strftime function\u0026rdquo; allows you to call the time in any format 24 hours or 12 hours.\n\nJust by defining control code like %I/H for hour, % M for minute, %S for second, one can call time for different formats\n12 hours time is declared [print now.strftime(\u0026ldquo;%I:%M:%S %P) ]\n24 hours time is declared [print now.strftime(\u0026ldquo;%H:%M\u0026rdquo;)]\nHere is the complete code to convert datetime to String object.\n# #Example file for formatting time and date output # from datetime import datetime def main(): #Times and dates can be formatted using a set of predefined string #Control codes now= datetime.now() #get the current date and time #%c - local date and time, %x-local's date, %X- local's time print(now.strftime(\u0026quot;%c\u0026quot;)) print(now.strftime(\u0026quot;%x\u0026quot;)) print(now.strftime(\u0026quot;%X\u0026quot;)) ##### Time Formatting #### #%I/%H - 12/24 Hour, %M - minute, %S - second, %p - local's AM/PM print(now.strftime(\u0026quot;%I:%M:%S %p\u0026quot;)) # 12-Hour:Minute:Second:AM print(now.strftime(\u0026quot;%H:%M\u0026quot;)) # 24-Hour:Minute if __name__== \u0026quot;__main__\u0026quot;: main()  How to use Timedelta Objects With timedelta objects, you can estimate the time for both future and the past. In other words, it is a timespan to predict any special day, date or time.\nRemember this function is not for printing out the time or date, but something to CALCULATE about the future or past. Let\u0026rsquo;s see an example to understand it better.\nStep 1) To run Timedelta Objects, you need to declare the import statement first and then execute the code\n\n Write import statement for timedelta Now write the code to print out object from time delta as shown in screen shot Run the code. The timedelta represents a span of 365 days, 8 hrs and 15 minutes and prints the same  Confusing? Next step will help-\nStep 2) Let\u0026rsquo;s get today\u0026rsquo;s date and time to check whether our import statement is working well. When code is executed, it prints out today\u0026rsquo;s date which means our import statement is working well\n\nStep 3) We will see how we can retrieve date a year from now through delta objects. When we run the code, it gives the output as expected.\n\nStep 4) Another example of how time delta can be used to calculate future date from current date and time\n\nStep 5) Let\u0026rsquo;s look into a more complex example. I would like to determine how many days past the New Year. Here is how we will proceed\n Using today= date.today() we will get todays date We know the newyear is always on 1-Jan, but the year could be different. Using nyd= date(today.year,1,1) we store the new year in variable nyd if nyd \u0026lt; today: compares whether the current date is greater than the new year. If yes, it enters the while loop ((today-nyd).days) gives the difference between a current date and new year in DAYS  \nThe output shows that \u0026ldquo;New Year Day already went by 11 days ago.\u0026rdquo;\nHere is the complete working code\n# # Example file for working with timedelta objects # from datetime import date from datetime import time from datetime import datetime from datetime import timedelta # construct a basic timedelta and print it print (timedelta(days=365, hours=8, minutes=15)) # print today's date print (\u0026quot;today is: \u0026quot; + str(datetime.now())) # print today's date one year from now print (\u0026quot;one year from now it will be:\u0026quot; + str(datetime.now() + timedelta(days=365))) # create a timedelta that uses more than one argument # print (in one week and 4 days it will be \u0026quot; + str(datetime.now() + timedelta(weeks=1, days=4))) # How many days until New Year's Day? today = date.today() # get todays date nyd = date(today.year, 1, 1) # get New Year Day for the same year # use date comparison to see if New Year Day has already gone for this year # if it has, use the replace() function to get the date for next year if nyd \u0026lt; today: print (\u0026quot;New Year day is already went by %d days ago\u0026quot; % ((today - nyd).days))  Output\n##365 days, 8:15:00 ##today is: 2020-02-06 00:24:07.151286 #one year from now it will be:2021-02-05 00:24:07.151286 #New Year day is already went by 36 days ago  Python 2 Example from datetime import date from datetime import time from datetime import datetime def main(): ##DATETIME OBJECTS #Get today's date from datetime class today=datetime.now() #print today # Get the current time #t = datetime.time(datetime.now()) #print \u0026quot;The current time is\u0026quot;, t #weekday returns 0 (monday) through 6 (sunday) wd = date.weekday(today) #Days start at 0 for monday days= [\u0026quot;monday\u0026quot;,\u0026quot;tuesday\u0026quot;,\u0026quot;wednesday\u0026quot;,\u0026quot;thursday\u0026quot;,\u0026quot;friday\u0026quot;,\u0026quot;saturday\u0026quot;,\u0026quot;sunday\u0026quot;] print \u0026quot;Today is day number %d\u0026quot; % wd print \u0026quot;which is a \u0026quot; + days[wd] if __name__== \u0026quot;__main__\u0026quot;: main()  Output\nToday is day number 3 which is a thursday  # #Example file for formatting time and date output # from datetime import datetime def main(): #Times and dates can be formatted using a set of predefined string #Control codes now= datetime.now() #get the current date and time #%c - local date and time, %x-local's date, %X- local's time print now.strftime(\u0026quot;%c\u0026quot;) print now.strftime(\u0026quot;%x\u0026quot;) print now.strftime(\u0026quot;%X\u0026quot;) ##### Time Formatting #### #%I/%H - 12/24 Hour, %M - minute, %S - second, %p - local's AM/PM print now.strftime(\u0026quot;%I:%M:%S %p\u0026quot;) # 12-Hour:Minute:Second:AM print now.strftime(\u0026quot;%H:%M\u0026quot;) # 24-Hour:Minute if __name__== \u0026quot;__main__\u0026quot;: main()  Output\nThu Feb 6 00:30:28 2020 02/06/20 00:30:28 12:30:28 AM 00:30  # # Example file for working with timedelta objects # from datetime import date from datetime import time from datetime import datetime from datetime import timedelta # construct a basic timedelta and print it print timedelta(days=365, hours=8, minutes=15) # print today's date print \u0026quot;today is: \u0026quot; + str(datetime.now()) # print today's date one year from now print \u0026quot;one year from now it will be:\u0026quot; + str(datetime.now() + timedelta(days=365)) # create a timedelta that uses more than one argument # print \u0026quot;in one week and 4 days it will be \u0026quot; + str(datetime.now() + timedelta(weeks=1, days=4)) # How many days until New Year's Day? today = date.today() # get todays date nyd = date(today.year, 1, 1) # get New Year Day for the same year # use date comparison to see if New Year Day has already gone for this year # if it has, use the replace() function to get the date for next year if nyd \u0026lt; today: print \u0026quot;New Year day is already went by %d days ago\u0026quot; % ((today - nyd).days)  Output\n365 days, 8:15:00 today is: 2020-02-06 00:58:18.425565 one year from now it will be:2021-02-05 00:58:18.425565 New Year day is already went by 36 days ago  Summary For manipulating dates and times in both simple and complex ways datetime module supplies different classes or categories like\n date – Manipulate just date ( Month, day, year) time – Time independent of the day (Hour, minute, second, microsecond) datetime – Combination of time and date (Month, day, year, hour, second, microsecond) timedelta— A duration of time used for manipulating dates tzinfo— An abstract class for dealing with timezones  Using datetime objects\n Importing datetime objects before executing the code is mandatory Using date.today function for printing individual date/month/year as well as indexing the day Using date.time object to get time in hours, minutes, seconds and milliseconds  Formatting Time-Out with \u0026ldquo;str f time function\u0026rdquo;\n Use \u0026ldquo;str f time function\u0026rdquo; to change the format of the year Print day, date, month and year separately, Call out time for any format 12 hrs or 24 hrs  Timedelta Objects\n With timedelta objects, you can estimate the time for both future and the past Calculate the total days left for the special day(birthday) from the current time Calculate the total days passed for special day(birthday) from the current time   Source : .\n "});index.add({'id':171,'href':'/library/tutorials/docs/python/snippets/decapitalize/','title':"decapitalize()",'content':" decapitalize() Decapitalizes the first letter of a string.\nDecapitalize the first letter of the string and then add it with rest of the string. Omit the upper_rest parameter to keep the rest of the string intact, or set it to True to convert to uppercase.\ndef decapitalize(s, upper_rest=False): return s[:1].lower() + (s[1:].upper() if upper_rest else s[1:])  decapitalize('FooBar') # 'fooBar' decapitalize('FooBar', True) # 'fOOBAR'  "});index.add({'id':172,'href':'/library/tutorials/docs/python/snippets/deep_flatten/','title':"deep_flatten()",'content':" deep_flatten() Deep flattens a list.\nUse recursion. Use isinstance() with collections.abc.Iterable to check if an element is iterable. If it is, apply deep_flatten() recursively, otherwise return [lst].\nfrom collections.abc import Iterable def deep_flatten(lst): return [a for i in lst for a in deep_flatten(i)] if isinstance(lst, Iterable) else [lst]  deep_flatten([1, [2], [[3], 4], 5]) # [1,2,3,4,5]  "});index.add({'id':173,'href':'/library/tutorials/docs/python/snippets/degrees_to_rads/','title':"degrees_to_rads()",'content':" degrees_to_rads() Converts an angle from degrees to radians.\nUse math.pi and the degrees to radians formula to convert the angle from degrees to radians.\nfrom math import pi def degrees_to_rads(deg): return (deg * pi) / 180.0  degrees_to_rads(180) # 3.141592653589793  "});index.add({'id':174,'href':'/library/tutorials/docs/python/snippets/delay/','title':"delay()",'content':" delay() Invokes the provided function after ms milliseconds.\nUse time.sleep() to delay the execution of fn by ms / 1000 seconds.\nfrom time import sleep def delay(fn, ms, *args): sleep(ms / 1000) return fn(*args)  delay( lambda x: print(x), 1000, 'later' ) # prints 'later' after one second  "});index.add({'id':175,'href':'/library/tutorials/docs/python/beginer/dictionary/dictionary-beginners-tutorial/','title':"Dictionary(Dict) with Example",'content':" Python Dictionary(Dict): Update, Cmp, Len, Sort, Copy, Items, str with Example Dictionaries are another example of a data structure. A dictionary is used to map or associate things you want to store the keys you need to get them. A dictionary in Python is just like a dictionary in the real world. Python Dictionary are defined into two elements Keys and Values.\n Keys will be a single element Values can be a list or list within a list, numbers, etc.  In this tutorial, we are going to learn,\n Python Dictionary Methods Copying dictionary Updating Dictionary Delete Keys from the dictionary Dictionary items() Method Sorting the Dictionary Python Dictionary in-built Functions Dictionary len() Method Variable Types Python List cmp() Method Dictionary Str(dict)  Syntax for Python Dictionary:\nDict = { ' Tim': 18, xyz,.. }  Dictionary is listed in curly brackets, inside these curly brackets, keys and values are declared. Each key is separated from its value by a colon (:) while each element is separated by commas.\nProperties of Dictionary Keys\nThere are two important points while using dictionary keys\n More than one entry per key is not allowed ( no duplicate key is allowed) The values in the dictionary can be of any type while the keys must be immutable like numbers, tuples or strings. Dictionary keys are case sensitive- Same key name but with the different case are treated as different keys in Python dictionaries.  Python 2 Example\nDict = {'Tim': 18,'Charlie':12,'Tiffany':22,'Robert':25}\tprint (Dict['Tiffany'])  Python 3 Example\nDict = {'Tim': 18,'Charlie':12,'Tiffany':22,'Robert':25}\tprint((Dict['Tiffany']))   In code, we have dictionary name \u0026ldquo;Dict\u0026rdquo; We declared the name and age of the person in the dictionary, where name is \u0026ldquo;Keys\u0026rdquo; and age is the\u0026rdquo;value\u0026rdquo; Now run the code It retrieves the age of tiffany from the dictionary.  Python Dictionary Methods Copying dictionary You can also copy the entire dictionary to new dictionary. For example, here we have copied our original dictionary to new dictionary name \u0026ldquo;Boys\u0026rdquo; and \u0026ldquo;Girls\u0026rdquo;.\nPython 2 Example\nDict = {'Tim': 18,'Charlie':12,'Tiffany':22,'Robert':25}\tBoys = {'Tim': 18,'Charlie':12,'Robert':25} Girls = {'Tiffany':22}\tstudentX=Boys.copy() studentY=Girls.copy() print studentX print studentY  Python 3 Example\nDict = {'Tim': 18,'Charlie':12,'Tiffany':22,'Robert':25}\tBoys = {'Tim': 18,'Charlie':12,'Robert':25} Girls = {'Tiffany':22}\tstudentX=Boys.copy() studentY=Girls.copy() print(studentX) print(studentY)   We have the original dictionary (Dict) with the name and age of the boys and girls together But we want boys list separate from girls list, so we defined the element of boys and girls in a separate dictionary name \u0026ldquo;Boys\u0026rdquo; and \u0026ldquo;Girls.\u0026rdquo; Now again we have created new dictionary name \u0026ldquo;studentX\u0026rdquo; and \u0026ldquo;studentY\u0026rdquo;, where all the keys and values of boy dictionary are copied into studentX, and the girls will be copied in studentY So now you don\u0026rsquo;t have to look into the whole list in main dictionary( Dict) to check who is boy and who is girl, you just have to print studentX if you want boys list and StudentY if you want girls list So, when you run the studentX and studentY dictionary, it will give all the element present in the dictionary of \u0026ldquo;boys\u0026rdquo; and \u0026ldquo;girls\u0026rdquo; separately  Updating Dictionary You can also update a dictionary by adding a new entry or a key-value pair to an existing entry or by deleting an existing entry. Here in the example we will add another name \u0026ldquo;Sarah\u0026rdquo; to our existing dictionary.\nPython 2 Example\nDict = {'Tim': 18,'Charlie':12,'Tiffany':22,'Robert':25}\tDict.update({\u0026quot;Sarah\u0026quot;:9}) print Dict  Python 3 Example\nDict = {'Tim': 18,'Charlie':12,'Tiffany':22,'Robert':25}\tDict.update({\u0026quot;Sarah\u0026quot;:9}) print(Dict)   Our existing dictionary \u0026ldquo;Dict\u0026rdquo; does not have the name \u0026ldquo;Sarah.\u0026rdquo; We use the method Dict.update to add Sarah to our existing dictionary Now run the code, it adds Sarah to our existing dictionary  Delete Keys from the dictionary Python dictionary gives you the liberty to delete any element from the dictionary list. Suppose you don\u0026rsquo;t want the name Charlie in the list, so you can delete the key element by following code.\nPython 2 Example\nDict = {'Tim': 18,'Charlie':12,'Tiffany':22,'Robert':25}\tdel Dict ['Charlie'] print Dict  Python 3 Example\nDict = {'Tim': 18,'Charlie':12,'Tiffany':22,'Robert':25}\tdel Dict ['Charlie'] print(Dict)  When you run this code, it should print the dictionary list without Charlie.\n We used the code del Dict When code executed, it has deleted the Charlie from the main dictionary  Dictionary items() Method The items() method returns a list of tuple pairs (Keys, Value) in the dictionary.\nPython 2 Example\nDict = {'Tim': 18,'Charlie':12,'Tiffany':22,'Robert':25}\tprint \u0026quot;Students Name: %s\u0026quot; % Dict.items()  Python 3 Example\nDict = {'Tim': 18,'Charlie':12,'Tiffany':22,'Robert':25}\tprint(\u0026quot;Students Name: %s\u0026quot; % list(Dict.items()))   We use the code items() method for our Dict. When code was executed, it returns a list of items ( keys and values) from the dictionary  Check if a given key already exists in a dictionary\nFor a given list, you can also check whether our child dictionary exists in a main dictionary or not. Here we have two sub-dictionaries \u0026ldquo;Boys\u0026rdquo; and \u0026ldquo;Girls\u0026rdquo;, now we want to check whether our dictionary Boys exist in our main \u0026ldquo;Dict\u0026rdquo; or not. For that, we use the forloop method with else if method.\nPython 2 Example\nDict = {'Tim': 18,'Charlie':12,'Tiffany':22,'Robert':25} Boys = {'Tim': 18,'Charlie':12,'Robert':25} Girls = {'Tiffany':22} for key in Dict.keys(): if key in Boys.keys(): print True else: print False  Python 3 Example\nDict = {'Tim': 18,'Charlie':12,'Tiffany':22,'Robert':25} Boys = {'Tim': 18,'Charlie':12,'Robert':25} Girls = {'Tiffany':22} for key in list(Dict.keys()): if key in list(Boys.keys()): print(True) else: print(False)   The forloop in code checks each key in the main dictionary for Boys keys If it exists in the main dictionary, it should print true or else it should print false When you execute the code, it will print \u0026ldquo;True\u0026rdquo; for three times, as we got three elements in our \u0026ldquo;Boys\u0026rdquo; dictionary So it indicates that the \u0026ldquo;Boys\u0026rdquo; exist in our main dictionary (Dict)  Sorting the Dictionary In the dictionary, you can also sort the elements. For example, if we want to print the name of the elements of our dictionary alphabetically we have to use the forloop. It will sort each element of dictionary accordingly.\nPython 2 Example\nDict = {'Tim': 18,'Charlie':12,'Tiffany':22,'Robert':25} Boys = {'Tim': 18,'Charlie':12,'Robert':25} Girls = {'Tiffany':22} Students = Dict.keys() Students.sort() for S in Students: print\u0026quot;:\u0026quot;.join((S,str(Dict[S])))  Python 3 Example\nDict = {'Tim': 18,'Charlie':12,'Tiffany':22,'Robert':25} Boys = {'Tim': 18,'Charlie':12,'Robert':25} Girls = {'Tiffany':22} Students = list(Dict.keys()) Students.sort() for S in Students: print(\u0026quot;:\u0026quot;.join((S,str(Dict[S]))))   We declared the variable students for our dictionary \u0026ldquo;Dict.\u0026rdquo; Then we use the code Students.sort, which will sort the element inside our dictionary But to sort each element in dictionary, we run the forloop by declaring variable S Now, when we execute the code the forloop will call each element from the dictionary, and it will print the string and value in an order  Python Dictionary in-built Functions Dictionary len() Method The len() function gives the number of pairs in the dictionary.\nFor example,\nPython 2 Example\nDict = {'Tim': 18,'Charlie':12,'Tiffany':22,'Robert':25}\tprint \u0026quot;Length : %d\u0026quot; % len (Dict)  Python 3 Example\nDict = {'Tim': 18,'Charlie':12,'Tiffany':22,'Robert':25}\tprint(\u0026quot;Length : %d\u0026quot; % len (Dict))  When len (Dict) function is executed it gives the output at \u0026ldquo;4\u0026rdquo; as there are four elements in our dictionary\nVariable Types Python does not require to explicitly declare the reserve memory space; it happens automatically. The assign values to variable \u0026ldquo;=\u0026rdquo; equal sign are used. The code to determine the variable type is \u0026ldquo; %type (Dict).\u0026rdquo;\nPython 2 Example\nDict = {'Tim': 18,'Charlie':12,'Tiffany':22,'Robert':25}\tprint \u0026quot;variable Type: %s\u0026quot; %type (Dict)  Python 3 Example\nDict = {'Tim': 18,'Charlie':12,'Tiffany':22,'Robert':25}\tprint(\u0026quot;variable Type: %s\u0026quot; %type (Dict))   Use the code %type to know the variable type When code was executed, it tells a variable type is a dictionary  Python List cmp() Method The compare method cmp() is used in Python to compare values and keys of two dictionaries. If method returns 0 if both dictionaries are equal, 1 if dic1 \u0026gt; dict2 and -1 if dict1 \u0026lt; dict2.\nPython 2 Example\nBoys = {'Tim': 18,'Charlie':12,'Robert':25} Girls = {'Tiffany':22}\tprint cmp(Girls, Boys)  Python 3 Example\ncmp is not supported in Python 3\n We have two dictionary name \u0026ldquo;Boys\u0026rdquo; and \u0026ldquo;Girls.\u0026rdquo; Which ever you declare first in code \u0026ldquo;cmp(Girls, Boys)\u0026rdquo; will be considered as dictionary 1. In our case, we declared \u0026ldquo;Girls\u0026rdquo; first, so it will be considered as dictionary 1 and boys as dictionary 2 When code is executed it prints out -1, It indicates that our dictionary 1 is less than dictionary 2.  Dictionary Str(dict) With Str() method, you can make a dictionary into a printable string format.\nPython 2 Example\nDict = {'Tim': 18,'Charlie':12,'Tiffany':22,'Robert':25}\tprint \u0026quot;printable string:%s\u0026quot; % str (Dict)  Python 3 Example\nDict = {'Tim': 18,'Charlie':12,'Tiffany':22,'Robert':25}\tprint(\u0026quot;printable string:%s\u0026quot; % str (Dict))   Use the code % str (Dict) It will return the dictionary elements into a printable string format  Here is the list of all Dictionary Methods\n   Method Description Syntax     copy() Copy the entire dictionary to new dictionary dict.copy()   update() Update a dictionary by adding a new entry or a key-value pair to an existing entry or by deleting an existing entry. Dict.update([other])   items() Returns a list of tuple pairs (Keys, Value) in the dictionary. dictionary.items()   sort() You can sort the elements dictionary.sort()   len() Gives the number of pairs in the dictionary. len(dict)   cmp() Compare values and keys of two dictionaries cmp(dict1, dict2)   Str() Make a dictionary into a printable string format Str(dict)    Summary: Dictionaries in a programming language is a type of data-structure used to store information connected in someway. Python Dictionary are defined into two elements Keys and Values. Dictionaries do not store their information in any particular order, so you may not get your information back in the same order you entered it.\n Keys will be a single element Values can be a list or list within a list, numbers, etc. More than one entry per key is not allowed ( no duplicate key is allowed) The values in the dictionary can be of any type while the keys must be immutable like numbers, tuples or strings. Dictionary keys are case sensitive- Same key name but with the different case are treated as different keys in Python dictionaries.   Source : .\n "});index.add({'id':176,'href':'/library/tutorials/docs/python/snippets/difference/','title':"difference()",'content':" difference() Returns the difference between two iterables.\nCreate a set from b, then use list comprehension on a to only keep values not contained in the previously created set, _b.\ndef difference(a, b): _b = set(b) return [item for item in a if item not in _b]  difference([1, 2, 3], [1, 2, 4]) # [3]  "});index.add({'id':177,'href':'/library/tutorials/docs/python/snippets/difference_by/','title':"difference_by()",'content':" difference_by() Returns the difference between two lists, after applying the provided function to each list element of both.\nCreate a set by applying fn to each element in b, then use list comprehension in combination with fn on a to only keep values not contained in the previously created set, _b.\ndef difference_by(a, b, fn): _b = set(map(fn, b)) return [item for item in a if fn(item) not in _b]  from math import floor difference_by([2.1, 1.2], [2.3, 3.4], floor) # [1.2] difference_by([{ 'x': 2 }, { 'x': 1 }], [{ 'x': 1 }], lambda v : v['x']) # [ { x: 2 } ]  "});index.add({'id':178,'href':'/library/tutorials/docs/python/snippets/digitize/','title':"digitize()",'content':" digitize() Converts a number to a list of digits.\nUse map() combined with int on the string representation of n and return a list from the result.\ndef digitize(n): return list(map(int, str(n)))  digitize(123) # [1, 2, 3]  "});index.add({'id':179,'href':'/library/tutorials/docs/','title':"Docs",'content':""});index.add({'id':180,'href':'/library/tutorials/docs/python/snippets/every/','title':"every()",'content':" every() Returns True if the provided function returns True for every element in the list, False otherwise.\nUse all() in combination with map and fn to check if fn returns True for all elements in the list.\ndef every(lst, fn=lambda x: x): return all(map(fn, lst))  every([4, 2, 3], lambda x: x \u0026gt; 1) # True every([1, 2, 3]) # True  "});index.add({'id':181,'href':'/library/tutorials/docs/python/snippets/every_nth/','title':"every_nth()",'content':" every_nth() Returns every nth element in a list.\nUse [nth-1::nth] to create a new list that contains every nth element of the given list.\ndef every_nth(lst, nth): return lst[nth - 1::nth]  every_nth([1, 2, 3, 4, 5, 6], 2) # [ 2, 4, 6 ]  "});index.add({'id':182,'href':'/library/tutorials/docs/python/pandas/pandas-explore-dataset/','title':"Explore Your Dataset",'content':" Using Pandas and Python to Explore Your Dataset Table of Contents  Setting Up Your Environment Using the Pandas Python Library Getting to Know Your Data  Displaying Data Types Showing Basics Statistics Exploring Your Dataset  Getting to Know Pandas\u0026rsquo; Data Structures  Understanding Series Objects Understanding DataFrame Objects  Accessing Series Elements  Using the Indexing Operator Using .loc and .iloc  Accessing DataFrame Elements  Using the Indexing Operator Using .loc and .iloc  Querying Your Dataset Grouping and Aggregating Your Data Manipulating Columns Specifying Data Types Cleaning Data  Missing Values Invalid Values Inconsistent Values  Combining Multiple Datasets Visualizing Your Pandas DataFrame Conclusion  Do you have a large dataset that’s full of interesting insights, but you’re not sure where to start exploring it? Has your boss asked you to generate some statistics from it, but they’re not so easy to extract? These are precisely the use cases where Pandas and Python can help you! With these tools, you’ll be able to slice a large dataset down into manageable parts and glean insight from that information.\nIn this tutorial, you’ll learn how to:\n Calculate metrics about your data Perform basic queries and aggregations Discover and handle incorrect data, inconsistencies, and missing values Visualize your data with plots  You’ll also learn about the differences between the main data structures that Pandas and Python use. To follow along, you can get all of the example code in this tutorial at the link below:\nGet Jupyter Notebook: Click here to get the Jupyter Notebook you\u0026rsquo;ll use to explore data with Pandas in this tutorial.\nRemove ads\nSetting Up Your Environment There are a few things you’ll need to get started with this tutorial. First is a familiarity with Python’s built-in data structures, especially lists and dictionaries. For more information, check out Lists and Tuples in Python and Dictionaries in Python.\nThe second thing you’ll need is a working Python environment. You can follow along in any terminal that has Python 3 installed. If you want to see nicer output, especially for the large NBA dataset you’ll be working with, then you might want to run the examples in a Jupyter notebook.\nNote: If you don’t have Python installed at all, then check out Python 3 Installation \u0026amp; Setup Guide. You can also follow along online in a try-out Jupyter notebook.\nThe last thing you’ll need is the Pandas Python library, which you can install with pip:\n$ python -m pip install pandas  You can also use the Conda package manager:\n$ conda install pandas  If you’re using the Anaconda distribution, then you’re good to go! Anaconda already comes with the Pandas Python library installed.\n Note: Have you heard that there are multiple package managers in the Python world and are somewhat confused about which one to pick? pip and conda are both excellent choices, and they each have their advantages.\n If you’re going to use Python mainly for data science work, then conda is perhaps the better choice. In the conda ecosystem, you have two main alternatives:\n If you want to get a stable data science environment up and running quickly, and you don’t mind downloading 500 MB of data, then check out the Anaconda distribution. If you prefer a more minimalist setup, then check out the section on installing Miniconda in Setting Up Python for Machine Learning on Windows.  The examples in this tutorial have been tested with Python 3.7 and Pandas 0.25.0, but they should also work in older versions. You can get all the code examples you’ll see in this tutorial in a Jupyter notebook by clicking the link below:\nGet Jupyter Notebook: Click here to get the Jupyter Notebook you\u0026rsquo;ll use to explore data with Pandas in this tutorial.\nLet’s get started!\nUsing the Pandas Python Library Now that you’ve installed Pandas, it’s time to have a look at a dataset. In this tutorial, you’ll analyze NBA results provided by FiveThirtyEight in a 17MB CSV file. Create a script download_nba_all_elo.py to download the data:\nimport requests download_url = \u0026quot;https://raw.githubusercontent.com/fivethirtyeight/data/master/nba-elo/nbaallelo.csv\u0026quot; target_csv_path = \u0026quot;nba_all_elo.csv\u0026quot; response = requests.get(download_url) response.raise_for_status() # Check that the request was successful with open(target_csv_path, \u0026quot;wb\u0026quot;) as f: f.write(response.content) print(\u0026quot;Download ready.\u0026quot;)  When you execute the script, it will save the file nba_all_elo.csv in your current working directory.\n Note: You could also use your web browser to download the CSV file.\n However, having a download script has several advantages:\n You can tell where you got your data. You can repeat the download anytime! That’s especially handy if the data is often refreshed. You don’t need to share the 17MB CSV file with your co-workers. Usually, it’s enough to share the download script.  Now you can use the Pandas Python library to take a look at your data:\nimport pandas as pd nba = pd.read_csv(\u0026quot;nba_all_elo.csv\u0026quot;) type(nba) # \u0026lt;class 'pandas.core.frame.DataFrame'\u0026gt;  Here, you follow the convention of importing Pandas in Python with the pd alias. Then, you use .read_csv() to read in your dataset and store it as a DataFrame object in the variable nba.\n Note: Is your data not in CSV format? No worries! The Pandas Python library provides several similar functions like read_json(), read_html(), and read_sql_table(). To learn how to work with these file formats, check out Reading and Writing Files With Pandas or consult the docs.\n You can see how much data nba contains:\nlen(nba) # 126314 nba.shape # (126314, 23)  You use the Python built-in function len() to determine the number of rows. You also use the .shape attribute of the DataFrame to see its dimensionality. The result is a tuple containing the number of rows and columns.\nNow you know that there are 126,314 rows and 23 columns in your dataset. But how can you be sure the dataset really contains basketball stats? You can have a look at the first five rows with .head():\nnba.head()  If you’re following along with a Jupyter notebook, then you’ll see a result like this:\nUnless your screen is quite large, your output probably won’t display all 23 columns. Somewhere in the middle, you’ll see a column of ellipses (...) indicating the missing data. If you’re working in a terminal, then that’s probably more readable than wrapping long rows. However, Jupyter notebooks will allow you to scroll. You can configure Pandas to display all 23 columns like this:\npd.set_option(\u0026quot;display.max.columns\u0026quot;, None)  While it’s practical to see all the columns, you probably won’t need six decimal places! Change it to two:\npd.set_option(\u0026quot;display.precision\u0026quot;, 2)  To verify that you’ve changed the options successfully, you can execute .head() again, or you can display the last five rows with .tail() instead:\nnba.tail()  Now, you should see all the columns, and your data should show two decimal places:\nYou can discover some further possibilities of .head() and .tail() with a small exercise. Can you print the last three lines of your DataFrame? Expand the code block below to see the solution:\nSolution: head \u0026amp; tailShow/Hide\nSimilar to the Python standard library, functions in Pandas also come with several optional parameters. Whenever you bump into an example that looks relevant but is slightly different from your use case, check out the official documentation. The chances are good that you’ll find a solution by tweaking some optional parameters!\nRemove ads\nGetting to Know Your Data You’ve imported a CSV file with the Pandas Python library and had a first look at the contents of your dataset. So far, you’ve only seen the size of your dataset and its first and last few rows. Next, you’ll learn how to examine your data more systematically.\nDisplaying Data Types The first step in getting to know your data is to discover the different data types it contains. While you can put anything into a list, the columns of a DataFrame contain values of a specific data type. When you compare Pandas and Python data structures, you’ll see that this behavior makes Pandas much faster!\nYou can display all columns and their data types with .info():\nnba.info()  This will produce the following output:\nYou’ll see a list of all the columns in your dataset and the type of data each column contains. Here, you can see the data types int64, float64, and object. Pandas uses the NumPy library to work with these types. Later, you’ll meet the more complex categorical data type, which the Pandas Python library implements itself.\nThe object data type is a special one. According to the Pandas Cookbook, the object data type is “a catch-all for columns that Pandas doesn’t recognize as any other specific type.” In practice, it often means that all of the values in the column are strings.\nAlthough you can store arbitrary Python objects in the object data type, you should be aware of the drawbacks to doing so. Strange values in an object column can harm Pandas’ performance and its interoperability with other libraries. For more information, check out the official getting started guide.\nShowing Basics Statistics Now that you’ve seen what data types are in your dataset, it’s time to get an overview of the values each column contains. You can do this with .describe():\nnba.describe()  This function shows you some basic descriptive statistics for all numeric columns:\n\n.describe() only analyzes numeric columns by default, but you can provide other data types if you use the include parameter:\nimport numpy as np nba.describe(include=np.object)  .describe() won’t try to calculate a mean or a standard deviation for the object columns, since they mostly include text strings. However, it will still display some descriptive statistics:\nTake a look at the team_id and fran_id columns. Your dataset contains 104 different team IDs, but only 53 different franchise IDs. Furthermore, the most frequent team ID is BOS, but the most frequent franchise ID Lakers. How is that possible? You’ll need to explore your dataset a bit more to answer this question.\nExploring Your Dataset Exploratory data analysis can help you answer questions about your dataset. For example, you can examine how often specific values occur in a column:\nnba[\u0026quot;team_id\u0026quot;].value_counts() ## output BOS 5997 NYK 5769 LAL 5078 ... SDS 11  nba[\u0026quot;fran_id\u0026quot;].value_counts() ## output Name: team_id, Length: 104, dtype: int64 Lakers 6024 Celtics 5997 Knicks 5769 ... Huskies 60 Name: fran_id, dtype: int64  It seems that a team named \u0026quot;Lakers\u0026quot; played 6024 games, but only 5078 of those were played by the Los Angeles Lakers. Find out who the other \u0026quot;Lakers\u0026quot; team is:\nnba.loc[nba[\u0026quot;fran_id\u0026quot;] == \u0026quot;Lakers\u0026quot;, \u0026quot;team_id\u0026quot;].value_counts() ## output LAL 5078 MNL 946 Name: team_id, dtype: int64  Indeed, the Minneapolis Lakers (\u0026quot;MNL\u0026quot;) played 946 games. You can even find out when they played those games:\nnba.loc[nba[\u0026quot;team_id\u0026quot;] == \u0026quot;MNL\u0026quot;, \u0026quot;date_game\u0026quot;].min() # '1/1/1949'  nba.loc[nba[\u0026quot;team_id\u0026quot;] == \u0026quot;MNL\u0026quot;, \u0026quot;date_game\u0026quot;].max() # '4/9/1959' nba.loc[nba[\u0026quot;team_id\u0026quot;] == \u0026quot;MNL\u0026quot;, \u0026quot;date_game\u0026quot;].agg((\u0026quot;min\u0026quot;, \u0026quot;max\u0026quot;)) # min 1/1/1949 # max 4/9/1959 # Name: date_game, dtype: object  It looks like the Minneapolis Lakers played between the years of 1949 and 1959. That explains why you might not recognize this team!\nYou’ve also found out why the Boston Celtics team \u0026quot;BOS\u0026quot; played the most games in the dataset. Let’s analyze their history also a little bit. Find out how many points the Boston Celtics have scored during all matches contained in this dataset. Expand the code block below for the solution:\nSolution: DataFrame introShow/Hide\nYou’ve got a taste for the capabilities of a Pandas DataFrame. In the following sections, you’ll expand on the techniques you’ve just used, but first, you’ll zoom in and learn how this powerful data structure works.\nGetting to Know Pandas’ Data Structures While a DataFrame provides functions that can feel quite intuitive, the underlying concepts are a bit trickier to understand. For this reason, you’ll set aside the vast NBA DataFrame and build some smaller Pandas objects from scratch.\nUnderstanding Series Objects Python’s most basic data structure is the list, which is also a good starting point for getting to know pandas.Series objects. Create a new Series object based on a list:\nrevenues = pd.Series([5555, 7000, 1980]) revenues ## output 0 5555 1 7000 2 1980 dtype: int64  You’ve used the list [5555, 7000, 1980] to create a Series object called revenues. A Series object wraps two components:\n A sequence of values A sequence of identifiers, which is the index  You can access these components with .values and .index, respectively:\nrevenues.values # array([5555, 7000, 1980]) revenues.index # RangeIndex(start=0, stop=3, step=1)  revenues.values returns the values in the Series, whereas revenues.index returns the positional index.\n Note: If you’re familiar with NumPy, then it might be interesting for you to note that the values of a Series object are actually n-dimensional arrays:\n type(revenues.values) # \u0026lt;class 'numpy.ndarray'\u0026gt;  If you’re not familiar with NumPy, then there’s no need to worry! You can explore the ins and outs of your dataset with the Pandas Python library alone. However, if you’re curious about what Pandas does behind the scenes, then check out Look Ma, No For-Loops: Array Programming With NumPy.\nWhile Pandas builds on NumPy, a significant difference is in their indexing. Just like a NumPy array, a Pandas Series also has an integer index that’s implicitly defined. This implicit index indicates the element’s position in the Series.\nHowever, a Series can also have an arbitrary type of index. You can think of this explicit index as labels for a specific row:\ncity_revenues = pd.Series( ... [4200, 8000, 6500], ... index=[\u0026quot;Amsterdam\u0026quot;, \u0026quot;Toronto\u0026quot;, \u0026quot;Tokyo\u0026quot;] ... ) city_revenues ## output Amsterdam 4200 Toronto 8000 Tokyo 6500 dtype: int64  Here, the index is a list of city names represented by strings. You may have noticed that Python dictionaries use string indices as well, and this is a handy analogy to keep in mind! You can use the code blocks above to distinguish between two types of Series:\n revenues: This Series behaves like a Python list because it only has a positional index. city_revenues: This Series acts like a Python dictionary because it features both a positional and a label index.  Here\u0026rsquo;s how to construct a Series with a label index from a Python dictionary:\ncity_employee_count = pd.Series({\u0026quot;Amsterdam\u0026quot;: 5, \u0026quot;Tokyo\u0026quot;: 8}) city_employee_count ## output Amsterdam 5 Tokyo 8 dtype: int64  The dictionary keys become the index, and the dictionary values are the Series values.\nJust like dictionaries, Series also support .keys() and the in keyword:\ncity_employee_count.keys() # Index(['Amsterdam', 'Tokyo'], dtype='object') \u0026quot;Tokyo\u0026quot; in city_employee_count # True \u0026quot;New York\u0026quot; in city_employee_count # False  You can use these methods to answer questions about your dataset quickly.\nRemove ads\nUnderstanding DataFrame Objects While a Series is a pretty powerful data structure, it has its limitations. For example, you can only store one attribute per key. As you’ve seen with the nba dataset, which features 23 columns, the Pandas Python library has more to offer with its DataFrame. This data structure is a sequence of Series objects that share the same index.\nIf you’ve followed along with the Series examples, then you should already have two Series objects with cities as keys:\n city_revenues city_employee_count  You can combine these objects into a DataFrame by providing a dictionary in the constructor. The dictionary keys will become the column names, and the values should contain the Series objects:\ncity_data = pd.DataFrame({ ... \u0026quot;revenue\u0026quot;: city_revenues, ... \u0026quot;employee_count\u0026quot;: city_employee_count ... }) city_data ## output revenue employee_count Amsterdam 4200 5.0 Tokyo 6500 8.0 Toronto 8000 NaN  Note how Pandas replaced the missing employee_count value for Toronto with NaN.\nThe new DataFrame index is the union of the two Series indices:\ncity_data.index # Index(['Amsterdam', 'Tokyo', 'Toronto'], dtype='object')  Just like a Series, a DataFrame also stores its values in a NumPy array:\ncity_data.values # array([[4.2e+03, 5.0e+00], # [6.5e+03, 8.0e+00], # [8.0e+03, nan]])  You can also refer to the 2 dimensions of a DataFrame as axes:\ncity_data.axes #[Index(['Amsterdam', 'Tokyo', 'Toronto'], dtype='object'), # Index(['revenue', 'employee_count'], dtype='object')] city_data.axes[0] # Index(['Amsterdam', 'Tokyo', 'Toronto'], dtype='object') city_data.axes[1] # Index(['revenue', 'employee_count'], dtype='object')`  The axis marked with 0 is the row index, and the axis marked with 1 is the column index. This terminology is important to know because you’ll encounter several DataFrame methods that accept an axis parameter.\nA DataFrame is also a dictionary-like data structure, so it also supports .keys() and the in keyword. However, for a DataFrame these don’t relate to the index, but to the columns:\ncity_data.keys() # Index(['revenue', 'employee_count'], dtype='object') \u0026quot;Amsterdam\u0026quot; in city_data # False \u0026quot;revenue\u0026quot; in city_data # True  You can see these concepts in action with the bigger NBA dataset. Does it contain a column called \u0026quot;points\u0026quot;, or was it called \u0026quot;pts\u0026quot;? To answer this question, display the index and the axes of the nba dataset, then expand the code block below for the solution:\nSolution: NBA indexShow/Hide\nAs you use these methods to answer questions about your dataset, be sure to keep in mind whether you’re working with a Series or a DataFrame so that your interpretation is accurate.\nAccessing Series Elements In the section above, you’ve created a Pandas Series based on a Python list and compared the two data structures. You’ve seen how a Series object is similar to lists and dictionaries in several ways. A further similarity is that you can use the indexing operator ([]) for Series as well.\nYou’ll also learn how to use two Pandas-specific access methods:\n .loc .iloc  You’ll see that these data access methods can be much more readable than the indexing operator.\nUsing the Indexing Operator Recall that a Series has two indices:\n A positional or implicit index, which is always a RangeIndex A label or explicit index, which can contain any hashable objects  Next, revisit the city_revenues object:\ncity_revenues # Amsterdam 4200 # Toronto 8000 # Tokyo 6500 # dtype: int64  You can conveniently access the values in a Series with both the label and positional indices:\ncity_revenues[\u0026quot;Toronto\u0026quot;] # 8000 city_revenues[1] # 8000  You can also use negative indices and slices, just like you would for a list:\ncity_revenues[-1] # 6500 city_revenues[1:] # Toronto 8000 # Tokyo 6500 # dtype: int64 city_revenues[\u0026quot;Toronto\u0026quot;:] # Toronto 8000 # Tokyo 6500 # dtype: int64  If you want to learn more about the possibilities of the indexing operator, then check out Lists and Tuples in Python.\nUsing .loc and .iloc The indexing operator ([]) is convenient, but there’s a caveat. What if the labels are also numbers? Say you have to work with a Series object like this:\ncolors = pd.Series( ... [\u0026quot;red\u0026quot;, \u0026quot;purple\u0026quot;, \u0026quot;blue\u0026quot;, \u0026quot;green\u0026quot;, \u0026quot;yellow\u0026quot;], ... index=[1, 2, 3, 5, 8] ... ) colors ## output 1 red 2 purple 3 blue 5 green 8 yellow dtype: object`  What will colors[1] return? For a positional index, colors[1] is \u0026quot;purple\u0026quot;. However, if you go by the label index, then colors[1] is referring to \u0026quot;red\u0026quot;.\nThe good news is, you don’t have to figure it out! Instead, to avoid confusion, the Pandas Python library provides two data access methods:\n .loc refers to the label index. .iloc refers to the positional index.  These data access methods are much more readable:\ncolors.loc[1] # 'red' colors.iloc[1] # 'purple'  colors.loc[1] returned \u0026quot;red\u0026quot;, the element with the label 1. colors.iloc[1] returned \u0026quot;purple\u0026quot;, the element with the index 1.\nThe following figure shows which elements .loc and .iloc refer to:\nAgain, .loc points to the label index on the right-hand side of the image. Meanwhile, .iloc points to the positional index on the left-hand side of the picture.\nIt’s easier to keep in mind the distinction between .loc and .iloc than it is to figure out what the indexing operator will return. Even if you’re familiar with all the quirks of the indexing operator, it can be dangerous to assume that everybody who reads your code has internalized those rules as well!\n Note: In addition to being confusing for Series with numeric labels, the Python indexing operator has some performance drawbacks. It’s perfectly okay to use it in interactive sessions for ad-hoc analysis, but for production code, the .loc and .iloc data access methods are preferable. For further details, check out the Pandas User Guide section on indexing and selecting data.\n .loc and .iloc also support the features you would expect from indexing operators, like slicing. However, these data access methods have an important difference. While .iloc excludes the closing element, .loc includes it. Take a look at this code block:\n# Return the elements with the implicit index: 1, 2 colors.iloc[1:3] # 2 purple # 3 blue # dtype: object  If you compare this code with the image above, then you can see that colors.iloc[1:3] returns the elements with the positional indices of 1 and 2. The closing item \u0026quot;green\u0026quot; with a positional index of 3 is excluded.\nOn the other hand, .loc includes the closing element:\n# Return the elements with the explicit index between 3 and 8 colors.loc[3:8] ## output 3 blue 5 green 8 yellow dtype: object  This code block says to return all elements with a label index between 3 and 8. Here, the closing item \u0026quot;yellow\u0026quot; has a label index of 8 and is included in the output.\nYou can also pass a negative positional index to .iloc:\ncolors.iloc[-2] # 'green'  You start from the end of the Series and return the second element.\n Note: There used to be an .ix indexer, which tried to guess whether it should apply positional or label indexing depending on the data type of the index. Because it caused a lot of confusion, it has been deprecated since Pandas version 0.20.0.\n It’s highly recommended that you do not use .ix for indexing. Instead, always use .loc for label indexing and .iloc for positional indexing. For further details, check out the Pandas User Guide.\nYou can use the code blocks above to distinguish between two Series behaviors:\n You can use .iloc on a Series similar to using [] on a list. You can use .loc on a Series similar to using [] on a dictionary.  Be sure to keep these distinctions in mind as you access elements of your Series objects.\nAccessing DataFrame Elements Since a DataFrame consists of Series objects, you can use the very same tools to access its elements. The crucial difference is the additional dimension of the DataFrame. You’ll use the indexing operator for the columns and the access methods .loc and .iloc on the rows.\nUsing the Indexing Operator If you think of a DataFrame as a dictionary whose values are Series, then it makes sense that you can access its columns with the indexing operator:\ncity_data[\u0026quot;revenue\u0026quot;] # Amsterdam 4200 # Tokyo 6500 # Toronto 8000 # Name: revenue, dtype: int64  type(city_data[\u0026quot;revenue\u0026quot;]) # pandas.core.series.Series  Here, you use the indexing operator to select the column labeled \u0026quot;revenue\u0026quot;.\nIf the column name is a string, then you can use attribute-style accessing with dot notation as well:\ncity_data.revenue ## output Amsterdam 4200 Tokyo 6500 Toronto 8000 Name: revenue, dtype: int64  city_data[\u0026quot;revenue\u0026quot;] and city_data.revenue return the same output.\nThere’s one situation where accessing DataFrame elements with dot notation may not work or may lead to surprises. This is when a column name coincides with a DataFrame attribute or method name:\ntoys = pd.DataFrame([ ... {\u0026quot;name\u0026quot;: \u0026quot;ball\u0026quot;, \u0026quot;shape\u0026quot;: \u0026quot;sphere\u0026quot;}, ... {\u0026quot;name\u0026quot;: \u0026quot;Rubik's cube\u0026quot;, \u0026quot;shape\u0026quot;: \u0026quot;cube\u0026quot;} ... ]) toys[\u0026quot;shape\u0026quot;] ## output 0 sphere 1 cube Name: shape, dtype: object  toys.shape # (2, 2)  The indexing operation toys[\u0026quot;shape\u0026quot;] returns the correct data, but the attribute-style operation toys.shape still returns the shape of the DataFrame. You should only use attribute-style accessing in interactive sessions or for read operations. You shouldn’t use it for production code or for manipulating data (such as defining new columns).\nUsing .loc and .iloc Similar to Series, a DataFrame also provides .loc and .iloc data access methods. Remember, .loc uses the label and .iloc the positional index:\ncity_data.loccity_data.loc[\u0026quot;Amsterdam\u0026quot;] ## output revenue 4200.0 employee_count 5.0 Name: Amsterdam, dtype: float64  city_data.loc[\u0026quot;Tokyo\u0026quot;: \u0026quot;Toronto\u0026quot;] # output revenue employee_count Tokyo 6500 8.0 Toronto 8000 NaN city_data.iloc[1] # output revenue 6500.0 employee_count 8.0 Name: Tokyo, dtype: float64  Each line of code selects a different row from city_data:\n city_data.loc[\u0026quot;Amsterdam\u0026quot;] selects the row with the label index \u0026quot;Amsterdam\u0026quot;. city_data.loc[\u0026quot;Tokyo\u0026quot;: \u0026quot;Toronto\u0026quot;] selects the rows with label indices from \u0026quot;Tokyo\u0026quot; to \u0026quot;Toronto\u0026quot;. Remember, .loc is inclusive. city_data.iloc[1] selects the row with the positional index 1, which is \u0026quot;Tokyo\u0026quot;.  Alright, you’ve used .loc and .iloc on small data structures. Now, it’s time to practice with something bigger! Use a data access method to display the second-to-last row of the nba dataset. Then, expand the code block below to see a solution:\nSolution: NBA accessing rowsShow/Hide\nFor a DataFrame, the data access methods .loc and .iloc also accept a second parameter. While the first parameter selects rows based on the indices, the second parameter selects the columns. You can use these parameters together to select a subset of rows and columns from your DataFrame:\ncity_data.loc[\u0026quot;Amsterdam\u0026quot;: \u0026quot;Tokyo\u0026quot;, \u0026quot;revenue\u0026quot;] # output Amsterdam 4200 Tokyo 6500 Name: revenue, dtype: int64  Note that you separate the parameters with a comma (,). The first parameter, \u0026quot;Amsterdam\u0026quot; : \u0026quot;Tokyo,\u0026quot; says to select all rows between those two labels. The second parameter comes after the comma and says to select the \u0026quot;revenue\u0026quot; column.\nIt’s time to see the same construct in action with the bigger nba dataset. Select all games between the labels 5555 and 5559. You’re only interested in the names of the teams and the scores, so select those elements as well. Expand the code block below to see a solution:\nSolution: NBA accessing a subsetShow/Hide\nWith data access methods like .loc and .iloc, you can select just the right subset of your DataFrame to help you answer questions about your dataset.\nQuerying Your Dataset You’ve seen how to access subsets of a huge dataset based on its indices. Now, you’ll select rows based on the values in your dataset’s columns to query your data. For example, you can create a new DataFrame that contains only games played after 2010:\ncurrent_decade = nba[nba[\u0026quot;year_id\u0026quot;] \u0026gt; 2010] current_decade.shape # (12658, 23)  You still have all 23 columns, but your new DataFrame only consists of rows where the value in the \u0026quot;year_id\u0026quot; column is greater than 2010.\nYou can also select the rows where a specific field is not null:\ngames_with_notes = nba[nba[\u0026quot;notes\u0026quot;].notnull()] games_with_notes.shape # (5424, 23)  This can be helpful if you want to avoid any missing values in a column. You can also use .notna() to achieve the same goal.\nYou can even access values of the object data type as str and perform string methods on them:\ners = nba[nba[\u0026quot;fran_id\u0026quot;].str.endswith(\u0026quot;ers\u0026quot;)] ers.shape # (27797, 23)  You use .str.endswith() to filter your dataset and find all games where the home team’s name ends with \u0026quot;ers\u0026quot;.\nYou can combine multiple criteria and query your dataset as well. To do this, be sure to put each one in parentheses and use the logical operators | and \u0026amp; to separate them.\n Note: The operators and, or, \u0026amp;\u0026amp;, and || won’t work here. If you’re curious as to why then check out the section on how the Pandas Python library uses Boolean operators in Python Pandas: Tricks \u0026amp; Features You May Not Know.\n Do a search for Baltimore games where both teams scored over 100 points. In order to see each game only once, you’ll need to exclude duplicates:\nnba[ ... (nba[\u0026quot;_iscopy\u0026quot;] == 0) \u0026amp; ... (nba[\u0026quot;pts\u0026quot;] \u0026gt; 100) \u0026amp; ... (nba[\u0026quot;opp_pts\u0026quot;] \u0026gt; 100) \u0026amp; ... (nba[\u0026quot;team_id\u0026quot;] == \u0026quot;BLB\u0026quot;) ... ]  Here, you use nba[\u0026quot;_iscopy\u0026quot;] == 0 to include only the entries that aren’t copies.\nYour output should contain five eventful games:\nTry to build another query with multiple criteria. In the spring of 1992, both teams from Los Angeles had to play a home game at another court. Query your dataset to find those two games. Both teams have an ID starting with \u0026quot;LA\u0026quot;. Expand the code block below to see a solution:\nSolution: QueriesShow/Hide\nWhen you know how to query your dataset with multiple criteria, you’ll be able to answer more specific questions about your dataset.\nGrouping and Aggregating Your Data You may also want to learn other features of your dataset, like the sum, mean, or average value of a group of elements. Luckily, the Pandas Python library offers grouping and aggregation functions to help you accomplish this task.\nA Series has more than twenty different methods for calculating descriptive statistics. Here are some examples:\ncity_revenues.sum() # 18700 city_revenues.max() # 8000  The first method returns the total of city_revenues, while the second returns the max value. There are other methods you can use, like .min() and .mean().\nRemember, a column of a DataFrame is actually a Series object. For this reason, you can use these same functions on the columns of nba:\npoints = nba[\u0026quot;pts\u0026quot;] type(points) # \u0026lt;class 'pandas.core.series.Series'\u0026gt; points.sum() # 12976235  A DataFrame can have multiple columns, which introduces new possibilities for aggregations, like\ngrouping:\nnba.groupby(\u0026quot;fran_id\u0026quot;, sort=False)[\u0026quot;pts\u0026quot;].sum() # output fran_id Huskies 3995 Knicks 582497 Stags 20398 Falcons 3797 Capitols 22387  By default, Pandas sorts the group keys during the call to .groupby(). If you don’t want to sort, then pass sort=False. This parameter can lead to performance gains.\nYou can also group by multiple columns:\nnba[ ... (nba[\u0026quot;fran_id\u0026quot;] == \u0026quot;Spurs\u0026quot;) \u0026amp; ... (nba[\u0026quot;year_id\u0026quot;] \u0026gt; 2010) ... ].groupby([\u0026quot;year_id\u0026quot;, \u0026quot;game_result\u0026quot;])[\u0026quot;game_id\u0026quot;].count() ## output year_id game_result 2011 L 25 W 63 2012 L 20 W 60 2013 L 30 W 73 2014 L 27 W 78 2015 L 31 W 58 Name: game_id, dtype: int64  You can practice these basics with an exercise. Take a look at the Golden State Warriors’ 2014-15 season (year_id: 2015). How many wins and losses did they score during the regular season and the playoffs? Expand the code block below for the solution:\nSolution: AggregationShow/Hide\nIn the examples above, you’ve only scratched the surface of the aggregation functions that are available to you in the Pandas Python library. To see more examples of how to use them, check out Pandas GroupBy: Your Guide to Grouping Data in Python.\nManipulating Columns You’ll need to know how to manipulate your dataset’s columns in different phases of the data analysis process. You can add and drop columns as part of the initial data cleaning phase, or later based on the insights of your analysis.\nCreate a copy of your original DataFrame to work with:\ndf = nba.copy() df.shape # (126314, 23)  You can define new columns based on the existing ones:\ndf[\u0026quot;difference\u0026quot;] = df.pts - df.opp_pts df.shape # (126314, 24)  Here, you used the \u0026quot;pts\u0026quot; and \u0026quot;opp_pts\u0026quot; columns to create a new one called \u0026quot;difference\u0026quot;. This new column has the same functions as the old ones:\ndf[\u0026quot;difference\u0026quot;].max() # 68  Here, you used an aggregation function .max() to find the largest value of your new column.\nYou can also rename the columns of your dataset. It seems that \u0026quot;game_result\u0026quot; and \u0026quot;game_location\u0026quot; are too verbose, so go ahead and rename them now:\nrenamed_df = df.rename( ... columns={\u0026quot;game_result\u0026quot;: \u0026quot;result\u0026quot;, \u0026quot;game_location\u0026quot;: \u0026quot;location\u0026quot;} ... ) renamed_df.info() ## output \u0026lt;class 'pandas.core.frame.DataFrame'\u0026gt; RangeIndex: 126314 entries, 0 to 126313 Data columns (total 24 columns): gameorder 126314 non-null int64 ... location 126314 non-null object result 126314 non-null object forecast 126314 non-null float64 notes 5424 non-null object difference 126314 non-null int64 dtypes: float64(6), int64(8), object(10) memory usage: 23.1+ MB  Note that there’s a new object, renamed_df. Like several other data manipulation methods, .rename() returns a new DataFrame by default. If you want to manipulate the original DataFrame directly, then .rename() also provides an inplace parameter that you can set to True.\nYour dataset might contain columns that you don’t need. For example, Elo ratings may be a fascinating concept to some, but you won’t analyze them in this tutorial. You can delete the four columns related to Elo:\ndf.shape # (126314, 24) elo_columns = [\u0026quot;elo_i\u0026quot;, \u0026quot;elo_n\u0026quot;, \u0026quot;opp_elo_i\u0026quot;, \u0026quot;opp_elo_n\u0026quot;] df.drop(elo_columns, inplace=True, axis=1) df.shape # (126314, 20)  Remember, you added the new column \u0026quot;difference\u0026quot; in a previous example, bringing the total number of columns to 24. When you remove the four Elo columns, the total number of columns drops to 20.\nSpecifying Data Types When you create a new DataFrame, either by calling a constructor or reading a CSV file, Pandas assigns a data type to each column based on its values. While it does a pretty good job, it’s not perfect. If you choose the right data type for your columns upfront, then you can significantly improve your code’s performance.\nTake another look at the columns of the nba dataset:\ndf.info()  You’ll see the same output as before:\nTen of your columns have the data type object. Most of these object columns contain arbitrary text, but there are also some candidates for data type conversion. For example, take a look at the date_game column:\ndf[\u0026quot;date_game\u0026quot;] = pd.to_datetime(df[\u0026quot;date_game\u0026quot;])  Here, you use .to_datetime() to specify all game dates as datetime objects.\nOther columns contain text that are a bit more structured. The game_location column can have only three different values:\ndf[\u0026quot;game_location\u0026quot;].nunique() # 3 df[\u0026quot;game_location\u0026quot;].value_counts() ## output A 63138 H 63138 N 38 Name: game_location, dtype: int64  Which data type would you use in a relational database for such a column? You would probably not use a varchar type, but rather an enum. Pandas provides the categorical data type for the same purpose:\ndf[\u0026quot;game_location\u0026quot;] = pd.Categorical(df[\u0026quot;game_location\u0026quot;]) df[\u0026quot;game_location\u0026quot;].dtype # CategoricalDtype(categories=['A', 'H', 'N'], ordered=False)  categorical data has a few advantages over unstructured text. When you specify the categorical data type, you make validation easier and save a ton of memory, as Pandas will only use the unique values internally. The higher the ratio of total values to unique values, the more space savings you’ll get.\nRun df.info() again. You should see that changing the game_location data type from object to categorical has decreased the memory usage.\n Note: The categorical data type also gives you access to additional methods through the .cat accessor. To learn more, check out the official docs.\n You’ll often encounter datasets with too many text columns. An essential skill for data scientists to have is the ability to spot which columns they can convert to a more performant data type.\nTake a moment to practice this now. Find another column in the nba dataset that has a generic data type and convert it to a more specific one. You can expand the code block below to see one potential solution:\nSolution: Specifying Data TypesShow/Hide\nAs you work with more massive datasets, memory savings becomes especially crucial. Be sure to keep performance in mind as you continue to explore your datasets.\nCleaning Data You may be surprised to find this section so late in the tutorial! Usually, you’d take a critical look at your dataset to fix any issues before you move on to a more sophisticated analysis. However, in this tutorial, you’ll rely on the techniques that you’ve learned in the previous sections to clean your dataset.\nMissing Values Have you ever wondered why .info() shows how many non-null values a column contains? The reason why is that this is vital information. Null values often indicate a problem in the data-gathering process. They can make several analysis techniques, like different types of machine learning, difficult or even impossible.\nWhen you inspect the nba dataset with nba.info(), you’ll see that it’s quite neat. Only the column notes contains null values for the majority of its rows:\nThis output shows that the notes column has only 5424 non-null values. That means that over 120,000 rows of your dataset have null values in this column.\nSometimes, the easiest way to deal with records containing missing values is to ignore them. You can remove all the rows with missing values using .dropna():\nrows_without_missing_data = nba.dropna() rows_without_missing_data.shape # (5424, 23)  Of course, this kind of data cleanup doesn’t make sense for your nba dataset, because it’s not a problem for a game to lack notes. But if your dataset contains a million valid records and a hundred where relevant data is missing, then dropping the incomplete records can be a reasonable solution.\nYou can also drop problematic columns if they’re not relevant for your analysis. To do this, use .dropna() again and provide the axis=1 parameter:\ndata_without_missing_columns = nba.dropna(axis=1) data_without_missing_columns.shape # (126314, 22)  Now, the resulting DataFrame contains all 126,314 games, but not the sometimes empty notes column.\nIf there’s a meaningful default value for your use case, then you can also replace the missing values with that:\ndata_with_default_notes = nba.copy() data_with_default_notes[\u0026quot;notes\u0026quot;].fillna( ... value=\u0026quot;no notes at all\u0026quot;, ... inplace=True ... ) data_with_default_notes[\u0026quot;notes\u0026quot;].describe() # output count 126314 unique 232 top no notes at all freq 120890 Name: notes, dtype: object  Here, you fill the empty notes rows with the string \u0026quot;no notes at all\u0026quot;.\nInvalid Values Invalid values can be even more dangerous than missing values. Often, you can perform your data analysis as expected, but the results you get are peculiar. This is especially important if your dataset is enormous or used manual entry. Invalid values are often more challenging to detect, but you can implement some sanity checks with queries and aggregations.\nOne thing you can do is validate the ranges of your data. For this, .describe() is quite handy. Recall that it returns the following output:\nThe year_id varies between 1947 and 2015. That sounds plausible.\nWhat about pts? How can the minimum be 0? Let’s have a look at those games:\nnba[nba[\u0026quot;pts\u0026quot;] == 0]  This query returns a single row:\nIt seems the game was forfeited. Depending on your analysis, you may want to remove it from the dataset.\nInconsistent Values Sometimes a value would be entirely realistic in and of itself, but it doesn’t fit with the values in the other columns. You can define some query criteria that are mutually exclusive and verify that these don’t occur together.\nIn the NBA dataset, the values of the fields pts, opp_pts and game_result should be consistent with each other. You can check this using the .empty attribute:\nnba[(nba[\u0026quot;pts\u0026quot;] \u0026gt; nba[\u0026quot;opp_pts\u0026quot;]) \u0026amp; (nba[\u0026quot;game_result\u0026quot;] != 'W')].empty # True nba[(nba[\u0026quot;pts\u0026quot;] \u0026lt; nba[\u0026quot;opp_pts\u0026quot;]) \u0026amp; (nba[\u0026quot;game_result\u0026quot;] != 'L')].empty # True  Fortunately, both of these queries return an empty DataFrame.\nBe prepared for surprises whenever you’re working with raw datasets, especially if they were gathered from different sources or through a complex pipeline. You might see rows where a team scored more points than their opponent, but still didn’t win—at least, according to your dataset! To avoid situations like this, make sure you add further data cleaning techniques to your Pandas and Python arsenal.\nCombining Multiple Datasets In the previous section, you’ve learned how to clean a messy dataset. Another aspect of real-world data is that it often comes in multiple pieces. In this section, you’ll learn how to grab those pieces and combine them into one dataset that’s ready for analysis.\nEarlier, you combined two Series objects into a DataFrame based on their indices. Now, you’ll take this one step further and use .concat() to combine city_data with another DataFrame. Say you’ve managed to gather some data on two more cities:\nfurther_city_data = pd.DataFrame( ... {\u0026quot;revenue\u0026quot;: [7000, 3400], \u0026quot;employee_count\u0026quot;:[2, 2]}, ... index=[\u0026quot;New York\u0026quot;, \u0026quot;Barcelona\u0026quot;] ... )  This second DataFrame contains info on the cities \u0026quot;New York\u0026quot; and \u0026quot;Barcelona\u0026quot;.\nYou can add these cities to city_data using .concat():\nall_city_data = pd.concat([city_data, further_city_data], sort=False) all_city_data ## output Amsterdam 4200 5.0 Tokyo 6500 8.0 Toronto 8000 NaN New York 7000 2.0 Barcelona 3400 2.0  Now, the new variable all_city_data contains the values from both DataFrame objects.\n Note: As of Pandas version 0.25.0, the sort parameter’s default value is True, but this will change to False soon. It’s good practice to provide an explicit value for this parameter to ensure that your code works consistently in different Pandas and Python versions. For more info, consult the Pandas User Guide.\n By default, concat() combines along axis=0. In other words, it appends rows. You can also use it to append columns by supplying the parameter axis=1:\ncity_countries = pd.DataFrame({ ... \u0026quot;country\u0026quot;: [\u0026quot;Holland\u0026quot;, \u0026quot;Japan\u0026quot;, \u0026quot;Holland\u0026quot;, \u0026quot;Canada\u0026quot;, \u0026quot;Spain\u0026quot;], ... \u0026quot;capital\u0026quot;: [1, 1, 0, 0, 0]}, ... index=[\u0026quot;Amsterdam\u0026quot;, \u0026quot;Tokyo\u0026quot;, \u0026quot;Rotterdam\u0026quot;, \u0026quot;Toronto\u0026quot;, \u0026quot;Barcelona\u0026quot;] ... ) cities = pd.concat([all_city_data, city_countries], axis=1, sort=False) cities ## output revenue employee_count country capital Amsterdam 4200.0 5.0 Holland 1.0 Tokyo 6500.0 8.0 Japan 1.0 Toronto 8000.0 NaN Canada 0.0 New York 7000.0 2.0 NaN NaN Barcelona 3400.0 2.0 Spain 0.0 Rotterdam NaN NaN Holland 0.0  Note how Pandas added NaN for the missing values. If you want to combine only the cities that appear in both DataFrame objects, then you can set the join parameter to inner:\npd.concat([all_city_data, city_countries], axis=1, join=\u0026quot;inner\u0026quot;) ## output revenue employee_count country capital Amsterdam 4200 5.0 Holland 1 Tokyo 6500 8.0 Japan 1 Toronto 8000 NaN Canada 0 Barcelona 3400 2.0 Spain 0  While it’s most straightforward to combine data based on the index, it’s not the only possibility. You can use .merge() to implement a join operation similar to the one from SQL:\ncountries = pd.DataFrame({ ... \u0026quot;population_millions\u0026quot;: [17, 127, 37], ... \u0026quot;continent\u0026quot;: [\u0026quot;Europe\u0026quot;, \u0026quot;Asia\u0026quot;, \u0026quot;North America\u0026quot;] ... }, index= [\u0026quot;Holland\u0026quot;, \u0026quot;Japan\u0026quot;, \u0026quot;Canada\u0026quot;]) pd.merge(cities, countries, left_on=\u0026quot;country\u0026quot;, right_index=True)  Here, you pass the parameter left_on=\u0026quot;country\u0026quot; to .merge() to indicate what column you want to join on. The result is a bigger DataFrame that contains not only city data, but also the population and continent of the respective countries:\nNote that the result contains only the cities where the country is known and appears in the joined DataFrame.\n.merge() performs an inner join by default. If you want to include all cities in the result, then you need to provide the how parameter:\npd.merge( ... cities, ... countries, ... left_on=\u0026quot;country\u0026quot;, ... right_index=True, ... how=\u0026quot;left\u0026quot; ... )  With this left join, you’ll see all the cities, including those without country data:\nWelcome back, New York \u0026amp; Barcelona!\nVisualizing Your Pandas DataFrame Data visualization is one of the things that works much better in a Jupyter notebook than in a terminal, so go ahead and fire one up. If you need help getting started, then check out Jupyter Notebook: An Introduction. You can also access the Jupyter notebook that contains the examples from this tutorial by clicking the link below:\nGet Jupyter Notebook: Click here to get the Jupyter Notebook you\u0026rsquo;ll use to explore data with Pandas in this tutorial.\nInclude this line to show plots directly in the notebook:\n%matplotlib inline  Both Series and DataFrame objects have a .plot() method, which is a wrapper around matplotlib.pyplot.plot(). By default, it creates a line plot. Visualize how many points the Knicks scored throughout the seasons:\nnba[nba[\u0026quot;fran_id\u0026quot;] == \u0026quot;Knicks\u0026quot;].groupby(\u0026quot;year_id\u0026quot;)[\u0026quot;pts\u0026quot;].sum().plot()  This shows a line plot with several peaks and two notable valleys around the years 2000 and 2010:\nYou can also create other types of plots, like a bar plot:\nnba[\u0026quot;fran_id\u0026quot;].value_counts().head(10).plot(kind=\u0026quot;bar\u0026quot;)  This will show the franchises with the most games played:\nThe Lakers are leading the Celtics by a minimal edge, and there are six further teams with a game count above 5000.\nNow try a more complicated exercise. In 2013, the Miami Heat won the championship. Create a pie plot showing the count of their wins and losses during that season. Then, expand the code block to see a solution:\nSolution: PlotShow/Hide\nSometimes, the numbers speak for themselves, but often a chart helps a lot with communicating your insights. To learn more about visualizing your data, check out Interactive Data Visualization in Python With Bokeh.\nConclusion In this tutorial, you’ve learned how to start exploring a dataset with the Pandas Python library. You saw how you could access specific rows and columns to tame even the largest of datasets. Speaking of taming, you’ve also seen multiple techniques to prepare and clean your data, by specifying the data type of columns, dealing with missing values, and more. You’ve even created queries, aggregations, and plots based on those.\nNow you can:\n Work with Series and DataFrame objects Subset your data with .loc, .iloc, and the indexing operator Answer questions with queries, grouping, and aggregation Handle missing, invalid, and inconsistent data Visualize your dataset in a Jupyter notebook  This journey using the NBA stats only scratches the surface of what you can do with the Pandas Python library. You can power up your project with Pandas tricks, learn techniques to speed up Pandas in Python, and even dive deep to see how Pandas works behind the scenes. There are many more features for you to discover, so get out there and tackle those datasets!\nYou can get all the code examples you saw in this tutorial by clicking the link below:\nGet Jupyter Notebook: Click here to get the Jupyter Notebook you\u0026rsquo;ll use to explore data with Pandas in this tutorial.\n Source : .\n "});index.add({'id':183,'href':'/library/tutorials/docs/python/snippets/factorial/','title':"factorial()",'content':" factorial() Calculates the factorial of a number.\nUse recursion. If num is less than or equal to 1, return 1. Otherwise, return the product of num and the factorial of num - 1. Throws an exception if num is a negative or a floating point number.\ndef factorial(num): if not ((num \u0026gt;= 0) and (num % 1 == 0)): raise Exception(\u0026quot;Number can't be floating point or negative.\u0026quot;) return 1 if num == 0 else num * factorial(num - 1)  factorial(6) # 720  "});index.add({'id':184,'href':'/library/tutorials/docs/python/snippets/fibonacci/','title':"fibonacci()",'content':" fibonacci() Generates a list, containing the Fibonacci sequence, up until the nth term.\nStarting with 0 and 1, use list.append() to add the sum of the last two numbers of the list to the end of the list, until the length of the list reaches n.\nIf n is less or equal to 0, return a list containing 0.\ndef fibonacci(n): if n \u0026lt;= 0: return [0] sequence = [0, 1] while len(sequence) \u0026lt;= n: next_value = sequence[len(sequence) - 1] + sequence[len(sequence) - 2] sequence.append(next_value) return sequence  fibonacci(7) # [0, 1, 1, 2, 3, 5, 8, 13]  "});index.add({'id':185,'href':'/library/tutorials/docs/python/snippets/filter_non_unique/','title':"filter_non_unique()",'content':" filter_non_unique() Filters out the non-unique values in a list.\nUse a collections.Counter to get the count of each value in the list. Use list comprehension to create a list containing only the unique values.\nfrom collections import Counter def filter_non_unique(lst): return [item for item, count in counter = Counter(lst).items() if count == 1]  filter_non_unique([1, 2, 2, 3, 4, 4, 5]) # [1, 3, 5]  "});index.add({'id':186,'href':'/library/tutorials/docs/python/snippets/filter_unique/','title':"filter_unique()",'content':" filter_unique() Filters out the unique values in a list.\nUse a collections.Counter to get the count of each value in the list. Use list comprehension to create a list containing only the non-unique values.\nfrom collections import Counter def filter_unique(lst): return [item for item, count in Counter(lst).items() if count \u0026gt; 1]  filter_unique([1, 2, 2, 3, 4, 4, 5]) # [2, 4]  "});index.add({'id':187,'href':'/library/tutorials/docs/python/snippets/find_parity_outliers/','title':"find_parity_outliers()",'content':" find_parity_outliers() Given a list, returns the items that are parity outliers.\nUse collections.Counter with a list comprehension to count even and odd values in the list, use collections.Counter.most_common() to get the most common parity. Use a list comprehension to find all elements that do not match the most common parity.\nfrom collections import Counter def find_parity_outliers(nums): return [ x for x in nums if x % 2 != Counter([n % 2 for n in nums]).most_common()[0][0] ]  find_parity_outliers([1, 2, 3, 4, 6]) # [1, 3]  "});index.add({'id':188,'href':'/library/tutorials/docs/articles/webapp/falsk/','title':"Flask",'content':" Flask framework "});index.add({'id':189,'href':'/library/tutorials/docs/python/snippets/flatten/','title':"flatten()",'content':" flatten() Flattens a list of lists once.\nUse nested list comprehension to extract each value from sub-lists in order.\ndef flatten(lst): return [x for y in lst for x in y]  flatten([[1,2,3,4],[5,6,7,8]]) # [1, 2, 3, 4, 5, 6, 7, 8]  "});index.add({'id':190,'href':'/library/tutorials/docs/python/beginer/string-format/','title':"Format a String in Python",'content':" How to Format a String in Python: Interpolation, Concatenation, and More POSTED ON SEPTEMBER 6, 2019 BY JEREMY GRIFSKI\nLast Updated on January 31, 2020\nIt’s been awhile since I’ve written one of these “how to” articles, but I’m back at it. This time, I want to talk about string formatting using techniques like interpolation and concatenation. In other words, it’s time to finally learn how to format a string in Python\nTable of Contents  Table of Contents Video Summary Problem Introduction Solutions  Format a String Using Concatenation Format a String Using Multiple Print Statements Format a String Using the Join Function Format a String Using the perator Format a String Using the Format Function Format a String Using f-Strings  Performance Challenge A Little Recap  Video Summary Once again, I’ve updated one of my Python articles to include a nice video summary. If you’d like to see all the code below executed live, check out this video. In addition to sharing all 6 solutions, I also run through performance testing, and I share a solution to the Mad Libs challenge.\nProblem Introduction Whether we’re trying to prompt a user or output a nice error message, string formatting can always be challenging. After all, the syntax varies from language to language which can feel like learning a metalanguage. For instance, in languages like Java and C, string formatting relies on understanding concepts like variable arguments and format specifiers:\n1. printf(\u0026quot;Hi, %s\u0026quot;, Jeremy); # Prints \u0026quot;Hi, Jeremy\u0026quot;  Of course, string formatting gets more complicated as we introduce different data types. For example, numbers have their own set of specifiers: %d, %f, etc. And, we can even specify how the numbers look in terms of padding and truncation.\nThat said, I don’t you’re here to learn string formatting in C, so how do we accomplish the same thing in Python? In this article, we’ll take a look at several methods—some silly—just to illustrate how many ways there are to solve this problem.\nTo get started, we’ll need a universal example which contains a few pitfalls like mixing numbers and strings. The following code snippet will serve as our base for the remainder of the article:\n1. name = \u0026quot;Jeremy\u0026quot; 2. age = 25  Using these variables, we’ll want to construct the following sentence:\n1. print(\u0026quot;My name is Jeremy, and I am 25 years old.\u0026quot;)  Of course, feel free to swap the name and age with your name and age!\nSolutions As it turns out, there are quite a few ways to format a string. We’ll start from a few direct approaches, then we’ll move into some the for elegant solutions.\nFormat a String Using Concatenation If you’re like me, concatenation is something you learned when you first started to code. As a result, concatenation can seem like a quick shortcut to string formatting:\n1. print(\u0026quot;My name is \u0026quot; + name + \u0026quot;, and I am \u0026quot; + age + \u0026quot; years old.\u0026quot;)  Unfortunately, a solution like this won’t work. If you tried to run this code, you’ll get a nasty error that looks something like this:\n Traceback (most recent call last):\nFile “”, line 1, in\n“My name is ” + name + “, and I am ” + age + ” years old.”\nTypeError: can only concatenate str (not “int”) to str\n Hopefully, the TypeError gives you the hint that the interpreter doesn’t like it when we try to concatenate a string with an integer. In other words, we need to cast the age variable to a string:\n1. print(\u0026quot;My name is \u0026quot; + name + \u0026quot;, and I am \u0026quot; + str(age) + \u0026quot; years old.\u0026quot;)  And, that’s it! For small strings, this is probably fine, but it’s not super readable. Also, it’s really easy to forget spaces on either side of the variables we’re concatenating. Luckily, there are other ways to build a string.\nFormat a String Using Multiple Print Statements Who needs concatenation when we can just call print a bunch of times?\n1. print(\u0026quot;My name is \u0026quot;, end=\u0026quot;\u0026quot;) 2. print(name, end=\u0026quot;\u0026quot;) 3. print(\u0026quot;, and I am \u0026quot;, end=\u0026quot;\u0026quot;) 4. print(age, end=\u0026quot;\u0026quot;) 5. print(\u0026quot; years old.\u0026quot;)  Now, I know what you’re thinking; yes, this only works in Python 3+. Oh, and this is a totally ridiculous solution, but it demonstrates something important: there are a lot of ways to solve the same problem.\nIn this case, we’ve taken the print function and leveraged one of its default arguments (end) to remove the newline behavior. That way, we could string together some text without concatenation.\nAgain, this is definitely hard to read, and I wouldn’t even advise it for small strings. That said, it does eliminate a type cast. Unfortunately, it introduces a lot of duplicate code.\nFormat a String Using the Join Function Continuing our quest for the most ridiculous way of formatting a string, I bring you the join function. If you’re not familiar with this function, it’s basically a more efficient way to concatenate strings. In addition, it allows us to provide a separator to place between our concatenated strings. Of course, we won’t be needing that:\n1. print(''.join([\u0026quot;My name is \u0026quot;, name, \u0026quot;, and I am \u0026quot;, str(age), \u0026quot; years old\u0026quot;]))  Here, we’ve called the join method on an empty separator string. As an argument, we’ve passed it a list of strings. Naturally, join will combine this list of strings into a single string without any separators.\nOddly enough, I sort of like this solution because it’s surprisingly readable. Unfortunately, there are a few drawbacks. For instance, we have to convert all our variables to strings manually. In addition, this line is already pretty long. Though, I suppose we could break everything out onto its own line.\nAt any rate, with these three out of the way, we can finally start getting to some more reasonable solutions.\nFormat a String Using the % Operator Now, we’re starting to get into the actual string formatting techniques. As it turns out, Python has its own set of formatting tools similar to printf from C:\n1. print(\u0026quot;My name is %s, and I am %d years old.\u0026quot; % (name, age))  Here, we’ve constructed a new string with %s replaced by name and %d replaced by age.\nIn addition to knowing the format specifiers, we’ll want to learn the syntax. In particular, our template string is following by the modulo operator. Of course, in this context, we can call it the string formatting or interpolation operator.\nThen, we create a tuple of values that we want to place in our string. Be very careful to ensure the order of these values. If they are out of order, the resulting string may be incorrect, or the program may crash altogether.\nWith this method, we get a much cleaner solution. Of course, there are pitfalls here, but they mostly have to do with how the values are mapped to the string. For example, we have to pay attention to how we order our arguments, and we need to know our format specifiers.\nSpeaking of format specifiers, what if we want to print out an object directly? Fortunately, we have better solutions ahead.\nFormat a String Using the Format Function Instead of using a fancy overloaded operator, we can make our code even more readable by using the format function for strings:\n1. print(\u0026quot;My name is {}, and I am {} years old\u0026quot;.format(name, age))  Previously, we would have had to use format specifiers to get the behavior we wanted, but now we can just use braces. In other words, we’ve eliminated a problem from the previous solution.\nFrom what I understand, this method leverages the __format__ method for objects, so we can pass just about anything to this method without issue. There goes yet another problem! Of course, if the class doesn’t have __str__ or __repr__ overridden, then the object will not print nicely. That said, I still count that as a win over the previous solution.\nAs it turns out, we can eliminate our ordering issue from the previous solution as well. All we have to do is provide keyword arguments:\n1. print(\u0026quot;My name is {n}, and I am {a} years old\u0026quot;.format(a=age, n=name))  In this example, we named the age keyword a and the name keyword n. That way, we could place the keywords inside their respective braces. To further drive home the point, we can even reorder the arguments without issue. Now that’s pretty cool!\nOf course, I should warn you that this solution may pose a security threat to your application depending on how you’re using it. If you’re writing your own format strings, there shouldn’t be any issues. However, if your accepting format strings from your users, you might want to be careful.\nFormat a String Using f-Strings Another way to perform string interpolation is using Python’s latest f-String feature (Python 3.6+). With this feature, all we need to do is prefix a string with the letter f and insert braces just like before. However, this time, we can insert the name of our variables directly:\n1. print(f\u0026quot;My name is {name}, and I am {age} years old\u0026quot;)  Now, that is incredibly elegant. No longer do we have to worry about:\n Mapping arguments to format specifiers Using format specifiers correctly Remembering obscure syntax  Instead, we prepend and f and insert our variables. That’s it! Now, I don’t know if there are any sort security vulnerabilities with this solution, but as far as I can tell, there’s no way to apply the f to an input string.\nAt any rate, that’s all I have for string formatting solutions. Now, let’s start to compare the performance of these solutions.\nPerformance As always, I like to setup on all of our solutions in strings first:\n1. setup = \u0026quot;\u0026quot;\u0026quot; 2. name = \u0026quot;Jeremy\u0026quot; 3. age = 25 4. \u0026quot;\u0026quot;\u0026quot; 6. concatenation = \u0026quot;\u0026quot;\u0026quot; 7. \u0026quot;My name is \u0026quot; + name + \u0026quot;, and I am \u0026quot; + str(age) + \u0026quot; years old.\u0026quot; 8. \u0026quot;\u0026quot;\u0026quot; 10. string_join = \u0026quot;\u0026quot;\u0026quot; 11. ''.join([\u0026quot;My name is \u0026quot;, name, \u0026quot;, and I am \u0026quot;, str(age), \u0026quot; years old\u0026quot;]) 12. \u0026quot;\u0026quot;\u0026quot; 14. modulus = \u0026quot;\u0026quot;\u0026quot; 15. \u0026quot;My name is %s, and I am %d years old.\u0026quot; % (name, age) 16. \u0026quot;\u0026quot;\u0026quot; 18. format_ordered = \u0026quot;\u0026quot;\u0026quot; 19. \u0026quot;My name is {}, and I am {} years old\u0026quot;.format(name, age) 20. \u0026quot;\u0026quot;\u0026quot; 22. format_named = \u0026quot;\u0026quot;\u0026quot; 23. \u0026quot;My name is {n}, and I am {a} years old\u0026quot;.format(a=age, n=name) 24. \u0026quot;\u0026quot;\u0026quot; 26. f_string = \u0026quot;\u0026quot;\u0026quot; 27. f\u0026quot;My name is {name}, and I am {age} years old\u0026quot; 28. \u0026quot;\u0026quot;\u0026quot;  For my sanity, I had to remove the print statements. As a result, I wasn’t able to test the print solution. That said, feel free to try your hand at it. I ran into some issues with the output string slowing down the test, and I even tried rerouting stdout to deal with it. It was a nightmare to say the least.\nAt any rate, it’s just a matter of calling our timeit commands now:\nimport timeit min(timeit.repeat(stmt=concatenation, setup=setup, repeat=10)) # 0.4947876000000022 min(timeit.repeat(stmt=string_join, setup=setup, repeat=10)) # 0.37328679999995984 min(timeit.repeat(stmt=modulus, setup=setup, repeat=10)) # 0.29478180000000265 min(timeit.repeat(stmt=format_ordered, setup=setup, repeat=10)) # 0.40419490000000735 min(timeit.repeat(stmt=format_named, setup=setup, repeat=10)) # 0.49794210000000305 min(timeit.repeat(stmt=f_string, setup=setup, repeat=10)) # 0.1918610999999828  As is often the case with these new features in Python, they are incredibly optimized. As a matter of fact, the only solution that even comes close to competing with the f-String solution is the modulus operator solution.\nAlso, I think it’s worth noting how much slower the format function is when the arguments are named rather than ordered. In fact, it’s about as slow as concatenation which I expected to be horrendous. After all, strings are immutable, so concatenation should be pretty bad.\nAs always, take these performance metrics with a grain of salt.\nChallenge If you haven’t had a chance to check out the video above, here’s the challenge. I want you to create a simple script which generates Mad Libs. If you’re not familiar with Mad Libs, check out the official site.\nTo summarize, however, Mad Libs is a word game where a paragraph of text is provided with several words missing. It’s your job to then fill those gaps with the appropriate words (e.g. nouns, verbs, adjectives, etc.) to complete the story:\n Be careful not to vacuum the NOUN when you clean under your bed.\nMad Libs\n Right now, I don’t really have any strict requirements. In other words, you could write a program that prompts the user for a few words then populates a text using the string formatting techniques above.\nLikewise, you might choose to make a program which generates random Mad Libs from lists of words. Regardless, the choice is yours! The goal is to practice these string formatting methods.\nAs always, check the comments below for a copy of my solution to the Mad Libs problem.\nA Little Recap With all that said, here are all of the solutions in one unified location:\n1. name = \u0026quot;Jeremy\u0026quot; 2. age = 25 4. # String formatting using concatenation 5. print(\u0026quot;My name is \u0026quot; + name + \u0026quot;, and I am \u0026quot; + str(age) + \u0026quot; years old.\u0026quot;) 7. # String formatting using multiple prints 8. print(\u0026quot;My name is \u0026quot;, end=\u0026quot;\u0026quot;) 9. print(name, end=\u0026quot;\u0026quot;) 10. print(\u0026quot;, and I am \u0026quot;, end=\u0026quot;\u0026quot;) 11. print(age, end=\u0026quot;\u0026quot;) 12. print(\u0026quot; years old.\u0026quot;) 14. # String formatting using join 15. print(''.join([\u0026quot;My name is \u0026quot;, name, \u0026quot;, and I am \u0026quot;, str(age), \u0026quot; years old\u0026quot;])) 17. # String formatting using modulus operator 18. print(\u0026quot;My name is %s, and I am %d years old.\u0026quot; % (name, age)) 20. # String formatting using format function with ordered parameters 21. print(\u0026quot;My name is {}, and I am {} years old\u0026quot;.format(name, age)) 23. # String formatting using format function with named parameters 24. print(\u0026quot;My name is {n}, and I am {a} years old\u0026quot;.format(a=age, n=name)) 26. # String formatting using f-Strings (Python 3.6+) 27. print(f\u0026quot;My name is {name}, and I am {age} years old\u0026quot;)  And with that, we’re done. If you liked this article and want more content like this to hit your inbox, subscribe to our newsletter. Even better, become a member of The Renegade Coder community and earn cool rewards like attribution at the end of an article like this one.\nAlternatively, you’re welcome to do your typical online shopping through the following Amazon affiliate links:\n Automate the Boring Stuff with Python: Practical Programming for Total Beginners by Al Sweigert Python Programming: The Ultimate Step By Step Guide To Programming With Python by Antony Mc Fedden  As always, I try to pick relevant products that I think will bring you some value. If you have any products of your own that you’d like to me to share, drop them down below in the comments.\nIn the meantime, why not improve my site metrics a bit by browsing some of the following Python articles:\n That Time I Shipped Insecure Code How to Automate Your GitHub Wiki How to Clone a List in Python: Slice, Copy, and More  At ant rate, thanks again for your support, and a special thanks to all my patrons who make this possible. Until next time!\n Source : .\n "});index.add({'id':191,'href':'/library/tutorials/docs/python/snippets/gcd/','title':"gcd()",'content':" gcd() Calculates the greatest common divisor of a list of numbers.\nUse functools.reduce() and math.gcd() over the given list.\nfrom functools import reduce from math import gcd def gcd(numbers): return reduce(gcd, numbers)  gcd([8, 36, 28]) # 4  "});index.add({'id':192,'href':'/library/tutorials/docs/python/snippets/group_by/','title':"group_by()",'content':" group_by() Groups the elements of a list based on the given function.\nUse map() and fn to map the values of the list to the keys of an object. Use list comprehension to map each element to the appropriate key.\ndef group_by(lst, fn): return {key : [el for el in lst if fn(el) == key] for key in map(fn, lst)}  from math import floor group_by([6.1, 4.2, 6.3], floor) # {4: [4.2], 6: [6.1, 6.3]} group_by(['one', 'two', 'three'], len) # {3: ['one', 'two'], 5: ['three']}  "});index.add({'id':193,'href':'/library/tutorials/docs/python/snippets/has_duplicates/','title':"has_duplicates()",'content':" has_duplicates() Returns True if there are duplicate values in a flast list, False otherwise.\nUse set() on the given list to remove duplicates, compare its length with the length of the list.\ndef has_duplicates(lst): return len(lst) != len(set(lst))  x = [1, 2, 3, 4, 5, 5] y = [1, 2, 3, 4, 5] has_duplicates(x) # True has_duplicates(y) # False  "});index.add({'id':194,'href':'/library/tutorials/docs/python/snippets/head/','title':"head()",'content':" head() Returns the head of a list.\nUse lst[0] to return the first element of the passed list.\ndef head(lst): return lst[0]  head([1, 2, 3]) # 1  "});index.add({'id':195,'href':'/library/tutorials/docs/articles/data-science/web-scraping/web-scrape-yahoo-finance/','title':"How to scrape Yahoo Finance",'content':" How to scrape Yahoo Finance and extract fundamental stock market data using Python, LXML, and Pandas In this blog post I’ll show you how to scrape Income Statement, Balance Sheet, and Cash Flow data for companies from Yahoo Finance using Python, LXML, and Pandas.\nI’ll use data from Mainfreight NZ (MFT.NZ) as an example, but the code will work for any stock symbol on Yahoo Finance.\nThe screenshot below shows a Pandas DataFrame with MFT.NZ balance sheet data, which you can expect to get by following the steps in this blog post:\nAfter taking you step by step on how to fetch data from the balance sheet, I’ll show you how to generalise the code to also generate a DataFrame containing data from the Income Statement, and Cash Flow statement.\nAfter creating the Pandas DataFrames, I’ll then show you how to export everything to an Excel file, so you’ll have output that looks something like this:\nThis post was last updated in October, 2019. Prior to this, Yahoo Finance conveniently had all this data in a regular HTML table, which made extracting the data super easy. Since then, they’ve updated the page with a new structure, which was a wee bit tricker to get the data from. Fortunately, it’s still possible. Read on to find out how.\nDisclaimers Before we start, a few disclaimers:\n This code doesn’t come with any guarantee or warranty. I’m not a financial advisor. This blog post doesn’t represent financial advice. I don’t recommend the use of this code for any investment decisions. This code is designed for personal use, and isn’t designed for high-volume extractions. Use the code at your own risk.  Prerequisites Make sure you have installed the Anaconda distribution of Python .. this includes Jupyter Notebook, which we’ll use throughout this blog post.\nNow we begin!\nFind the ticker symbol In this case, we’ll be scraping data for Mainfreight NZ.\nIn Yahoo Finance, the symbol for Mainfreight is MFT.NZ:\nTake a look at the Balance Sheet data that we’re going to scrape. Here’s an example of some of the financial data we’ll be wanting to extract. Take note of the data displayed. Once we’ve scraped the data, we’ll cross-check it to ensure the scraping was accurate.\nInspect the page source Open up the Chrome developer tools, and inspect the page source. If you inspect the “Cash And Cash Equivalents” row, you’ll see something like this:\nNote that:\n Table rows in the table have the class D(tbr) Values such as Cash And Cash Equivalents and 115,184 are within a span within each row This is true for all rows in the table, including the first row titled Breakdown with dates such as 3/31/2019  Because of this, we can use XPath queries to extract the data that we want.\nScrape some balance sheet data Open up Jupyter Notebook, and execute the following code block:\nfrom datetime import datetime import lxml from lxml import html import requests import numpy as np import pandas as pd symbol = 'MFT.NZ' url = 'https://finance.yahoo.com/quote/' + symbol + '/balance-sheet?p=' + symbol # Set up the request headers that we're going to use, to simulate # a request by the Chrome browser. Simulating a request from a browser # is generally good practice when building a scraper headers = { 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3', 'Accept-Encoding': 'gzip, deflate, br', 'Accept-Language': 'en-US,en;q=0.9', 'Cache-Control': 'max-age=0', 'Pragma': 'no-cache', 'Referrer': 'https://google.com', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.120 Safari/537.36' } # Fetch the page that we're going to parse, using the request headers # defined above page = requests.get(url, headers) # Parse the page with LXML, so that we can start doing some XPATH queries # to extract the data that we want tree = html.fromstring(page.content) # Smoke test that we fetched the page by fetching and displaying the H1 element tree.xpath(\u0026quot;//h1/text()\u0026quot;)  You should see some output which looks like the following:\nReading the financial data Add a new cell to your Jupyter notebook, and add the following:\ntable_rows = tree.xpath(\u0026quot;//div[contains(@class, 'D(tbr)')]\u0026quot;) # Ensure that some table rows are found; if none are found, then it's possible # that Yahoo Finance has changed their page layout, or have detected # that you're scraping the page. assert len(table_rows) \u0026gt; 0 parsed_rows = [] for table_row in table_rows: parsed_row = [] el = table_row.xpath(\u0026quot;./div\u0026quot;) none_count = 0 for rs in el: try: (text,) = rs.xpath('.//span/text()[1]') parsed_row.append(text) except ValueError: parsed_row.append(np.NaN) none_count += 1 if (none_count \u0026lt; 4): parsed_rows.append(parsed_row) df = pd.DataFrame(parsed_rows) df  After executing the code, you should see output which looks like:\nThere are a few observations to be taken from the screenshot of the Pandas DataFrame above:\n The header row contains index values (0, 1, 2, 3, etc), rather than useful column names. The first row of the table contains dates. The first column contains account names. Rows such as Short Term Investments contain “None” where there are dashes (which represent no value) in Yahoo Finance, and 0’s when there are 0’s.  Cross-check this output with the Balance Sheet in Yahoo Finance. The data should match. For example:\nNext, we’ll do some data cleanups and transformations to make the data more useful.\nClean up the data Because we’re using Pandas, it’ll be more convenient if the columns are the account names, and the rows are indexed by Date, so let’s do that now:\ndf = pd.DataFrame(parsed_rows) df = df.set_index(0) # Set the index to the first column: 'Period Ending'. df = df.transpose() # Transpose the DataFrame, so that our header contains the account names # Rename the \u0026quot;Breakdown\u0026quot; column to \u0026quot;Date\u0026quot; cols = list(df.columns) cols[0] = 'Date' df = df.set_axis(cols, axis='columns', inplace=False) df  You should now see output which looks like:\nMuch better!\nNow, let’s look at the data types of these columns:\ndf.dtypes  A few observations:\n Period Ending is of type ‘object’ when it should be a date type. We’re not going to be able to convert this to a date column since Income Statement and Statement of Cash Flows have “ttm” as the date value of the first column. All other columns such as Cash and Cash Equivalents are also of type ‘object’ when they should be numeric.  Let’s do the conversion to numeric:\nnumeric_columns = list(df.columns)[1::] # Take all columns, except the first (which is the 'Date' column) for column_name in numeric_columns: df[column_name] = df[column_name].str.replace(',', '') # Remove the thousands separator df[column_name] = df[column_name].astype(np.float64) # Convert the column to float64 df.dtypes  The numeric columns should be now of type float64:\nLet’s have another look at the DataFrame,:\ndf  Which should output something something like:\nLooking good! Now the Balance Sheet data has been fully scraped, with correct data types, in a form that’s ready to use.\nScraping Income Statement data from Yahoo Finance Now we’ll create a more generalised form of the code above, by combining the code into a method.\nfrom datetime import datetime import lxml from lxml import html import requests import numpy as np import pandas as pd def get_page(url): # Set up the request headers that we're going to use, to simulate # a request by the Chrome browser. Simulating a request from a browser # is generally good practice when building a scraper headers = { 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3', 'Accept-Encoding': 'gzip, deflate, br', 'Accept-Language': 'en-US,en;q=0.9', 'Cache-Control': 'max-age=0', 'Pragma': 'no-cache', 'Referrer': 'https://google.com', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.120 Safari/537.36' } return requests.get(url, headers) def parse_rows(table_rows): parsed_rows = [] for table_row in table_rows: parsed_row = [] el = table_row.xpath(\u0026quot;./div\u0026quot;) none_count = 0 for rs in el: try: (text,) = rs.xpath('.//span/text()[1]') parsed_row.append(text) except ValueError: parsed_row.append(np.NaN) none_count += 1 if (none_count \u0026lt; 4): parsed_rows.append(parsed_row) return pd.DataFrame(parsed_rows) def clean_data(df): df = df.set_index(0) # Set the index to the first column: 'Period Ending'. df = df.transpose() # Transpose the DataFrame, so that our header contains the account names # Rename the \u0026quot;Breakdown\u0026quot; column to \u0026quot;Date\u0026quot; cols = list(df.columns) cols[0] = 'Date' df = df.set_axis(cols, axis='columns', inplace=False) numeric_columns = list(df.columns)[1::] # Take all columns, except the first (which is the 'Date' column) for column_name in numeric_columns: df[column_name] = df[column_name].str.replace(',', '') # Remove the thousands separator df[column_name] = df[column_name].astype(np.float64) # Convert the column to return df def scrape_table(url): # Fetch the page that we're going to parse page = get_page(url); # Parse the page with LXML, so that we can start doing some XPATH queries # to extract the data that we want tree = html.fromstring(page.content) # Fetch all div elements which have class 'D(tbr)' table_rows = tree.xpath(\u0026quot;//div[contains(@class, 'D(tbr)')]\u0026quot;) # Ensure that some table rows are found; if none are found, then it's possible # that Yahoo Finance has changed their page layout, or have detected # that you're scraping the page. assert len(table_rows) \u0026gt; 0 df = parse_rows(table_rows) df = clean_data(df) return df symbol = 'MFT.NZ' balance_sheet_url = 'https://finance.yahoo.com/quote/' + symbol + '/balance-sheet?p=' + symbol df_balance_sheet = scrape_table(balance_sheet_url) df_balance_sheet  You should get the same output as the final balance sheet above. The only change will be that the ‘Period Ending’ column is now called ‘Date’.\nNow, let’s try the same method with the URL for income statement:\ndf_income_statement = scrape_table('https://finance.yahoo.com/quote/' + symbol + '/financials?p=' + symbol) df_income_statement  Cross check these values with the income statement on yahoo finance:\nand they match!\nScraping Statement of Cash Flows data from Yahoo Finance Now that we’ve got a generic method that can be used on the Balance Sheet, and Income Statement, let’s try it on the Cash Flow statement.\ndf_cash_flow = scrape_table('https://finance.yahoo.com/quote/' + symbol + '/cash-flow?p=' + symbol) df_cash_flow  Cross check these values with the cash flow statement on Yahoo Finance:\nand they match!\nNow you’ve got the following Pandas DataFrames:\n df_cash_flow, containing data scraped from the Statement of Cash Flows df_income_statement, containing data scraped from the Income Statement df_balance_sheet, containing data scraped from the Balance Sheet  Exporting to Excel It’s possible to export the Pandas DataFrame to Excel via ExcelWriter.\nBelow is the code to export to an Excel file with three worksheets; Income Statement, Balance Sheet, and Statement of Cash Flows\ndate = datetime.today().strftime('%Y-%m-%d') writer = pd.ExcelWriter(symbol + '-' + date + '-scraped.xlsx') df_income_statement.to_excel(writer,'Income Statement') df_balance_sheet.to_excel(writer,'Balance Sheet') df_cash_flow.to_excel(writer,'Statement of Cash Flows') writer.save()  I imported the file into Google Sheets, and got the following:\n Source: MattButton.com.\n "});index.add({'id':196,'href':'/library/tutorials/docs/python/snippets/in_range/','title':"in_range()",'content':" in_range() Checks if the given number falls within the given range.\nUse arithmetic comparison to check if the given number is in the specified range. If the second parameter, end, is not specified, the range is considered to be from 0 to start.\ndef in_range(n, start, end = 0): return start \u0026lt;= n \u0026lt;= end if end \u0026gt;= start else end \u0026lt;= n \u0026lt;= start  in_range(3, 2, 5) # True in_range(3, 4) # True in_range(2, 3, 5) # False in_range(3, 2) # False  "});index.add({'id':197,'href':'/library/tutorials/docs/python/snippets/initial/','title':"initial",'content':"Returns all the elements of a list except the last one.\nUse lst[0:-1] to return all but the last element of the list.\ndef initial(lst): return lst[0:-1]  initial([1, 2, 3]) # [1,2]  "});index.add({'id':198,'href':'/library/tutorials/docs/python/snippets/initialize_2d_list/','title':"initialize_2d_list",'content':"Initializes a 2D list of given width and height and value.\nUse list comprehension and range() to generate h rows where each is a list with length h, initialized with val. If val is not provided, default to None.\ndef initialize_2d_list(w,h, val = None): return [[val for x in range(w)] for y in range(h)]  initialize_2d_list(2, 2, 0) # [[0,0], [0,0]]  "});index.add({'id':199,'href':'/library/tutorials/docs/python/snippets/initialize_list_with_range/','title':"initialize_list_with_range",'content':"Initializes a list containing the numbers in the specified range where start and end are inclusive with their common difference step.\nUse list and range() to generate a list of the appropriate length, filled with the desired values in the given range. Omit start to use the default value of 0. Omit step to use the default value of 1.\ndef initialize_list_with_range(end, start=0, step=1): return list(range(start, end + 1, step))  initialize_list_with_range(5) # [0, 1, 2, 3, 4, 5] initialize_list_with_range(7, 3) # [3, 4, 5, 6, 7] initialize_list_with_range(9, 0, 2) # [0, 2, 4, 6, 8]  "});index.add({'id':200,'href':'/library/tutorials/docs/python/snippets/initialize_list_with_values/','title':"initialize_list_with_values",'content':"Initializes and fills a list with the specified value.\nUse list comprehension and range() to generate a list of length equal to n, filled with the desired values. Omit val to use the default value of 0.\ndef initialize_list_with_values(n, val = 0): return [val for x in range(n)]  initialize_list_with_values(5, 2) # [2, 2, 2, 2, 2]  "});index.add({'id':201,'href':'/library/tutorials/docs/python/snippets/intersection/','title':"intersection",'content':"Returns a list of elements that exist in both lists.\nCreate a set from a and b, then use the built-in set operator \u0026amp; to only keep values contained in both sets, then transform the set back into a list.\ndef intersection(a, b): _a, _b = set(a), set(b) return list(_a \u0026amp; _b)  intersection([1, 2, 3], [4, 3, 2]) # [2, 3]  "});index.add({'id':202,'href':'/library/tutorials/docs/python/snippets/intersection_by/','title':"intersection_by",'content':"Returns a list of elements that exist in both lists, after applying the provided function to each list element of both.\nCreate a set by applying fn to each element in b, then use list comprehension in combination with fn on a to only keep values contained in both lists.\ndef intersection_by(a, b, fn): _b = set(map(fn, b)) return [item for item in a if fn(item) in _b]  from math import floor intersection_by([2.1, 1.2], [2.3, 3.4],floor) # [2.1]  "});index.add({'id':203,'href':'/library/tutorials/docs/articles/data-science/finance/intro-stock-analysis-pandas/','title':"Introduction to Stock Analysis using Pandas",'content':" Introduction to Stock Analysis using Pandas  http://www.quantsbin.com/introduction-stock-analysis-pandas1/  As defined in Investopedia A time series is a sequence of numerical data points in successive order. Generally, observation points are successively equally spaced in time. Most of the financial data is in the time series format and hence \u0026ldquo;Financial Time Series Analysis\u0026rdquo; is an important tool for anyone trying to understand the historical movements, predict the future movements or manage the risk associated with the future movements.\nThrough this tutorial, we are providing tools that are neccessary to get access to the financial data and perform a preliminary analysis and visualization to understand the data better.\nBy the end of this tutorial you will be capable of doing the following tasks:\n1. Download and Know your data\n Load data of any financial instrument using Quandl\u0026rsquo;s Python package Know your data  2. Plot Time Series data\n Plot the stock price data Plot subplot for price and volume traded Normalize the time series to see how your investment grew  3. Returns Calculation\n Calculate simple return Calculate and plot the daily returns Calculate the Compound Annual Growth Rate(CAGR)  4. Volatility Calculation\n Calculate the annualized volatility Calculate and plot the rolling volatilty Relationship between Vol and returns  5. Correlation Calculation\n Generate pair-wise plot and analyse Generate correlation metrics  6. Returns Distribution and Analysis\n Plot the return distribution Normality test  7. Monthly plot\n Comment on seasonality  8. Digging deep\n Calculate and plot the moving average Perform the drawdown analysis  1. Downloading and Knowing your data There are multiple sources that provide APIs to download data into your python code directly.\nIn this tutorial we are using Quandl\u0026rsquo;s free API for sourcing financial data. The pre-requisites for using Quandl API are:\n Register on Quandl and generate API key. Install Quandl package in python and import the same.  Note: For further information please refer to link Quandl for Python\nImporting Packages Before jumping into the actual code, the first step is to import all the packages that will be used in this tutorial.\nimport quandl as qd #Quandl for downloading financial data import pandas as pd #Pandas for access to dataframes import numpy as np #Numpy for access to arrays and vectorization of calculaitons import matplotlib.pyplot as plt #Matplotlib for pythons basic plotting import seaborn as sns #Seaborn for heatmap plotting import scipy.stats as stats #Scipy Stats module for access to statistical formula. import plotly import chart_studio.plotly import plotly.graph_objs as go import seaborn as sns import pylab import scipy.stats as stats import warnings from datetime import date warnings.filterwarnings('ignore') plt.style.use('ggplot')#For chart formating we have set in-build formating convention  authtoken = \u0026quot;dhpDwSsxjAu6XDfnVTjd\u0026quot; ticker = \u0026quot;NSE/NIFTY_50\u0026quot; start_date = \u0026quot;2010-01-01\u0026quot; end_date = \u0026quot;2018-06-30\u0026quot; nifty_levels_test = qd.get(ticker, start_date=start_date, end_date=end_date, authtoken=authtoken) print(nifty_levels_test.head())   Open High Low Close Shares Traded \\ Date 2010-01-04 5200.90 5238.45 5167.10 5232.20 148652424.0 2010-01-05 5277.15 5288.35 5242.40 5277.90 240844424.0 2010-01-06 5278.15 5310.85 5260.05 5281.80 216147837.0 2010-01-07 5281.80 5302.55 5244.75 5263.10 181246734.0 2010-01-08 5264.25 5276.75 5234.70 5244.75 201910800.0 Turnover (Rs. Cr) Date 2010-01-04 6531.61 2010-01-05 7969.62 2010-01-06 7892.60 2010-01-07 6890.99 2010-01-08 7777.04  Load live data of any financial instrument using Quandl\u0026rsquo;s Python package. The data can be downloaded by specifying following parameters to the get function of Quandl\n Ticker for which the data is required Start date for the time series End date for the time series Quandl API key for aunthentication  The data will be downloaded as a pandas DataFrame, which will have the dates as index and market data such as Open, High, Low, Close prices, Shares Traded and Turnover (Rs. Cr) as columns.\nLets start with downloading NIFTY50 Index data\nTo know more about NIFTY50 click here.\nWe can print first 5 rows of our data by using \u0026ldquo;head\u0026rdquo; function. This helps us to have a quick look at the structure of the data downloaded.\nprint(\u0026quot;***************Basic information about data downloaded***************\u0026quot;) print(nifty_levels_test.info()) print(\u0026quot;***************Data description***************\u0026quot;) print(nifty_levels_test.describe())   ***************Basic information about data downloaded*************** \u0026lt;class 'pandas.core.frame.DataFrame'\u0026gt; DatetimeIndex: 2111 entries, 2010-01-04 to 2018-06-29 Data columns (total 6 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 Open 2111 non-null float64 1 High 2111 non-null float64 2 Low 2111 non-null float64 3 Close 2111 non-null float64 4 Shares Traded 2093 non-null float64 5 Turnover (Rs. Cr) 2093 non-null float64 dtypes: float64(6) memory usage: 115.4 KB None ***************Data description*************** Open High Low Close Shares Traded \\ count 2111.000000 2111.000000 2111.000000 2111.000000 2.093000e+03 mean 7135.990881 7172.192492 7090.158361 7131.309332 1.727730e+08 std 1779.522933 1779.082316 1775.820220 1777.239695 5.805946e+07 min 4623.150000 4623.150000 4531.150000 4544.200000 6.555703e+06 25% 5530.525000 5564.650000 5486.650000 5530.825000 1.353542e+08 50% 6530.000000 6562.850000 6497.650000 6526.650000 1.628396e+08 75% 8470.825000 8505.850000 8423.425000 8471.825000 1.989305e+08 max 11120.850000 11171.550000 11075.950000 11130.400000 6.291986e+08 Turnover (Rs. Cr) count 2093.000000 mean 7656.236885 std 2854.432124 min 297.890000 25% 5782.230000 50% 7105.680000 75% 8920.290000 max 29479.770000  Printing basic information about about your data\ninfo function gives list of column names in pandas dataframe, their data type and number of non \u0026lsquo;NaN\u0026rsquo; values.\ndescribe function provides basic statistics such as count, mean, std, min/max etc. for each column\nplt.rcParams['figure.figsize'] = [12, 8] _ = nifty_levels_test[['Close','High','Low']].plot() plt.ylabel('Index Level') plt.title (ticker +' LEVEL TIME SERIES') plt.legend() plt.show()  2. Ploting Time Series data The first step to understand and analyse financial data is through visualization. By simply ploting the financial timeseries we can get the understanding of how an investment has performed over the time period.\nPlot the Stock Price data The code given below uses the package matplotlib.pyplot to plot the \u0026lsquo;Close\u0026rsquo;, \u0026lsquo;High\u0026rsquo; and \u0026lsquo;Low\u0026rsquo; columns of the time series downloaded for NIFTY50 as a line graph. We can customize the chart to show its title, the label for the y axis and its legend.\nslice_start_date = pd.datetime(2017,12,31) nifty_levels_test_sliced = nifty_levels_test[nifty_levels_test.index \u0026gt; slice_start_date].fillna(method='ffill') f, (a0, a1) = plt.subplots(2,1, gridspec_kw = {'height_ratios':[3, 1]}) _ = nifty_levels_test_sliced[['Close','High','Low']].plot(ax=a0) a0.set_ylabel('Index Level') a0.grid(True) a0.set_xticklabels([]) x_label = a0.set_xlabel('') x_label.set_visible(False) a0.set_title (ticker +' LEVEL TIME SERIES (Sliced)') a0.legend() nifty_levels_test_sliced['Shares Traded'].plot(ax=a1) a1.set_ylabel('Volume') f.tight_layout() plt.show()  Plot Subplot for Price and Volume traded The code given below subsets the timeseries downloaded for NIFTY50 for dates greater than 2017-12-31 and handles the missing values by using the forward fill method. Then it creates 2 subplots, one of which is the line chart for \u0026lsquo;Close\u0026rsquo;, \u0026lsquo;High\u0026rsquo; and \u0026lsquo;Low\u0026rsquo;, while the second is the line chart for the volume of \u0026lsquo;Shares Traded\u0026rsquo;. Looking at these graphs adjacent to each other helps us in observing the relationship between price movement and volumen traded.\nnifty_close_levels = nifty_levels_test_sliced['Close'] normalised_start_level = 1000 nifty_close_normalized = nifty_close_levels/nifty_close_levels[0]*normalised_start_level _ = nifty_close_normalized.plot() plt.ylabel('Index Level') plt.title (ticker +' LEVEL TIME SERIES (Normalized)') plt.legend() plt.show()  Normalize the Time Series A financial time series is normalized to observe how an investment of x amount changes with time. It is useful for comparing the performance of multiple time series.\nNormalization is done by using the formula given below:\n$$p ( t ) p ( 0 ) ∗ x for 0 \u0026lt;= t \u0026lt;= T$$ where T is period end date\nThe code given below normalizes and plots the sliced time series to see how an investment of 1000 made in NIFTY50 on 2017-12-31 changes over time.\nstock_codes = stock_codes =[\u0026quot;GM\u0026quot;, \u0026quot;F\u0026quot;, \u0026quot;AAPL\u0026quot;, \u0026quot;MSFT\u0026quot;] start_date_multi = '2011-12-31' source = 'WIKI/PRICES' stock_prices = qd.get_table(source, qopts = { 'columns': ['ticker', 'date', 'adj_close'] }, ticker = stock_codes, date = { 'gte': start_date_multi, 'lte': end_date }) print(stock_prices.head())   ticker date adj_close None 0 MSFT 2018-03-27 89.47 1 MSFT 2018-03-26 93.78 2 MSFT 2018-03-23 87.18 3 MSFT 2018-03-22 89.79 4 MSFT 2018-03-21 92.48  stock_prices_formatted = stock_prices.pivot(columns = 'ticker', index='date', values='adj_close') stock_prices_formatted.head()  ticker AAPL F GM MSFT date 2012-01-03 52.848787 8.772734 18.035831 22.792249 2012-01-04 53.132802 8.906729 18.121512 23.332995 2012-01-05 53.722681 9.135309 18.995457 23.571435 2012-01-06 54.284287 9.229893 19.638064 23.933352 2012-01-09 54.198183 9.300832 19.569519 23.622529  data = [go.Scatter(x=stock_prices_formatted.index, y=stock_prices_formatted[udl_code], name=udl_code) for udl_code in stock_prices_formatted.columns] data.show()  import plotly.express as px norm_stock_prices_formatted = stock_prices_formatted/stock_prices_formatted.iloc[0,:]*100 data = [px.scatter(x=norm_stock_prices_formatted.index, y=norm_stock_prices_formatted[udl_code], name=udl_code) for udl_code in norm_stock_prices_formatted.columns] layout = dict( title = \u0026quot;Normalized Price Time Series\u0026quot;) fig = dict(data=data, layout=layout) fig.show() # go.plot(fig, filename = 'Normalized Price Time Series')  3. Returns Calculation The return of a financial instrument is the profit/loss incurred on an investment over a period of time, expressed as a proportion of the original investment. It gives a complete, scale-free summary of the investment opportunity.\nThe simple single period return of financial instrument is calculated using the formula given below\nR(t)=P(f)P(i)−1where P(i) and P(f)  are the prices at the starting time point and ending time point of the $$periodR(t)=P(f)P(i)−1where P(i) and P(f)$$ are the prices at the starting time point and ending time point of the period\nThe code given below calculates the simple return for the period between 2017-12-31 and 2018-06-30\nnifty_simple_return = (nifty_close_levels[-1]/nifty_close_levels[0] -1) print(\u0026quot;Nifty returns for period starting from {} till {} is {:.2f}%\u0026quot;.format\\ (slice_start_date.date(),end_date, nifty_simple_return*100))  Nifty returns for period starting from 2017-12-31 till 2018-06-30 is 2.67%  Simple Daily Return The daily return is the day over day return.\nThe underlying formula for calculating simple daily return is\n$$R(t)=(P(t)P(t−1)−1)for 0\u0026lt;=t\u0026lt;=T R(t)=(P(t)P(t−1)−1)for 0\u0026lt;=t\u0026lt;=T$$\nThe code given below calculates the daily returns using the pandas dataframe function pct_change. We also calculated the mean daily simple return, which comes out to be close to zero. This tells the importance of compounding effect.\nThe return series hence obtained is first plotted as a line chart and then as a histogram to observe its underlying distribution. From histogram we can observe that return distribution is bell shaped and similar to famous normal distribution.\ndaily_returns = nifty_levels_test['Close'].pct_change() print(\u0026quot;Avg daily return is {:.6f}%\u0026quot;.format(daily_returns.mean()*100)) _ = daily_returns.plot() plt.ylabel('Index Daily Returns') plt.title (ticker +' RETURN TIME SERIES') plt.legend() plt.rcParams['figure.figsize'] = [12, 8] plt.show() _1 = daily_returns.hist(bins=30) plt.title('Daily return distribution') plt.show()  Avg daily return is 0.038790%  Logarithmic Return / Continuously Compounded Return The logarithmic return or continuously compounded return, D(t), is calculated using the formula\n$$D(t)=log(P(f)P(i))where P(i) and P(f)$$ are the initial and the final prices of the $$instrumentD(t)=log(R(t)+1)where R(t)$$ is the simple return during the $$periodD(t)=log⁡(P(f)P(i))$$where $$P(i) and P(f)$$ are the initial and the final prices of the instrument$$D(t)=log⁡(R(t)+1)where R(t)$$ is the simple return during the period\nThe advantages of using log returns over simple returns are as follows:\n The logarithmic returns are symmetric in nature, as opposed to simple returns. In case the prices are distributed log-normally, $$log(1+R(t))$$ is distributed normally. The log returns are additive in nature.  The code given below calculates the log returns using the log function from the numpy library. Instead of calculating log returns from scratch, we have used simple returns timeseries to calculate log returns.\nThe returns hence obtained are plotted as a histogram to observe the distribution of these returns. As we can observe the log returns distribution is also bell shaped and similar to normal distibution.\ndaily_log_returns = np.log(daily_returns+1) _1 = daily_log_returns.hist(bins=30) plt.title('Daily log return distribution') plt.show()  Compound Annual Growth Rate (CAGR) The Compound Annual Growth Rate (CAGR) is the mean annual growth rate of an investment over a specified period of time longer than one year. It describes the rate at which an investment would have grown, if it had grown at a steady rate, which doesn\u0026rsquo;t ususally happen in reality. CAGR can be essentially viewed as a way to smooth out an investment’s returns so that they may be more easily understood.\nThe formula for calculating CAGR is\n$$R(t)=(P(f)P(i))(1n)−1where P(f) and P(i)$$ are the final and the initial values for a period and n is the time in years $$R(t)=(P(f)P(i))(1n)−1where P(f) and P(i)$$ are the final and the initial values for a period and n is the time in years\nCAGR is a relatively simple metric and hence has a variety of uses.\n CAGR can be used to calculate the average growth of a single investment It can be used to compare investments of different types with one another. For example it can be used to compare an investment in risk free instrument with an investment in a portfolio with varying growth rate It can also be used to track the performance of various business measures of one or multiple companies alongside one another  The code given below illustrates how CAGR can be calculated.\ntime_in_years = (nifty_levels_test.index[-1] - nifty_levels_test.index[0]).days/365.0 cagr = (nifty_levels_test['Close'][-1]/nifty_levels_test['Close'][0])**(1/time_in_years) - 1 print(\u0026quot;Compound annual growth rate from {} to {} for {} is {:.2f}%\u0026quot;.format\\ (nifty_levels_test.index[0].date(), nifty_levels_test.index[-1].date(), ticker, cagr*100))  Compound annual growth rate from 2010-01-04 to 2018-06-29 for NSE/NIFTY_50 is 8.81%  4. Volatility Calculation Annualized Volatility Annualised volatility is the degree of variation observed in the prices of a financial instrument over a period of one year. It can be calculated by scaling the daily volatility, which is measured as the standard deviation of the returns of the stock prices, to 1 year. The daily volatility can be scaled to annual by simply multiplying with $$252−−−√252$$ (considering that there are 252 business days in a year) in case it is calculated as the standard deviation of the log returns.\nThe code given below calcluates annualised volatility by calculating the standard deviation of log returns of NIFTY50 using pandas dataframe function std and then multiplying it by $$252−−−√252$$.\nvolatility = daily_log_returns.std() * (252**0.5) print(\u0026quot;Annualized daily volatility from {} to {} for {} is {:.2f}%\u0026quot;.format\\ (nifty_levels_test.index[0].date(), nifty_levels_test.index[-1].date(), ticker, volatility*100))  Annualized daily volatility from 2010-01-04 to 2018-06-29 for NSE/NIFTY_50 is 15.58%  N-days Rolling Volatility N-days rolling volatility is calculated by rolling the dates for a window of N days and using the corresponding data for calculating the volatility.\nThe code given below calculates the rolling annualized volatility for NIFTY50 for a window of 252 days using pandas function rolling. The series of rolling volatility hence obtained is plotted on the secondary y-axis, along with index levels plotted on the primary y-axis.\nrolling_volatility = daily_log_returns.rolling(window = 252).std()*(252**0.5)*100 nifty_levels_test['Close'].plot(label='Index Levels', color='Blue') plt.ylabel(ticker + ' levels') plt.legend() ax = plt.gca() ax2 = ax.twinx() ax2.set_ylim(ymax=50) rolling_volatility.plot(label='Volatility') plt.title(ticker +\u0026quot; levels and 252 days Rolling Volatility\u0026quot;) plt.ylabel(\u0026quot;Volatility in %\u0026quot;) plt.legend() plt.show()  5. Correlation Calculation log_returns = np.log(norm_stock_prices_formatted.pct_change().dropna()+1) log_returns.head()  ticker AAPL F GM MSFT date 2012-01-04 0.005360 0.015159 0.004739 0.023448 2012-01-05 0.011041 0.025340 0.047100 0.010167 2012-01-06 0.010400 0.010301 0.033270 0.015237 2012-01-09 -0.001587 0.007656 -0.003497 -0.013072 2012-01-10 0.003574 0.000000 0.017362 0.003598  g = sns.pairplot(log_returns, diag_kind=\u0026quot;kde\u0026quot;) plt.show()  log_returns.corr()  ticker AAPL F GM MSFT ticker AAPL 1.000000 0.295965 0.282291 0.356120 F 0.295965 1.000000 0.692737 0.329482 GM 0.282291 0.692737 1.000000 0.323293 MSFT 0.356120 0.329482 0.323293 1.000000  6. Return Distribution Analysis Through below excercises we are comparing NIFTY50 log returns ditribution with Normal distribution using various methods.\nMany simple models assume underlying distribution to be normal and hence it is very important for us to understand the distribution of our data to develop an understanding about the challenges posed when the data is run on models having Normality as an assumption.\nRead more about Normal distribution here\nQuantile-Quantile Plot (Q-Q Plot) The quantile-quantile $$(q-q)$$ plot is a graphical technique for determining if two data sets come from populations with a common distribution, such as Normal, Exponential,etc. It is created by plotting two sets of quantiles against one another. If both sets of quantiles came from the same distribution, we should see the points forming a line that’s roughly straight. Normal q-q plot is used more frequently in practice due to so many statistical methods assuming normality. For creating the plot, the quantile of our sample data is plotted against the quantile calculated from a theoretical distribution. A 45-degree reference line is also plotted to see the alignment.\nThe normal $$q-q plot$$ for sample data belonging to a skewed distribution will from a curve instead of a straight line. On the other hand, the normal $$q-q plot$$ for a distribution with heavy tails will have points fall along a line in the middle of the graph, but curved off in the extremities.\nThe code given below calculates the z-score for the daily log returns and then plots its quantile against that of a theoretical normal distribution to generate the Normal Q-Q Plot\nz = (daily_log_returns[1:]-np.mean(daily_log_returns[1:]))/np.std(daily_log_returns[1:]) stats.probplot(z, dist=\u0026quot;norm\u0026quot;, plot=plt) plt.title(\u0026quot;Normal Q-Q plot\u0026quot;) plt.rcParams['figure.figsize'] = [12, 8] plt.show()  The above Normal Q-Q plot indicates that the distribution of the log returns is heavy tailed.\nKurtosis and Skewness Kurtosis — Kurtosis is a measure of the combined weight of a distribution\u0026rsquo;s tails relative to the center of the distribution. It esssentially tells us whether the data is heavy-tailed or light-tailed relative to a normal distribution. The kurtosis of any univariate normal distribution is 3. Distributions with kurtosis less than 3 are said to be platykurtic, while those with kurtosis greater than 3 are said to be leptokurtic. In python, the kurtosis can be calculated using the kurtosis function of pandas. This, however, calculates the excess Kurtosis(Kurtosis expressed as above or below 3), as it assumes the Fisher\u0026rsquo;s definition of Kurtosis, whereby Kurtosis of Normal distribution is equal to 0.\nSkewness — Skewness is a measure of symmetricity of the distribution and can be mathematically defined as the averaged cubed deviation from the mean divided by the standard deviation cubed. If the result of the computation is greater than zero, the distribution is positively skewed. If it\u0026rsquo;s less than zero, it\u0026rsquo;s negatively skewed. If equal to zero, it\u0026rsquo;s roughly symmetric. Normal distrbution has a skewness measure of zero. The funtion skew of pandas can be used to calculate the skewness of a distribution.\ndaily_return_excess_kurtosis = daily_log_returns[1:].kurtosis() daily_return_excess_skewness = daily_log_returns[1:].skew() print(\u0026quot;Excess Kurtosis of distribution of {} daily returns is {:.3f}\u0026quot;.format(ticker, daily_return_excess_kurtosis)) print(\u0026quot;Skewness of distribution of {} daily returns is {:.3f}\u0026quot;.format(ticker, daily_return_excess_skewness)) # p = stats.normaltest(daily_returns[1:])[1] # p1 = adfuller(daily_returns[1:])[1] # print(p1) # print(p)  Excess Kurtosis of distribution of NSE/NIFTY_50 daily returns is 1.756 Skewness of distribution of NSE/NIFTY_50 daily returns is -0.195  JB Test for Normality The Jarque-Bera Test (JB Test) is a test for Normality. Specifically, the test matches the skewness and kurtosis of data to see if it matches a Normal distribution.\nThe JB test tests the hypothesis\nHo : Data is Normal\nHa : Data is NOT Normal\nusing the test statistic\n$$JBTestStat=n(Skewness^26+ExcessKurtosis^224)$$where n is the sample size$$JBTestStat=n(Skewness^26+ExcessKurtosis^224)$$where n is the sample size\nIf data came from a Normal distriubtion, the test statistic would assume the value zero.\nNote that this test only works for a large enough number of data samples $$$$(\u0026gt;2000)$$ as the test statistic asymptotically has a Chi-squared distribution with 2 degrees of freedom.\nThe code given below calculates the JB test statistic and its corresponding p-value for the distribution using the function jarque_bera from scipy.stats\nJB_TestStat = len(daily_log_returns[1:])*((daily_return_excess_skewness**2)/6+(daily_return_excess_kurtosis**2)/24) print(\u0026quot;JB test statistic calculated for {} daily returns is {:.3f}\u0026quot;.format(ticker,JB_TestStat)) JB_TestStat,JBpv = stats.jarque_bera(daily_log_returns[1:]) print(\u0026quot;JB test statistic for {} daily returns is {:.3f}\u0026quot;.format(ticker,JB_TestStat)) print(\u0026quot;p-value for JB test for {} daily returns is {:.3f}\u0026quot;.format(ticker,JBpv)) if JBpv\u0026gt;0.05: print(\u0026quot;The p-value of {} implies that we reject the alternate hypothesis of distribution of log returns of {} not being normal with 95% confidence level\u0026quot;.format(JBpv,ticker)) else: print(\u0026quot;The p-value of {} implies that we reject the null hypothesis of distribution of log returns of {} being normal with 95% confidence level\u0026quot;.format(JBpv,ticker))   JB test statistic calculated for NSE/NIFTY_50 daily returns is 284.384 JB test statistic for NSE/NIFTY_50 daily returns is 282.208 p-value for JB test for NSE/NIFTY_50 daily returns is 0.000 The p-value of 0.0 implies that we reject the null hypothesis of distribution of log returns of NSE/NIFTY_50 being normal with 95% confidence level  7. Heatmap and Seasonality Monthly Returns as a Heatmap A heatmap is a graphical representation of matrix data where the individual values contained are represented as colors.\nThe code given below plots the monthly returns against their respective years in the form of a heatmap. It is done by first resampling the daily data as monthly, by taking the last published value of the month. Using these end of month levels, we calculate the monthly return, which is then grouped by \u0026lsquo;Year\u0026rsquo; and \u0026lsquo;Month\u0026rsquo;. The matrix hence obtained is plotted as a heatmap using the function heatmap of the library seaborn.\nThe colour scheme of the map highlights the high positive returns towards the green side of the spectrum, while high negative returns are towards the red side.\nIn [99]:\nnifty_levels_monthly = nifty_levels_test.resample('M').last() nifty_monthly_returns = pd.DataFrame(index = nifty_levels_monthly.index[1:]) nifty_monthly_returns['Monthly Returns'] = nifty_levels_monthly['Close'].pct_change() nifty_monthly_returns['Month'] = nifty_monthly_returns.index.strftime('%b') nifty_monthly_returns['Year'] = nifty_monthly_returns.index.year df = nifty_monthly_returns.groupby(['Year', 'Month'], sort=False)['Monthly Returns'].last() df = df.unstack(level=0) _ = sns.heatmap(df, annot=True, fmt=\u0026quot;.2%\u0026quot;, cmap=\u0026quot;RdYlGn\u0026quot;, center=0) plt.rcParams['figure.figsize'] = [12, 8] plt.title(\u0026quot;Monthly Return Plot\u0026quot;) plt.show()  WTI_close_prices = qd.get(\u0026quot;FRED/DCOILWTICO\u0026quot;, start_date=start_date, end_date=end_date, authtoken=authtoken) WTI_close_prices_monthly = WTI_close_prices.resample(\u0026quot;M\u0026quot;, how='last') WTI_close_prices_monthly_return = WTI_close_prices_monthly.pct_change() WTI_M_Y = WTI_close_prices_monthly_return.groupby([(WTI_close_prices_monthly_return.index.year) ,(WTI_close_prices_monthly_return.index.strftime('%b'))], sort=False).last() WTI_M_Y.head()  8. Digging deep N-days Moving Average N-days moving average is calculated by rolling the dates for a window of N days at a time and using the corresponding data for calculating the volatility.\nThe code given below calculates and plots the 20-day and 120-day moving average for NIFTY50 using the pandas rolling function.\nmoving_avgs_20 = nifty_levels_test['Close'].rolling(window=20).mean() moving_avgs_120 = nifty_levels_test['Close'].rolling(window=120).mean() moving_avgs_20.plot(label='20 days moving average') moving_avgs_120.plot(label='120 days moving average') nifty_levels_test['Close'].plot(label='Index Levels') plt.ylabel(ticker + ' levels') plt.legend() plt.title(ticker + ' levels and Moving averages') plt.show()  Drawdown Analysis A drawdown is the peak-to-trough decline during a specific recorded period of an investment, fund or commodity security. It is usually quoted as the percentage between the peak and the subsequent trough and it respresents the downside risk. Drawdowns help determine an investment\u0026rsquo;s financial risk by evaluating recovery-period, which is the time taken for the investment to recover from a decline in its net asset value back to the peak.\nThe code given below calculates the Maximum Rolling Drawdown for a window of 250 days, which is essentially the largest percentage loss a hypothetical investor could have incurred on the investment over a period of 250 days. It also calculates the recovery period and finally highlights the maximum drawdown period and recovery period, along with the plots for maximum rolling drawdown and index closing levels.\nwindow = 250 fig, (ax0, ax1) = plt.subplots(2,1) plt.rcParams['figure.figsize'] = [12, 16] roll_max_price = nifty_levels_test['Close'].rolling(window=window,min_periods=1).max() daily_rolling_drawdown = nifty_levels_test['Close']/roll_max_price-1 rolling_max_drawdown = daily_rolling_drawdown.rolling(window=window,min_periods=1).min() daily_rolling_drawdown.plot(kind='area', ax=ax0) rolling_max_drawdown.plot(linewidth=3.0, ax=ax0) max_drawdown_peak_i = ((np.maximum.accumulate(nifty_levels_test['Close'])-nifty_levels_test['Close'])/np.maximum.accumulate(nifty_levels_test['Close'])).values.argmax() max_drawdown_start_j = nifty_levels_test['Close'][:max_drawdown_peak_i].values.argmax() ax0.set_title(ticker + \u0026quot; Maximum rolling Drawdown for {} days\u0026quot;.format(window)) _ = nifty_levels_test['Close'].plot(ax=ax1, color='Blue') ax1.axvspan(nifty_levels_test.index[max_drawdown_peak_i],nifty_levels_test.index[max_drawdown_start_j], alpha=0.5, color='red') recovery_date = nifty_levels_test['Close'][max_drawdown_peak_i:]\\ [nifty_levels_test['Close'][max_drawdown_peak_i:]\u0026gt;nifty_levels_test['Close'][max_drawdown_start_j]].index[0] ax1.axvspan(nifty_levels_test.index[max_drawdown_peak_i],recovery_date, alpha=0.5, color='green') ax0.grid(True) ax0.set_xticklabels([]) x_label = ax0.set_xlabel('') x_label.set_visible(False) fig.tight_layout() plt.show()  The code given below calculates the Max Drawdown dates and the period start and end date. It also evaluates the Max Drawdown percentage, and the recovery period and completion time.\nmax_DD_perc = nifty_levels_test['Close'][max_drawdown_peak_i]/nifty_levels_test['Close'][max_drawdown_start_j]-1 max_DD_perc_period_len = (nifty_levels_test.index[max_drawdown_peak_i] - nifty_levels_test.index[max_drawdown_start_j]).days recovery_period = (recovery_date - nifty_levels_test.index[max_drawdown_peak_i]).days print(\u0026quot;Max Drawdown period for {} was between {} to {}\u0026quot;.format(ticker, nifty_levels_test.index[max_drawdown_start_j].date(), nifty_levels_test.index[max_drawdown_peak_i].date())) print(\u0026quot;Recovery was completed at {} post drawdown\u0026quot;.format(recovery_date.date())) print(\u0026quot;Max Drawdown Percentage = {:2%}\u0026quot;.format(max_DD_perc)) print(\u0026quot;Max Drawdown period = {} days\u0026quot;.format(max_DD_perc_period_len)) print(\u0026quot;Max Drawdown recovery period = {} days\u0026quot;.format(recovery_period))   Max Drawdown period for NSE/NIFTY_50 was between 2010-11-05 to 2011-12-20 Recovery was completed at 2013-11-03 post drawdown Max Drawdown Percentage = -28.012103% Max Drawdown period = 410 days Max Drawdown recovery period = 684 days  from IPython.display import HTML HTML('''\u0026lt;script\u0026gt; code_show=true; function code_toggle() { if (code_show){ $('div.input').hide(); } else { $('div.input').show(); } code_show = !code_show } $( document ).ready(code_toggle); \u0026lt;/script\u0026gt; \u0026lt;form action=\u0026quot;javascript:code_toggle()\u0026quot;\u0026gt;\u0026lt;input type=\u0026quot;submit\u0026quot; value=\u0026quot;Click here to toggle on/off the raw code.\u0026quot;\u0026gt;\u0026lt;/form\u0026gt;''')   code_show=true; function code_toggle() { if (code_show){ $(\u0026lsquo;div.input\u0026rsquo;).hide(); } else { $(\u0026lsquo;div.input\u0026rsquo;).show(); } code_show = !code_show } $( document ).ready(code_toggle);  \n "});index.add({'id':204,'href':'/library/tutorials/docs/python/snippets/is_anagram/','title':"is_anagram",'content':"Checks if a string is an anagram of another string (case-insensitive, ignores spaces, punctuation and special characters).\nUse s.replace() to remove spaces from both strings. Compare the lengths of the two strings, return False if they are not equal. Use sorted() on both strings and compare the results.\ndef is_anagram(s1, s2): _str1, _str2 = s1.replace(\u0026quot; \u0026quot;, \u0026quot;\u0026quot;), s2.replace(\u0026quot; \u0026quot;, \u0026quot;\u0026quot;) return False if len(_str1) != len(_str2) else sorted(_str1.lower()) == sorted(_str2.lower())  is_anagram(\u0026quot;anagram\u0026quot;, \u0026quot;Nag a ram\u0026quot;) # True  "});index.add({'id':205,'href':'/library/tutorials/docs/python/snippets/is_divisible/','title':"is_divisible",'content':"Checks if the first numeric argument is divisible by the second one.\nUse the modulo operator (%) to check if the remainder is equal to 0.\ndef is_divisible(dividend, divisor): return dividend % divisor == 0  is_divisible(6, 3) # True  "});index.add({'id':206,'href':'/library/tutorials/docs/python/snippets/is_even/','title':"is_even",'content':"Returns True if the given number is even, False otherwise.\nChecks whether a number is odd or even using the modulo (%) operator. Returns True if the number is even, False if the number is odd.\ndef is_even(num): return num % 2 == 0  is_even(3) # False  "});index.add({'id':207,'href':'/library/tutorials/docs/python/snippets/is_odd/','title':"is_odd",'content':"Returns True if the given number is odd, False otherwise.\nChecks whether a number is even or odd using the modulo (%) operator. Returns True if the number is odd, False if the number is even.\ndef is_odd(num): return num % 2 != 0  is_odd(3) # True  "});index.add({'id':208,'href':'/library/tutorials/docs/python/snippets/kebab/','title':"kebab",'content':"Converts a string to kebab case.\nBreak the string into words and combine them adding - as a separator, using a regexp.\nfrom re import sub def kebab(s): return sub( r\u0026quot;(\\s|_|-)+\u0026quot;,\u0026quot;-\u0026quot;, sub( r\u0026quot;[A-Z]{2,}(?=[A-Z][a-z]+[0-9]*|\\b)|[A-Z]?[a-z]+[0-9]*|[A-Z]|[0-9]+\u0026quot;, lambda mo: mo.group(0).lower(), s))  kebab('camelCase') # 'camel-case' kebab('some text') # 'some-text' kebab('some-mixed_string With spaces_underscores-and-hyphens') # 'some-mixed-string-with-spaces-underscores-and-hyphens' kebab('AllThe-small Things') # \u0026quot;all-the-small-things\u0026quot;  "});index.add({'id':209,'href':'/library/tutorials/docs/python/snippets/keys_only/','title':"keys_only",'content':"Returns a flat list of all the keys in a flat dictionary.\nUse dict.keys() to return the keys in the given dictionary. Return a list() of the previous result.\ndef keys_only(flat_dict): return list(flat_dict.keys())  ages = { \u0026quot;Peter\u0026quot;: 10, \u0026quot;Isabel\u0026quot;: 11, \u0026quot;Anna\u0026quot;: 9, } keys_only(ages) # ['Peter', 'Isabel', 'Anna']  "});index.add({'id':210,'href':'/library/tutorials/docs/python/snippets/last/','title':"last",'content':"Returns the last element in a list.\nuse lst[-1] to return the last element of the passed list.\ndef last(lst): return lst[-1]  last([1, 2, 3]) # 3  "});index.add({'id':211,'href':'/library/tutorials/docs/python/snippets/lcm/','title':"lcm",'content':"Returns the least common multiple of a list of numbers.\nUse functools.reduce(), math.gcd() and lcm(x,y) = x * y / gcd(x,y) over the given list.\nfrom functools import reduce from math import gcd def lcm(numbers): return reduce((lambda x, y: int(x * y / gcd(x, y))), numbers)  lcm([12, 7]) # 84 lcm([1, 3, 4, 5]) # 60  "});index.add({'id':212,'href':'/library/tutorials/docs/articles/webapp/html/learning-web-development/','title':"Learning Full Stack Web Development",'content':" The Ultimate Guide to Learning Full Stack Web Development in 6 months, for $30 Hey everyone! In this article I’m going to show you how to go from knowing little to nothing about Web Development to Junior Full Stack Developer in just six months, for under $30.\nThis article will cover everything you need to know! You’ll first learn the basics of Web Development with an online coding bootcamp ($15). You’ll follow that up with an advanced bootcamp ($15). Then, we’ll jump into free tutorials, articles, and documentation where you will reinforce everything you’ve learned in the first two bootcamps. Next, you’ll build a few projects with your new skills and open-source them on GitHub. Finally, we’ll focus on resume creation, interview preparation, and salary negotiation.\nDisclosure: I write reviews and receive compensation from the companies whose products I review. All opinions expressed here are my own.\nHere’s what you’ll learn if you follow this guide:  HTML/CSS jQuery JavaScript Git/Version Control React Node.js MongoDB  Ready? Lets dive in.\n1. The Web Development Bootcamp First thing’s first — You need to learn the basics and build a solid foundation of web development principles. There are many ways to do this, but in my opinion, this is the best and easiest way.\nColt Steele’s Web Development Bootcamp is the single best web development course money can buy. It’s sometimes on sale for $20 or less, and it’s packed with more than 40 hours of on-demand content.\nColt Steele, the instructor, was a lead instructor at a coding bootcamp in San Fransisco before moving to online coding education. This course is the online equivalent of what he taught at his in-person bootcamp.\nThis course covers all of the web dev basics: HTML5, CSS3, JavaScript, Bootstrap, SemanticUI, DOM Manipulation, jQuery, Unix(Command Line) Commands\nOnce you’ve got the basics down, you’ll explore more advanced topics like: NodeJS, NPM, ExpressJS, REST, MongoDB, Database Associations, Authentication, PassportJS, and Authorization.\nColt not only knows web development, but almost more importantly, he knows how to teach it. He clearly explains tougher concepts and breaks everything down in the easy to handle chunks. Plus, the course revolves around projects, so you learn by building real-world things, not boring reading and test taking.\nClick here to learn more or to sign up!\n2. The Advanced Web Development Bootcamp Now that you’ve taken the first bootcamp and know how to build full stack web applications, it’s time to take your learning a little deeper. This course builds upon the first by introducing more complex technologies, frameworks, and tools you can use to build beautiful, responsive, web applications.\nThe Advanced Web Development Bootcamp is designed to take your coding skills to the next level! Don’t worry, this course is also project based. You’ll build 10+ projects and explore dozens of code challenges with solutions to ensure you understand everything!\nHere’s what you’ll learn in this course:\n Build upon your CSS Skills by learning CSS3 Transitions, Transforms and Animations Dive into a front-end Framework and learn React, React-Router, and Redux Enhance your JavaScript skills with ES2015, ES2016, and ES2017, as well as Callbacks, Promises, Generators and Async Functions Building charts, force graphs and data visualizations Testing with Jasmine D3 SVG Building Node.js APIs Building Single Page Applications Object Oriented Programming in JavaScript Closures and the keyword ‘this’ Functional Programming in JavaScript Authentication and Authorization Asynchronous Code with JavaScript  This course has nearly 350 lectures and 30 hours of content, you’re going to learn a lot!!\nClick here to learn more or to sign up!\n3. Reinforce your Skills At this point, you’ve taken two online coding bootcamps and you’re hopefully starting to feel comfortable with your web development skills. You can successfully take a simple idea and build it out beautifully using a Node.js backend, and React on the front-end. Plus, you’re confident in your CSS abilities to style out a mobile first, responsive page.\nNow it’s time to continue learning while reinforcing your new skills. Below is a list of documentation, articles, and tutorials.\nReading these a few months ago probably would’ve made no sense — but with your new skills you can handle them like a champ.\nYou don’t have to work through every link I’ve provided. Think of these more like starting points.\nHTML/CSS  MDN HTML Documentation Flexbox Froggy The CSS Box Model Bootstrap  JavaScript  JavaScript — The keyword ‘this’ for beginners JavaScript — Arrow Functions for Beginners JavaScript: What the heck is a Callback? JavaScript: What the heck is an Immediately-Invoked Function Expression? JavaScript for Beginners: The new Operator Javascript: Learn Regular Expressions for Beginners JavaScript Template Literals and Tag Functions for Beginners JavaScript \u0026amp; the spread operator JavaScript: What is short-circuit evaluation? JavaScript: What is the ternary operator? JavaScript: Why does 3 + true = 4? (and 7 other tricky equations) JavaScript — What’s the difference between Null \u0026amp; Undefined? Learn and Understand Recursion in JavaScript Understand Closures in JavaScript JavaScript 30 for 30 — Learn to build 30 things in 30 days with 30 tutorials. No Frameworks, No Compilers, No Libraries, No Boilerplate. Learn FrontEnd Frameworks — Free 8 Week course focused on JavaScript Frameworks. Learn to build SPA’s (Single Page Applications) in both Angular and Ember from scratch.  React  create-react-app — Learn the quickest way to get started with React. react-router — Simple routing for React. Navigating the React.JS Ecosystem Official React Tutorial  Full Stack  Intro to Back End Web Development Deploying Applications with Heroku Client Server Communication Serverless Stack is a comprehensive guide to creating full-stack serverless applications. Create a note taking app from scratch using React.js, AWS Lambda, API Gateway, DynamoDB, and Cognito. Node JS and Authentication Express JS Database Integration  Databases  Relational vs. Non Relational SQL vs. NoSQL Learn MongoDB — Free courses \u0026amp; tutorials Express — Using a DB with Mongoose Node JS and Databases  Git  New Developer? You should’ve learned Git yesterday. A Step by Step Guide to Making Your First GitHub Contribution  Deployment\n Heroku Now Deploying Applications with Heroku  4. [Optional] Courses Want to keep learning? Here are some additional courses that I recommend that dive deeper into the subject of your choosing:\n Build React JS Projects Build Node.js Projects Learn Advanced JavaScript  5. Coding Games Level up your skills in your free time with these fun coding games and challenge websites.\n Codechef Code Wars Coding Game Hacker Rank  6. Build Something Go forth and build something cool! Show off all of the skills you’ve learned and bring an idea from concept to production!\nNeed some help brainstorming what to build? Here are a few links that should have you thinking in the right direction:\n 94 Full Stack Examples 6 Absurd Ideas For Building Your First Web App Fullstack Student Final Projects Web app ideas for the growing web developer  Make sure to open source your project so you can show off everything you’ve learned. The first bootcamp goes into Git and GitHub with great depth, but if you’re still not feeling comfortable with it, you can check out these two links for a little additional motivation and help:\n New Developer? You should’ve learned Git yesterday. A Step by Step Guide to Making Your First GitHub Contribution  7. Resume \u0026amp; Portfolio You’ve learned the skills, now it’s time to make your resume shine and make your portfolio stand out. Here’s a collection of links to help you accomplish that:\nMake your portfolio\n Customizable Web Developer Portfolio — Built with Flexbox. 10 Awesome Web Developer Portfolios  How to Apply\n I spent 3 months applying to jobs after a coding bootcamp. Here’s what I learned. (FCC) Lessons from my Post-bootcamp Job search (FCC) How to land a six figure job in tech with no connections (FCC)  Resume \u0026amp; LinkedIn\n What are some of the best resume formats you’ve seen? Model examples for Fullstack Developer LinkedIn profiles  Personal Projects\n Recruiters, what kind of CS projects impress?  8. Interview Prep Your resume and portfolio got you the interview! Awesome! Use these links to prepare for your interview:\n CS50 — Prep and Practice for Technical Interviews [YouTube] How to Break Into the Tech Industry — a Guide to Job Hunting and Tech Interviews Common JavaScript Interview Questions and Answers Ammon Bartram — Ask an interviewer anything: interview questions, answers, mistakes Sharing some interview tips (Silicon valley employee) Job interview questions to ask the interviewer I suck at programming interviews. When solving an interview problem, talk all the time. Hiring managers (or other seasoned developers), what qualities do you look for in your ideal candidate? Post your best interview questions Been interviewing with a lot of tech startups as a frontend dev, here are the technical questions I’ve been asked (MID-SENIOR LEVEL) 10 Interview Questions every JS Developer should know (Medium)  9. Salary Information You’ve gotten the offer! Now you just need to negotiate your compensation package. Here are a collection of links to help:\n How Much Do Software Developers Make in 2017? 12\u0026frasl;2016 Salary Sharing Thread (\u0026lt;2 yrs Experience) Salary Negotiations and how not to set a bunch of money on fire (Medium) 10 Rules for negotiating a job offer (Medium) How not to bomb your offer negotiation (Medium)  Closing Notes You made it to the end of the article… Good luck on your Web Development journey! It’s certainly not going to be easy, but by following this guide, you are one stop closer to accomplishing your goal.\nPlease consider entering your email here if you’d like to be added to my once-weekly email list, and don’t forget to follow codeburst on Twitter!\nIf this post was helpful, please click the clap 👏 button below a few times to show your support! ⬇⬇  Source: codeburst.io.\n "});index.add({'id':213,'href':'/library/tutorials/docs/python/beginer/list/','title':"List",'content':" Python List "});index.add({'id':214,'href':'/library/tutorials/docs/python/snippets/longest_item/','title':"longest_item",'content':"Takes any number of iterable objects or objects with a length property and returns the longest one. If multiple objects have the same length, the first one will be returned.\nUse max() with len as the key to return the item with the greatest length.\ndef longest_item(*args): return max(args, key=len)  longest_item('this', 'is', 'a', 'testcase') # 'testcase' longest_item([1, 2, 3], [1, 2], [1, 2, 3, 4, 5]) # [1, 2, 3, 4, 5] longest_item([1, 2, 3], 'foobar') # 'foobar'  "});index.add({'id':215,'href':'/library/tutorials/docs/python/snippets/map_values/','title':"map_values",'content':"Creates an object with the same keys as the provided object and values generated by running the provided function for each value.\nUse dict.keys() to iterate over the object\u0026rsquo;s keys, assigning the values produced by fn to each key of a new object.\ndef map_values(obj, fn): ret = {} for key in obj.keys(): ret[key] = fn(obj[key]) return ret  users = { 'fred': { 'user': 'fred', 'age': 40 }, 'pebbles': { 'user': 'pebbles', 'age': 1 } } map_values(users, lambda u : u['age']) # {'fred': 40, 'pebbles': 1}  "});index.add({'id':216,'href':'/library/tutorials/docs/python/snippets/max_by/','title':"max_by",'content':"Returns the maximum value of a list, after mapping each element to a value using the provided function.\nUse map() with fn to map each element to a value using the provided function, use max() to return the maximum value.\ndef max_by(lst, fn): return max(map(fn, lst))  max_by([{ 'n': 4 }, { 'n': 2 }, { 'n': 8 }, { 'n': 6 }], lambda v : v['n']) # 8  "});index.add({'id':217,'href':'/library/tutorials/docs/python/snippets/max_element_index/','title':"max_element_index",'content':"Returns the index of the element with the maximum value in a list.\nUse max() and list.index() to get the maximum value in the list and return its index.\ndef max_element_index(arr): return arr.index(max(arr))  max_element_index([5, 8, 9, 7, 10, 3, 0]) # 4  "});index.add({'id':218,'href':'/library/tutorials/docs/python/snippets/max_n/','title':"max_n",'content':"Returns the n maximum elements from the provided list. If n is greater than or equal to the provided list\u0026rsquo;s length, then return the original list (sorted in descending order).\nUse sorted() to sort the list, [:n] to get the specified number of elements. Omit the second argument, n, to get a one-element list.\ndef max_n(lst, n=1): return sorted(lst, reverse=True)[:n]  max_n([1, 2, 3]) # [3] max_n([1, 2, 3], 2) # [3,2]  "});index.add({'id':219,'href':'/library/tutorials/docs/python/snippets/median/','title':"median",'content':"Finds the median of a list of numbers.\nSort the numbers of the list using list.sort() and find the median, which is either the middle element of the list if the list length is odd or the average of the two middle elements if the list length is even.\nstatistics.median() provides similar functionality to this snippet.\ndef median(list): list.sort() list_length = len(list) if list_length % 2 == 0: return (list[int(list_length / 2) - 1] + list[int(list_length / 2)]) / 2 return list[int(list_length / 2)]  median([1,2,3]) # 2 median([1,2,3,4]) # 2.5  "});index.add({'id':220,'href':'/library/tutorials/docs/python/beginer/dictionary/merge-two-dictionaries/','title':"Merge Two Dictionaries",'content':" How to Merge Two Dictionaries in Python: Dictionary Comprehensions and Unpacking POSTED ON JUNE 7, 2019 BY JEREMY GRIFSKI\nWhen I’m trying to find a topic for this series, I either decide to write about something I just learned, or I choose to write about something I found from the list of top Python questions on Stack Overflow. Today, I’m hitting both by covering how to merge two dictionaries in Python.\nTable of Contents  Table of Contents Problem Introduction Solutions  Merge Two Dictionaries with Brute Force Merge Two Dictionaries with a Dictionary Comprehension Merge Two Dictionaries with Copy and Update Merge Two Dictionaries with Dictionary Unpacking  Performance A Little Recap  Problem Introduction Earlier in this series, I covered a similar problem where I wanted to convert two lists into a dictionary. In that article, I covered various methods for mapping one list onto the other. This time around I want to convert two dictionaries into a single dictionary like so:\n1. yusuke_power = {\u0026quot;Yusuke Urameshi\u0026quot;: \u0026quot;Spirit Gun\u0026quot;} 2. hiei_power = {\u0026quot;Hiei\u0026quot;: \u0026quot;Jagan Eye\u0026quot;} 4. # Insert merge code here 6. powers = { 7. \u0026quot;Yusuke Urameshi\u0026quot;: \u0026quot;Spirit Gun\u0026quot;, 8. \u0026quot;Hiei\u0026quot;: \u0026quot;Jagan Eye\u0026quot; 9. }  Here, we have two dictionaries: yusuke_power and hiei_power. Each dictionary maps a YuYu Hakasho character to one of their abilities. In this case, I chose Yusuke and his Spirit Gun as well as Hiei and his Jagan Eye. Ultimately, we want to be able to merge these dictionaries, so we have a collection of characters and their powers. Let’s see if we can accomplish that below.\nSolutions As always, I like to list off a few possible ways to solve the problem. To start, we’ll try a brute force solution, then we’ll dig into some more sophisticated solutions.\nMerge Two Dictionaries with Brute Force As is tradition in this series, I always like to kick things off with a roll-your-own solution. In this case, we’re looking to iterate over one dictionary and add its items to the other dictionary:\n1. yusuke_power = {\u0026quot;Yusuke Urameshi\u0026quot;: \u0026quot;Spirit Gun\u0026quot;} 2. hiei_power = {\u0026quot;Hiei\u0026quot;: \u0026quot;Jagan Eye\u0026quot;} 4. for key, value in hiei_power.items(): 5. yusuke_power[key] = value  Naturally, this solution leaves a lot to be desired, but it gets the job done. At the end of the day, yusuke_power should look like the powers dictionary we want.\nTo accomplish something closer to what we want, we would have to iterate over both dictionaries separately:\n1. yusuke_power = {\u0026quot;Yusuke Urameshi\u0026quot;: \u0026quot;Spirit Gun\u0026quot;} 2. hiei_power = {\u0026quot;Hiei\u0026quot;: \u0026quot;Jagan Eye\u0026quot;} 3. powers = dict() 5. for dictionary in (yusuke_power, hiei_power): 6. for key, value in dictionary.items(): 7. powers[key] = value  Unfortunately, this solution doesn’t scale very well. That said, there are better ways to solve this problem.\nMerge Two Dictionaries with a Dictionary Comprehension Since I’m a big fan of comprehensions, I think it’s worth mentioning that the solution above can be written in a single line with a dictionary comprehension:\n1. yusuke_power = {\u0026quot;Yusuke Urameshi\u0026quot;: \u0026quot;Spirit Gun\u0026quot;} 2. hiei_power = {\u0026quot;Hiei\u0026quot;: \u0026quot;Jagan Eye\u0026quot;} 4. powers = {key: value for d in (yusuke_power, hiei_power) for key, value in d.items()}  Here, we have written a dictionary comprehension that iterates over both dictionaries and copies each item into a new dictionary. Naturally, it works just like the brute force solution.\nMerge Two Dictionaries with Copy and Update As with many of the collections in Python, they have a builtin copy function associated with them. As a result, we can leverage that copy function to generate a new dictionary which includes all the items of the original dictionary. In addition, dictionaries have an update function which can be used to add all the items from one dictionary into another:\n1. yusuke_power = {\u0026quot;Yusuke Urameshi\u0026quot;: \u0026quot;Spirit Gun\u0026quot;} 2. hiei_power = {\u0026quot;Hiei\u0026quot;: \u0026quot;Jagan Eye\u0026quot;} 4. powers = yusuke_power.copy() 5. powers.update(hiei_power)  With this solution, we’re able to generate that powers dictionary which contains all the items from the original two dictionaries. As an added benefit, copy and update are backwards compatible, so Python 2 users won’t feel left out.\nIt’s worth noting that we can extend this solution to merge any number of dictionaries with a custom function:\n1. def merge_dicts(*dicts: dict): 2. merged_dict = dict() 3. for dictionary in dicts: 4. merge_dict.update(dictionary) 5. return merged_dict  Now, we can generate a new dictionary which contains all the items in any number of dictionaries.\nMerge Two Dictionaries with Dictionary Unpacking When Python 3.5 rolled out, it introduced a dictionary unpacking syntax which allows us to merge dictionaries with a new operator:\n1. yusuke_power = {\u0026quot;Yusuke Urameshi\u0026quot;: \u0026quot;Spirit Gun\u0026quot;} 2. hiei_power = {\u0026quot;Hiei\u0026quot;: \u0026quot;Jagan Eye\u0026quot;} 4. powers = {**yusuke_power, **hiei_power}  Naturally, this solution scales for any number of arguments:\n1. yusuke_power = {\u0026quot;Yusuke Urameshi\u0026quot;: \u0026quot;Spirit Gun\u0026quot;} 2. hiei_power = {\u0026quot;Hiei\u0026quot;: \u0026quot;Jagan Eye\u0026quot;} 4. powers = {**yusuke_power, **hiei_power, \u0026quot;Yoko Kurama\u0026quot;: \u0026quot;Rose Whip\u0026quot;}  Of course, the drawback is backwards compatibility. If you’re still rocking Python 2 or even older versions of Python 3, this feature may not be available to you. Regardless, I think it’s a pretty clever piece of syntax, and I like how it looks.\nPerformance For the first time in this series, I thought it would be beneficial to take a look at the performance of each of the methods above (if you’re lucky, I might update the old articles to include performance as well). To do that, I’m going to use the builtin timeit library.\nTo use the timeit library, we have to set up some strings for testing:\n1. setup = \u0026quot;\u0026quot;\u0026quot;\\ 2. yusuke_power = {\u0026quot;Yusuke Urameshi\u0026quot;: \u0026quot;Spirit Gun\u0026quot;}; 3. hiei_power = {\u0026quot;Hiei\u0026quot;: \u0026quot;Jagan Eye\u0026quot;}; 4. powers = dict() 5. \u0026quot;\u0026quot;\u0026quot; 7. brute_force = \u0026quot;\u0026quot;\u0026quot;\\ 8. for dictionary in (yusuke_power, hiei_power): 9. for key, value in dictionary.items(): 10. powers[key] = value 11. \u0026quot;\u0026quot;\u0026quot; 13. dict_comprehension = \u0026quot;\u0026quot;\u0026quot;\\ 14. powers = {key: value for d in (yusuke_power, hiei_power) for key, value in d.items()} 15. \u0026quot;\u0026quot;\u0026quot; 17. copy_and_update = \u0026quot;\u0026quot;\u0026quot;\\ 18. powers = yusuke_power.copy() 19. powers.update(hiei_power) 20. \u0026quot;\u0026quot;\u0026quot; 22. dict_unpacking = \u0026quot;\u0026quot;\u0026quot;\\ 23. powers = {**yusuke_power, **hiei_power} 24. \u0026quot;\u0026quot;\u0026quot;  With our strings setup, we can begin our performance test:\n1. \u0026gt;\u0026gt;\u0026gt; import timeit 2. \u0026gt;\u0026gt;\u0026gt; timeit.timeit(stmt=brute_force, setup=setup) 3. 1.517404469999974 4. \u0026gt;\u0026gt;\u0026gt; timeit.timeit(stmt=dict_comprehension, setup=setup) 5. 1.6243454339999062 6. \u0026gt;\u0026gt;\u0026gt; timeit.timeit(stmt=copy_and_update, setup=setup) 7. 0.7273476979999032 8. \u0026gt;\u0026gt;\u0026gt; timeit.timeit(stmt=dict_unpacking, setup=setup) 9. 0.2897768919999635  As it turns out, dictionary unpacking is very fast. For reference, I performed the testing on a Surface Go with Windows 10 and Python 3.7.1.\nA Little Recap Well, that’s all I have in terms of typical solutions. All that said, be aware that all of these solutions will overwrite duplicate values. In other words, if two dictionaries contain the same key, the last dictionary to be merged will overwrite the previous dictionary’s value.\nAlso, it’s worth noting that all of these solutions perform a shallow copy of the dictionaries. As a result, dictionaries that may be nested or store objects will only have their references copied, not the actual values. If that’s a constraint in your application, you may need to write your own recursive copy function.\nAt any rate, here are all the solutions:\n1. yusuke_power = {\u0026quot;Yusuke Urameshi\u0026quot;: \u0026quot;Spirit Gun\u0026quot;} 2. hiei_power = {\u0026quot;Hiei\u0026quot;: \u0026quot;Jagan Eye\u0026quot;} 3. powers = dict() 5. # Brute force 6. for dictionary in (yusuke_power, hiei_power): 7. for key, value in dictionary.items(): 8. powers[key] = value 10. # Dictionary Comprehension 11. powers = {key: value for d in (yusuke_power, hiei_power) for key, value in d.items()} 13. # Copy and update 14. powers = yusuke_power.copy() 15. powers.update(hiei_power) 17. # Dictionary unpacking (Python 3.5+) 18. powers = {**yusuke_power, **hiei_power} 20. # Backwards compatible function for any number of dicts 21. def merge_dicts(*dicts: dict): 22. merged_dict = dict() 23. for dictionary in dicts: 24. merge_dict.update(dictionary) 25. return merged_dict  And, that’s it! As always, I appreciate the support. If you liked this article, do me a favor and share it with someone. For those feeling extra generous, consider becoming a member of The Renegade Coder. If you’re not convinced, check out some of these other Python articles:\n Rock Paper Scissors Using Modular Arithmetic How to Write a List Comprehension in Python The Coolest Programming Language Features  Once again, thanks for the support! Before you go, share your recommendation for a topic you’d like to see in the comments.\n Source : .\n "});index.add({'id':221,'href':'/library/tutorials/docs/python/snippets/min_by/','title':"min_by",'content':"Returns the minimum value of a list, after mapping each element to a value using the provided function.\nUse map() with fn to map each element to a value using the provided function, use min() to return the minimum value.\ndef min_by(lst, fn): return min(map(fn, lst))  min_by([{ 'n': 4 }, { 'n': 2 }, { 'n': 8 }, { 'n': 6 }], lambda v : v['n']) # 2  "});index.add({'id':222,'href':'/library/tutorials/docs/python/snippets/min_n/','title':"min_n",'content':"Returns the n minimum elements from the provided list. If n is greater than or equal to the provided list\u0026rsquo;s length, then return the original list (sorted in ascending order).\nUse sorted() to sort the list,[:n]to get the specified number of elements. Omit the second argument,n`, to get a one-element list.\ndef min_n(lst, n=1): return sorted(lst, reverse=False)[:n]  min_n([1, 2, 3]) # [1] min_n([1, 2, 3], 2) # [1,2]  "});index.add({'id':223,'href':'/library/tutorials/docs/python/snippets/most_frequent/','title':"most_frequent",'content':"Returns the most frequent element in a list.\nUse set(list) to get the unique values in the list combined with max() to find the element that has the most appearances.\ndef most_frequent(list): return max(set(list), key=list.count)  most_frequent([1, 2, 1, 2, 3, 2, 1, 4, 2]) #2  "});index.add({'id':224,'href':'/library/tutorials/docs/python/snippets/n_times_string/','title':"n_times_string",'content':"Prints out the same string a defined number of times.\nRepeat the string n times, using the * operator.\ndef n_times_string(s, n): return (s * n)  n_times_string('py', 4) #'pypypypy'  "});index.add({'id':225,'href':'/library/tutorials/docs/python/snippets/none/','title':"none",'content':"Returns False if the provided function returns True for at least one element in the list, True otherwise.\nUse all() and fn to check if fn returns False for all the elements in the list.\ndef none(lst, fn=lambda x: x): return all(not fn(x) for x in lst)  none([0, 1, 2, 0], lambda x: x \u0026gt;= 2 ) # False none([0, 0, 0]) # True  "});index.add({'id':226,'href':'/library/tutorials/docs/python/snippets/offset/','title':"offset",'content':"Moves the specified amount of elements to the end of the list.\nUse lst[offset:] and lst[:offset] to get the two slices of the list and combine them before returning.\ndef offset(lst, offset): return lst[offset:] + lst[:offset]  offset([1, 2, 3, 4, 5], 2) # [3, 4, 5, 1, 2] offset([1, 2, 3, 4, 5], -2) # [4, 5, 1, 2, 3]  "});index.add({'id':227,'href':'/library/tutorials/docs/python/snippets/palindrome/','title':"palindrome",'content':"Returns True if the given string is a palindrome, False otherwise.\nUse s.lower() and re.sub() to convert to lowercase and remove non-alphanumeric characters from the given string. Then, compare the new string with its reverse.\nfrom re import sub def palindrome(s): s = sub('[\\W_]', '', s.lower()) return s == s[::-1]  palindrome('taco cat') # True  "});index.add({'id':228,'href':'/library/tutorials/docs/articles/data-science/finance/portfolio-optimization-python/','title':"Portfolio Optimization in Python",'content':" Portfolio Optimization in Python 5/31/2018 Written by DD\nIn this post we will demonstrate how to use python to calculate the optimal portfolio and visualize the efficient frontier.\nIn this post we will only show the code with minor explanations.\nLets begin with loading the modules.\nimport pandas as pd import numpy as np import matplotlib.pyplot as plt import pandas_datareader as web  Next we will get the stock tickers and the price data.\ntick = ['AMZN', 'AAPL', 'NFLX', 'XOM', 'T'] price_data = web.get_data_yahoo(tick, start = '2014-01-01', end = '2018-05-31')['Adj Close']  Now lets calculate the log returns.\nlog_ret = np.log(price_data/price_data.shift(1))  Next we will calculate the covariance matrix.\ncov_mat = log_ret.cov() * 252 print(cov_mat)  ## Symbols AAPL AMZN NFLX T XOM ## Symbols ## AAPL 0.052338 0.023844 0.026897 0.008896 0.012677 ## AMZN 0.023844 0.086810 0.048926 0.007808 0.012902 ## NFLX 0.026897 0.048926 0.175844 0.008173 0.013306 ## T 0.008896 0.007808 0.008173 0.026032 0.010989 ## XOM 0.012677 0.012902 0.013306 0.010989 0.034014  Next we will jump right into the for loop and simulate the portfolio returns and risk on 5000 random portfolios. If you need the further explanation, please see the code in R.\n# Simulating 5000 portfolios num_port = 5000 # Creating an empty array to store portfolio weights all_wts = np.zeros((num_port, len(price_data.columns))) # Creating an empty array to store portfolio returns port_returns = np.zeros((num_port)) # Creating an empty array to store portfolio risks port_risk = np.zeros((num_port)) # Creating an empty array to store portfolio sharpe ratio sharpe_ratio = np.zeros((num_port))  Lets run the for loop.\nfor i in range(num_port): wts = np.random.uniform(size = len(price_data.columns)) wts = wts/np.sum(wts) # saving weights in the array all_wts[i,:] = wts  # Portfolio Returns port_ret = np.sum(log_ret.mean() * wts) port_ret = (port_ret + 1) ** 252 - 1  # Saving Portfolio returns port_returns[i] = port_ret  # Portfolio Risk port_sd = np.sqrt(np.dot(wts.T, np.dot(cov_mat, wts))) port_risk[i] = port_sd  # Portfolio Sharpe Ratio # Assuming 0% Risk Free Rate sr = port_ret / port_sd sharpe_ratio[i] = sr  Now that all the heavy lifting has been done. We will start by getting the minimum variance portfolio and the tangency portfolio.\nnames = price_data.columns min_var = all_wts[port_risk.argmin()] print(min_var)  ## [0.1479928 0.08456108 0.01861031 0.43988479 0.30895102]  max_sr = all_wts[sharpe_ratio.argmax()] print(max_sr)  ## [0.33134387 0.38121158 0.23987104 0.04371634 0.00385717]  Lets see the max sharpe ratio and the minimum risk for these portfolios\nprint(sharpe_ratio.max())  ## 1.5976782731708208  print(port_risk.min())  ## 0.13362971668665094  Since we are only simulating 5000 portfolio, it very likely our allocations and our sharpe ratios/risk metrics will be different than what we got on the last post in R. The point of this exercise is to demonstrate the underlying process of getting optimal portfolio. If we need more accuracy then we need to use optimization packages instead of this trial and error method described in this post.\nNow lets visualize the weights of the portfolio. First we will visualize the minimum variance portfolio.\nmin_var = pd.Series(min_var, index=names) min_var = min_var.sort_values() fig = plt.figure() ax1 = fig.add_axes([0.1,0.1,0.8,0.8]) ax1.set_xlabel('Asset') ax1.set_ylabel(\u0026quot;Weights\u0026quot;) ax1.set_title(\u0026quot;Minimum Variance Portfolio weights\u0026quot;) min_var.plot(kind = 'bar') plt.show();  Next we will visualize the max sharpe ratio portfolio.\nmax_sr = pd.Series(max_sr, index=names) max_sr = max_sr.sort_values() fig = plt.figure() ax1 = fig.add_axes([0.1,0.1,0.8,0.8]) ax1.set_xlabel('Asset') ax1.set_ylabel(\u0026quot;Weights\u0026quot;) ax1.set_title(\u0026quot;Tangency Portfolio weights\u0026quot;) max_sr.plot(kind = 'bar') plt.show();  Finally we can plot all the 5000 portfolios.\nfig = plt.figure() ax1 = fig.add_axes([0.1,0.1,0.8,0.8]) ax1.set_xlabel('Risk') ax1.set_ylabel(\u0026quot;Returns\u0026quot;) ax1.set_title(\u0026quot;Portfolio optimization and Efficient Frontier\u0026quot;) plt.scatter(port_risk, port_returns) plt.show();    https://www.codingfinance.com/post/2018-05-31-portfolio-opt-in-python/   "});index.add({'id':229,'href':'/library/tutorials/docs/articles/data-science/finance/portfolio-optimization-methods/','title':"Portfolio Optimization Methods",'content':" Portfolio Optimization Methods When constructing a multi-asset portfolio, coming up with the strategy to allocate weights to the portfolio components is a very important step in the process. Coming up with weights for a portfolio given its components can be done in a number of ways and is a question that boggles even the most skilled managers. So what is the most optimal way to do this? in this article we will try to introduce the most widely used methods and understand the intuition behind them.\nWhen we think naively about this, the most intuitive way of allocating to the securities would be based on our conviction for them. In the early days of the financial market’s history traders actually used to do that and be profitable. As the trend following strategies saw crashes in early 1997 with increased volatility in the markets, traders started adding stop losses and take profits and staggered entry and exit to the strategies.\nAfter the Global Financial Crisis in 2008 “risk-parity” became a widely followed strategy. This strategy allocated equal risk budgets to all participating assets and does not look at investor views or expected return projections. The most popular method that does incorporate views is the Markovitz Mean-Variance Optimal portfolio based on the Capital Asset Pricing Model or CAPM. The passive portfolios like the market index use a market-cap-weighted allocation. Other naive methodologies are the equal weight portfolio or the minimum variance portfolio.\nThe literature around portfolio optimization is rich and vast. There are a wide variety of variations and improvements upon the basic methods and a lot of active research that goes around it. I worked on a variation of risk parity called \u0026ldquo;risk budgeting\u0026rdquo; and a novel “active risk budgeting” when working on the US managed futures strategies. There is even a use case of machine learning methods like reinforcement learning methods that find a good fit for this problem.\nIn this post, we take an introductory glance at the rationale of some popular portfolio construction methods and their implementation in Python. We will also look at how each of these methods performs for an example portfolio consisting of sectoral indices published on the NSE namely, Bank, Auto, Fin Service, FMCG, IT, Media, Metal, Pharma, PSU Bank, Private Bank, Realty.\nWe rebalance our portfolios quarterly and trade in a long-only fashion.\nEqual Weight This method assigns equal weights to all components. This would be most useful when the returns across all interested assets are purely random and we have no views.\ndef equal_weighted_portfolio(w, V): '' The equal-weighted portfolio returns equal weights to each of the portfolio components ''' return [1.0/len(w)]*len(w)  We’ll see the returns of an equal-weighted portfolio comprising of the sectoral indices below.\nThe annualized return is 13.3% and the annualized risk is 21.7%\nRisk Parity The risk contribution of each asset is equal. This method gained popularity after the 2008 crisis. Risk parity works best in a world where the Sharpe ratios between all asset classes are the same (and consequently equal risk contribution would contribute equal returns).\nThe weights are a solution to the optimization equation -\nWhere, w is the weight, ∑ is the covariance matrix and n is the number of assets\ndef risk_parity(w, V): def calculate_portfolio_variance(w,V): # function that calculates portfolio risk w = np.matrix(w) return (w*V*w.T)[0,0] def calculate_risk_contribution(w,V): # function that calculates asset contribution to total risk w = np.matrix(w) sigma = np.sqrt(calculate_portfolio_variance(w,V)) # Marginal Risk Contribution MRC = V*w.T # Risk Contribution RC = np.multiply(MRC,w.T)/sigma return RC def risk_budget_objective(x,pars): # calculate portfolio risk V = pars[0]# covariance table x_t = pars[1] # risk target in percent of portfolio risk sig_p = np.sqrt(calculate_portfolio_variance(x,V))# portfolio sigma risk_target = np.asmatrix(np.multiply(sig_p,x_t)) asset_RC = calculate_risk_contribution(x,V) J = sum(np.square(asset_RC-risk_target.T))[0,0] # sum of squared error return J def total_weight_constraint(x): return np.sum(x)-1.0 w0 = x_t = [1.0/len(w)]*len(w) cons = ({'type': 'eq', 'fun': total_weight_constraint}) res= minimize(risk_budget_objective, w0, args=[V,x_t], method='SLSQP',constraints=cons, options={'disp': True}) return np.asmatrix(res.x)  The annualized return is 13.40% and the annualized risk is 24.7%. We can see that low volatility sector like FMCG get higher weight and high-risk sectors like PSU Bank get lower weight.\nMinimum Variance This method minimizes the portfolio’s volatility. This would work best when the returns are not proportional to risk and lowering risk does not lead to lower returns as well.\nThe weights are a solution to the equation,\nWhere, w is the weight, ∑ is the covariance matrix\ndef minimum_variance(w0, V): def calculate_portfolio_var(w, pars): # function that calculates portfolio risk V = pars # covariance table w = np.matrix(w) return (w * V * w.T)[0, 0] def total_weight_constraint(x): return np.sum(x) - 1.0 cons = ({'type': 'eq', 'fun': total_weight_constraint}) res = minimize calculate_portfolio_var, w0, args=V, method='SLSQP', constraints=cons, options={ 'disp': False}) return np.asmatrix(res.x)  The annualized return is 13.6% and the annualized risk is 20.8%. This looks quite similar to the equal weight example and could be because the risks of the indices are similar and the optimizer based solution to low-risk portfolio stops at a local minimum.\nMean-Variance Optimization This is the famous Markovitz Portfolio. This is a mathematical framework for assembling a portfolio of assets such that the expected return is maximized for a given level of risk.\nThe weights are a solution to the optimization problem for different levels of expected returns,\nWhere, w is the weight, ∑ is the covariance matrix and N is the number of assets, R is the expected return and q is a \u0026ldquo;risk tolerance\u0026rdquo; factor, where 0 results in the portfolio with minimal risk and ∞ results in the portfolio infinitely far out on the frontier with both expected return and risk unbounded.\ndef mean_variance_optimization(w, V): def calculate_portfolio_risk(w, V): # function that calculates portfolio risk w = np.matrix(w) return np.sqrt((w * V * w.T)[0, 0]) def calculate_portfolio_return(w, r): # function that calculates portfolio return return np.sum(w*r) # optimizer def optimize(w, V, target_return=0.1): init_guess = np.ones(len(symbols)) * (1.0 / len(symbols)) weights = minimize(get_portfolio_risk, init_guess, args=(normalized_prices,), method='SLSQP', options={'disp': False}, constraints=({'type': 'eq', 'fun': lambda inputs: 1.0 - np.sum(inputs)}, {'type': 'eq', 'args': (normalized_prices,), 'fun': lambda inputs, normalized_prices: target_return - get_portfolio_return(weights=inputs, normalized_prices=normalized_prices)})) return weights.x optimal_risk_all = np.array([]) optimal_return_all = np.array([]) for target_return in np.arange(0.005, .0402, .0005): opt_w = optimize(prices=prices, symbols=symbols, target_return=target_return) optimal_risk_all = np.append(optimal_risk_all, get_portfolio_risk(opt_w, V)) optimal_return_all = np.append(optimal_return_all, get_portfolio_return(opt_w, w)) return optimal_return_all, optimal_risk_all  The annualized return is 15.2% and the annualized risk is 21.9%. We have taken the portfolio with the highest level of risk, one could actually choose a risk-based on her risk tolerance.\nOn an overall level, we see that mean-variance optimization is possibly the best method for our example.\nNow surely each of these methods could be of choice under different conditions contingent on different factors. So what are the factors to look at?\nFactors Affecting Portfolio Optimization Behavioural Factors The investor\u0026rsquo;s risk outlook or risk aversion is obviously the most important factor to keep in mind while deciding the portfolio construction method. The choice of instruments and the investment horizon guide the diversification available and the methodology so this is the most important factor.\nCorrelation Correlation guides diversification. In their research posted recently Resolve Asset Management demonstrate that the optimization-based methods outperform naive methods only when there is an opportunity to diversify and a large number of risk factors present. For imperfectly correlated assets the portfolio returns and volatility are different from the weighted sum. So correlation plays a big role in the choice of the portfolio construction method.\nMarket Regime We showed that minimum variance is optimal when all return assumptions are same and risk parity is optimal when all risk-adjusted returns are the same. Such scenarios actually occur as the markets change regimes. There are actual regimes where returns are inversely correlated to risk while others where higher risk is rewarded by higher returns. This makes market regimes a good factor to look at when evaluating the portfolio construction methods.\nConclusion I hope this article gives the reader a good start in the exploration of the wonderful field of research on portfolio construction and optimization. This interesting area of research can add levels of sophistication to any systematic trading strategy.\nDisclaimer: The views, opinions, and information provided within this guest post are those of the author alone and do not represent those of QuantInsti®. The accuracy, completeness, and validity of any statements made or the links shared within this article are not guaranteed. We accept no liability for any errors, omissions or representations. Any liability with regards to infringement of intellectual property rights remains with them.\n Source : .\n "});index.add({'id':230,'href':'/library/tutorials/docs/python/beginer/date-and-time/python-date-and-time/','title':"Python - Date \u0026 Time",'content':" Python - Date \u0026amp; Time A Python program can handle date and time in several ways. Converting between date formats is a common chore for computers. Python\u0026rsquo;s time and calendar modules help track dates and times.\nWhat is Tick? Time intervals are floating-point numbers in units of seconds. Particular instants in time are expressed in seconds since 12:00am, January 1, 1970(epoch).\nThere is a popular time module available in Python which provides functions for working with times, and for converting between representations. The function time.time() returns the current system time in ticks since 12:00am, January 1, 1970(epoch).\nExample #!/usr/bin/python import time; # This is required to include time module. ticks = time.time() print \u0026quot;Number of ticks since 12:00am, January 1, 1970:\u0026quot;, ticks  This would produce a result something as follows −\nNumber of ticks since 12:00am, January 1, 1970: 7186862.73399  Date arithmetic is easy to do with ticks. However, dates before the epoch cannot be represented in this form. Dates in the far future also cannot be represented this way - the cutoff point is sometime in 2038 for UNIX and Windows.\nWhat is TimeTuple? Many of Python\u0026rsquo;s time functions handle time as a tuple of 9 numbers, as shown below −\n   Index Field Values     0 4-digit year 2008   1 Month 1 to 12   2 Day 1 to 31   3 Hour 0 to 23   4 Minute 0 to 59   5 Second 0 to 61 (60 or 61 are leap-seconds)   6 Day of Week 0 to 6 (0 is Monday)   7 Day of year 1 to 366 (Julian day)   8 Daylight savings -1, 0, 1, -1 means library determines DST    The above tuple is equivalent to struct_time structure. This structure has following attributes −\n   Index Attributes Values     0 tm_year 2008   1 tm_mon 1 to 12   2 tm_mday 1 to 31   3 tm_hour 0 to 23   4 tm_min 0 to 59   5 tm_sec 0 to 61 (60 or 61 are leap-seconds)   6 tm_wday 0 to 6 (0 is Monday)   7 tm_yday 1 to 366 (Julian day)   8 tm_isdst -1, 0, 1, -1 means library determines DST    Getting current time To translate a time instant from a seconds since the epoch floating-point value into a time-tuple, pass the floating-point value to a function (e.g., localtime) that returns a time-tuple with all nine items valid.\n#!/usr/bin/python import time; localtime = time.localtime(time.time()) print \u0026quot;Local current time :\u0026quot;, localtime  This would produce the following result, which could be formatted in any other presentable form −\nLocal current time : time.struct_time(tm_year=2013, tm_mon=7, tm_mday=17, tm_hour=21, tm_min=26, tm_sec=3, tm_wday=2, tm_yday=198, tm_isdst=0)  Getting formatted time You can format any time as per your requirement, but simple method to get time in readable format is asctime() −\n#!/usr/bin/python import time; localtime = time.asctime( time.localtime(time.time()) ) print \u0026quot;Local current time :\u0026quot;, localtime  This would produce the following result −\nLocal current time : Tue Jan 13 10:17:09 2009  Getting calendar for a month The calendar module gives a wide range of methods to play with yearly and monthly calendars. Here, we print a calendar for a given month ( Jan 2008 ) −\n#!/usr/bin/python import calendar cal = calendar.month(2008, 1) print \u0026quot;Here is the calendar:\u0026quot; print cal  This would produce the following result −\nHere is the calendar: January 2008 Mo Tu We Th Fr Sa Su 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  The time Module There is a popular time module available in Python which provides functions for working with times and for converting between representations. Here is the list of all available methods −\n   Sr.No. Function with Description     1 time.altzone The offset of the local DST timezone, in seconds west of UTC, if one is defined. This is negative if the local DST timezone is east of UTC (as in Western Europe, including the UK). Only use this if daylight is nonzero.   2 time.asctime([tupletime]) Accepts a time-tuple and returns a readable 24-character string such as \u0026lsquo;Tue Dec 11 18:07:14 2008\u0026rsquo;.   3 time.clock( ) Returns the current CPU time as a floating-point number of seconds. To measure computational costs of different approaches, the value of time.clock is more useful than that of time.time().   4 time.ctime([secs]) Like asctime(localtime(secs)) and without arguments is like asctime( )   5 time.gmtime([secs]) Accepts an instant expressed in seconds since the epoch and returns a time-tuple t with the UTC time. Note : t.tm_isdst is always 0   6 time.localtime([secs]) Accepts an instant expressed in seconds since the epoch and returns a time-tuple t with the local time (t.tm_isdst is 0 or 1, depending on whether DST applies to instant secs by local rules).   7 time.mktime(tupletime) Accepts an instant expressed as a time-tuple in local time and returns a floating-point value with the instant expressed in seconds since the epoch.   8 time.sleep(secs) Suspends the calling thread for secs seconds.   9 time.strftime(fmt[,tupletime]) Accepts an instant expressed as a time-tuple in local time and returns a string representing the instant as specified by string fmt.   10 time.strptime(str,fmt=\u0026lsquo;%a %b %d %H:%M:%S %Y\u0026rsquo;) Parses str according to format string fmt and returns the instant in time-tuple format.   11 time.time( ) Returns the current time instant, a floating-point number of seconds since the epoch.   12 time.tzset() Resets the time conversion rules used by the library routines. The environment variable TZ specifies how this is done.    Let us go through the functions briefly −\nThere are following two important attributes available with time module −\n   Sr.No. Attribute with Description     1 time.timezone Attribute time.timezone is the offset in seconds of the local time zone (without DST) from UTC (\u0026gt;0 in the Americas; \u0026lt;=0 in most of Europe, Asia, Africa).   2 time.tzname Attribute time.tzname is a pair of locale-dependent strings, which are the names of the local time zone without and with DST, respectively.    The calendar Module The calendar module supplies calendar-related functions, including functions to print a text calendar for a given month or year.\nBy default, calendar takes Monday as the first day of the week and Sunday as the last one. To change this, call calendar.setfirstweekday() function.\nHere is a list of functions available with the _calendar_ module −\n   Sr.No. Function with Description     1 calendar.calendar(year,w=2,l=1,c=6) Returns a multiline string with a calendar for year year formatted into three columns separated by c spaces. w is the width in characters of each date; each line has length 21*w+18+2*c. l is the number of lines for each week.   2 calendar.firstweekday( ) Returns the current setting for the weekday that starts each week. By default, when calendar is first imported, this is 0, meaning Monday.   3 calendar.isleap(year) Returns True if year is a leap year; otherwise, False.   4 calendar.leapdays(y1,y2) Returns the total number of leap days in the years within range(y1,y2).   5 calendar.month(year,month,w=2,l=1) Returns a multiline string with a calendar for month month of year year, one line per week plus two header lines. w is the width in characters of each date; each line has length 7*w+6. l is the number of lines for each week.   6 calendar.monthcalendar(year,month) Returns a list of lists of ints. Each sublist denotes a week. Days outside month month of year year are set to 0; days within the month are set to their day-of-month, 1 and up.   7 calendar.monthrange(year,month) Returns two integers. The first one is the code of the weekday for the first day of the month month in year year; the second one is the number of days in the month. Weekday codes are 0 (Monday) to 6 (Sunday); month numbers are 1 to 12.   8 calendar.prcal(year,w=2,l=1,c=6) Like print calendar.calendar(year,w,l,c).   9 calendar.prmonth(year,month,w=2,l=1) Like print calendar.month(year,month,w,l).   10 calendar.setfirstweekday(weekday) Sets the first day of each week to weekday code weekday. Weekday codes are 0 (Monday) to 6 (Sunday).   11 calendar.timegm(tupletime) The inverse of time.gmtime: accepts a time instant in time-tuple form and returns the same instant as a floating-point number of seconds since the epoch.   12 calendar.weekday(year,month,day) Returns the weekday code for the given date. Weekday codes are 0 (Monday) to 6 (Sunday); month numbers are 1 (January) to 12 (December).    Other Modules \u0026amp; Functions If you are interested, then here you would find a list of other important modules and functions to play with date \u0026amp; time in Python −\n The datetime Module\n The pytz Module\n The dateutil Module\n   Source : .\nSource : .\n "});index.add({'id':231,'href':'/library/tutorials/docs/articles/python/python-101-for-beginner/','title':"Python 101 สําหรับมือใหม่",'content':" Python 101 สําหรับมือใหม่ Interpreted Language (ความหมายง่ายๆของภาษาแบบนี้คือ มันสามารถทํางานได้บนทุกแพลตฟอร์มขอให้มีแค่ interpreter ให้มันก็พอ และ อีกอย่างคือมันจะทําการแปลงจากโค้ดที่เรามีไปเป็นภาษาที่เครื่องเข้าใจแบบ on the fly)\nถ้าเทียบกับการพัฒนาโปรแกรมด้วย Java การเขียน Python นี้จะแตกต่างแล้วก็เห็นได้ชัดเลยว่ามันเร็วกว่ามากๆ เช่นตัวอย่างนี้เลย\npublic class { public static void main(String[]args) { System.out.println(\u0026quot;Hello, world!\u0026quot;); } }  ตัวอย่างภาษา Java\nprint(\u0026quot;Hello, world!\u0026quot;)\nตัวอย่างภาษา Python\nแค่เทียบก็เห็นละว่า Line of code น้อยกว่ามาก เขียนสั้นง่ายๆดี\nBasic Python Syntax Indent\nปกติภาษาเขียนโปรแกรมทั่วไปจะต้องมี วงเล็บ (Bracket – {}) เพื่อระบุว่าอะไรคือขอบเขตของมัน แต่ Python ไม่ได้ใช้วงเล็บ แต่ใช้ Indent หรือ Space แทน\npublic class { public static void main(String[]args) { System.out.println(\u0026quot;Hello, world!\u0026quot;); } }  แบบ Java ใช้ Bracket\ndef functionname( parameters ): \u0026quot;\u0026quot;\u0026quot;function_doc\u0026quot;\u0026quot;\u0026quot; function_detail return [expression]  แบบ python ใช้ Indent ซึ่งตาม สไตลด์ไกด์ ที่ดีควรเว้น 4 Indents น่ะ\nQuotation\nPython รับได้หมดทั้ง 3 แบบนี้ในการใส่ quote\n ‘…..’ ( single quote ) “…..” ( double quote ) “””……””” ( tripple double quote – สไตล์นี้ควรจะใช้กับ Document เท่านั้นน่ะ)  Comment\nมี 2 รูปแบบ\n Inline Comment # …… ( 1 sharp ) Multiple Line Comment ”’ ……. ”’ ( 3 single quote )  Data Types Python มี data types ง่ายๆเลยแค่ 5 อย่าง\n Numbers (int,float,long,complex) String List Tuple Dictionary  ใน python เราเองไม่ต้องประกาศตัวแปรว่าเป็น type ไหนก่อนใช้ ( explicit declaration ) มันจะถูกกําหนด type เมื่อมีการ assign ค่าให้มัน\nNumber no_need_to_declare_int = 2 no_need_to_declare_float = 3.14  ซึ่งใน Number เนี่ย มันจะ support type อยู่ 4 แบบคือ\n int long float complex  แต่จริงๆแล้วเราไม่จําเป็นต้องรู้ก็ได้ เพราะถึงเวลาใช้ เราไม่จําเป็นต้องประกาศอะไร\nString String ใน python มีลูกเล่นมากกว่าภาษาอื่นตรงที่มีว่ามี function ในการ slice ที่แตกต่างไป โดยใช้คําสั่งต่อไปนี้\n [] สามารถใส่ Index ลงไปตรงๆได้เลย [:] เลือกจะเอาหัวหรือท้ายได้ * ใช้วิธี Multiple ให้ string มีหลายตัวก็ได้ concat ก็ตรงๆคือ เครื่องหมาย +\nstr = 'Hello World!' print str # Prints complete string print str[0] # Prints first character of the string print str[2:5] # Prints characters starting from 3rd to 5th print str[2:] # Prints string starting from 3rd character print str * 2 # Prints string two times print str + \u0026quot;TEST\u0026quot; # Prints concatenated string   Lists list ใน Python ถูกเอาไปใช้หลากหลายได้มากสุดละ มี function คล้ายๆ string แหละ\n [] สามารถใส่ Index ลงไปตรงๆได้เลย [:] เลือกจะเอาหัวหรือท้ายได้ * ใช้วิธี Multiple ให้ string มีหลายตัวก็ได้ concat ก็ตรงๆคือ เครื่องหมาย +\nlist = [ 'abcd', 786 , 2.23, 'john', 70.2 ] tinylist = [123, 'john'] print list # Prints complete list print list[0] # Prints first element of the list print list[1:3] # Prints elements starting from 2nd till 3rd print list[2:] # Prints elements starting from 3rd element print tinylist * 2 # Prints list two times print list + tinylist # Prints concatenated lists   Tuple ตัวนี้จะแปลกหน่อยถ้าคนไม่รู้จัก type นี้ มันคือ tuple ตัวแปลที่ลักษณะคล้าย List แต่จะแตกต่างกันตรงที่มันจะปิดด้วย Parentheses () ไม่ใช่ square bracket และมันจะ read-only เท่านั้น!\ntuple = ( 'abcd', 786 , 2.23, 'john', 70.2 ) tinytuple = (123, 'john') print tuple # Prints complete list print tuple[0] # Prints first element of the list print tuple[1:3] # Prints elements starting from 2nd till 3rd print tuple[2:] # Prints elements starting from 3rd element print tinytuple * 2 # Prints list two times print tuple + tinytuple # Prints concatenated lists  Dictionary อันนี้มีทุกภาษาแหละ การใช้ key,value หรือ dictionary ในการเก็บข้อมูลแบบต่างๆ\ndict = {} dict['one'] = \u0026quot;This is one\u0026quot; dict[2] = \u0026quot;This is two\u0026quot; tinydict = {'name': 'john','code':6734, 'dept': 'sales'} print dict['one'] # Prints value for 'one' key print dict[2] # Prints value for 2 key print tinydict # Prints complete dictionary print tinydict.keys() # Prints all the keys print tinydict.values() # Prints all the values  Operators Operator อื่นๆ ที่ใช้กันประจํา พวก +,-,*,/ หรือ % คงไม่ต้องพูดถึงเพราะเป็นพื้นฐานที่มีในทุกภาษา แต่ตัวที่น่าสนใจคือ operator 2 ตัวนี้มากกว่า\n Membership Identity  Membership Operator Description Example in จะให้ค่า true หรือ false เมื่อเช็คว่าค่าของสิ่งนั้นอยู่ในกรอบที่ต้องการเช็คหรือไม่ x in y จะ return true เมื่อ x อยู่ใน y หรือจะ return false เมื่อ x ไม่ได้อยู่ not in จะให้ค่า true หรือ false เมื่อเช็คว่าค่าของสิ่งนั้นไม่ได้อยู่ในกรอบที่ต้องการเช็ค x not in y จะ return true เมื่อ x ไม่ได้อยู่ใน y และ return false เมื่อ x อยู่ใน y\n   Operator Description Example     in จะให้ค่า true หรือ false เมื่อเช็คว่าค่าของสิ่งนั้นอยู่ในกรอบที่ต้องการเช็คหรือไม่ x in y จะ return true เมื่อ x อยู่ใน y หรือจะ return false เมื่อ x ไม่ได้อยู่   not in จะให้ค่า true หรือ false เมื่อเช็คว่าค่าของสิ่งนั้นไม่ได้อยู่ในกรอบที่ต้องการเช็ค x not in y จะ return true เมื่อ x ไม่ได้อยู่ใน y และ return false เมื่อ x อยู่ใน y    name = \u0026quot;John\u0026quot; if name in [\u0026quot;John\u0026quot;, \u0026quot;Rick\u0026quot;]: print(\u0026quot;Your name is either John or Rick.\u0026quot;)     Operator Description Example     is จะให้ค่า true หรือ false เมื่อเช็คว่าค่าของสิ่งนั้นชี้ไปที่ object เดียวกัน x is y จะ return true เมื่อ x ชี้ไปที่ object เดียวกับ y หรือจะ return false เมื่อ x ไม่ได้ชี้ไปที่ object เดียวกับ y ชี้   not is จะให้ค่า true หรือ false เมื่อเช็คว่าค่าของสิ่งนั้นไม่ได้ชี้ไปที่ object เดียวกัน x is y จะ return true เมื่อ x ไม่ได้ชี้ไปที่ object เดียวกับ y หรือจะ return false เมื่อ x ไม่ได้ชี้ไปที่ object เดียวกับ y ชี้    x = [1,2,3] y = [1,2,3] print(x == y) # Prints out True print(x is y) # Prints out False  Condition อย่างนึงที่น่าสนใจเกี่ยวกับ Python ก็คือมันสะดวก กระทัดรัด และใช้งานได้ดีเลย เช่น ในกรณีของ If-else ใน Java แบบบรรทัดเดียวจะหน้าตาแบบนี้\nname = ((city.getName() == null) ? \u0026quot;N/A\u0026quot; : city.getName());  ไม่รู้คนอื่นเข้าง่ายรึเปล่าแต่สําหรับผมแล้วมันเข้าใจอยากที่เดียวเลย แต่ถ้าเป็นใน Python จะเป็น\n'Yes' if fruit == 'Apple' else 'No' # value_when_true if condition else value_when_false  มันมีความแตกต่างกันอย่างเห็นได้ชัดในการเขียน Python กับ Java มันมีความสะดวกสบายกว่ามากๆเลย (ternary operator)\nString Formatting การ Format string ใน Python เราจะใช้ % operator เป็นตัวระบุไปที่ string และตัวแปรนั้นๆเช่น\nname = \u0026quot;John\u0026quot; print(\u0026quot;Hello, %s!\u0026quot; % name) #Hello, John name = \u0026quot;John\u0026quot; age = 23 print(\u0026quot;%s is %d years old.\u0026quot; % (name, age)) #John is 23 years old.  ซึ่งการ Format string มีความหมายแตกต่างกันดั่งด้านล่างนี้\n %s = string %d = integer  Loops ไม่เหมือนนกับภาษา Java ที่ต้อง for แล้ววนตามตัวเลข index ( index.length() แบบนั้น ) แต่ Python สามารถใช้ list วนเข้าไปได้เลย ทําให้สะดวกสบายกว่ามาก\nfor loop\nfor(int i=1; i\u0026lt;11; i++){ System.out.println(\u0026quot;Count is: \u0026quot; + i); }  แบบภาษา Java เห็นว่าต้อง set เยอะมากในการลูป\n# Prints out the numbers 0,1,2,3,4 for x in range(5): print(x) # Prints out 3,4,5 for x in [\u0026quot;3\u0026quot;,\u0026quot;5\u0026quot;]: print(x)  python ก็แค่โยน list เข้าไปให้มันลูปง่ายๆแค่นั้นเอง\nwhile loop\nอันนี้เหมือนทั่วไป ไม่มีไรแปลกใหม่\ncount = 0 while (count \u0026lt; 5): print(count) count += 1 # This is the same as count = count + 1  แต่ที่เด็ดน่ะคือ ซึ่งภาษา Java ไม่มีก็คือ มันสามารถใส่ else กับ loop ได้ เช่น\ncount=0 while(count \u0026lt; 5): print(count) count +=1 else: print(\u0026quot;count value reached %d\u0026quot; %(count)) # Prints out 1,2,3,4 for i in range(1, 10): if(i%5==0): break print(i) else: print(\u0026quot;this is not printed because for loop is terminated because of break but not due to fail in condition\u0026quot;)  Functions วิธีการสร้าง Function ใน Python จะใช้ “:” เป็นตัว บอกว่ากําลังจะสร้าง function แบบนี้ ไม่ซับซ้อนอะไรเรื่องนี้\ndef my_function(): print(\u0026quot;Hello From My Function!\u0026quot;) def sum_two_numbers(a, b): return a + b  Modules and Packages importing\nModules ใน Python นี้คือเข้าใจง่ายมาก แค่ไฟล์ .py ไฟล์เดียว ซึ่งจะรวบรวม functions ต่างๆไว้ เพราะฉะนั้นแค่ใช้คําสั่ง import เข้ามาเลยก็จะสามารถทํางานได้เลย\nซึ่งไม่จบแค่นั้นใน modules ของ python เรามี function ช่วยอีกหลายอย่าง เช่น\n สามารถ Explore Modules ได้ด้วยการใช้คําสั่ง dir(x) กับ modules ใช้คําสั่ง help(x) เพื่อดูว่ามันมี document อะไรบ้าง  แต่จริงๆเปิดเว็ปเอาก็ได้น่ะ ฮรี่ๆ ง่ายกว่า\nimport urllib dir(urllib) help(urllib)  วิธีการใช้ Package ต่างๆ มีหลักๆ 2 แบบคือ\nImport เฉพาะ function ของ package เพื่อใช้งานแค่นั้น Import package แล้วเปลี่ยน​ alias name ก็ได้\nimport numpy as np np.pi #3.14XXXXX เป็นต้น from mupy import array a = array([1,2,3])  Exception Handling การจัดการกับ exception ใน python ก็คล้ายๆทั่วไป แต่ที่แปลกคือเราสามารใช้ else-block เข้ามจัดการโค้ดได้ด้วย เหมือน Loop ต่างๆ\ntry: fh = open(\u0026quot;testfile\u0026quot;, \u0026quot;w\u0026quot;) fh.write(\u0026quot;This is my test file for exception handling!!\u0026quot;) except IOError: print \u0026quot;Error: can\\'t find file or read data\u0026quot; else: print \u0026quot;Written content in the file successfully\u0026quot; fh.close()  โดยถ้าต้องการที่จัดการกับ exception ทั้งหมด ก็ทําได้โดยการไม่ใส่ specific exception ลงไปง่ายๆเลย\nหรือจะใส่เป็น multiple exception ก็ได้แบบตัวอยางด้านล่าง\ntry: You do your operations here; ...................... except: If there is any exception, then execute this block. ...................... else: If there is no exception then execute this block. try: You do your operations here; ...................... except(Exception1[, Exception2[,...ExceptionN]]]): If there is any exception from the given exception list, then execute this block. ...................... else: If there is no exception then execute this block.  Summary เนื้อหาเยอะอย่างแรง… แต่ภาพรวมของภาษา Python มีแค่นี้แหละที่เป็น Basic เพราะถ้าเรารู้เรื่องของ syntax – indent, loop, data type แค่นั้นเราก็สามารถต่อยอดได้อีกเยอะละ\nจะเริ่มเขียน Python ให้ดีควรเขียนให้ถูกต้องตามสไตล์ guide ด้วยน่ะ ดูได้จากทที่นี้เลย Pep 8 Style guides\nเดี๋ยวครั้งหน้าจะมาลงรายละเอียดตัวอื่นๆเช่นพวก Regular Expression, Files I/O อีกหน่อย จะได้ใช้งานได้ง่าย\nCredit Knowledge:\n https://www.tutorialspoint.com/python https://www.learnpython.org/ http://stackoverflow.com/questions/8898590/short-form-for-java-if-statement http://stackoverflow.com/questions/2802726/putting-a-simple-if-then-statement-on-one-line  Credit Image:\n http://www.pygamepro.com/   Source : .\n "});index.add({'id':232,'href':'/library/tutorials/docs/articles/data-science/finance/yahoo-finance-api_2/','title':"Quantitative Trading Strategies",'content':" Python for Finance, Part 2: Intro to Quantitative Trading Strategies In Python for Finance, Part I, we focused on using Python and Pandas to\n retrieve financial time-series from free online sources (Yahoo), format the data by filling missing observations and aligning them, calculate some simple indicators such as rolling moving averages and visualise the final time-series.  As a reminder, the dataframe containing the three “cleaned” price timeseries has the following format:\nimport pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns sns.set(style='darkgrid', context='talk', palette='Dark2') data = pd.read_pickle('./data.pkl') data.head(10)     Date AAPL MSFT ^GSPC     03/01/2000 3.625643 39.33463 1455.219971   04/01/2000 3.319964 38.0059 1399.420044   05/01/2000 3.36854 38.406628 1402.109985   06/01/2000 3.077039 37.12008 1403.449951   07/01/2000 3.222794 37.60517 1441.469971   10/01/2000 3.166112 37.879354 1457.599976   11/01/2000 3.004162 36.90917 1438.560059   12/01/2000 2.823993 35.706986 1432.25   13/01/2000 3.133722 36.381896 1449.680054   14/01/2000 3.253159 37.879354 1465.150024    has the following format:\n# Calculating the short-window moving average short_rolling = data.rolling(window=20).mean() short_rolling.head() has the following format:  # Calculating the short-window moving average long_rolling = data.rolling(window=100).mean() long_rolling.tail()     Date AAPL MSFT ^GSPC     26/12/2016 110.958205 58.41818 2176.628791   27/12/2016 111.047874 58.476117 2177.50018   28/12/2016 111.1405889 58.532936 2178.24449   29/12/2016 111.233698 58.586112 2178.879189   30/12/2016 111.31527 58.63526 2179.42699    General considerations about trading strategies There are several ways one can go about when a trading strategy is to be developed. One approach would be to use the price time-series directly and work with numbers that correspond to some monetary value.\nFor example, a researcher could be working with time-series expressing the price of a given stock, like the time-series we used in the previous article. Similarly, if working with fixed income instruments, e.g. bonds, one could be using a time-series expressing the price of the bond as a percentage of a given reference value, in this case the par value of the bond. Working with this type of time-series can be more intuitive as people are used to thinking in terms of prices. However, price time-series have some drawbacks. Prices are usually only positive, which makes it harder to use models and approaches which require or produce negative numbers. In addition, price time-series are usually non-stationary, that is their statistical properties are less stable over time.\nBoth of these are trivially calculated using Pandas:\n# Relative returns returns = data.pct_change(1) returns.head()  # Log returns - First the logarithm of the prices is taken and the the difference of consecutive (log) observations log_returns = np.log(data).diff() log_returns.head()  fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(16,12)) for c in log_returns: ax1.plot(log_returns.index, log_returns[c].cumsum(), label=str(c)) ax1.set_ylabel('Cumulative log returns') ax1.legend(loc='best') for c in log_returns: ax2.plot(log_returns.index, 100*(np.exp(log_returns[c].cumsum()) - 1), label=str(c)) ax2.set_ylabel('Total relative returns (%)') ax2.legend(loc='best') plt.show()  So this simple investing strategy would yield a total return of more than 325% in the course of almost 16 years.\nHow does this translate to a yearly performance? Since we have kept all weekdays in our portfolio, there are 52×5=260 weekdays each year. There are 4435 days in our simulation which corresponds roughly to 16.92 years. We will be calculating the average geometric return, that is an average return r¯ which when compounded for 16.92 years will produce the total relative return of 325.14%. So we need to solve:\n# Calculating the time-related parameters of the simulation days_per_year = 52 * 5 total_days_in_simulation = data.shape[0] number_of_years = total_days_in_simulation / days_per_year # The last data point will give us the total portfolio return total_portfolio_return = total_relative_returns[-1] # Average portfolio return assuming compunding of returns average_yearly_return = (1 + total_portfolio_return)**(1 / number_of_years) - 1 print('Total portfolio return is: ' + '{:5.2f}'.format(100 * total_portfolio_return) + '%') print('Average yearly return is: ' + '{:5.2f}'.format(100 * average_yearly_return) + '%')  Total portfolio return is: 325.14% Average yearly return is: 8.85%\nWhat next? Our strategy is a very simple example of a buy-and-hold strategy. The investor simply splits up the available funds in the three assets and keeps the same position throughout the period under investigation. Although simple, the strategy does produce a healthy 8.85% per year.\nHowever, the simulation is not completely accurate. Let us not forget that we have used ALL weekdays in our example, but we do know that on some days the markets are not trading. This will not affect the strategy we presented as the returns on the days the markets are closed are 0, but it may potentially affect other types of strategies. Furthermore, the weights here are constant over time. Ideally, we would like weights that change over time so that we can take advantage of price swings and other market events.\nAlso, we have said nothing at all about the risk of this strategy. Risk is the most important consideration in any investment strategy and is closely related to the expected returns. In what follows, we will start designing a more complex strategy, the weights of which will not be constant over time. At the same time we will start looking into the risk of the strategy and present appropriate metrics to measure it. Finally, we will look into the issue of optimizing the strategy parameters and how this can improve our return to risk profile.\nSee Part 3 of this series: Moving Average Trading Strategies. \u0026gt; Written with StackEdit.\n"});index.add({'id':233,'href':'/library/tutorials/docs/python/snippets/rads_to_degrees/','title':"rads_to_degrees",'content':"Converts an angle from radians to degrees.\nUse math.pi and the radian to degree formula to convert the angle from radians to degrees.\nfrom math import pi def rads_to_degrees(rad): return (rad * 180.0) / math.pi  from math import pi rads_to_degrees(math.pi / 2) # 90.0  "});index.add({'id':234,'href':'/library/tutorials/docs/python/pandas/read-and-write-files/','title':"Read and Write Files",'content':" Pandas: How to Read and Write Files Table of Contents  Installing Pandas Preparing Data Using the Pandas read_csv() and .to_csv() Functions  Write a CSV File Read a CSV File  Using Pandas to Write and Read Excel Files  Write an Excel File Read an Excel File  Understanding the Pandas IO API  Write Files Read Files  Working With Different File Types  CSV Files JSON Files HTML Files Excel Files SQL Files Pickle Files  Working With Big Data  Compress and Decompress Files Choose Columns Omit Rows Force Less Precise Data Types Use Chunks to Iterate Through Files  Conclusion  Pandas is a powerful and flexible Python package that allows you to work with labeled and time series data. It also provides statistics methods, enables plotting, and more. One crucial feature of Pandas is its ability to write and read Excel, CSV, and many other types of files. Functions like the Pandas read_csv() method enable you to work with files effectively. You can use them to save the data and labels from Pandas objects to a file and load them later as Pandas Series or DataFrame instances.\nIn this tutorial, you’ll learn:\n What the Pandas IO tools API is How to read and write data to and from files How to work with various file formats How to work with big data efficiently  Let’s start reading and writing files!\nFree Bonus: 5 Thoughts On Python Mastery, a free course for Python developers that shows you the roadmap and the mindset you\u0026rsquo;ll need to take your Python skills to the next level.\nInstalling Pandas The code in this tutorial is executed with CPython 3.7.4 and Pandas 0.25.1. It would be beneficial to make sure you have the latest versions of Python and Pandas on your machine. You might want to create a new virtual environment and install the dependencies for this tutorial.\nFirst, you’ll need the Pandas library. You may already have it installed. If you don’t, then you can install it with pip:\n$ pip install pandas  Once the installation process completes, you should have Pandas installed and ready.\nAnaconda is an excellent Python distribution that comes with Python, many useful packages like Pandas, and a package and environment manager called Conda. To learn more about Anaconda, check out Setting Up Python for Machine Learning on Windows.\nIf you don’t have Pandas in your virtual environment, then you can install it with Conda:\n$ conda install pandas  Conda is powerful as it manages the dependencies and their versions. To learn more about working with Conda, you can check out the official documentation.\nPreparing Data In this tutorial, you’ll use the data related to 20 countries. Here’s an overview of the data and sources you’ll be working with:\n Country is denoted by the country name. Each country is in the top 10 list for either population, area, or gross domestic product (GDP). The row labels for the dataset are the three-letter country codes defined in ISO 3166-1. The column label for the dataset is COUNTRY.\n Population is expressed in millions. The data comes from a list of countries and dependencies by population on Wikipedia. The column label for the dataset is POP.\n Area is expressed in thousands of kilometers squared. The data comes from a list of countries and dependencies by area on Wikipedia. The column label for the dataset is AREA.\n Gross domestic product is expressed in millions of U.S. dollars, according to the United Nations data for 2017. You can find this data in the list of countries by nominal GDP on Wikipedia. The column label for the dataset is GDP.\n Continent is either Africa, Asia, Oceania, Europe, North America, or South America. You can find this information on Wikipedia as well. The column label for the dataset is CONT.\n Independence day is a date that commemorates a nation’s independence. The data comes from the list of national independence days on Wikipedia. The dates are shown in ISO 8601 format. The first four digits represent the year, the next two numbers are the month, and the last two are for the day of the month. The column label for the dataset is IND_DAY.\n  This is how the data looks as a table:\n   CODE COUNTRY POP AREA GDP CONT IND_DAY     CHN China 1398.72 9596.96 12234.8 Asia nan   IND India 1351.16 3287.26 2575.67 Asia 15/08/1947   USA US 329.74 9833.52 19485.4 N.America 1776-07-04   IDN Indonesia 268.07 1910.93 1015.54 Asia 17/08/1945   BRA Brazil 210.32 8515.77 2055.51 S.America 1822-09-07   PAK Pakistan 205.71 881.91 302.14 Asia 14/08/1947   NGA Nigeria 200.96 923.77 375.77 Africa 01/10/1960   BGD Bangladesh 167.09 147.57 245.63 Asia 26/03/1971   RUS Russia 146.79 17098.2 1530.75 nan 12/06/1992   MEX Mexico 126.58 1964.38 1158.23 N.America 1810-09-16   JPN Japan 126.22 377.97 4872.42 Asia nan   DEU Germany 83.02 357.11 3693.2 Europe nan   FRA France 67.02 640.68 2582.49 Europe 1789-07-14   GBR UK 66.44 242.5 2631.23 Europe nan   ITA Italy 60.36 301.34 1943.84 Europe nan   ARG Argentina 44.94 2780.4 637.49 S.America 1816-07-09   DZA Algeria 43.38 2381.74 167.56 Africa 05/07/1962   CAN Canada 37.59 9984.67 1647.12 N.America 1867-07-01    AUS Australia 25.47 7692.02 1408.68 Oceania    You may notice that some of the data is missing. For example, the continent for Russia is not specified because it spreads across both Europe and Asia. There are also several missing independence days because the data source omits them.\nYou can organize this data in Python using a nested dictionary:\ndata = { 'CHN': {'COUNTRY': 'China', 'POP': 1_398.72, 'AREA': 9_596.96, 'GDP': 12_234.78, 'CONT': 'Asia'}, 'IND': {'COUNTRY': 'India', 'POP': 1_351.16, 'AREA': 3_287.26, 'GDP': 2_575.67, 'CONT': 'Asia', 'IND_DAY': '1947-08-15'}, 'USA': {'COUNTRY': 'US', 'POP': 329.74, 'AREA': 9_833.52, 'GDP': 19_485.39, 'CONT': 'N.America', 'IND_DAY': '1776-07-04'}, 'IDN': {'COUNTRY': 'Indonesia', 'POP': 268.07, 'AREA': 1_910.93, 'GDP': 1_015.54, 'CONT': 'Asia', 'IND_DAY': '1945-08-17'}, 'BRA': {'COUNTRY': 'Brazil', 'POP': 210.32, 'AREA': 8_515.77, 'GDP': 2_055.51, 'CONT': 'S.America', 'IND_DAY': '1822-09-07'}, 'PAK': {'COUNTRY': 'Pakistan', 'POP': 205.71, 'AREA': 881.91, 'GDP': 302.14, 'CONT': 'Asia', 'IND_DAY': '1947-08-14'}, 'NGA': {'COUNTRY': 'Nigeria', 'POP': 200.96, 'AREA': 923.77, 'GDP': 375.77, 'CONT': 'Africa', 'IND_DAY': '1960-10-01'}, 'BGD': {'COUNTRY': 'Bangladesh', 'POP': 167.09, 'AREA': 147.57, 'GDP': 245.63, 'CONT': 'Asia', 'IND_DAY': '1971-03-26'}, 'RUS': {'COUNTRY': 'Russia', 'POP': 146.79, 'AREA': 17_098.25, 'GDP': 1_530.75, 'IND_DAY': '1992-06-12'}, 'MEX': {'COUNTRY': 'Mexico', 'POP': 126.58, 'AREA': 1_964.38, 'GDP': 1_158.23, 'CONT': 'N.America', 'IND_DAY': '1810-09-16'}, 'JPN': {'COUNTRY': 'Japan', 'POP': 126.22, 'AREA': 377.97, 'GDP': 4_872.42, 'CONT': 'Asia'}, 'DEU': {'COUNTRY': 'Germany', 'POP': 83.02, 'AREA': 357.11, 'GDP': 3_693.20, 'CONT': 'Europe'}, 'FRA': {'COUNTRY': 'France', 'POP': 67.02, 'AREA': 640.68, 'GDP': 2_582.49, 'CONT': 'Europe', 'IND_DAY': '1789-07-14'}, 'GBR': {'COUNTRY': 'UK', 'POP': 66.44, 'AREA': 242.50, 'GDP': 2_631.23, 'CONT': 'Europe'}, 'ITA': {'COUNTRY': 'Italy', 'POP': 60.36, 'AREA': 301.34, 'GDP': 1_943.84, 'CONT': 'Europe'}, 'ARG': {'COUNTRY': 'Argentina', 'POP': 44.94, 'AREA': 2_780.40, 'GDP': 637.49, 'CONT': 'S.America', 'IND_DAY': '1816-07-09'}, 'DZA': {'COUNTRY': 'Algeria', 'POP': 43.38, 'AREA': 2_381.74, 'GDP': 167.56, 'CONT': 'Africa', 'IND_DAY': '1962-07-05'}, 'CAN': {'COUNTRY': 'Canada', 'POP': 37.59, 'AREA': 9_984.67, 'GDP': 1_647.12, 'CONT': 'N.America', 'IND_DAY': '1867-07-01'}, 'AUS': {'COUNTRY': 'Australia', 'POP': 25.47, 'AREA': 7_692.02, 'GDP': 1_408.68, 'CONT': 'Oceania'}, 'KAZ': {'COUNTRY': 'Kazakhstan', 'POP': 18.53, 'AREA': 2_724.90, 'GDP': 159.41, 'CONT': 'Asia', 'IND_DAY': '1991-12-16'} } columns = ('COUNTRY', 'POP', 'AREA', 'GDP', 'CONT', 'IND_DAY')  Each row of the table is written as an inner dictionary whose keys are the column names and values are the corresponding data. These dictionaries are then collected as the values in the outer data dictionary. The corresponding keys for data are the three-letter country codes.\nYou can use this data to create an instance of a Pandas DataFrame. First, you need to import Pandas:\nimport pandas as pd  Now that you have Pandas imported, you can use the DataFrame constructor and data to create a DataFrame object.\ndata is organized in such a way that the country codes correspond to columns. You can reverse the rows and columns of a DataFrame with the property .T:\ndf = pd.DataFrame(data=data).T df ## output COUNTRY POP AREA GDP CONT IND_DAY CHN China 1398.72 9596.96 12234.8 Asia NaN IND India 1351.16 3287.26 2575.67 Asia 1947-08-15 USA US 329.74 9833.52 19485.4 N.America 1776-07-04 IDN Indonesia 268.07 1910.93 1015.54 Asia 1945-08-17 BRA Brazil 210.32 8515.77 2055.51 S.America 1822-09-07 PAK Pakistan 205.71 881.91 302.14 Asia 1947-08-14 NGA Nigeria 200.96 923.77 375.77 Africa 1960-10-01 BGD Bangladesh 167.09 147.57 245.63 Asia 1971-03-26 RUS Russia 146.79 17098.2 1530.75 NaN 1992-06-12 MEX Mexico 126.58 1964.38 1158.23 N.America 1810-09-16 JPN Japan 126.22 377.97 4872.42 Asia NaN DEU Germany 83.02 357.11 3693.2 Europe NaN FRA France 67.02 640.68 2582.49 Europe 1789-07-14 GBR UK 66.44 242.5 2631.23 Europe NaN ITA Italy 60.36 301.34 1943.84 Europe NaN ARG Argentina 44.94 2780.4 637.49 S.America 1816-07-09 DZA Algeria 43.38 2381.74 167.56 Africa 1962-07-05 CAN Canada 37.59 9984.67 1647.12 N.America 1867-07-01 AUS Australia 25.47 7692.02 1408.68 Oceania NaN KAZ Kazakhstan 18.53 2724.9 159.41 Asia 1991-12-16`  Now you have your DataFrame object populated with the data about each country.\n Note: You can use .transpose() instead of .T to reverse the rows and columns of your dataset. If you use .transpose(), then you can set the optional parameter copy to specify if you want to copy the underlying data. The default behavior is False.\n Versions of Python older than 3.6 did not guarantee the order of keys in dictionaries. To ensure the order of columns is maintained for older versions of Python and Pandas, you can specify index=columns:\ndf = pd.DataFrame(data=data, index=columns).T  Now that you’ve prepared your data, you’re ready to start working with files!\nUsing the Pandas read_csv() and .to_csv() Functions A comma-separated values (CSV) file is a plaintext file with a .csv extension that holds tabular data. This is one of the most popular file formats for storing large amounts of data. Each row of the CSV file represents a single table row. The values in the same row are by default separated with commas, but you could change the separator to a semicolon, tab, space, or some other character.\nWrite a CSV File You can save your Pandas DataFrame as a CSV file with .to_csv():\ndf.to_csv('data.csv')\nThat’s it! You’ve created the file data.csv in your current working directory. You can expand the code block below to see how your CSV file should look:\ndata.csvShow/Hide\nThis text file contains the data separated with commas. The first column contains the row labels. In some cases, you’ll find them irrelevant. If you don’t want to keep them, then you can pass the argument index=False to .to_csv().\nRead a CSV File Once your data is saved in a CSV file, you’ll likely want to load and use it from time to time. You can do that with the Pandas read_csv() function:\ndf = pd.read_csv('data.csv', index_col=0) df ## output COUNTRY POP AREA GDP CONT IND_DAY CHN China 1398.72 9596.96 12234.78 Asia NaN IND India 1351.16 3287.26 2575.67 Asia 1947-08-15 USA US 329.74 9833.52 19485.39 N.America 1776-07-04 IDN Indonesia 268.07 1910.93 1015.54 Asia 1945-08-17 BRA Brazil 210.32 8515.77 2055.51 S.America 1822-09-07 PAK Pakistan 205.71 881.91 302.14 Asia 1947-08-14 NGA Nigeria 200.96 923.77 375.77 Africa 1960-10-01 BGD Bangladesh 167.09 147.57 245.63 Asia 1971-03-26 RUS Russia 146.79 17098.25 1530.75 NaN 1992-06-12 MEX Mexico 126.58 1964.38 1158.23 N.America 1810-09-16 JPN Japan 126.22 377.97 4872.42 Asia NaN DEU Germany 83.02 357.11 3693.20 Europe NaN FRA France 67.02 640.68 2582.49 Europe 1789-07-14 GBR UK 66.44 242.50 2631.23 Europe NaN ITA Italy 60.36 301.34 1943.84 Europe NaN ARG Argentina 44.94 2780.40 637.49 S.America 1816-07-09 DZA Algeria 43.38 2381.74 167.56 Africa 1962-07-05 CAN Canada 37.59 9984.67 1647.12 N.America 1867-07-01 AUS Australia 25.47 7692.02 1408.68 Oceania NaN KAZ Kazakhstan 18.53 2724.90 159.41 Asia 1991-12-16  In this case, the Pandas read_csv() function returns a new DataFrame with the data and labels from the file data.csv, which you specified with the first argument. This string can be any valid path, including URLs.\nThe parameter index_col specifies the column from the CSV file that contains the row labels. You assign a zero-based column index to this parameter. You should determine the value of index_col when the CSV file contains the row labels to avoid loading them as data.\nYou’ll learn more about using Pandas with CSV files later on in this tutorial. You can also check out Reading and Writing CSV Files in Python to see how to handle CSV files with the built-in Python library csv as well.\nUsing Pandas to Write and Read Excel Files Microsoft Excel is probably the most widely-used spreadsheet software. While older versions used binary .xls files, Excel 2007 introduced the new XML-based .xlsx file. You can read and write Excel files in Pandas, similar to CSV files. However, you’ll need to install the following Python packages first:\n xlwt to write to .xls files openpyxl or XlsxWriter to write to .xlsx files xlrd to read Excel files  You can install them using pip with a single command:\n$ pip install xlwt openpyxl xlsxwriter xlrd\nYou can also use Conda:\n$ conda install xlwt openpyxl xlsxwriter xlrd\nPlease note that you don’t have to install all these packages. For example, you don’t need both openpyxl and XlsxWriter. If you’re going to work just with .xls files, then you don’t need any of them! However, if you intend to work only with .xlsx files, then you’re going to need at least one of them, but not xlwt. Take some time to decide which packages are right for your project.\nWrite an Excel File Once you have those packages installed, you can save your DataFrame in an Excel file with .to_excel():\ndf.to_excel('data.xlsx')  The argument 'data.xlsx' represents the target file and, optionally, its path. The above statement should create the file data.xlsx in your current working directory. That file should look like this:\n\nThe first column of the file contains the labels of the rows, while the other columns store data.\nRead an Excel File You can load data from Excel files with read_excel():\ndf = pd.read_excel('data.xlsx', index_col=0) df ## output COUNTRY POP AREA GDP CONT IND_DAY CHN China 1398.72 9596.96 12234.78 Asia NaN IND India 1351.16 3287.26 2575.67 Asia 1947-08-15 USA US 329.74 9833.52 19485.39 N.America 1776-07-04 IDN Indonesia 268.07 1910.93 1015.54 Asia 1945-08-17 BRA Brazil 210.32 8515.77 2055.51 S.America 1822-09-07 PAK Pakistan 205.71 881.91 302.14 Asia 1947-08-14 NGA Nigeria 200.96 923.77 375.77 Africa 1960-10-01 BGD Bangladesh 167.09 147.57 245.63 Asia 1971-03-26 RUS Russia 146.79 17098.25 1530.75 NaN 1992-06-12 MEX Mexico 126.58 1964.38 1158.23 N.America 1810-09-16 JPN Japan 126.22 377.97 4872.42 Asia NaN DEU Germany 83.02 357.11 3693.20 Europe NaN FRA France 67.02 640.68 2582.49 Europe 1789-07-14 GBR UK 66.44 242.50 2631.23 Europe NaN ITA Italy 60.36 301.34 1943.84 Europe NaN ARG Argentina 44.94 2780.40 637.49 S.America 1816-07-09 DZA Algeria 43.38 2381.74 167.56 Africa 1962-07-05 CAN Canada 37.59 9984.67 1647.12 N.America 1867-07-01 AUS Australia 25.47 7692.02 1408.68 Oceania NaN KAZ Kazakhstan 18.53 2724.90 159.41 Asia 1991-12-16`  read_excel() returns a new DataFrame that contains the values from data.xlsx. You can also use read_excel() with OpenDocument spreadsheets, or .ods files.\nYou’ll learn more about working with Excel files later on in this tutorial. You can also check out Using Pandas to Read Large Excel Files in Python.\nUnderstanding the Pandas IO API Pandas IO Tools is the API that allows you to save the contents of Series and DataFrame objects to the clipboard, objects, or files of various types. It also enables loading data from the clipboard, objects, or files.\nWrite Files Series and DataFrame objects have methods that enable writing data and labels to the clipboard or files. They’re named with the pattern .to_\u0026lt;file-type\u0026gt;(), where \u0026lt;file-type\u0026gt; is the type of the target file.\nYou’ve learned about .to_csv() and .to_excel(), but there are others, including:\n .to_json() .to_html() .to_sql() .to_pickle()  There are still more file types that you can write to, so this list is not exhaustive.\nNote: To find similar methods, check the official documentation about serialization, IO, and conversion related to Series and DataFrame objects.\nThese methods have parameters specifying the target file path where you saved the data and labels. This is mandatory in some cases and optional in others. If this option is available and you choose to omit it, then the methods return the objects (like strings or iterables) with the contents of DataFrame instances.\nThe optional parameter compression decides how to compress the file with the data and labels. You’ll learn more about it later on. There are a few other parameters, but they’re mostly specific to one or several methods. You won’t go into them in detail here.\nRead Files Pandas functions for reading the contents of files are named using the pattern .read_\u0026lt;file-type\u0026gt;(), where \u0026lt;file-type\u0026gt; indicates the type of the file to read. You’ve already seen the Pandas read_csv() and read_excel() functions. Here are a few others:\n read_json() read_html() read_sql() read_pickle()  These functions have a parameter that specifies the target file path. It can be any valid string that represents the path, either on a local machine or in a URL. Other objects are also acceptable depending on the file type.\nThe optional parameter compression determines the type of decompression to use for the compressed files. You’ll learn about it later on in this tutorial. There are other parameters, but they’re specific to one or several functions. You won’t go into them in detail here.\nWorking With Different File Types The Pandas library offers a wide range of possibilities for saving your data to files and loading data from files. In this section, you’ll learn more about working with CSV and Excel files. You’ll also see how to use other types of files, like JSON, web pages, databases, and Python pickle files.\nCSV Files You’ve already learned how to read and write CSV files. Now let’s dig a little deeper into the details. When you use .to_csv() to save your DataFrame, you can provide an argument for the parameter path_or_buff to specify the path, name, and extension of the target file.\npath_or_buff is the first argument .to_csv() will get. It can be any string that represents a valid file path that includes the file name and its extension. You’ve seen this in a previous example. However, if you omit path_or_buff, then .to_csv() won’t create any files. Instead, it’ll return the corresponding string:\ndf = pd.DataFrame(data=data).T s = df.to_csv() print(s) ## output COUNTRY,POP,AREA,GDP,CONT,IND_DAY CHN,China,1398.72,9596.96,12234.78,Asia, IND,India,1351.16,3287.26,2575.67,Asia,1947-08-15 USA,US,329.74,9833.52,19485.39,N.America,1776-07-04 IDN,Indonesia,268.07,1910.93,1015.54,Asia,1945-08-17 BRA,Brazil,210.32,8515.77,2055.51,S.America,1822-09-07 PAK,Pakistan,205.71,881.91,302.14,Asia,1947-08-14 NGA,Nigeria,200.96,923.77,375.77,Africa,1960-10-01 BGD,Bangladesh,167.09,147.57,245.63,Asia,1971-03-26 RUS,Russia,146.79,17098.25,1530.75,,1992-06-12 MEX,Mexico,126.58,1964.38,1158.23,N.America,1810-09-16 JPN,Japan,126.22,377.97,4872.42,Asia, DEU,Germany,83.02,357.11,3693.2,Europe, FRA,France,67.02,640.68,2582.49,Europe,1789-07-14 GBR,UK,66.44,242.5,2631.23,Europe, ITA,Italy,60.36,301.34,1943.84,Europe, ARG,Argentina,44.94,2780.4,637.49,S.America,1816-07-09 DZA,Algeria,43.38,2381.74,167.56,Africa,1962-07-05 CAN,Canada,37.59,9984.67,1647.12,N.America,1867-07-01 AUS,Australia,25.47,7692.02,1408.68,Oceania, KAZ,Kazakhstan,18.53,2724.9,159.41,Asia,1991-12-16  Now you have the string s instead of a CSV file. You also have some missing values in your DataFrame object. For example, the continent for Russia and the independence days for several countries (China, Japan, and so on) are not available. In data science and machine learning, you must handle missing values carefully. Pandas excels here! By default, Pandas uses the NaN value to replace the missing values.\nNote: nan, which stands for “not a number,” is a particular floating-point value in Python.\nYou can get a nan value with any of the following functions:\n float('nan') math.nan numpy.nan  The continent that corresponds to Russia in df is nan:\nKAZ,Kazakhstan,18.53,2724.9,159.41,Asia,1991-12-16\ndf.loc['RUS', 'CONT'] # nan  KAZ,Kazakhstan,18.53,2724.9,159.41,Asia,1991-12-16\nThis example uses .loc[] to get data with the specified row and column names.\nWhen you save your DataFrame to a CSV file, empty strings ('') will represent the missing data. You can see this both in your file data.csv and in the string s. If you want to change this behavior, then use the optional parameter na_rep:\nKAZ,Kazakhstan,18.53,2724.9,159.41,Asia,1991-12-16\ndf.to_csv('new-data.csv', na_rep='(missing)') KAZ,Kazakhstan,18.53,2724.9,159.41,Asia,1991-12-16  This code produces the file new-data.csv where the missing values are no longer empty strings. You can expand the code block below to see how this file should look: KAZ,Kazakhstan,18.53,2724.9,159.41,Asia,1991-12-16 new-data.csvShow/Hide\nNow, the string '(missing)' in the file corresponds to the nan values from df.\nWhen Pandas reads files, it considers the empty string ('') and a few others as missing values by default:\n 'nan' '-nan' 'NA' 'N/A' 'NaN' 'null'  If you don’t want this behavior, then you can pass keep_default_na=False to the Pandas read_csv() function. To specify other labels for missing values, use the parameter na_values:\npd.read_csv('new-data.csv', index_col=0, na_values='(missing)') ## output COUNTRY POP AREA GDP CONT IND_DAY CHN China 1398.72 9596.96 12234.78 Asia NaN IND India 1351.16 3287.26 2575.67 Asia 1947-08-15 USA US 329.74 9833.52 19485.39 N.America 1776-07-04 IDN Indonesia 268.07 1910.93 1015.54 Asia 1945-08-17 BRA Brazil 210.32 8515.77 2055.51 S.America 1822-09-07 PAK Pakistan 205.71 881.91 302.14 Asia 1947-08-14 NGA Nigeria 200.96 923.77 375.77 Africa 1960-10-01 BGD Bangladesh 167.09 147.57 245.63 Asia 1971-03-26 RUS Russia 146.79 17098.25 1530.75 NaN 1992-06-12 MEX Mexico 126.58 1964.38 1158.23 N.America 1810-09-16 JPN Japan 126.22 377.97 4872.42 Asia NaN DEU Germany 83.02 357.11 3693.20 Europe NaN FRA France 67.02 640.68 2582.49 Europe 1789-07-14 GBR UK 66.44 242.50 2631.23 Europe NaN ITA Italy 60.36 301.34 1943.84 Europe NaN ARG Argentina 44.94 2780.40 637.49 S.America 1816-07-09 DZA Algeria 43.38 2381.74 167.56 Africa 1962-07-05 CAN Canada 37.59 9984.67 1647.12 N.America 1867-07-01 AUS Australia 25.47 7692.02 1408.68 Oceania NaN KAZ Kazakhstan 18.53 2724.90 159.41 Asia 1991-12-16  Here, you’ve marked the string '(missing)' as a new missing data label, and Pandas replaced it with nan when it read the file.\nWhen you load data from a file, Pandas assigns the data types to the values of each column by default. You can check these types with .dtypes:\ndf = pd.read_csv('data.csv', index_col=0) df.dtypes ## output COUNTRY object POP float64 AREA float64 GDP float64 CONT object IND_DAY object dtype: object  The columns with strings and dates ('COUNTRY', 'CONT', and 'IND_DAY') have the data type object. Meanwhile, the numeric columns contain 64-bit floating-point numbers (float64).\nYou can use the parameter dtype to specify the desired data types and parse_dates to force use of datetimes:\ndtypes = {'POP': 'float32', 'AREA': 'float32', 'GDP': 'float32'} df = pd.read_csv('data.csv', index_col=0, dtype=dtypes, parse_dates=['IND_DAY']) df.dtypes ## output COUNTRY object POP float32 AREA float32 GDP float32 CONT object IND_DAY datetime64[ns] dtype: object  df['IND_DAY'] ## output CHN NaT IND 1947-08-15 USA 1776-07-04 IDN 1945-08-17 BRA 1822-09-07 PAK 1947-08-14 NGA 1960-10-01 BGD 1971-03-26 RUS 1992-06-12 MEX 1810-09-16 JPN NaT DEU NaT FRA 1789-07-14 GBR NaT ITA NaT ARG 1816-07-09 DZA 1962-07-05 CAN 1867-07-01 AUS NaT KAZ 1991-12-16 Name: IND_DAY, dtype: datetime64[ns]  Now, you have 32-bit floating-point numbers ()float32) as specified with dtype. These differ slightly from the original 64-bit numbers because of smaller precision. The values in the last column are considered as dates and have the data type datetime64. That’s why the NaN values in this column are replaced with NaT.\nNow that you have real dates, you can save them in the format you like:\ndf = pd.read_csv('data.csv', index_col=0, parse_dates=['IND_DAY']) df.to_csv('formatted-data.csv', date_format='%B %d, %Y')  Here, you’ve specified the parameter date_format to be '%B %d, %Y'. You can expand the code block below to see the resulting file:\nformatted-data.csvShow/Hide\nThe format of the dates is different now. The format '%B %d, %Y' means the date will first display the full name of the month, then the day followed by a comma, and finally the full year.\nThere are several other optional parameters that you can use with .to_csv():\n sep denotes a values separator. decimal indicates a decimal separator. encoding sets the file encoding. header specifies whether you want to write column labels in the file.  Here’s how you would pass arguments for sep and header:\ns = df.to_csv(sep=';', header=False) print(s) ## output CHN;China;1398.72;9596.96;12234.78;Asia; IND;India;1351.16;3287.26;2575.67;Asia;1947-08-15 USA;US;329.74;9833.52;19485.39;N.America;1776-07-04 IDN;Indonesia;268.07;1910.93;1015.54;Asia;1945-08-17 BRA;Brazil;210.32;8515.77;2055.51;S.America;1822-09-07 PAK;Pakistan;205.71;881.91;302.14;Asia;1947-08-14 NGA;Nigeria;200.96;923.77;375.77;Africa;1960-10-01 BGD;Bangladesh;167.09;147.57;245.63;Asia;1971-03-26 RUS;Russia;146.79;17098.25;1530.75;;1992-06-12 MEX;Mexico;126.58;1964.38;1158.23;N.America;1810-09-16 JPN;Japan;126.22;377.97;4872.42;Asia; DEU;Germany;83.02;357.11;3693.2;Europe; FRA;France;67.02;640.68;2582.49;Europe;1789-07-14 GBR;UK;66.44;242.5;2631.23;Europe; ITA;Italy;60.36;301.34;1943.84;Europe; ARG;Argentina;44.94;2780.4;637.49;S.America;1816-07-09 DZA;Algeria;43.38;2381.74;167.56;Africa;1962-07-05 CAN;Canada;37.59;9984.67;1647.12;N.America;1867-07-01 AUS;Australia;25.47;7692.02;1408.68;Oceania; KAZ;Kazakhstan;18.53;2724.9;159.41;Asia;1991-12-16  The data is separated with a semicolon (';') because you’ve specified sep=';'. Also, since you passed header=False, you see your data without the header row of column names.\nThe Pandas read_csv() function has many additional options for managing missing data, working with dates and times, quoting, encoding, handling errors, and more. For instance, if you have a file with one data column and want to get a Series object instead of a DataFrame, then you can pass squeeze=True to read_csv(). You’ll learn later on about data compression and decompression, as well as how to skip rows and columns.\nJSON Files JSON stands for JavaScript object notation. JSON files are plaintext files used for data interchange, and humans can read them easily. They follow the ISO/IEC 21778:2017 and ECMA-404 standards and use the .json extension. Python and Pandas work well with JSON files, as Python’s json library offers built-in support for them.\nYou can save the data from your DataFrame to a JSON file with .to_json(). Start by creating a DataFrame object again. Use the dictionary data that holds the data about countries and then apply .to_json():\ndf = pd.DataFrame(data=data).T df.to_json('data-columns.json')  This code produces the file data-columns.json. You can expand the code block below to see how this file should look:\ndata-columns.jsonShow/Hide\ndata-columns.json has one large dictionary with the column labels as keys and the corresponding inner dictionaries as values.\nYou can get a different file structure if you pass an argument for the optional parameter orient:\ndf.to_json('data-index.json', orient='index')  The orient parameter defaults to 'columns'. Here, you’ve set it to index.\nYou should get a new file data-index.json. You can expand the code block below to see the changes:\ndata-index.jsonShow/Hide\ndata-index.json also has one large dictionary, but this time the row labels are the keys, and the inner dictionaries are the values.\nThere are few more options for orient. One of them is 'records':\ndf.to_json('data-records.json', orient='records')  This code should yield the file data-records.json. You can expand the code block below to see the content:\ndata-records.jsonShow/Hide\ndata-records.json holds a list with one dictionary for each row. The row labels are not written.\nYou can get another interesting file structure with orient='split':\ndf.to_json('data-split.json', orient='split')  The resulting file is data-split.json. You can expand the code block below to see how this file should look:\ndata-split.jsonShow/Hide\ndata-split.json contains one dictionary that holds the following lists:\n The names of the columns The labels of the rows The inner lists (two-dimensional sequence) that hold data values  If you don’t provide the value for the optional parameter path_or_buf that defines the file path, then .to_json() will return a JSON string instead of writing the results to a file. This behavior is consistent with .to_csv().\nThere are other optional parameters you can use. For instance, you can set index=False to forego saving row labels. You can manipulate precision with double_precision, and dates with date_format and date_unit. These last two parameters are particularly important when you have time series among your data:\ndf = pd.DataFrame(data=data).T df['IND_DAY'] = pd.to_datetime(df['IND_DAY']) df.dtypes ## output COUNTRY object POP object AREA object GDP object CONT object IND_DAY datetime64[ns] dtype: object  df.to_json('data-time.json')  In this example, you’ve created the DataFrame from the dictionary data and used to_datetime() to convert the values in the last column to datetime64. You can expand the code block below to see the resulting file:\ndata-time.jsonShow/Hide\nIn this file, you have large integers instead of dates for the independence days. That’s because the default value of the optional parameter date_format is 'epoch' whenever orient isn’t 'table'. This default behavior expresses dates as an epoch in milliseconds relative to midnight on January 1, 1970.\nHowever, if you pass date_format='iso', then you’ll get the dates in the ISO 8601 format. In addition, date_unit decides the units of time:\ndf = pd.DataFrame(data=data).T df['IND_DAY'] = pd.to_datetime(df['IND_DAY']) df.to_json('new-data-time.json', date_format='iso', date_unit='s')  This code produces the following JSON file:\nnew-data-time.jsonShow/Hide\nThe dates in the resulting file are in the ISO 8601 format.\nYou can load the data from a JSON file with read_json():\ndf = pd.read_json('data-index.json', orient='index', convert_dates=['IND_DAY'])  files. The optional parameter orient is very important because it specifies how Pandas understands the structure of the file.\nThere are other optional parameters you can use as well:\n Set the encoding with encoding. Manipulate dates with convert_dates and keep_default_dates. Impact precision with dtype and precise_float. Decode numeric data directly to NumPy arrays with numpy=True.  Note that you might lose the order of rows and columns when using the JSON format to store your data.\nHTML Files An HTML is a plaintext file that uses hypertext markup language to help browsers render web pages. The extensions for HTML files are .html and .htm. You’ll need to install an HTML parser library like lxml or html5lib to be able to work with HTML files:\n`$pip install lxml html5lib  You can also use Conda to install the same packages:\n`$ conda install lxml html5lib  Once you have these libraries, you can save the contents of your DataFrame as an HTML file with .to_html():\ndf = pd.DataFrame(data=data).T df.to_html('data.html')  This code generates a file data.html. You can expand the code block below to see how this file should look:\ndata.htmlShow/Hide\nThis file shows the DataFrame contents nicely. However, notice that you haven’t obtained an entire web page. You’ve just output the data that corresponds to df in the HTML format.\n.to_html() won’t create a file if you don’t provide the optional parameter buf, which denotes the buffer to write to. If you leave this parameter out, then your code will return a string as it did with .to_csv() and .to_json().\nHere are some other optional parameters:\n header determines whether to save the column names. index determines whether to save the row labels. classes assigns cascading style sheet (CSS) classes. render_links specifies whether to convert URLs to HTML links. table_id assigns the CSS id to the table tag. escape decides whether to convert the characters \u0026lt;, \u0026gt;, and \u0026amp; to HTML-safe strings.  You use parameters like these to specify different aspects of the resulting files or strings.\nYou can create a DataFrame object from a suitable HTML file using read_html(), which will return a DataFrame instance or a list of them:\ndf = pd.read_html('data.html', index_col=0, parse_dates=['IND_DAY'])  This is very similar to what you did when reading CSV files. You also have parameters that help you work with dates, missing values, precision, encoding, HTML parsers, and more.\nExcel Files You’ve already learned how to read and write Excel files with Pandas. However, there are a few more options worth considering. For one, when you use .to_excel(), you can specify the name of the target worksheet with the optional parameter sheet_name:\ndf = pd.DataFrame(data=data).T df.to_excel('data.xlsx', sheet_name='COUNTRIES')  Here, you create a file data.xlsx with a worksheet called COUNTRIES that stores the data. The string 'data.xlsx' is the argument for the parameter excel_writer that defines the name of the Excel file or its path.\nThe optional parameters startrow and startcol both default to 0 and indicate the upper left-most cell where the data should start being written:\ndf.to_excel('data-shifted.xlsx', sheet_name='COUNTRIES', startrow=2, startcol=4)  Here, you specify that the table should start in the third row and the fifth column. You also used zero-based indexing, so the third row is denoted by 2 and the fifth column by 4.\nNow the resulting worksheet looks like this:\n\nAs you can see, the table starts in the third row 2 and the fifth column E.\n.read_excel() also has the optional parameter sheet_name that specifies which worksheets to read when loading data. It can take on one of the following values:\n The zero-based index of the worksheet The name of the worksheet The list of indices or names to read multiple sheets The value None to read all sheets  Here’s how you would use this parameter in your code:\ndf = pd.read_excel('data.xlsx', sheet_name=0, index_col=0, parse_dates=['IND_DAY']) df = pd.read_excel('data.xlsx', sheet_name='COUNTRIES', index_col=0, parse_dates=['IND_DAY'])  Both statements above create the same DataFrame because the sheet_name parameters have the same values. In both cases, sheet_name=0 and sheet_name='COUNTRIES' refer to the same worksheet. The argument parse_dates=['IND_DAY'] tells Pandas to try to consider the values in this column as dates or times.\nThere are other optional parameters you can use with .read_excel() and .to_excel() to determine the Excel engine, the encoding, the way to handle missing values and infinities, the method for writing column names and row labels, and so on.\nSQL Files Pandas IO tools can also read and write databases. In this next example, you’ll write your data to a database called data.db. To get started, you’ll need the SQLAlchemy package. To learn more about it, you can read the official ORM tutorial. You’ll also need the database driver. Python has a built-in driver for SQLite.\nYou can install SQLAlchemy with pip:\n$ pip install sqlalchemy\nYou can also install it with Conda:\n$ conda install sqlalchemy\nOnce you have SQLAlchemy installed, import create_engine() and create a database engine:\nfrom sqlalchemy import create_engine engine = create_engine('sqlite:///data.db', echo=False)  Now that you have everything set up, the next step is to create a DataFrame object. It’s convenient to specify the data types and apply .to_sql().\ndtypes = {'POP': 'float64', 'AREA': 'float64', 'GDP': 'float64', 'IND_DAY': 'datetime64'} df = pd.DataFrame(data=data).T.astype(dtype=dtypes) df.dtypes ## output COUNTRY object POP float64 AREA float64 GDP float64 CONT object IND_DAY datetime64[ns] dtype: object  .astype() is a very convenient method you can use to set multiple data types at once.\nOnce you’ve created your DataFrame, you can save it to the database with .to_sql():\ndf.to_sql('data.db', con=engine, index_label='ID')  The parameter con is used to specify the database connection or engine that you want to use. The optional parameter index_label specifies how to call the database column with the row labels. You’ll often see it take on the value ID, Id, or id.\nYou should get the database data.db with a single table that looks like this:\n\nThe first column contains the row labels. To omit writing them into the database, pass index=False to .to_sql(). The other columns correspond to the columns of the DataFrame.\nThere are a few more optional parameters. For example, you can use schema to specify the database schema and dtype to determine the types of the database columns. You can also use if_exists, which says what to do if a database with the same name and path already exists:\n if_exists='fail' raises a ValueError and is the default. if_exists='replace' drops the table and inserts new values. if_exists='append' inserts new values into the table.  You can load the data from the database with read_sql():\ndf = pd.read_sql('data.db', con=engine, index_col='ID') df ## output COUNTRY POP AREA GDP CONT IND_DAY ID CHN China 1398.72 9596.96 12234.78 Asia NaT IND India 1351.16 3287.26 2575.67 Asia 1947-08-15 USA US 329.74 9833.52 19485.39 N.America 1776-07-04 IDN Indonesia 268.07 1910.93 1015.54 Asia 1945-08-17 BRA Brazil 210.32 8515.77 2055.51 S.America 1822-09-07 PAK Pakistan 205.71 881.91 302.14 Asia 1947-08-14 NGA Nigeria 200.96 923.77 375.77 Africa 1960-10-01 BGD Bangladesh 167.09 147.57 245.63 Asia 1971-03-26 RUS Russia 146.79 17098.25 1530.75 None 1992-06-12 MEX Mexico 126.58 1964.38 1158.23 N.America 1810-09-16 JPN Japan 126.22 377.97 4872.42 Asia NaT DEU Germany 83.02 357.11 3693.20 Europe NaT FRA France 67.02 640.68 2582.49 Europe 1789-07-14 GBR UK 66.44 242.50 2631.23 Europe NaT ITA Italy 60.36 301.34 1943.84 Europe NaT ARG Argentina 44.94 2780.40 637.49 S.America 1816-07-09 DZA Algeria 43.38 2381.74 167.56 Africa 1962-07-05 CAN Canada 37.59 9984.67 1647.12 N.America 1867-07-01 AUS Australia 25.47 7692.02 1408.68 Oceania NaT KAZ Kazakhstan 18.53 2724.90 159.41 Asia 1991-12-16`  The parameter index_col specifies the name of the column with the row labels. Note that this inserts an extra row after the header that starts with ID. You can fix this behavior with the following line of code:\ndf.index.name = None df ## output COUNTRY POP AREA GDP CONT IND_DAY CHN China 1398.72 9596.96 12234.78 Asia NaT IND India 1351.16 3287.26 2575.67 Asia 1947-08-15 USA US 329.74 9833.52 19485.39 N.America 1776-07-04 IDN Indonesia 268.07 1910.93 1015.54 Asia 1945-08-17 BRA Brazil 210.32 8515.77 2055.51 S.America 1822-09-07 PAK Pakistan 205.71 881.91 302.14 Asia 1947-08-14 NGA Nigeria 200.96 923.77 375.77 Africa 1960-10-01 BGD Bangladesh 167.09 147.57 245.63 Asia 1971-03-26 RUS Russia 146.79 17098.25 1530.75 None 1992-06-12 MEX Mexico 126.58 1964.38 1158.23 N.America 1810-09-16 JPN Japan 126.22 377.97 4872.42 Asia NaT DEU Germany 83.02 357.11 3693.20 Europe NaT FRA France 67.02 640.68 2582.49 Europe 1789-07-14 GBR UK 66.44 242.50 2631.23 Europe NaT ITA Italy 60.36 301.34 1943.84 Europe NaT ARG Argentina 44.94 2780.40 637.49 S.America 1816-07-09 DZA Algeria 43.38 2381.74 167.56 Africa 1962-07-05 CAN Canada 37.59 9984.67 1647.12 N.America 1867-07-01 AUS Australia 25.47 7692.02 1408.68 Oceania NaT KAZ Kazakhstan 18.53 2724.90 159.41 Asia 1991-12-16  Now you have the same DataFrame object as before.\nNote that the continent for Russia is now None instead of nan. If you want to fill the missing values with nan, then you can use .fillna():\ndf.fillna(value=float('nan'), inplace=True)  .fillna() replaces all missing values with whatever you pass to value. Here, you passed float('nan'), which says to fill all missing values with nan.\nAlso note that you didn’t have to pass parse_dates=['IND_DAY'] to read_sql(). That’s because your database was able to detect that the last column contains dates. However, you can pass parse_dates if you’d like. You’ll get the same results.\nThere are other functions that you can use to read databases, like read_sql_table() and read_sql_query(). Feel free to try them out!\nPickle Files Pickling is the act of converting Python objects into byte streams. Unpickling is the inverse process. Python pickle files are the binary files that keep the data and hierarchy of Python objects. They usually have the extension .pickle or .pkl.\nYou can save your DataFrame in a pickle file with .to_pickle():\ndtypes = {'POP': 'float64', 'AREA': 'float64', 'GDP': 'float64', 'IND_DAY': 'datetime64'} df = pd.DataFrame(data=data).T.astype(dtype=dtypes) df.to_pickle('data.pickle')  Like you did with databases, it can be convenient first to specify the data types. Then, you create a file data.pickle to contain your data. You could also pass an integer value to the optional parameter protocol, which specifies the protocol of the pickler.\nYou can get the data from a pickle file with read_pickle():\ndf = pd.read_pickle('data.pickle') df ## output COUNTRY POP AREA GDP CONT IND_DAY CHN China 1398.72 9596.96 12234.78 Asia NaT IND India 1351.16 3287.26 2575.67 Asia 1947-08-15 USA US 329.74 9833.52 19485.39 N.America 1776-07-04 IDN Indonesia 268.07 1910.93 1015.54 Asia 1945-08-17 BRA Brazil 210.32 8515.77 2055.51 S.America 1822-09-07 PAK Pakistan 205.71 881.91 302.14 Asia 1947-08-14 NGA Nigeria 200.96 923.77 375.77 Africa 1960-10-01 BGD Bangladesh 167.09 147.57 245.63 Asia 1971-03-26 RUS Russia 146.79 17098.25 1530.75 NaN 1992-06-12 MEX Mexico 126.58 1964.38 1158.23 N.America 1810-09-16 JPN Japan 126.22 377.97 4872.42 Asia NaT DEU Germany 83.02 357.11 3693.20 Europe NaT FRA France 67.02 640.68 2582.49 Europe 1789-07-14 GBR UK 66.44 242.50 2631.23 Europe NaT ITA Italy 60.36 301.34 1943.84 Europe NaT ARG Argentina 44.94 2780.40 637.49 S.America 1816-07-09 DZA Algeria 43.38 2381.74 167.56 Africa 1962-07-05 CAN Canada 37.59 9984.67 1647.12 N.America 1867-07-01 AUS Australia 25.47 7692.02 1408.68 Oceania NaT KAZ Kazakhstan 18.53 2724.90 159.41 Asia 1991-12-16`  read_pickle() returns the DataFrame with the stored data. You can also check the data types:\ndf.dtypes ## output COUNTRY object POP float64 AREA float64 GDP float64 CONT object IND_DAY datetime64[ns] dtype: object  These are the same ones that you specified before using .to_pickle().\nAs a word of caution, you should always beware of loading pickles from untrusted sources. This can be dangerous! When you unpickle an untrustworthy file, it could execute arbitrary code on your machine, gain remote access to your computer, or otherwise exploit your device in other ways.\nWorking With Big Data If your files are too large for saving or processing, then there are several approaches you can take to reduce the required disk space:\n Compress your files Choose only the columns you want Omit the rows you don’t need Force the use of less precise data types Split the data into chunks  You’ll take a look at each of these techniques in turn.\nCompress and Decompress Files You can create an archive file like you would a regular one, with the addition of a suffix that corresponds to the desired compression type:\n '.gz' '.bz2' '.zip' '.xz'  Pandas can deduce the compression type by itself:\ndf = pd.DataFrame(data=data).T df.to_csv('data.csv.zip')  Here, you create a compressed .csv file as an archive. The size of the regular .csv file is 1048 bytes, while the compressed file only has 766 bytes.\nYou can open this compressed file as usual with the Pandas read_csv() function:\ndf = pd.read_csv('data.csv.zip', index_col=0, parse_dates=['IND_DAY']) df  COUNTRY POP AREA GDP CONT IND_DAY CHN China 1398.72 9596.96 12234.78 Asia NaT IND India 1351.16 3287.26 2575.67 Asia 1947-08-15 USA US 329.74 9833.52 19485.39 N.America 1776-07-04 IDN Indonesia 268.07 1910.93 1015.54 Asia 1945-08-17 BRA Brazil 210.32 8515.77 2055.51 S.America 1822-09-07 PAK Pakistan 205.71 881.91 302.14 Asia 1947-08-14 NGA Nigeria 200.96 923.77 375.77 Africa 1960-10-01 BGD Bangladesh 167.09 147.57 245.63 Asia 1971-03-26 RUS Russia 146.79 17098.25 1530.75 NaN 1992-06-12 MEX Mexico 126.58 1964.38 1158.23 N.America 1810-09-16 JPN Japan 126.22 377.97 4872.42 Asia NaT DEU Germany 83.02 357.11 3693.20 Europe NaT FRA France 67.02 640.68 2582.49 Europe 1789-07-14 GBR UK 66.44 242.50 2631.23 Europe NaT ITA Italy 60.36 301.34 1943.84 Europe NaT ARG Argentina 44.94 2780.40 637.49 S.America 1816-07-09 DZA Algeria 43.38 2381.74 167.56 Africa 1962-07-05 CAN Canada 37.59 9984.67 1647.12 N.America 1867-07-01 AUS Australia 25.47 7692.02 1408.68 Oceania NaT KAZ Kazakhstan 18.53 2724.90 159.41 Asia 1991-12-16  read_csv() decompresses the file before reading it into a DataFrame.\nYou can specify the type of compression with the optional parameter compression, which can take on any of the following values:\n 'infer' 'gzip' 'bz2' 'zip' 'xz' None  The default value compression='infer' indicates that Pandas should deduce the compression type from the file extension.\nHere’s how you would compress a pickle file:\ndf = pd.DataFrame(data=data).T df.to_pickle('data.pickle.compress', compression='gzip')  You should get the file data.pickle.compress that you can later decompress and read:\ndf = pd.read_pickle('data.pickle.compress', compression='gzip')  df again corresponds to the DataFrame with the same data as before.\nYou can give the other compression methods a try, as well. If you’re using pickle files, then keep in mind that the .zip format supports reading only.\nChoose Columns The Pandas read_csv() and read_excel() functions have the optional parameter usecols that you can use to specify the columns you want to load from the file. You can pass the list of column names as the corresponding argument:\ndf = pd.read_csv('data.csv', usecols=['COUNTRY', 'AREA']) df ## output COUNTRY AREA 0 China 9596.96 1 India 3287.26 2 US 9833.52 3 Indonesia 1910.93 4 Brazil 8515.77 5 Pakistan 881.91 6 Nigeria 923.77 7 Bangladesh 147.57 8 Russia 17098.25 9 Mexico 1964.38 10 Japan 377.97 11 Germany 357.11 12 France 640.68 13 UK 242.50 14 Italy 301.34 15 Argentina 2780.40 16 Algeria 2381.74 17 Canada 9984.67 18 Australia 7692.02 19 Kazakhstan 2724.90  Now you have a DataFrame that contains less data than before. Here, there are only the names of the countries and their areas.\nInstead of the column names, you can also pass their indices:\ndf = pd.read_csv('data.csv',index_col=0, usecols=[0, 1, 3]) df ## output COUNTRY AREA CHN China 9596.96 IND India 3287.26 USA US 9833.52 IDN Indonesia 1910.93 BRA Brazil 8515.77 PAK Pakistan 881.91 NGA Nigeria 923.77 BGD Bangladesh 147.57 RUS Russia 17098.25 MEX Mexico 1964.38 JPN Japan 377.97 DEU Germany 357.11 FRA France 640.68 GBR UK 242.50 ITA Italy 301.34 ARG Argentina 2780.40 DZA Algeria 2381.74 CAN Canada 9984.67 AUS Australia 7692.02 KAZ Kazakhstan 2724.90  Expand the code block below to compare these results with the file 'data.csv':\ndata.csvShow/Hide\nYou can see the following columns:\n The column at index 0 contains the row labels. The column at index 1 contains the country names. The column at index 3 contains the areas.  Simlarly, read_sql() has the optional parameter columns that takes a list of column names to read:\ndf = pd.read_sql('data.db', con=engine, index_col='ID', ... columns=['COUNTRY', 'AREA']) df.index.name = None df ## output COUNTRY AREA CHN China 9596.96 IND India 3287.26 USA US 9833.52 IDN Indonesia 1910.93 BRA Brazil 8515.77 PAK Pakistan 881.91 NGA Nigeria 923.77 BGD Bangladesh 147.57 RUS Russia 17098.25 MEX Mexico 1964.38 JPN Japan 377.97 DEU Germany 357.11 FRA France 640.68 GBR UK 242.50 ITA Italy 301.34 ARG Argentina 2780.40 DZA Algeria 2381.74 CAN Canada 9984.67 AUS Australia 7692.02 KAZ Kazakhstan 2724.90  Again, the DataFrame only contains the columns with the names of the countries and areas. If columns is None or omitted, then all of the columns will be read, as you saw before. The default behavior is columns=None.\nOmit Rows When you test an algorithm for data processing or machine learning, you often don’t need the entire dataset. It’s convenient to load only a subset of the data to speed up the process. The Pandas read_csv() and read_excel() functions have some optional parameters that allow you to select which rows you want to load:\n skiprows: either the number of rows to skip at the beginning of the file if it’s an integer, or the zero-based indices of the rows to skip if it’s a list-like object skipfooter: the number of rows to skip at the end of the file nrows: the number of rows to read  Here’s how you would skip rows with odd zero-based indices, keeping the even ones:\ndf = pd.read_csv('data.csv', index_col=0, skiprows=range(1, 20, 2)) df ## output COUNTRY POP AREA GDP CONT IND_DAY IND India 1351.16 3287.26 2575.67 Asia 1947-08-15 IDN Indonesia 268.07 1910.93 1015.54 Asia 1945-08-17 PAK Pakistan 205.71 881.91 302.14 Asia 1947-08-14 BGD Bangladesh 167.09 147.57 245.63 Asia 1971-03-26 MEX Mexico 126.58 1964.38 1158.23 N.America 1810-09-16 DEU Germany 83.02 357.11 3693.20 Europe NaN GBR UK 66.44 242.50 2631.23 Europe NaN ARG Argentina 44.94 2780.40 637.49 S.America 1816-07-09 CAN Canada 37.59 9984.67 1647.12 N.America 1867-07-01 KAZ Kazakhstan 18.53 2724.90 159.41 Asia 1991-12-16`  In this example, skiprows is range(1, 20, 2) and corresponds to the values 1, 3, …, 19. The instances of the Python built-in class range behave like sequences. The first row of the file data.csv is the header row. It has the index 0, so Pandas loads it in. The second row with index 1 corresponds to the label CHN, and Pandas skips it. The third row with the index 2 and label IND is loaded, and so on.\nIf you want to choose rows randomly, then skiprows can be a list or NumPy array with pseudo-random numbers, obtained either with pure Python or with NumPy.\nForce Less Precise Data Types If you’re okay with less precise data types, then you can potentially save a significant amount of memory! First, get the data types with .dtypes again:\ndf = pd.read_csv('data.csv', index_col=0, parse_dates=['IND_DAY']) df.dtypes ## output COUNTRY object POP float64 AREA float64 GDP float64 CONT object IND_DAY datetime64[ns] dtype: object  The columns with the floating-point numbers are 64-bit floats. Each number of this type float64 consumes 64 bits or 8 bytes. Each column has 20 numbers and requires 160 bytes. You can verify this with .memory_usage():\ndf.memory_usage() ## output Index 160 COUNTRY 160 POP 160 AREA 160 GDP 160 CONT 160 IND_DAY 160 dtype: int64  .memory_usage() returns an instance of Series with the memory usage of each column in bytes. You can conveniently combine it with .loc[] and .sum() to get the memory for a group of columns:\ndf.loc[:, ['POP', 'AREA', 'GDP']].memory_usage(index=False).sum() # 480  This example shows how you can combine the numeric columns 'POP', 'AREA', and 'GDP' to get their total memory requirement. The argument index=False excludes data for row labels from the resulting Series object. For these three columns, you’ll need 480 bytes.\nYou can also extract the data values in the form of a NumPy array with .to_numpy() or .values. Then, use the .nbytes attribute to get the total bytes consumed by the items of the array:\ndf.loc[:, ['POP', 'AREA', 'GDP']].to_numpy().nbytes # 480  The result is the same 480 bytes. So, how do you save memory?\nIn this case, you can specify that your numeric columns 'POP', 'AREA', and 'GDP' should have the type float32. Use the optional parameter dtype to do this:\ndtypes = {'POP': 'float32', 'AREA': 'float32', 'GDP': 'float32'} df = pd.read_csv('data.csv', index_col=0, dtype=dtypes, ... parse_dates=['IND_DAY'])  The dictionary dtypes specifies the desired data types for each column. It’s passed to the Pandas read_csv() function as the argument that corresponds to the parameter dtype.\nNow you can verify that each numeric column needs 80 bytes, or 4 bytes per item:\ndf.dtypes ## output COUNTRY object POP float32 AREA float32 GDP float32 CONT object IND_DAY datetime64[ns] dtype: object  df.memory_usage() ## output Index 160 COUNTRY 160 POP 80 AREA 80 GDP 80 CONT 160 IND_DAY 160 dtype: int64  df.loc[:, ['POP', 'AREA', 'GDP']].memory_usage(index=False).sum() # 240 df.loc[:, ['POP', 'AREA', 'GDP']].to_numpy().nbytes # 240  Each value is a floating-point number of 32 bits or 4 bytes. The three numeric columns contain 20 items each. In total, you’ll need 240 bytes of memory when you work with the type float32. This is half the size of the 480 bytes you’d need to work with float64.\nIn addition to saving memory, you can significantly reduce the time required to process data by using float32 instead of float64 in some cases.\nUse Chunks to Iterate Through Files Another way to deal with very large datasets is to split the data into smaller chunks and process one chunk at a time. If you use read_csv(), read_json() or read_sql(), then you can specify the optional parameter chunksize:\ndata_chunk = pd.read_csv('data.csv', index_col=0, chunksize=8) type(data_chunk) # \u0026lt;class 'pandas.io.parsers.TextFileReader'\u0026gt; hasattr(data_chunk, '__iter__') # True hasattr(data_chunk, '__next__') # True  chunksize defaults to None and can take on an integer value that indicates the number of items in a single chunk. When chunksize is an integer, read_csv() returns an iterable that you can use in a for loop to get and process only a fragment of the dataset in each iteration:\nfor df_chunk in pd.read_csv('data.csv', index_col=0, chunksize=8): ... print(df_chunk, end='\\n\\n') ... print('memory:', df_chunk.memory_usage().sum(), 'bytes', ... end='\\n\\n\\n') ## output COUNTRY POP AREA GDP CONT IND_DAY CHN China 1398.72 9596.96 12234.78 Asia NaN IND India 1351.16 3287.26 2575.67 Asia 1947-08-15 USA US 329.74 9833.52 19485.39 N.America 1776-07-04 IDN Indonesia 268.07 1910.93 1015.54 Asia 1945-08-17 BRA Brazil 210.32 8515.77 2055.51 S.America 1822-09-07 PAK Pakistan 205.71 881.91 302.14 Asia 1947-08-14 NGA Nigeria 200.96 923.77 375.77 Africa 1960-10-01 BGD Bangladesh 167.09 147.57 245.63 Asia 1971-03-26 memory: 448 bytes  COUNTRY POP AREA GDP CONT IND_DAY RUS Russia 146.79 17098.25 1530.75 NaN 1992-06-12 MEX Mexico 126.58 1964.38 1158.23 N.America 1810-09-16 JPN Japan 126.22 377.97 4872.42 Asia NaN DEU Germany 83.02 357.11 3693.20 Europe NaN FRA France 67.02 640.68 2582.49 Europe 1789-07-14 GBR UK 66.44 242.50 2631.23 Europe NaN ITA Italy 60.36 301.34 1943.84 Europe NaN ARG Argentina 44.94 2780.40 637.49 S.America 1816-07-09 memory: 448 bytes COUNTRY POP AREA GDP CONT IND_DAY DZA Algeria 43.38 2381.74 167.56 Africa 1962-07-05 CAN Canada 37.59 9984.67 1647.12 N.America 1867-07-01 AUS Australia 25.47 7692.02 1408.68 Oceania NaN KAZ Kazakhstan 18.53 2724.90 159.41 Asia 1991-12-16 memory: 224 bytes  In this example, the chunksize is 8. The first iteration of the for loop returns a DataFrame with the first eight rows of the dataset only. The second iteration returns another DataFrame with the next eight rows. The third and last iteration returns the remaining four rows.\nNote: You can also pass iterator=True to force the Pandas read_csv() function to return an iterator object instead of a DataFrame object.\nIn each iteration, you get and process the DataFrame with the number of rows equal to chunksize. It’s possible to have fewer rows than the value of chunksize in the last iteration. You can use this functionality to control the amount of memory required to process data and keep that amount reasonably small.\nConclusion You now know how to save the data and labels from Pandas DataFrame objects to different kinds of files. You also know how to load your data from files and create DataFrame objects.\nYou’ve used the Pandas read_csv() and .to_csv() methods to read and write CSV files. You also used similar methods to read and write Excel, JSON, HTML, SQL, and pickle files. These functions are very convenient and widely used. They allow you to save or load your data in a single function or method call.\nYou’ve also learned how to save time, memory, and disk space when working with large data files:\n Compress or decompress files Choose the rows and columns you want to load Use less precise data types Split data into chunks and process them one by one  You’ve mastered a significant step in the machine learning and data science process! If you have any questions or comments, then please put them in the comments section below.\n Source : .\n "});index.add({'id':235,'href':'/library/tutorials/docs/python/python-regular-expressions/','title':"Regular Expressions",'content':" Tutorial: Python Regex (Regular Expressions) for Data Scientists Diving headlong into data sets is a part of the mission for anyone working in data science. Often, this means number-crunching, but what do we do when our data set is primarily text-based? We can use regular expressions. In this tutorial, we’re going to take a closer look at how to use regular expressions (regex) in Python.\nRegular expressions (regex) are essentially text patterns that you can use to automate searching through and replacing elements within strings of text. This can make cleaning and working with text-based data sets much easier, saving you the trouble of having to search through mountains of text by hand.\nRegular expressions can be used across a variety of programming languages, and they’ve been around for a very long time!\nIn this tutorial, though, we’ll learning about regular expressions in Python, so basic familiarity with key Python concepts like if-else statements, while and for loops, etc., is required. (If you need a refresher on any of this stuff, our introductory Python courses cover all of the relevant topics interactively, right in your browser, and they’re free!)\nBy the end of the tutorial, you’ll be familiar with how Python regex works, and be able to use the basic patterns and functions in Python’s regex module, re, for to analyze text strings. You’ll also get an introduction to how regex can be used in concert with pandas to work with large text corpuses (corpus means a data set of text).\n(To work through the pandas section of this tutorial, you will need to have the pandas library installed. The easiest way to do this is to download Anaconda and work through this tutorial in a Jupyter notebook. For other options, check out the pandas installation guide.)\nLet\u0026rsquo;s dig into some data about everyone\u0026rsquo;s least favorite types of email: spam and scams.\nOur Task: Analyze Spam Emails In this tutorial, we’ll use the Fraudulent Email Corpus from Kaggle. It contains thousands of phishing emails sent between 1998 and 2007. They’re pretty entertaining to read.\nYou can find the full corpus here. But we’ll start by learning basic regex commands using a few emails. If you’d like, you can use our test file as well, or you can try this with the full corpus.\nIntroducing Python’s Regex Module First, we’ll prepare the data set by opening the test file, setting it to read-only, and reading it. We’ll also assign it to a variable, fh (for “file handle”).\nfh = open(r\u0026quot;test_emails.txt\u0026quot;, \u0026quot;r\u0026quot;).read()  Notice that we precede the directory path with an r. This technique converts a string into a raw string, which helps to avoid conflicts caused by how some machines read characters, such as backslashes in directory paths on Windows.\nNow, suppose we want to find out who the emails are from. We could try raw Python on its own:\nfor line in fh.split(\u0026quot;n\u0026quot;): if \u0026quot;From:\u0026quot; in line: print(line)  der.com\u0026gt; Message-Id: \u0026lt;200210311310.g9VDANt24674@bloodwork.mr.itd.UM\u0026gt; From: \u0026quot;Mr. Be g_715@epatra.com\u0026gt; Message-Id: \u0026lt;200210312227.g9VMQvDj017948@bluewhale.cs.CU\u0026gt; From: \u0026quot;PRINCE OBONG ELEME\u0026quot; \u0026lt;obo  But that’s not giving us exactly what we want. If you take a look at our test file, we could figure out why and fix it, but instead, let’s use Python’s re module and do it with regular expressions!\nWe’ll start by importing Python’s re module. Then, we’ll use a function called re.findall() that returns a list of all instances of a pattern we define in the string we’re looking at.\nHere’s how it looks:\nimport re for line in re.findall(\u0026quot;From:.*\u0026quot;, fh): print(line)  From: \u0026quot;Mr. Ben Suleman\u0026quot; \u0026lt;bensul2004nng@spinfinder.com\u0026gt; From: \u0026quot;PRINCE OBONG ELEME\u0026quot; \u0026lt;obong_715@epatra.com\u0026gt;  This is essentially the same length as our raw Python, but that’s because it’s a very simple example. The more you’re trying to do, the more effort Python regex is likely to save you.\nBefore we move on, let’s take a closer look at re.findall(). This function takes two arguments in the form of re.findall(pattern, string). Here, pattern represents the substring we want to find, and string represents the main string we want to find it in. The main string can consist of multiple lines. In this case, we’re having it search through all of fh, the file with our selected emails.\nThe .* is a shorthand for a string pattern. Regular expressions work by using these shorthand patterns to find specific patterns in text, so let’s take a look at some other common examples:\nCommon Python Regex Patterns The pattern we used with re.findall() above contains a fully spelled-out out string, \u0026quot;From:\u0026quot;. This is useful when we know precisely what we’re looking for, right down to the actual letters and whether or not they’re upper or lower case. If we don’t know the exact format of the strings we want, we’d be lost. Fortunately, regex has basic patterns that account for this scenario. Let’s look at the ones we use in this tutorial:\n w matches alphanumeric characters, which means a-z, A-Z, and 0-9. It also matches the underscore, _, and the dash, -. d matches digits, which means 0-9. s matches whitespace characters, which include the tab, new line, carriage return, and space characters. S matches non-whitespace characters. . matches any character except the new line character n.  With these regex patterns in hand, you’ll quickly understand our code above as we go on to explain it.\nWorking with Regex Patterns We can now explain the use of .* in the line re.findall(\u0026quot;From:.*\u0026quot;, text) above. Let’s look at . first:\nfor line in re.findall(\u0026quot;From:.\u0026quot;, fh): print(line)  From: From:  By adding a . next to From:, we look for one additional character next to it. Because . looks for any character except n, it captures the space character, which we cannot see. We can try more dots to verify this.\nfor line in re.findall(\u0026quot;From:...........\u0026quot;, fh): print(line)  From: \u0026quot;Mr. Ben S From: \u0026quot;PRINCE OB  It looks like adding dots does acquire the rest of the line for us. But, it’s tedious and we don’t know how many dots to add. This is where the asterisk symbol, *, comes in.\n* matches zero or more instances of a pattern on its left. This means it looks for repeating patterns. When we look for repeating patterns, we say that our search is “greedy.” If we don’t look for repeating patterns, we can call our search “non-greedy” or “lazy.”\nLet’s construct a greedy search for . with *.\nfor line in re.findall(\u0026quot;From:.*\u0026quot;, fh): print(line)  From: \u0026quot;Mr. Ben Suleman\u0026quot; \u0026lt;bensul2004nng@spinfinder.com\u0026gt; From: \u0026quot;PRINCE OBONG ELEME\u0026quot; \u0026lt;obong_715@epatra.com\u0026gt;  Because * matches zero or more instances of the pattern indicated on its left, and . is on its left here, we are able to acquire all the characters in the From: field until the end of the line. This prints out the full line with beautifully succinct code.\nWe might even go further and isolate only the name. Let’s use re.findall() to return a list of lines containing the pattern \u0026quot;From:.*\u0026quot; as we’ve done before. We’ll assign it to the variable match for neatness. Next, we’ll iterate through the list. In each cycle, we’ll execute re.findall again, matching the first quotation mark to pick out just the name:\nmatch = re.findall(\u0026quot;From:.*\u0026quot;, fh) for line in match: print(re.findall('\\\u0026quot;.*\\\u0026quot;', line))  ['\u0026quot;Mr. Ben Suleman\u0026quot;'] ['\u0026quot;PRINCE OBONG ELEME\u0026quot;']  Notice that we use a backslash next to the first quotation mark. The backslash is a special character used for escaping other special characters. For instance, when we want to use a quotation mark as a string literal instead of a special character, we escape it with a backslash like this: \\\u0026quot;. If we do not escape the pattern above with backslashes, it would become \u0026quot;\u0026quot;.*\u0026quot;\u0026quot;, which the Python interpreter would read as a period and an asterisk between two empty strings. It would produce an error and break the script. Hence, it’s crucial that we escape the quotation marks here with backslashes.\nAfter the first quotation mark is matched, .* acquires all the characters in the line until the next quotation mark, also escaped in the pattern. This gets us just the name, within quotation marks. The name is also printed within square brackets because re.findall returns matches in a list.\nWhat if we want the email address instead?\nmatch = re.findall(\u0026quot;From:.*\u0026quot;, fh) for line in match: print(re.findall(\u0026quot;\\w\\S*@*.\\w\u0026quot;, line))  ['bensul2004nng@spinfinder.com'] ['obong_715@epatra.com']  Looks simple enough, doesn’t it? Only the pattern is different. Let’s walk through it.\nHere’s how we match just the front part of the email address:\nfor line in match: print(re.findall(\u0026quot;\\w\\S*@\u0026quot;, line))  ['bensul2004nng@'] ['obong_715@']  Emails always contain an @ symbol, so we start with it. The part of the email before the @ symbol might contain alphanumeric characters, which means w is required. However, because some emails contain a period or a dash, that’s not enough. We add S to look for non-whitespace characters. But, w\\S will get only two characters. Add * to look for repetitions. The front part of the pattern thus looks like this: \\w\\S*@.\nNow for the pattern behind the @ symbol:\nfor line in match: print(re.findall(\u0026quot;@.*\u0026quot;, line))  ['@spinfinder.com\u0026gt;'] ['@epatra.com\u0026gt;']  The domain name usually contains alphanumeric characters, periods, and a dash sometimes, so a . will do. To make it greedy, we extend the search with a *. This allows us to match any character till the end of the line.\nIf we look at the line closely, we see that each email is encapsulated within angle brackets, \u0026lt; and \u0026gt;. Our pattern, .*, includes the closing bracket, \u0026gt;. Let’s remedy it:\nfor line in match: print(re.findall(\u0026quot;@.*\\w\u0026quot;, line))  ['@spinfinder.com'] ['@epatra.com']  Email addresses end with an alphanumeric character, so we cap the pattern with w. So, after the @ symbol we have .*\\w, which means that the pattern we want is a group of any type of characters ending with an alphanumeric character. This excludes \u0026gt;.\nOur full email address pattern thus looks like this: \\w\\S*@.*\\w.\nPhew! That was quite a bit to work through. Next, we’ll run through some common re functions that will be useful when we start reorganizing our corpus.\nCommon Python Regex Functions re.findall() is undeniably useful, but it’s not the only built-in function that’s available to us in re:\n re.search() re.split() re.sub()  Let’s look at these one by one before using them to bring some order to our data set.\nre.search() While re.findall() matches all instances of a pattern in a string and returns them in a list, re.search() matches the first instance of a pattern in a string, and returns it as a re match object.\nmatch = re.search(\u0026quot;From:.*\u0026quot;, fh) print(type(match)) print(type(match.group())) print(match) print(match.group())  \u0026lt;class 're.Match'\u0026gt; \u0026lt;class 'str'\u0026gt; \u0026lt;re.Match object; span=(3590, 3644), match='From: \u0026quot;Mr. Ben Suleman\u0026quot; \u0026lt;bensul2004nng@spinfinder\u0026gt; From: \u0026quot;Mr. Ben Suleman\u0026quot; \u0026lt;bensul2004nng@spinfinder.com\u0026gt;  Like re.findall(), re.search() also takes two arguments. The first is the pattern to match, and the second is the string to find it in. Here, we’ve assigned the results to the match variable for neatness.\nBecause re.search() returns a re match object, we can’t display the name and email address by printing it directly. Instead, we have to apply the group() function to it first. We’ve printed both their types out in the code above. As we can see, group() converts the match object into a string.\nWe can also see that printing match displays properties beyond the string itself, whereas printing match.group() displays only the string.\nre.split() Suppose we need a quick way to get the domain name of the email addresses. We could do it with three regex operations, like so:\naddress = re.findall(\u0026quot;From:.*\u0026quot;, fh) for item in address: for line in re.findall(\u0026quot;\\w\\S*@.*\\w\u0026quot;, item): username, domain_name = re.split(\u0026quot;@\u0026quot;, line) print(\u0026quot;{}, {}\u0026quot;.format(username, domain_name))  bensul2004nng, spinfinder.com obong_715, epatra.com  The first line is familiar. We return a list of strings, each containing the contents of the From: field, and assign it to a variable. Next, we iterate through the list to find the email addresses. At the same time, we iterate through the email addresses and use the re module’s split() function to snip each address in half, with the @ symbol as the delimiter. Finally, we print it.\nre.sub() Another handy re function is re.sub(). As the function name suggests, it substitutes parts of a string. An example:\nsender = re.search(\u0026quot;From:.*\u0026quot;, fh) address = sender.group() email = re.sub(\u0026quot;From\u0026quot;, \u0026quot;Email\u0026quot;, address) print(address) print(email)  From: \u0026quot;Mr. Ben Suleman\u0026quot;   Source : .\n "});index.add({'id':236,'href':'/library/tutorials/docs/articles/data-science/web-scraping/request-and-beautifulsoup/','title':"Requests and BeautifulSoup",'content':" Ultimate Guide to Web Scraping with Python Part 1: Requests and BeautifulSoup After the 2016 election I became much more interested in media bias and the manipulation of individuals through advertising. This series will be a walkthrough of a web scraping project that monitors political news from both left and right wing media outlets and performs an analysis on the rhetoric being used, the ads being displayed, and the sentiment of certain topics.\nThe first part of the series will we be getting media bias data and focus on only working locally on your computer, but if you wish to learn how to deploy something like this into production, feel free to leave a comment and let me know.\nLimit your impact when scraping Every time you load a web page you\u0026rsquo;re making a request to a server, and when you\u0026rsquo;re just a human with a browser there\u0026rsquo;s not a lot of damage you can do. With a Python script that can execute thousands of requests a second if coded incorrectly, you could end up costing the website owner a lot of money and possibly bring down their site (see Denial-of-service attack (DoS)).\nWith this in mind, we want to be very careful with how we program scrapers to avoid crashing sites and causing damage. Every time we scrape a website we want to attempt to make only one request per page. We don\u0026rsquo;t want to be making a request every time our parsing or other logic doesn\u0026rsquo;t work out, so we need to parse only after we\u0026rsquo;ve saved the page locally.\nIf I\u0026rsquo;m just doing some quick tests, I\u0026rsquo;ll usually start out in a Jupyter notebook because you can request a web page in one cell and have that web page available to every cell below it without making a new request. Since this article is available as a Jupyter notebook, you will see how it works if you choose that format.\nHow to save HTML locally After we make a request and retrieve a web page\u0026rsquo;s content, we can store that content locally with Python\u0026rsquo;s open() function. To do so we need to use the argument wb, which stands for \u0026ldquo;write bytes\u0026rdquo;. This let\u0026rsquo;s us avoid any encoding issues when saving.\nBelow is a function that wraps the open() function to reduce a lot of repetitive coding later on:\ndef save_html(html, path): with open(path, 'wb') as f: f.write(html) save_html(r.content, 'google_com')  Assume we have captured the HTML from google.com in html, which you\u0026rsquo;ll see later how to do. After running this function we will now have a file in the same directory as this notebook called google_com that contains the HTML.\nHow to open/read HTML from a local file To retrieve our saved file we\u0026rsquo;ll make another function to wrap reading the HTML back into html. We need to use rb for \u0026ldquo;read bytes\u0026rdquo; in this case.\ndef open_html(path): with open(path, 'rb') as f: return f.read() html = open_html('google_com')  The open function is doing just the opposite: read the HTML from google_com. If our script fails, notebook closes, computer shutsdown, etc., we no longer need to request google.com again, lessening our impact on their servers. While it doesn\u0026rsquo;t matter much with Google since they have a lot of resources, smaller sites with smaller servers will benefit from this.\nI save almost every page and parse later when web scraping as a safety precaution.\nFollow the rules for scrapers and bots Each site usually has a robots.txt on the root of their domain. This is where the website owner explicitly states what bots are allowed to do on their site. Simply go to example.com/robots.txt and you should find a text file that looks something like this:\nUser-agent: * Crawl-delay: 10 Allow: /pages/ Disallow: /scripts/ # more stuff  The User-agent field is the name of the bot and the rules that follow are what the bot should follow. Some robots.txt will have many User-agents with different rules. Common bots are googlebot, bingbot, and applebot, all of which you can probably guess the purpose and origin of.\nWe don\u0026rsquo;t really need to provide a User-agent when scraping, so User-agent: * is what we would follow. A * means that the following rules apply to all bots (that\u0026rsquo;s us).\nThe Crawl-delay tells us the number of seconds to wait before requests, so in this example we need to wait 10 seconds before making another request.\nAllow gives us specific URLs we\u0026rsquo;re allowed to request with bots, and vice versa for Disallow.\nIn this example we\u0026rsquo;re allowed to request anything in the /pages/ subfolder which means anything that starts with example.com/pages/. On the other hand, we are disallowed from scraping anything from the /scripts/ subfolder.\nMany times you\u0026rsquo;ll see a * next to Allow or Disallow which means you are either allowed or not allowed to scrape everything on the site.\nSometimes there will be a disallow all pages followed by allowed pages like this:\nDisallow: * Allow: /pages/  This means that you\u0026rsquo;re not allowed to scrape anything except the subfolder /pages/. Essentially, you just want to read the rules in order where the next rule overrides the previous rule.\nScraping Project: Getting Media Bias Data This project will primarily be run through a Jupyter notebook, which is done for teaching purposes and is not the usual way scrapers are programmed. After showing you the pieces, we\u0026rsquo;ll put it all together into a Python script that can be run from command line or your IDE of choice.\nMaking web requests With Python\u0026rsquo;s requests library we\u0026rsquo;re getting a web page by using get() on the URL. The response r contains many things, but using r.content will give us the HTML. Once we have the HTML we can then parse it for the data we\u0026rsquo;re interested in analyzing.\nThere\u0026rsquo;s an interesting website called AllSides that has a media bias rating table where users can agree or disagree with the rating.\nSince there\u0026rsquo;s nothing in their robots.txt that disallows us from scraping this section of the site, I\u0026rsquo;m assuming it\u0026rsquo;s okay to go ahead and extract this data for our project. Let\u0026rsquo;s request the this first page:\n!pip install requests  import requests url = 'https://www.allsides.com/media-bias/media-bias-ratings' r = requests.get(url) print(r.content[:100])  Since we essentially have a giant string of HTML, we can print a slice of 100 characters to confirm we have the source of the page. Let\u0026rsquo;s start extracting data.\nParsing HTML with BeautifulSoup What does BeautifulSoup do? We used requests to get the page from the AllSides server, but now we need the BeautifulSoup library to parse HTML and XML. When we pass our HTML to the BeautifulSoup constructor we get an object in return that we can then navigate like the original tree structure of the DOM.\nThis way we can find elements using names of tags, classes, IDs, and through relationships to other elements, like getting the children and siblings of elements.\nCreating a new soup object We create a new BeautifulSoup object by passing the constructor our newly acquired HTML content and the type of parser we want to use:\n!pip install beautifulsoup4  from bs4 import BeautifulSoup soup = BeautifulSoup(r.content, 'html.parser')  This soup object defines a bunch of methods — many of which can achieve the same result — that we can use to extract data from the HTML. Let\u0026rsquo;s start with finding elements.\nFinding elements and data To find elements and data inside our HTML we\u0026rsquo;ll be using select_one, which returns a single element, and select, which returns a list of elements (even if only one item exists). Both of these methods use CSS selectors to find elements, so if you\u0026rsquo;re rusty on how CSS selectors work here\u0026rsquo;s a quick refresher:\nA CSS selector refresher\n To get a tag, such as \u0026lt;a\u0026gt;\u0026lt;/a\u0026gt;, \u0026lt;body\u0026gt;\u0026lt;/body\u0026gt;, use the naked name for the tag. E.g. select_one('a') gets an anchor/link element, select_one('body') gets the body element\n .temp gets an element with a class of temp, E.g. to get \u0026lt;a class=\u0026quot;temp\u0026quot;\u0026gt;\u0026lt;/a\u0026gt; use select_one('.temp')\n #temp gets an element with an id of temp, E.g. to get \u0026lt;a id=\u0026quot;temp\u0026quot;\u0026gt;\u0026lt;/a\u0026gt; use select_one('#temp')\n .temp.example gets an element with both classes temp and example, E.g. to get \u0026lt;a class=\u0026quot;temp example\u0026quot;\u0026gt;\u0026lt;/a\u0026gt; use select_one('.temp.example')\n .temp a gets an anchor element nested inside of a parent element with class temp, E.g. to get \u0026lt;div class=\u0026quot;temp\u0026quot;\u0026gt;\u0026lt;a\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/div\u0026gt; use select_one('.temp a'). Note the space between .temp and a.\n .temp .example gets an element with class example nested inside of a parent element with class temp, E.g. to get \u0026lt;div class=\u0026quot;temp\u0026quot;\u0026gt;\u0026lt;a class=\u0026quot;example\u0026quot;\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/div\u0026gt; use select_one('.temp .example'). Again, note the space between .temp and .example. The space tells the selector that the class after the space is a child of the class before the space.\n ids, such as \u0026lt;a id=one\u0026gt;\u0026lt;/a\u0026gt;, are unique so you can usually use the id selector by itself to get the right element. No need to do nested selectors when using ids.\n  There\u0026rsquo;s many more selectors for for doing various tasks, like selecting certain child elements, specific links, etc., that you can look up when needed. The selectors above get us pretty close to everything we would need for now.\nTips on figuring out how to select certain elements\nMost browsers have a quick way of finding the selector for an element using their developer tools. In Chrome, we can quickly find selectors for elements by\n Right-click on the the element then select \u0026ldquo;Inspect\u0026rdquo; in the menu. Developer tools opens and and highlights the element we right-clicked\n Right-click the code element in developer tools, hover over \u0026ldquo;Copy\u0026rdquo; in the menu, then click \u0026ldquo;Copy selector\u0026rdquo;\n  Sometimes it\u0026rsquo;ll be a little off and we need to scan up a few elements to find the right one. Here\u0026rsquo;s what it looks like to find the selector and Xpath, another type of selector, in Chrome:\n Let\u0026rsquo;s start! Getting data out of a table Our data is housed in a table on AllSides, and by inspecting the header element we can find the code that renders the table and rows. What we need to do is select all the rows from the table and then parse out the information from each row.\n\nSimplifying the table\u0026rsquo;s HTML, the structure looks like this (comments \u0026lt;!-- --\u0026gt; added by me):\n\u0026lt;table\u0026gt; \u0026lt;thead\u0026gt; \u0026lt;!-- header information --\u0026gt; \u0026lt;/thead\u0026gt; \u0026lt;tbody\u0026gt; \u0026lt;tr class=\u0026quot;odd views-row-first\u0026quot;\u0026gt; \u0026lt;!-- begin table row --\u0026gt; \u0026lt;td class=\u0026quot;views-field views-field-title source-title\u0026quot;\u0026gt; \u0026lt;!-- table cell --\u0026gt; \u0026lt;!-- outlet name --\u0026gt; \u0026lt;/td\u0026gt; \u0026lt;td class=\u0026quot;views-field views-field-field-bias-image\u0026quot;\u0026gt; \u0026lt;!-- table cell --\u0026gt; \u0026lt;!-- bias data --\u0026gt; \u0026lt;/td\u0026gt; \u0026lt;td class=\u0026quot;views-field views-field-nothing-1 what-do-you-think\u0026quot;\u0026gt; \u0026lt;!-- table cell --\u0026gt; \u0026lt;!-- agree / disagree buttons --\u0026gt; \u0026lt;/td\u0026gt; \u0026lt;td class=\u0026quot;views-field views-field-nothing community-feedback\u0026quot;\u0026gt; \u0026lt;!-- table cell --\u0026gt; \u0026lt;!-- agree / disagree data --\u0026gt; \u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;!-- end table row --\u0026gt; \u0026lt;!-- more rows --\u0026gt; \u0026lt;/tbody\u0026gt; \u0026lt;/table\u0026gt;  So to get each row, we just select all \u0026lt;tr\u0026gt; inside \u0026lt;tbody\u0026gt;:\nrows = soup.select('tbody tr')  tbody tr tells the selector to extract all \u0026lt;tr\u0026gt; (table row) tags that are children of the \u0026lt;tbody\u0026gt; body tag. If there were more than one table on this page we would have to make a more specific selector, but since this is the only table, we\u0026rsquo;re good to go.\nNow we have a list of HTML table rows that each contain four cells:\n News source name and link\n Bias data\n Agreement buttons\n Community feedback data\n  Below is a breakdown of how to extract each one.\nNews source name  Let\u0026rsquo;s look at the first cell:\n\u0026lt;td class=\u0026quot;views-field views-field-title source-title\u0026quot;\u0026gt; \u0026lt;a href=\u0026quot;/news-source/abc-news-media-bias\u0026quot;\u0026gt;ABC News\u0026lt;/a\u0026gt; \u0026lt;/td\u0026gt;  The outlet name (ABC News) is the text of an anchor tag that\u0026rsquo;s nested inside a \u0026lt;td\u0026gt; tag, which is a cell — or table data tag.\nGetting the outlet name is pretty easy: just get the first row in rows and run a select_one off that object:\nrow = rows[0] name = row.select_one('.source-title').text.strip() print(name)  The only class we needed to use in this case was .source-title since .views-field looks to be just a class each row is given for styling and doesn\u0026rsquo;t provide any uniqueness.\nNotice that we didn\u0026rsquo;t need to worry about selecting the anchor tag a that contains the text. When we use .text is gets all text in that element, and since \u0026ldquo;ABC News\u0026rdquo; is the only text, that\u0026rsquo;s all we need to do. Bear in mind that using select or select_one will give you the whole element with the tags included, so we need .text to give us the text between the tags.\n.strip() ensures all the whitespace surrounding the name is removed. This is a good thing to always do since many websites use whitespace as a way to visually pad the text inside elements.\nYou\u0026rsquo;ll notice that we can run BeautifulSoup methods right off one of the rows. That\u0026rsquo;s because the rows become their own BeautifulSoup objects when we make a select from another BeautifulSoup object. On the other hand, our name variable is no longer a BeautifulSoup object because we called .text.\nNews source page link We also need the link to this news source\u0026rsquo;s page on AllSides. If we look back at the HTML we\u0026rsquo;ll see that in this case we do want to select the anchor in order to get the href that contains the link, so let\u0026rsquo;s do that:\nallsides_page = row.select_one('.source-title a')['href'] allsides_page = 'https://www.allsides.com' + allsides_page print(allsides_page)  It is a relative path in the HTML, so we prepend the site\u0026rsquo;s URL to make it a link we can request later.\nGetting the link was a bit different than just selecting an element. We had to access an attribute (href) of the element, which is done using brackets, like how we would access a Python dictionary. This will be the same for other attributes of elements, like src in images and videos.\nBias rating  We can see that the rating is displayed as an image so how can we get the rating in words? Looking at the HTML notice the link that surrounds the image has the text we need:\n\u0026lt;td class=\u0026quot;views-field views-field-field-bias-image\u0026quot;\u0026gt; \u0026lt;a href=\u0026quot;/media-bias/left-center\u0026quot;\u0026gt; \u0026lt;img src=\u0026quot;...\u0026quot; width=\u0026quot;144\u0026quot; height=\u0026quot;24\u0026quot; alt=\u0026quot;Political News Media Bias Rating: Lean Left\u0026quot; title=\u0026quot;Political News Media Bias Rating: Lean Left\u0026quot;\u0026gt; \u0026lt;/a\u0026gt; \u0026lt;/td\u0026gt;  We could also pull the alt attribute, but the link looks easier. Let\u0026rsquo;s grab it:\nbias = row.select_one('.views-field-field-bias-image a')['href'] bias = bias.split('/')[-1] print(bias)  Here we selected the anchor tag by using the class name and tag together: .views-field-field-bias-image is the class of the \u0026lt;td\u0026gt; and \u0026lt;a\u0026gt; is for the anchor nested inside.\nAfter that we extract the href just like before, but now we only want the last part of the URL for the name of the bias so we split on slashes and get the last element of that split (left-center).\nCommunity feedback data \nThe last thing to scrape is the agree/disagree ratio from the community feedback area. The HTML of this cell is pretty convoluted due to the styling, but here\u0026rsquo;s the basic structure:\n\u0026lt;td class=\u0026quot;views-field views-field-nothing community-feedback\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;getratingval\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;rate-widget-4 rate-widget clear-block rate-average rate-widget-yesno\u0026quot; id=\u0026quot;rate-node-76-4-1\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;item-list\u0026quot;\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li class=\u0026quot;first\u0026quot;\u0026gt; \u0026lt;a class=\u0026quot;rate-button rate-btn\u0026quot; href=\u0026quot;...\u0026quot; id=\u0026quot;rate-button-3\u0026quot;\u0026gt;agree\u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;last\u0026quot;\u0026gt; \u0026lt;a class=\u0026quot;rate-button rate-btn\u0026quot; href=\u0026quot;...\u0026quot; id=\u0026quot;rate-button-4\u0026quot;\u0026gt;disagree\u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;rate-details\u0026quot;\u0026gt; \u0026lt;span class=\u0026quot;agree\u0026quot;\u0026gt;8241\u0026lt;/span\u0026gt;/\u0026lt;span class=\u0026quot;disagree\u0026quot;\u0026gt;6568\u0026lt;/span\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/td\u0026gt;  The numbers we want are located in two span elements in the last div. Both span elements have classes that are unique in this cell so we can use them to make the selection:\nagree = row.select_one('.agree').text agree = int(agree) disagree = row.select_one('.disagree').text disagree = int(disagree) agree_ratio = agree / disagree print(f\u0026quot;Agree: {agree}, Disagree: {disagree}, Ratio {agree_ratio:.2f}\u0026quot;)  Using .text will return a string, so we need to convert them to integers in order to calculate the ratio.\nSide note: If you\u0026rsquo;ve never seen this way of formatting print statements in Python, the f at the front allows us to insert variables right into the string using curly braces. The :.2f is a way to format floats to only show two decimals places.\nIf you look at the page in your browser you\u0026rsquo;ll notice that they say how much the community is in agreement by using \u0026ldquo;somewhat agree\u0026rdquo;, \u0026ldquo;strongly agree\u0026rdquo;, etc. so how do we get that? If we try to select it:\nprint(row.select_one('.community-feedback-rating-page'))  It shows up as None because this element is rendered with Javascript and requests can\u0026rsquo;t pull HTML rendered with Javascript. We\u0026rsquo;ll be looking at how to get data rendered with JS in a later article, but since this is the only piece of information that\u0026rsquo;s rendered this way we can manually recreate the text.\nTo find the JS files they\u0026rsquo;re using, just CTRL+F for \u0026ldquo;.js\u0026rdquo; in the page source and open the files in a new tab to look for that logic.\nIt turned out the logic was located in the eleventh JS file and they have a function that calculates the text and color with these parameters:\n Range Agreeance   $ratio  3$ absolutely agrees   $2 strongly agrees   $1.5 agrees   $1 somewhat agrees   $ratio = 1$ neutral   $0.67 somewhat disgrees   $0.5 disgrees   $0.33 strongly disagrees   $ratio \\leq 0.33$ absolutely disagrees   Let\u0026rsquo;s make a function that replicates this logic:\ndef get_agreeance_text(ratio): if ratio \u0026gt; 3: return \u0026quot;absolutely agrees\u0026quot; elif 2 \u0026lt; ratio \u0026lt;= 3: return \u0026quot;strongly agrees\u0026quot; elif 1.5 \u0026lt; ratio \u0026lt;= 2: return \u0026quot;agrees\u0026quot; elif 1 \u0026lt; ratio \u0026lt;= 1.5: return \u0026quot;somewhat agrees\u0026quot; elif ratio == 1: return \u0026quot;neutral\u0026quot; elif 0.67 \u0026lt; ratio \u0026lt; 1: return \u0026quot;somewhat disagrees\u0026quot; elif 0.5 \u0026lt; ratio \u0026lt;= 0.67: return \u0026quot;disagrees\u0026quot; elif 0.33 \u0026lt; ratio \u0026lt;= 0.5: return \u0026quot;strongly disagrees\u0026quot; elif ratio \u0026lt;= 0.33: return \u0026quot;absolutely disagrees\u0026quot; else: return None print(get_agreeance_text(2.5))  Now that we have the general logic for a single row and we can generate the agreeance text, let\u0026rsquo;s create a loop that gets data from every row on the first page:\ndata= [] for row in rows: d = dict() d['name'] = row.select_one('.source-title').text.strip() d['allsides_page'] = 'https://www.allsides.com' + row.select_one('.source-title a')['href'] d['bias'] = row.select_one('.views-field-field-bias-image a') ['href'].split('/')[-1] d['agree'] = int(row.select_one('.agree').text) d['disagree'] = int(row.select_one('.disagree').text) d['agree_ratio'] = d['agree'] / d['disagree'] d['agreeance_text'] = get_agreeance_text(d['agree_ratio']) data.append(d)  In the loop we can combine any multi-step extractions into one to create the values in the least number of steps.\nOur data list now contains a dictionary containing key information for every row.\nprint(data[0])  Keep in mind that this is still only the first page. The list on AllSides is three pages long as of this writing, so we need to modify this loop to get the other pages.\nRequesting and parsing multiple pages Notice that the URLs for each page follow a pattern. The first page has no parameters on the URL, but the next pages do; specifically they attach a ?page=# to the URL where \u0026lsquo;#\u0026rsquo; is the page number.\nRight now, the easiest way to get all pages is just to manually make a list of these three pages and loop over them. If we were working on a project with thousands of pages we might build a more automated way of constructing/finding the next URLs, but for now this works.\npages = [ 'https://www.allsides.com/media-bias/media-bias-ratings', 'https://www.allsides.com/media-bias/media-bias-ratings?page=1', 'https://www.allsides.com/media-bias/media-bias-ratings?page=2' ]  According to AllSides\u0026rsquo; robots.txt we need to make sure we wait ten seconds before each request.\nOur loop will:\n request a page parse the page wait ten seconds repeat for next page.   Remember, we\u0026rsquo;ve already tested our parsing above on a page that was cached locally so we know it works. You\u0026rsquo;ll want to make sure to do this before making a loop that performs requests to prevent having to reloop if you forgot to parse something.\nBy combining all the steps we\u0026rsquo;ve done up to this point and adding a loop over pages, here\u0026rsquo;s how it looks:\nfrom time import sleep data= [] for page in pages: r = requests.get(page) soup = BeautifulSoup(r.content, 'html.parser') rows = soup.select('tbody tr') for row in rows: d = dict() d['name'] = row.select_one('.source-title').text.strip() d['allsides_page'] = 'https://www.allsides.com' + row.select_one('.source-title a')['href'] d['bias'] = row.select_one('.views-field-field-bias-image a')['href'].split('/')[-1] d['agree'] = int(row.select_one('.agree').text) d['disagree'] = int(row.select_one('.disagree').text) d['agree_ratio'] = d['agree'] / d['disagree'] d['agreeance_text'] = get_agreeance_text(d['agree_ratio']) data.append(d) sleep(10)  Now we have a list of dictionaries for each row on all three pages.\nTo cap it off, we want to get the real URL to the news source, not just the link to their presence on AllSides. To do this, we will need to get the AllSides page and look for the link.\nIf we go to ABC News\u0026rsquo; page there\u0026rsquo;s a row of external links to Facebook, Twitter, Wikipedia, and the ABC News website. The HTML for that sections looks like this:\n\u0026lt;div class=\u0026quot;row-fluid source-links gray-bg-box\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;container\u0026quot;\u0026gt; \u0026lt;a href=\u0026quot;https://www.facebook.com/ABCNews/\u0026quot; class=\u0026quot;facebook\u0026quot;\u0026gt; \u0026lt;i class=\u0026quot;fa fa-facebook\u0026quot; aria-hidden=\u0026quot;true\u0026quot;\u0026gt;\u0026lt;/i\u0026gt;\u0026lt;span\u0026gt;Facebook\u0026lt;/span\u0026gt; \u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;https://twitter.com/ABC\u0026quot; class=\u0026quot;twitter\u0026quot;\u0026gt; \u0026lt;i class=\u0026quot;fa fa-twitter\u0026quot; aria-hidden=\u0026quot;true\u0026quot;\u0026gt;\u0026lt;/i\u0026gt; \u0026lt;span\u0026gt;Twitter\u0026lt;/span\u0026gt; \u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;https://en.wikipedia.org/wiki/ABC_News\u0026quot; class=\u0026quot;wikipedia\u0026quot;\u0026gt; \u0026lt;i class=\u0026quot;fa fa-wikipedia-w\u0026quot; aria-hidden=\u0026quot;true\u0026quot;\u0026gt;\u0026lt;/i\u0026gt; \u0026lt;span\u0026gt;Wikipedia\u0026lt;/span\u0026gt; \u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;http://abcnews.go.com/\u0026quot; class=\u0026quot;www\u0026quot;\u0026gt;\u0026lt;i class=\u0026quot;fa fa-globe\u0026quot; aria-hidden=\u0026quot;true\u0026quot;\u0026gt; \u0026lt;/i\u0026gt;\u0026lt;span\u0026gt;ABC News\u0026lt;/span\u0026gt; \u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;/contact\u0026quot; class=\u0026quot;improve-this-page\u0026quot;\u0026gt; \u0026lt;i class=\u0026quot;fa fa-line-chart\u0026quot; aria-hidden=\u0026quot;true\u0026quot;\u0026gt;\u0026lt;/i\u0026gt; \u0026lt;span\u0026gt;Improve this page\u0026lt;/span\u0026gt; \u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt;  Notice the anchor tag (\u0026lt;a\u0026gt;) that contains the link to ABC News has a class of \u0026ldquo;www\u0026rdquo;. Pretty easy to get with what we\u0026rsquo;ve already learned:\nwebsite = soup.select_one('.www')['href']  So let\u0026rsquo;s make another loop to request the AllSides page and get links for each news source. Unfortunately, some pages don\u0026rsquo;t have a link in this grey bar to the news source, which brings up a good point: always account for elements to randomly not exist.\nUp until now we\u0026rsquo;ve assumed elements exist in the tables we scraped, but it\u0026rsquo;s always a good idea to program scrapers in way so they don\u0026rsquo;t break when an element goes missing.\nUsing select_one or select will always return None or an empty list if nothing is found, so in this loop we\u0026rsquo;ll check if we found the website element or not so it doesn\u0026rsquo;t throw an Exception when trying to access the href attribute.\nFinally, since there\u0026rsquo;s 265 news source pages and the wait time between pages is 10 seconds, it\u0026rsquo;s going to take ~44 minutes to do this. Instead of blindly not knowing our progress, let\u0026rsquo;s use the tqdm library to give us a nice progress bar:\n!pip install tqdm  from tqdm import tqdm_notebook for d in tqdm_notebook(data): r = requests.get(d['allsides_page']) soup = BeautifulSoup(r.content, 'html.parser') try: website = soup.select_one('.www')['href'] d['website'] = website except TypeError: pass sleep(10)  tqdm is a little weird at first, but essentially tqdm_notebook is just wrapping around our data list to produce a progress bar. We are still able to access each dictionary, d, just as we would normally. Note that tqdm_notebook is only for Jupyter notebooks. In regular editors you\u0026rsquo;ll just import tqdm from tqdm and use tqdm instead.\nSaving our data So what do we have now? At this moment, data is a list of dictionaries, each of which contains all the data from the tables as well as the websites from each individual news source\u0026rsquo;s page on AllSides.\nThe first thing we\u0026rsquo;ll want to do now is save that data to a file so we don\u0026rsquo;t have to make those requests again. We\u0026rsquo;ll be storing the data as JSON since it\u0026rsquo;s already in that form anyway:\nimport json with open('allsides.json', 'w') as f: json.dump(data, f)  To load it back in when you need it:\nwith open('allsides.json', 'r') as f: data = json.load(f)  If you\u0026rsquo;re not familiar with JSON, just quickly open allsides.json in an editor and see what it looks like. It should look almost exactly like what data looks like if we print it in Python: a list of dictionaries.\nBrief Data Analysis Before ending this article I think it would be worthwhile to actually see what\u0026rsquo;s interesting about this data we just retrieved. So, let\u0026rsquo;s answer a couple of questions.\nWhich ratings for outlets does the community absolutely agree on?\nTo find where the community absolutely agrees we can do a simple list comprehension that checks each dict for the agreeance text we want:\nabs_agree = [d for d in data if d['agreeance_text'] == 'absolutely agrees'] print(f\u0026quot;{'Outlet':\u0026lt;20} {'Bias':\u0026lt;20}\u0026quot;) print(\u0026quot;-\u0026quot; * 30) for d in abs_agree: print(f\u0026quot;{d['name']:\u0026lt;20} {d['bias']:\u0026lt;20}\u0026quot;)  Using some string formatting we can make it look somewhat tabular. Interestingly, C-SPAN is the only center bias that the community absolutely agrees on. The others for left and right aren\u0026rsquo;t that surprising.\nMaking analysis easier with Pandas Which ratings for outlets does the community absolutely disagree on?\nTo make analysis a little easier, we can also load our JSON data into a Pandas DataFrame as well. This is easy with Pandas since they have a simple function for reading JSON into a DataFrame.\nAs an aside, if you\u0026rsquo;ve never used Pandas, Matplotlib, or any of the other data science libraries, I would definitely recommend checking out [Jose Portilla\u0026rsquo;s data science course]() for a great intro to these tools and many machine learning concepts.\nNow to the DataFrame:\nimport pandas as pd df = pd.read_json(open('allsides.json', 'r')) df.set_index('name', inplace=True) df.head()  Now filter the DataFrame by \u0026ldquo;agreeance_text\u0026rdquo;:\ndf[df['agreeance_text'] == 'strongly disagrees']  It looks like much of the community disagrees strongly with certain outlets being rated with a \u0026ldquo;center\u0026rdquo; bias.\nLet\u0026rsquo;s make a quick visualization of agreeance. Since there\u0026rsquo;s too many news sources to plot so let\u0026rsquo;s pull only those with the most votes. To do that, we can make a new column that counts the total votes and then sort by that value:\ndf['total_votes'] = df['agree'] + df['disagree'] df.sort_values('total_votes', ascending=False, inplace=True) df.head(10)  Visualizing the data To make a bar plot we\u0026rsquo;ll use Matplotlib with Seaborn\u0026rsquo;s dark grid style:\nimport matplotlib.pyplot as plt plt.style.use('seaborn-darkgrid')  As mentioned above, we have too many news outlets to plot comfortably, so just make a copy of the top 25 and place it in a new df2 variable:\ndf2 = df.head(25).copy() df2.head()  With the top 25 news sources by amount of feedback, let\u0026rsquo;s create a stacked bar chart where the number of agrees are stacked on top of the number of disagrees. This makes the total height of the bar the total amount of feedback.\nBelow, we first create a figure and axes, plot the agree bars, plot the disagree bars on top of the agrees using bottom, then set various text features:\nfig, ax = plt.subplots(figsize=(20, 10)) ax.bar(df2.index, df2['agree'], color='#5DAF83') ax.bar(df2.index, df2['disagree'], bottom=df2['agree'], color='#AF3B3B') ax.set_ylabel = 'Total feedback' plt.yticks(fontsize='x-large') plt.xticks(rotation=60, ha='right', fontsize='x-large', rotation_mode='anchor') plt.title('AllSides Bias Rating vs. Community Feedback', fontsize='xx-large') plt.show()  For a slightly more complex version, let\u0026rsquo;s make a subplot for each bias and plot the respective news sources.\nThis time we\u0026rsquo;ll make a new copy of the original DataFrame beforehand since we can plot more news outlets now.\nInstead of making one axes, we\u0026rsquo;ll create a new one for each bias to make six total subplots:\ndf3 = df.copy() fig = plt.figure(figsize=(15,15)) biases = df3['bias'].unique() for i, bias in enumerate(biases): # Get top 10 news sources for this bias and sort index alphabetically temp_df = df3[df3['bias'] == bias].iloc[:10] temp_df.sort_index(inplace=True) # Get max votes, i.e. the y value for tallest bar in this temp dataframe max_votes = temp_df['total_votes'].max() # Add a new subplot in the correct grid position ax = fig.add_subplot(len(biases) / 2, 2, i + 1) # Create the stacked bars ax.bar(temp_df.index, temp_df['agree'], color='#5DAF83') ax.bar(temp_df.index, temp_df['disagree'], bottom=temp_df['agree'], color='#AF3B3B') # Place text for the ratio on top of each bar for x, y, ratio in zip(ax.get_xticks(), temp_df['total_votes'], temp_df['agree_ratio']): ax.text(x, y + (0.02 * max_votes), f\u0026quot;{ratio:.2f}\u0026quot;, ha='center') ax.set_ylabel('Total feedback') ax.set_title(bias.title()) # Make y limit larger to compensate for text on bars ax.set_ylim(0, max_votes + (0.12 * max_votes)) # Rotate tick labels so they don't overlap plt.setp(ax.get_xticklabels(), rotation=30, ha='right') plt.tight_layout(w_pad=3.0, h_pad=1.0) plt.show()  Hopefully the comments help with how these plots were created. We\u0026rsquo;re just looping through each unique bias and adding a subplot to the figure.\nWhen interpreting these plots keep in mind that the y-axis has different scales for each subplot. Overall it\u0026rsquo;s a nice way to see which outlets have a lot of votes and where the most disagreement is. This is what makes scraping so much fun!\nFinal words We have the tools to make some fairly complex web scrapers now, but there\u0026rsquo;s still the issue with Javascript rendering. This is something that deserves its own article, but for now we can do quite a lot.\nThere\u0026rsquo;s also some project organization that needs to occur when making this into a more easily runnable program. We need to pull it out of this notebook and code in command-line arguments if we plan to run it often for updates.\nThese sorts of things will be addressed later when we build more complex scrapers, but feel free to let me know in the comments of anything in particular you\u0026rsquo;re interested in learning about.\n"});index.add({'id':237,'href':'/library/tutorials/docs/python/snippets/reverse_string/','title':"reverse_string",'content':"Returns the reverse of a string.\nUse string slicing to reverse the string.\ndef reverse_string(s): return s[::-1]  reverse_string(\u0026quot;snippet\u0026quot;) #\u0026quot;teppins\u0026quot;  "});index.add({'id':238,'href':'/library/tutorials/docs/python/snippets/sample/','title':"sample",'content':"Returns a random element from a list.\nUse random.randint() to generate a random number that corresponds to an index in the list, return the element at that index.\nrandom.sample() provides similar functionality to this snippet.\nfrom random import randint def sample(lst): return lst[randint(0, len(lst) - 1)]  sample([3, 7, 9, 11]) # 9  "});index.add({'id':239,'href':'/library/tutorials/docs/python/snippets/shuffle/','title':"shuffle",'content':"Randomizes the order of the values of an list, returning a new list.\nUses the Fisher-Yates algorithm to reorder the elements of the list.\nrandom.shuffle provides similar functionality to this snippet.\nfrom copy import deepcopy from random import randint def shuffle(lst): temp_lst = deepcopy(lst) m = len(temp_lst) while (m): m -= 1 i = randint(0, m) temp_lst[m], temp_lst[i] = temp_lst[i], temp_lst[m] return temp_lst  foo = [1,2,3] shuffle(foo) # [2,3,1], foo = [1,2,3]  "});index.add({'id':240,'href':'/library/tutorials/docs/python/snippets/similarity/','title':"similarity",'content':"Returns a list of elements that exist in both lists.\nUse list comprehension on a to only keep values contained in both lists.\ndef similarity(a, b): return [item for item in a if item in b]  similarity([1, 2, 3], [1, 2, 4]) # [1, 2]  "});index.add({'id':241,'href':'/library/tutorials/docs/python/snippets/snake/','title':"snake",'content':"Converts a string to snake case.\nBreak the string into words and combine them adding _ as a separator, using a regexp.\nfrom re import sub def snake(s): return '_'.join( sub('([A-Z][a-z]+)', r' \\1', sub('([A-Z]+)', r' \\1', s.replace('-', ' '))).split()).lower()  snake('camelCase') # 'camel_case' snake('some text') # 'some_text' snake('some-mixed_string With spaces_underscores-and-hyphens') # 'some_mixed_string_with_spaces_underscores_and_hyphens' snake('AllThe-small Things') # \u0026quot;all_the_small_things\u0026quot;  "});index.add({'id':242,'href':'/library/tutorials/docs/python/snippets/some/','title':"some",'content':"Returns True if the provided function returns True for at least one element in the list, False otherwise.\nUse any() in combination with map() and fn to check if fn returns True for any element in the list.\ndef some(lst, fn=lambda x: x): return any(map(fn, lst))  some([0, 1, 2, 0], lambda x: x \u0026gt;= 2 ) # True some([0, 0, 1, 0]) # True  "});index.add({'id':243,'href':'/library/tutorials/docs/python/snippets/split_lines/','title':"split_lines",'content':"Splits a multiline string into a list of lines.\nUse s.split() and '\\n' to match line breaks and create a list.\nstr.splitlines() provides similar functionality to this snippet.\ndef split_lines(s): return s.split('\\n')  split_lines('This\\nis a\\nmultiline\\nstring.\\n') # ['This', 'is a', 'multiline', 'string.' , '']  "});index.add({'id':244,'href':'/library/tutorials/docs/python/snippets/spread/','title':"spread",'content':"Flattens a list, by spreading its elements into a new list.\nLoop over elements, use list.extend() if the element is a list, list.append() otherwise.\ndef spread(arg): ret = [] for i in arg: ret.extend(i) if isinstance(i, list) else ret.append(i) return ret  spread([1, 2, 3, [4, 5, 6], [7], 8, 9]) # [1, 2, 3, 4, 5, 6, 7, 8, 9]  "});index.add({'id':245,'href':'/library/tutorials/docs/articles/webapp/django/django-rest-framework/','title':"Start Django RestFramework",'content':" เริ่มต้นใช้งาน Django RestFramework ปัจจุบันการพัฒนาเวปไซด์จะแยกการพัฒนาออกเป็น FrontEnd (เช่น React, Angular, Vue) และ BackEnd ( เช่น Django ) ซึ่งสิ่งที่ใช้เป็นสื่อกลางในการแลกเปลี่ยนข้อมูลกันระหว่าง FrontEnd และ BackEnd คือ Rest API นั่นเอง ในบทความนี้จะเป็นการอธิบายการสร้าง BackEnd ให้รองรับ Rest API ด้วย Django โดยได้มีการเลือกใช้ Library ชื่อ Django Rest framework เพื่อช่วยให้การพัฒนา REST API ทำได้อย่างง่ายดายและรวดเร็ว\nสิ่งที่ต้องเตรียม  Python 3.7 ความรู้ด้านการเขียน Django ขั้นพื้นฐาน ( สร้าง model และเขียน view ได้ ) ติดตั้ง package พื้นฐานด้วยคำสั่งต่อไปนี้\n$ pip install -r requirements.txt  ทำความรู้จักกับ REST API REST API คือข้อกำหนดที่ใช้ในการแลกเปลี่ยนข้อมูลระหว่าง FrontEnd และ BackEnd โดยทั่วไปข้อกำหนดนี้จะถูกใช้งานอยู่บน HTTP Protocol\nHTTP Protocol คือ message ที่ใช้รับและส่งกันระหว่าง web browser (FrontEnd) กับ Web Server (Backend/Django) ซึ่งลักษณะของ HTTP Request จะอยู่ในรูปแบบของ text message ที่สามารถแบ่งชิ้นส่วนออกมาได้ตามรูปต่อไปนี้\n ส่วน Request Line ใช้สำหรับบอกว่า HTTP message นี้ใช้ทำอะไร ซึ่งส่วนสำคัญคือส่วนที่อยู่ด้านหน้าสุดของบรรทัดที่เรียกว่า HTTP Method ซึ่งจากรูปจะเป็น HTTP Method “POST” โดยข้อตกลง REST API จะแบ่ง HTTP Method ออกเป็น\n1.1 GET หมายถึง HTTP Message นี้ต้องการดึงข้อมูลบางอย่างจาก server\n1.2 POST หมายถึง HTTP Message นี้ต้องการสร้างข้อมูล (Create) ขึ้นมาใหม่บน server\n1.3 PUT หมายถึง​ HTTP Message นี้ต้องการแก้ไข (Update)ข้อมูลบน server\n1.4 PATCH หมายถึง HTTP Message นี้ต้องการแก้ไขข้อมูลบางส่วน (Partial Update) บน server\n1.5 DELETE หมายถึง HTTP Message นี้ต้องการลบข้อมูลบน server ส่วน HTTP Header เป็นส่วนที่ใช้ระบุรายละเอียดของ HTTP message นี้ เช่น ชนิดของ browser ที่ส่งข้อมูลมา, ระบุ Token สำหรับยืนยันตัวตนของผู้ใช้งาน, ชนิดข้อมูลของ Body มี format แบบไหน, ความยาวของ Body มีจำนวนกี่ตัวอักษร เป็นต้น ส่วนของ HTTP Body เป็นข้อมูลที่รับและส่งกับ web server โดยปกติแล้ว REST API จะใช้มาตรฐาน JSON (Javascript Object Notation) ในการแลกเปลี่ยนข้อมูล  ดังน้ันโดยสรุปแล้วหน้าที่ของ Django ในการจัดการ REST API คือรอรับ HTTP Message จาก Browser (FrontEnd Client) แล้วตีความว่า client ต้องการทำอะไร กับข้อมูลที่เก็บอยู่ใน database แล้วสร้าง JSON message เพื่อตอบกลับ client ให้ถูกต้องนั่นเอง\nเริ่มต้น Checkout Tutorial Project เพื่อความรวดเร็วในบทเรียน จะอ้างอิง code ที่ checkout มาจาก\nhttps://github.com/WasinTh/rest_tutorial\nซึ่ง project นี้เก็บข้อมูลของ Author และ Book และมี REST API เพื่อใช้จัดการกับข้อมูลของ Author และ Book\nภาพตัวอย่างฐานข้อมูลที่ใช้ในการทดลองครั้งนี้\nโครงสร้างไฟล์ของ project มีดังต่อไปนี้\n db.sqlite3 คือไฟล์ database ที่เก็บข้อมูลของ Author และ Book manage.py เป็นไฟล์สำหรับรัน Django project rest_tutorial โฟลเดอร์ใช้สำหรับเก็บ urls.py และ settings.py ของ project library โฟลเดอร์ application ที่จะใช้ในบทความนี้\n4.1 sample_1 เป็นตัวอย่าง code การสร้าง REST API โดยไม่ใช้ framework\n4.2 sample_2 เป็นตัวอย่าง code การใช้งาน serializer ของ Django Rest framework\n4.3 sample_3 เป็นตัวอย่าง code การใช้งาน Generics API View\n4.4 sample_4 เป็นตัวอย่าง code การใช้งาน ViewSets และ Router  การสร้าง REST API โดยไม่ใช้ Framework (Sample_1) จากไฟล์ตัวอย่าง sample_1/views.py แสดงให้เห็นถึงการใช้ Django เพื่อ Query ข้อมูลจากฐานข้อมูลออกมาแล้ว Return กลับไปยัง client ในรูปแบบของ JSON\n class AuthorList ทำหน้าที่รับ HTTP GET จาก client และ Query Author object ทั้งหมดออกมาจากนั้น สร้าง list ของ dictionary ขึ้นมา 1 ตัวชื่อ response เพื่อเก็บข้อมูล id และ name ของ Author จากนั้นจึงใช้คำสั่ง json.dumps (ซึ่งเป็น build in library ของ Python) ในการแปลง list object ให้กลายเป็น JSON Array เพื่อตอบกลับไปยัง client class AuthorDetail ทำหน้าที่รับ HTTP GET จาก client พร้อมทั้งรับ url parameter 1 ตัวชื่อ ID เพื่อใช้สำหรับดึงข้อมูล Author คนที่ต้องการ ซึ่งมีการเรียกใช้ get_object_or_404 ที่เป็นคำสั่งพิเศษของ Django เพื่อตอบกลับ 404 not found ไปโดยอัตโนมัติ เมื่อผู้ใช้งานใส่ ID ที่ไม่มีอยู่จริงในระบบ class BookDetail และ BookList ทำหน้าที่เช่นเดียวกันกับของ Author แต่เปลี่ยน object เป็น Book  ตัวอย่างผลการรัน Code เป็นดังต่อไปนี้\nตัวอย่างการรัน Class AuthorList\nตัวอย่างการรัน Class AuthorDetail\nตัวอย่างการรัน Class BookList\nตัวอย่างการรัน Class BookDetail\nจากตัวอย่างข้างต้นจะเห็นว่าการรอรับ HTTP Request ในทุกๆ method (GET, POST, PUT, PATCH, DELETE) และสร้าง JSON Response กลับไปนั้น เป็นเรื่องที่ใช้แรงงานสูงมาก และ code ที่เขียนก็จะซ้ำๆกันเป็นส่วนมาก ดังนั้นจึงเป็นที่มาของการนำ Django Rest framework มาใช้งาน\nการติดตั้ง Django Rest framework ติดตั้งโดยใช้คำสั่ง pip ดังต่อไปนี้\nจากนั้นแก้ไขไฟล์ rest_tutorial/settings.py โดยเพิ่ม “rest_framework” เข้าไปใน INSTALLED_APP\nIntroduction to Serializer (Sample_2) Serializer คือตัวกลางที่ทำหน้าที่ในการแปลง Django model object ให้กลายเป็น JSON โดยการทำงานของ Serializer จะทำหน้าที่ใน 2 กรณีคือ\n การแปลงค่าที่ query ออกมาจากฐานข้อมูลให้กลายเป็น JSON เพื่อเตรียมส่งกลับไปยัง Client (มักจะใช้กับ HTTP GET method)\nการใช้งานรูปแบบนี้ เราสามารถ new object ของ Serializer ที่ต้องการ แล้วส่ง Django model object เข้าไปเป็น parameter ได้ทันที จากนั้นเมื่อต้องการ JSON สามารถเรียก Serializer.data ได้ เช่น\nauthor_serializer = AuthorSerializer(Author.objects.first()) author_json = author_serializer.data  การแปลงค่า JSON ที่รับมาจาก client แล้วแปลงกลับมาเป็น Django object เพื่อเตรียม save ลงฐานข้อมูล (มักใช้กับ HTTP POST, PUT, PATCH method)\nการใช้งานรูปแบบนี้จะเป็นการสร้าง object ของ serializer โดยการส่ง json ผ่านตัวแปรชื่อ data จากนั้นสามารถเรียกใช้ serializer.is_valid() เพื่อตรวจสอบความถูกต้องของ JSON หรือเรียกใช้ serializer.save() เพื่อบันทึกข้อมูลได้\nauthor_serializer = AuthorSerializer(data=request_json) if author_serializer.is_valid(): author_serializer.save()  จาก Project ตัวอย่างให้ดูในโฟลเดอร์ sample_2\n  ตัวอย่างการประกาศ Serializer โดยใช้ไฟล์ sample_2/serializers.py\nการประกาศ Serializer อย่างง่ายที่สุดคือการใช้งาน ModelSerializer โดยมีวิธีการสร้างดังต่อไปนี้\n สร้าง class ที่สืบทอด rest_framework.serializers.ModelSerializer ประกาศ class Meta พร้อมระบุข้อมูลที่จำเป็น 2 อย่างได้แก่\n2.1 model เป็นการระบุ Model Class ที่เราต้องการจะทำ serializ\n2.2 fields คือการระบุ field ที่ต้องการ  จากตัวอย่างใน class AuthorSerializer มีการประกาศตัวแปรใหม่ชื่อ book_count ที่จะใช้นับจำนวน Book ทั้งหมดของ Author คนนี้ ( การใช้ reverse relationship ใน Django อ่านเพิ่มเติมได้ ที่นี่ ) ซึ่งจะเห็นว่าสามารถเพิ่ม field ใหม่เข้าไปใน JSON response ได้อย่างง่ายดาย\nการนำ Serializer มาใช้งานใน sample_2/views.py\nจากภาพด้านบนเป็นตัวอย่างการนำ Serializer มาใช้งานร่วมกับ View ที่เราได้เคยสร้างไว้ก่อนหน้านี้ จะเห็นว่า code สั้นลงและเป็นระเบียบอย่างชัดเจน\nสามารถรัน code ตัวอย่างนี้ได้โดยการเข้าไปที่ URL ดังต่อไปนี้\nhttp://localhost:8000/library/sample_2/author\nhttp://localhost:8000/library/sample_2/author/1\nhttp://localhost:8000/library/sample_2/book\nhttp://localhost:8000/library/sample_2/book/1\nการใช้งาน GenericAPIView (Sample_3) Django Rest framework สามารถนำมาใช้ใน View เพื่อลดการเขียน code ที่ซ้ำซ้อนออกไปจาก View และ Django Rest framework จะสร้าง GUI สำหรับให้ผู้ใช้งานทดสอบ REST API โดยอัตโนมัติอีกด้วย\nซึ่งการนำ Django Rest framework มาใช้งานใน View นี้มีได้หลายวิธีด้วยกัน แต่เพื่อให้กระชับในหัวข้อนี้จะกล่าวถึงการใช้ Generics APIView ซึ่งเมื่อนำมาใช้ร่วมกับ serializer ที่เขียนไว้ก่อนหน้าจะทำให้สร้าง REST API ได้อย่างง่ายมากขึ้น\nการใช้งาน Generics APIView ทำได้โดยขั้นตอนดังต่อไปนี้\n แก้ไข class ใน view ที่ต้องการให้เปลี่ยนมาสืบทอด generics.XXXView\nโดย generics ได้แบ่ง API ออกเป็นกลุ่มใหญ่ๆ 2 กลุ่มคือ\n1.1 กลุ่มของ API ที่ไม่จำเป็นต้องระบุ ID ของ object ซึ่ง API กลุ่มนี้ได้แก่การทำ GET (เพื่อ list ข้อมูลทั้งหมด) และการทำ POST (เพื่อสร้าง/create object ใหม่ขึ้นในฐานข้อมูล) โดยใช้งานผ่าน generics.ListAPIView, CreateAPIView, ListCreateAPIView\n1.2 กลุ่มของ API ที่ต้องระบุ ID ของ object ซึ่ง API กลุ่มนี้ได้แก่การทำ GET (กรณีต้องการ detail ของ object เพียงตัวเดียว), PUT, PATCH, DELETE โดยจะใช้งานผ่าน generics.RetrieveAPIView (GET), UpdateAPIView (PUT), DestroyAPIView (Delete) ประกาศตัวแปรชื่อ queryset ซึ่งจะเป็นวิธีการระบุถึง Object ที่เราจะใช้ในการ query ออกมา ซึ่งโดยปกติจะใช้ Model.objects.all() แต่อาจมีบางกรณีที่ต้องการ filter object โดยเฉพาะ เช่น Model.objects.filter(is_active=True) เป็นต้น ประกาศตัวแปรชื่อ serializer_class ซึ่งเป็น Class Serializer ตัวเดียวกับที่ประกาศไว้ก่อนหน้า เพื่อบอกว่า View นี้จะใช้ Serializer ใดในการแปลง Django Model Object ไปอยู่ในรูปแบบของ JSON เพิ่มเติมกรณีเลือกใช้ GenericsAPI ในกลุ่มที่ต้องระบุ ID จะต้องเพิ่ม ตัวแปรชื่อ lookup_field และระบุ String ของชื่อ field ที่ต้องการนำ URL Parameter ไปค้นหาโดยชื่อของ lookup_field นี้ต้องเป็นชื่อที่ตรงกันทั้งชื่อของ model field และ url parameter field (หากไม่ระบุ lookup_field ต้องกำหนดชื่อตัวแปร URL Parameter ใน urls.py ให้เป็นชื่อ “pk” ซึ่งจะ map กับ id ของ object เท่านั้น)  จาก Project ตัวอย่างดูในโฟลเดอร์ sample_3\nตัวอย่าง urls ของไฟล์ sample_3/urls.py\nตัวอย่างการนำ Generics APIView มาใช้งานใน sample_3/views.py\nจากรูปตัวอย่างจะเห็นว่ามีการแก้ไข code ให้สั้นลง และ code ดังกล่าวยังครอบคลุม REST API ในเกือบทุก Method อีกด้วย\n AuthorList ใช้ในการแสดง author ทั้งหมดออกมา โดยสืบทอด generics.ListCreateAPIView เพื่อให้รองรับ GET และ POST API AuthorDetail ใช้ในการแสดงรายละเอียดของ author ที่ต้องการออกมา โดยหากดูใน urls.py จะเห็นว่ามีการใช้ URL Parameter ชื่อ id และประกาศ lookup_field เป็น id BookDetail มีการเรียกใช้ method ชื่อ get_queryset() แทนการประกาศตัวแปร queryset ธรรมดา กรณีนี้จะถูกใช้เมื่อมี logic ในการ query object ที่ต้องการที่ค่อนข้างซับซ้อน และในไฟล์ urls.py ได้มีการระบุค่า URL Parameter เป็น “pk” ซึ่งเป็นค่า default ของ Django Rest framework จึงไม่จำเป็นต้องระบุ lookup_field ใน class นี้  สามารถรัน code ตัวอย่างนี้ได้โดยการเข้าไปที่ URL ดังต่อไปนี้\nhttp://localhost:8000/library/sample_3/author\nhttp://localhost:8000/library/sample_3/author/1\nhttp://localhost:8000/library/sample_3/book\nhttp://localhost:8000/library/sample_3/book/1\nตัวอย่างการเรียกใช้งาน URL sample_3/author\nการใช้งาน Viewsets และ Router (Sample_4) Django Rest framework ยังอำนวยความสะดวกให้กับการสร้าง Rest API กรณีที่ API สะท้อนถึงข้อมูลในฐานข้อมูลตรง ๆ โดยผ่านการใช้งาน Viewsets\nViewsets ที่นำมาใช้งานในบทความนี้จะประกอบไปด้วย ModelViewSet คือ การระบุว่า Model ที่ระบุถึงนี้สามารถใช้งานได้ทั้ง GET, POST, PUT, PATCH, DELETE ส่วน ReadOnlyModelViewSet คือการระบุว่า Model นี้สามารถใช้งานได้ผ่านทาง GET สำหรับ list และ detail เท่านั้น\nRouter ถูกนำมาใช้ใน urls.py เพื่อช่วยลด code ที่ต้องเขียนซ้ำๆในการประกาศ URL ไปยัง View ต่าง ๆ\nการประกาศ URL โดยใช้ router ของ sample_4/urls.py\nการนำ Viewsets มาใช้ใน sample_4/views.py\nสามารถรัน code ตัวอย่างนี้ได้โดยการเข้าไปที่ URL ดังต่อไปนี้\nhttp://localhost:8000/library/sample_4/author\nhttp://localhost:8000/library/sample_4/author/1\nhttp://localhost:8000/library/sample_4/book\nhttp://localhost:8000/library/sample_4/book/1\nREST API Documentation Django Rest framework ยังช่วยทำ Document ให้โดยอัตโนมัติอีกด้วย โดยวิธีการคือแก้ไขไฟล์ rest_tutorial/urls.py โดยเพิ่ม URL ของ rest_framework.documentation.include_docs_urls ลงไป\nและเพิ่มบรรทัดในไฟล์ settings.py ให้ถูกต้องตามรูปต่อไปนี้\nrest_tutorial/urls.py\nsettings.py\nจากนั้นสามารถเข้าดู document ได้ที่ URL\nhttp://localhost:8000/docs/\nตัวอย่างหน้าจอ Document ที่ Generate ออกมา\nนอกจากนี้ Django Rest framework ยังสามารถสร้าง document ใน format อื่น ๆ ได้ผ่านทาง third party library ต่าง ๆ รายละเอียดเพิ่มเติมอ่านได้ ที่นี่\nส่งท้าย Django Rest framework เป็น framework ที่มีขนาดใหญ่และมีรายละเอียดเยอะมาก ตัวอย่างที่ยกมาอธิบายในบทความนี้เป็นเพียงแค่ส่วนหนึ่งในการเรียกใช้งาน เพื่อให้เห็นภาพรวมของการนำ Django Rest framework มาใช้งาน รายละเอียดทั้งหมดสามารถอ่านต่อได้ ที่นี่ ครับ\n Written with StackEdit.\n "});index.add({'id':246,'href':'/library/tutorials/docs/articles/data-science/finance/stock-portfolio-analyses-1/','title':"Stock Portfolio Analyses",'content':" Python for Finance: Stock Portfolio Analyses  Written with StackEdit.\n My two most recent blog posts were about Scaling Analytical Insights with Python; part 1 can be found here and part 2 can be found here. It has been several months since I wrote those, largely due to the fact that I relocated my family to Seattle to join Amazon in November; I’ve spent most of the time on my primary project determining our global rollout plan and related business intelligence roadmap.\nPrior to my departure at my former company, FloSports, we were in the process of overhauling our analytics reporting across the organization (data, marketing, product et al), and part of this overhaul included our financial reporting. While I left early on in that implementation, over the past several months I’ve continued using Python extensively for financial analyses, particularly pandas. In this post, I will share how I leveraged some very helpful online resources, the Yahoo Finance API (requires a work around and may require a future data source replacement), and Jupyter notebook to largely automate the tracking and benchmarking of a stock portfolio’s performance.\nOverview of PME and benchmarking individual stock performance As a quick background, I have been investing in my own stock portfolio since 2002 and developed a financial model for my portfolio a number of years ago. For years, I would download historical prices and load the data into the financial model — while online brokers calculate realized and unrealized returns, as well as income and dividends, I like to have historical data in the model as I conduct my own analyses to evaluate positions. One view / report which I’ve never found from online brokers and services is a “Public Market Equivalent”-like analysis. In short, the Public Market Equivalent (PME) is a set of analyses used in the private equity industry to compare the performance of a private equity fund relative to an industry benchmark. Much more detail here.\nRelated, the vast majority of equity portfolio managers are unable to select a portfolio of stocks which outperforms the broader market, e.g., S\u0026amp;P 500, over the long-term (~1 in 20 actively managed domestic funds beat index funds). Even when some individual stocks outperform, the underperformance of others often outweighs the better performing stocks, meaning overall an investor is worse off than simply investing in an index fund. During business school I learned about PME, and I incorporated a conceptually similar analysis into the evaluation of my current public equity holdings. To do this properly, you should measure the timing of investment inflows specific to each portfolio position (holding periods) relative to an S\u0026amp;P 500 equivalent dollar investment over the identical holding period. As an example, if you bought a stock on 6/1/2016 and you still own it, you would want to compare the stock’s return over that period to the return of an equal dollar investment on 6/1/2016 in the S\u0026amp;P 500 (our benchmark example). Among other things, you may find that even if a stock has done relatively well it may still trail the S\u0026amp;P 500’s return over the same time period.\nIn the past, I downloaded historical price data from Yahoo Finance and used INDEX and MATCH functions in excel to calculate the relative holding period performance of each position versus the S\u0026amp;P 500. While this is an OK way to accomplish this goal, conducting the same using pandas in Jupyter notebook is more scalable and extensible. Whenever you download new data and load into excel, you inevitably need to modify some formulas and validate for errors. Using pandas, adding new calculations, such as a cumulative ROI multiple (which I’ll cover), takes almost no time to implement. And the visualizations, for which I use Plotly, are highly reproducible and much more useful in generating insights.\nDisclosure: Nothing in this post should be considered investment advice. Past performance is not necessarily indicative of future returns. These are general examples about how to import data using pandas for a small sample of stocks across different time intervals and to benchmark their individual performance against an index. You should direct all investment related questions that you have to your financial advisor.\nIn addition to contributing this tutorial, I’m continuing to revise and build upon this approach, and I outline some considerations for further development at the end of this post. I believe this post will be helpful for novice to intermediate-level data science oriented finance professionals, especially since this should extend to many other types of financial analyses. This approach is “PME-like” in the sense that’s it’s measuring investment inflows over equal holding periods. As public market investments are much more liquid than private equity, and presuming you follow a trailing stop approach, from my perspective it’s more important to focus on active holdings — it’s generally advisable to divest holdings which underperform a benchmark or which you no longer want to own for various reasons, while I take a long-term view and am happy to own outperforming stocks for as long as they’ll have me.\nResources:\n I am a current DataCamp subscriber (future post forthcoming on DataCamp) and this community tutorial on Python for Finance is great. I have created a repo for this post including the Python notebook here, and the excel file here. If you want to see the full interactive version (because Jupyter \u0026lt;←\u0026gt;\u0026gt; GitHub integration is awesome), you can view using nbviewer here.  Outline of what we want to accomplish:\n Import S\u0026amp;P 500 and sample ticker data, using the Yahoo Finance API Create a merged portfolio ‘master’ file which combines the sample portfolio dataframe with the historical ticker and historical S\u0026amp;P 500 data Determine what the S\u0026amp;P 500 close was on the date of acquisition of each investment, which allows us to calculate the S\u0026amp;P 500 equivalent share position with the same dollars invested Calculate the relative % and dollar value returns for the portfolio positions versus S\u0026amp;P 500 returns over that time Calculate cumulative portfolio returns and ROI multiple, in order to assess how well this example portfolio compared to a market index One of the more important items: dynamically calculate how each position is doing relative to a trailing stop, e.g., if a position closes 25% below its closing high, consider selling the position on the next trading day. Visualizations Total Return Comparisons — % return of each position relative to index benchmark Cumulative Returns Over Time — $ Gain / (Loss) of each position relative to benchmark Cumulative Investments Over Time — given the above, how do the overall investment returns compare to the equal weighting and time period of S\u0026amp;P 500 investments? Adjusted Close % off of High Comparison — what is each position’s most recent close relative to its adjusted closing high since purchased?  Investment Portfolio Python Notebook Data Import and Dataframe Manipulation You will begin by importing the necessary Python libraries, import the Plotly offline module, and read in our sample portfolio dataframe.\n# Import initial libraries import pandas as pd import numpy as np import datetime import matplotlib.pyplot as plt import plotly.graph_objs as go %matplotlib inline # Imports in order to be able to use Plotly offline. from plotly import __version__ from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot print(__version__) # requires version \u0026gt;= 1.9.0 init_notebook_mode(connected=True) # Import the Sample worksheet with acquisition dates and initial cost basis: portfolio_df = pd.read_excel('Sample stocks acquisition dates_costs.xlsx', sheetname='Sample') portfolio_df.head(10)  Now that you have read in the sample portfolio file, you’ll create a few variables which capture the date ranges for the S\u0026amp;P 500 and all of the portfolio’s tickers. Note that this is one of the few aspects of this notebook which requires an update each week (adjust the date range to include the most recent trading week — here, we are running this off of prices through 3/9/2018).\n# Date Ranges for SP 500 and for all tickers # Modify these date ranges each week. # The below will pull back stock prices from the start date until end date specified. start_sp = datetime.datetime(2013, 1, 1) end_sp = datetime.datetime(2018, 3, 9) # This variable is used for YTD performance. end_of_last_year = datetime.datetime(2017, 12, 29) # These are separate if for some reason want different date range than SP. stocks_start = datetime.datetime(2013, 1, 1) stocks_end = datetime.datetime(2018, 3, 9)  As mentioned in the Python Finance training post, the pandas-datareader package enables us to read in data from sources like Google, Yahoo! Finance and the World Bank. Here I’ll focus on Yahoo! Finance, although I’ve worked very preliminarily with Quantopian and have also begun looking into quandl as a data source. As also mentioned in the DataCamp post, the Yahoo API endpoint recently changed and this requires the installation of a temporary fix in order for Yahoo! Finance to work. I’ve made this needed slight adjustment in the code below. I have noticed some minor data issues where the data does not always read in as expected, or the last trading day is sometimes missing. While these issues have been relatively infrequent, I’m continuing to monitor whether or not Yahoo! Finance will be the best and most reliable data source going forward.\n# Leveraged from the helpful Datacamp Python Finance trading blog post. from pandas_datareader import data as pdr import fix_yahoo_finance as yf yf.pdr_override() # \u0026lt;== that's all it takes :-) sp500 = pdr.get_data_yahoo('^GSPC', start_sp, end_sp) sp500.head()  If you’re following along with your own notebook, you should see something like the below once you’ve successfully read in the data from Yahoo’s API:\nAfter loading in the S\u0026amp;P 500 data, you’ll see that I inspect the head and tail of the dataframe, as well as condense the dataframe to only include the Adj Close column. The difference between the Adjusted Close and the Close columns is that an adjusted close reflects dividends (see future areas for development below). When a company issues a dividend, the share price is reduced by the size of the dividend per share, as the company is distributing a portion of the company’s earnings. For purposes of this analysis, you will only need to analyze this column. I also create a dataframe which only includes the S\u0026amp;P’s adjusted close on the last day of 2017 (start of 2018); this is in order to run YTD comparisons of individual tickers relative to the S\u0026amp;P 500’s performance.\nIn the below code, you create an array of all of the tickers in our sample portfolio dataframe. You then write a function to read in all of the tickers and their relevant data into a new dataframe, which is essentially the same approach you took for the S\u0026amp;P500 but applied to all of the portfolio’s tickers.\n# Generate a dynamic list of tickers to pull from Yahoo Finance API based on the imported file with tickers. tickers = portfolio_df['Ticker'].unique() tickers # Stock comparison code def get(tickers, startdate, enddate): def data(ticker): return (pdr.get_data_yahoo(ticker, start=startdate, end=enddate)) datas = map(data, tickers) return(pd.concat(datas, keys=tickers, names=['Ticker', 'Date'])) all_data = get(tickers, stocks_start, stocks_end)  As with the S\u0026amp;P 500 dataframe, you’ll create an adj_close dataframe which only has the Adj Closecolumn for all of your stock tickers. If you look at the notebook in the repo I link to above, this code is chunked out in more code blocks than shown below. For purposes of describing this here, I’ve included below all of the code which leads up to our initial merged_portfolio dataframe.\n# Also only pulling the ticker, date and adj. close columns for our tickers. adj_close = all_data[['Adj Close']].reset_index() adj_close.head() # Grabbing the ticker close from the end of last year adj_close_start = adj_close[adj_close['Date']==end_of_last_year] adj_close_start.head() # Grab the latest stock close price adj_close_latest = adj_close[adj_close['Date']==stocks_end] adj_close_latest adj_close_latest.set_index('Ticker', inplace=True) adj_close_latest.head() # Set portfolio index prior to merging with the adj close latest. portfolio_df.set_index(['Ticker'], inplace=True) portfolio_df.head() # Merge the portfolio dataframe with the adj close dataframe; they are being joined by their indexes. merged_portfolio = pd.merge(portfolio_df, adj_close_latest, left_index=True, right_index=True) merged_portfolio.head() # The below creates a new column which is the ticker return; takes the latest adjusted close for each position # and divides that by the initial share cost. merged_portfolio['ticker return'] = merged_portfolio['Adj Close'] / merged_portfolio['Unit Cost'] - 1 merged_portfolio  Depending on your level of familiarity with pandas, this will be very straightforward to slightly overwhelming. Below, I’ll unpack what these lines are doing:\n The overall approach you are taking is an example of split-apply-combine (note this downloads a PDF). The all_data[['Adj Close']] line creates a new dataframe with only the columns provided in the list; here Adj Close is the only item provided in the list. Using this line of code, adj_close[adj_close['Date']==end_of_last_year], you are filtering the adj_close dataframe to only the row where the data’s Date column equals the date which you earlier specified in the end_of_last_year variable (2017, 12, 29). You also set the index of the adj_close_latest and portfolio_df dataframes. I did this because this is how you’ll merge the two dataframes. The merge function, very similar to SQL joins, is an extremely useful function which I use very often. Within the merge function, you specify the left dataframe ( portfolio_df ) and our right dataframe ( adj_close_latest ). By specifying left_index and right_index equal True, you are stating that the two dataframes share a common index and you will join both on this. Last, you create a new column called 'ticker return' . This calculates the percent return for each stock position by dividing the Adj Close by the Unit Cost (initial purchase price for stock) and subtracting 1. This is similar to calculating a formula in excel and carrying it down, but in pandasthis is accomplished with one-line of code.  You have taken the individual dataframes for the S\u0026amp;P 500 and individual stocks, and you are beginning to develop a ‘master’ dataframe which we’ll use for calculations, visualizations and any further analysis. Next, you continue to build on this ‘master’ dataframe with further use of pandas merge function. Below, you reset the current dataframe’s index and begin joining your smaller dataframes with the master one. Once again, the below code block is broken out further in the Jupyter notebook; here I take a similar approach to before where I’ll share the code below and then break down the key callouts below the code block.\nmerged_portfolio.reset_index(inplace=True) # Here we are merging the new dataframe with the sp500 adjusted closes since the sp start price based on # each ticker's acquisition date and sp500 close date. merged_portfolio_sp = pd.merge(merged_portfolio, sp_500_adj_close, left_on='Acquisition Date', right_on='Date') # .set_index('Ticker') # We will delete the additional date column which is created from this merge. # We then rename columns to Latest Date and then reflect Ticker Adj Close and SP 500 Initial Close. del merged_portfolio_sp['Date_y'] merged_portfolio_sp.rename(columns={'Date_x': 'Latest Date', 'Adj Close_x': 'Ticker Adj Close' , 'Adj Close_y': 'SP 500 Initial Close'}, inplace=True) # This new column determines what SP 500 equivalent purchase would have been at purchase date of stock. merged_portfolio_sp['Equiv SP Shares'] = merged_portfolio_sp['Cost Basis'] / merged_portfolio_sp['SP 500 Initial Close'] merged_portfolio_sp.head() # We are joining the developing dataframe with the sp500 closes again, this time with the latest close for SP. merged_portfolio_sp_latest = pd.merge(merged_portfolio_sp, sp_500_adj_close, left_on='Latest Date', right_on='Date') # Once again need to delete the new Date column added as it's redundant to Latest Date. # Modify Adj Close from the sp dataframe to distinguish it by calling it the SP 500 Latest Close. del merged_portfolio_sp_latest['Date'] merged_portfolio_sp_latest.rename(columns={'Adj Close': 'SP 500 Latest Close'}, inplace=True) merged_portfolio_sp_latest.head()   You use reset_index on the merged_portfolio in order to flatten the master dataframe and join on the smaller dataframes’ relevant columns. In the merged_portfolio_sp line, you merge the current master dataframe (merged_portfolio) with the sp_500_adj_close; you do this in order to have the S\u0026amp;P’s closing price on each position’s purchase date – this allows you to track the S\u0026amp;P performance over the same time period that each position is held (from acquisition date to most recent market close date). The merge here is slightly different than before, in that we join on the left dataframe’s Acquisition Date column and on the right dataframe’s Date column. After completing this merge, you will have extra columns which you do not need — since our master dataframe will eventually have a considerable number of columns for analysis, it is important to prune duplicative and unnecessary columns along the way. There are several ways to remove unnecessary columns and perform various column name cleanups; for simplicity, I use python del and then rename a few columns with pandas rename method, clarifying the ticker’s Adj Close column by renaming to Ticker Adj Close; and you distinguish the S\u0026amp;P’s initial adjusted close with SP 500 Initial Close. When you calculate merged_portfolio_sp['Equiv SP Shares'], you do so in order to be able to calculate the S\u0026amp;P 500’s equivalent value for the close on the date you acquired each ticker position: if you spend $5,000 on a new stock position, you could have spent $5,000 on the S\u0026amp;P 500; continuing the example, if the S\u0026amp;P 500 was trading at $2,500 per share at the time of purchase, you would have been able to purchase 2 shares. Later, if the S\u0026amp;P 500 is trading for $3,000 per share, your stake would be worth $6,000 (2 equivalent shares * $3,000 per share) and you would have $1,000 in paper profits over this comparable time period. In the rest of the code block, you next perform a similar merge, this time joining on the S\u0026amp;P 500’s latest close — this provides the second piece needed to calculate the S\u0026amp;P’s comparable return relative to each position’s holding period: the S\u0026amp;P 500 price on each ticker’s acquisition day and the S\u0026amp;P 500’s latest market close.  You have now further developed your ‘master’ dataframe with the following:\n Each portfolio position’s price, shares and value on the position acquisition day, as well as the latest market’s closing price. An equivalent S\u0026amp;P 500 price, shares and value on the equivalent position acquisition day for each ticker, as well as the latest S\u0026amp;P 500 closing price.  Given the above, you will next perform the requisite calculations in order to compare each position’s performance, as well as the overall performance of this strategy / basket of stocks, relative to comparable dollar investment and holding times of the S\u0026amp;P 500.\nBelow is a summary of the new columns which you are adding to the ‘master’ dataframe.\n In the first column, ['SP Return'], you create a column which calculates the absolute percent return of the S\u0026amp;P 500 over the holding period of each position (note, this is an absolute return and is not an annualized return). In the second column (['Abs. Return Compare']), you compare the ['ticker return'] (each position’s return) relative to the ['SP Return'] over the same time period. In the next three columns, ['Ticker Share Value'], ['SP 500 Value'] and ['Abs Value Compare'], we calculate the dollar value (market value) equivalent based on the shares we hold multiplied by the latest adjusted close price (and subtract the S\u0026amp;P return from the ticker to calculate over / (under) performance). Last, the ['Stock Gain / (Loss)'] and ['SP 500 Gain / (Loss)'] columns calculate our unrealized dollar gain / loss on each position and comparable S\u0026amp;P 500 gain / loss; this allows us to compare the value impact of each position versus simply investing those dollars in the S\u0026amp;P 500.\n# Percent return of SP from acquisition date of position through latest trading day. merged_portfolio_sp_latest['SP Return'] = merged_portfolio_sp_latest['SP 500 Latest Close'] / merged_portfolio_sp_latest['SP 500 Initial Close'] - 1 # This is a new column which takes the tickers return and subtracts the sp 500 equivalent range return. merged_portfolio_sp_latest['Abs. Return Compare'] = merged_portfolio_sp_latest['ticker return'] - merged_portfolio_sp_latest['SP Return'] # This is a new column where we calculate the ticker's share value by multiplying the original quantity by the latest close. merged_portfolio_sp_latest['Ticker Share Value'] = merged_portfolio_sp_latest['Quantity'] * merged_portfolio_sp_latest['Ticker Adj Close'] # We calculate the equivalent SP 500 Value if we take the original SP shares * the latest SP 500 share price. merged_portfolio_sp_latest['SP 500 Value'] = merged_portfolio_sp_latest['Equiv SP Shares'] * merged_portfolio_sp_latest['SP 500 Latest Close'] # This is a new column where we take the current market value for the shares and subtract the SP 500 value. merged_portfolio_sp_latest['Abs Value Compare'] = merged_portfolio_sp_latest['Ticker Share Value'] - merged_portfolio_sp_latest['SP 500 Value'] # This column calculates profit / loss for stock position. merged_portfolio_sp_latest['Stock Gain / (Loss)'] = merged_portfolio_sp_latest['Ticker Share Value'] - merged_portfolio_sp_latest['Cost Basis'] # This column calculates profit / loss for SP 500. merged_portfolio_sp_latest['SP 500 Gain / (Loss)'] = merged_portfolio_sp_latest['SP 500 Value'] - merged_portfolio_sp_latest['Cost Basis'] merged_portfolio_sp_latest.head()  You now have what you need in order to compare your portfolio’s performance to a portfolio equally invested in the S\u0026amp;P 500. The next two code block sections allow you to i) compare YTD performance of each position relative to the S\u0026amp;P 500 (a measure of momentum and how your positions are pacing) and ii) compare the most recent closing price for each portfolio position relative to its most recent closing high (this allows you to assess if a position has triggered a trailing stop, e.g., closed 25% below closing high).\n  Below, I’ll start with the YTD performance code block and provide details regarding the code further below.\n# Merge the overall dataframe with the adj close start of year dataframe for YTD tracking of tickers. merged_portfolio_sp_latest_YTD = pd.merge(merged_portfolio_sp_latest, adj_close_start, on='Ticker') # , how='outer' # Deleting date again as it's an unnecessary column. Explaining that new column is the Ticker Start of Year Close. del merged_portfolio_sp_latest_YTD['Date'] merged_portfolio_sp_latest_YTD.rename(columns={'Adj Close': 'Ticker Start Year Close'}, inplace=True) # Join the SP 500 start of year with current dataframe for SP 500 ytd comparisons to tickers. merged_portfolio_sp_latest_YTD_sp = pd.merge(merged_portfolio_sp_latest_YTD, sp_500_adj_close_start , left_on='Start of Year', right_on='Date') # Deleting another unneeded Date column. del merged_portfolio_sp_latest_YTD_sp['Date'] # Renaming so that it's clear this column is SP 500 start of year close. merged_portfolio_sp_latest_YTD_sp.rename(columns={'Adj Close': 'SP Start Year Close'}, inplace=True) # YTD return for portfolio position. merged_portfolio_sp_latest_YTD_sp['Share YTD'] = merged_portfolio_sp_latest_YTD_sp['Ticker Adj Close'] / merged_portfolio_sp_latest_YTD_sp['Ticker Start Year Close'] - 1 # YTD return for SP to run compares. merged_portfolio_sp_latest_YTD_sp['SP 500 YTD'] = merged_portfolio_sp_latest_YTD_sp['SP 500 Latest Close'] / merged_portfolio_sp_latest_YTD_sp['SP Start Year Close'] - 1   When creating the merged_portfolio_sp_latest_YTD dataframe, you are now merging the ‘master’ dataframe with the adj_close_start dataframe; as a quick reminder, you created this dataframe by filtering on the adj_close dataframe where the 'Date' column equaled the variable end_of_last_year; you do this because it’s how YTD (year-to-date) stock and index performances are measured; last year’s ending close is the following year’s starting price. From here, we once again use del to remove unnecessary columns and the rename method to clarify the ‘master’ dataframe’s newly added columns. Last, we take each Ticker (in the ['Ticker Adj Close'] column) and calculate the YTD return for each (we also have an S\u0026amp;P 500 equivalent value for each value in the 'SP 500 Latest Close'column).  In the below code block, you use the sort_values method to re-sort our ‘master’ dataframe and then you calculate cumulative portfolio investments (sum of your position acquisition costs), as well the cumulative value of portfolio positions and the cumulative value of the theoretical S\u0026amp;P 500 investments. This allows you to be able to see how your total portfolio, with investments in positions made at different times across the entire period, compares overall to a strategy where you had simply invested in an index. Later on, you’ll use the ['Cum Ticker ROI Mult'] to help you visualize how much each investment contributed to or decreased your overall return on investment (ROI).\nmerged_portfolio_sp_latest_YTD_sp = merged_portfolio_sp_latest_YTD_sp.sort_values(by='Ticker', ascending=True) # Cumulative sum of original investment merged_portfolio_sp_latest_YTD_sp['Cum Invst'] = merged_portfolio_sp_latest_YTD_sp['Cost Basis'].cumsum() # Cumulative sum of Ticker Share Value (latest FMV based on initial quantity purchased). merged_portfolio_sp_latest_YTD_sp['Cum Ticker Returns'] = merged_portfolio_sp_latest_YTD_sp['Ticker Share Value'].cumsum() # Cumulative sum of SP Share Value (latest FMV driven off of initial SP equiv purchase). merged_portfolio_sp_latest_YTD_sp['Cum SP Returns'] = merged_portfolio_sp_latest_YTD_sp['SP 500 Value'].cumsum() # Cumulative CoC multiple return for stock investments merged_portfolio_sp_latest_YTD_sp['Cum Ticker ROI Mult'] = merged_portfolio_sp_latest_YTD_sp['Cum Ticker Returns'] / merged_portfolio_sp_latest_YTD_sp['Cum Invst'] merged_portfolio_sp_latest_YTD_sp.head()  You are now nearing the home stretch and almost ready to start visualizing your data and assessing the strengths and weaknesses of your portfolio’s individual ticker and overall strategy performance.\nAs before, I’ve included the main code block for determining where positions are trading relative to their recent closing high; I’ll then unpack the code further below.\n# Need to factor in that some positions were purchased much more recently than others. # Join adj_close dataframe with portfolio in order to have acquisition date. portfolio_df.reset_index(inplace=True) adj_close_acq_date = pd.merge(adj_close, portfolio_df, on='Ticker') # delete_columns = ['Quantity', 'Unit Cost', 'Cost Basis', 'Start of Year'] del adj_close_acq_date['Quantity'] del adj_close_acq_date['Unit Cost'] del adj_close_acq_date['Cost Basis'] del adj_close_acq_date['Start of Year'] # Sort by these columns in this order in order to make it clearer where compare for each position should begin. adj_close_acq_date.sort_values(by=['Ticker', 'Acquisition Date', 'Date'], ascending=[True, True, True], inplace=True) # Anything less than 0 means that the stock close was prior to acquisition. adj_close_acq_date['Date Delta'] = adj_close_acq_date['Date'] - adj_close_acq_date['Acquisition Date'] adj_close_acq_date['Date Delta'] = adj_close_acq_date[['Date Delta']].apply(pd.to_numeric) # Modified the dataframe being evaluated to look at highest close which occurred after Acquisition Date (aka, not prior to purchase). adj_close_acq_date_modified = adj_close_acq_date[adj_close_acq_date['Date Delta']\u0026gt;=0] # This pivot table will index on the Ticker and Acquisition Date, and find the max adjusted close. adj_close_pivot = adj_close_acq_date_modified.pivot_table(index=['Ticker', 'Acquisition Date'], values='Adj Close', aggfunc=np.max) adj_close_pivot.reset_index(inplace=True) # Merge the adj close pivot table with the adj_close table in order to grab the date of the Adj Close High (good to know). adj_close_pivot_merged = pd.merge(adj_close_pivot, adj_close , on=['Ticker', 'Adj Close']) # Merge the Adj Close pivot table with the master dataframe to have the closing high since you have owned the stock. merged_portfolio_sp_latest_YTD_sp_closing_high = pd.merge(merged_portfolio_sp_latest_YTD_sp, adj_close_pivot_merged , on=['Ticker', 'Acquisition Date']) # Renaming so that it's clear that the new columns are closing high and closing high date. merged_portfolio_sp_latest_YTD_sp_closing_high.rename(columns={'Adj Close': 'Closing High Adj Close', 'Date': 'Closing High Adj Close Date'}, inplace=True) merged_portfolio_sp_latest_YTD_sp_closing_high['Pct off High'] = merged_portfolio_sp_latest_YTD_sp_closing_high['Ticker Adj Close'] / merged_portfolio_sp_latest_YTD_sp_closing_high['Closing High Adj Close'] - 1 merged_portfolio_sp_latest_YTD_sp_closing_high   To begin, you merge the adj_close dataframe with the portfolio_df dataframe; this is the third time that you’ve leveraged this adj_close dataframe in order to conduct an isolated analysis which you’ll then combine with the overall ‘master’ dataframe. This initial merge is not particularly useful, as you have dates and adjusted close prices which pre-date your acquisition date for each position; as a result, we’ll subset the data post our acquisition date, and then find the max closing price since that time. Once again, I used del to delete the merged dataframe’s unneeded columns; this is code I should refactor, as creating a list, e.g., cols_to_keep, and then filtering the dataframe with this would be a better approach – as an FYI, running the del code block more than once will throw an error and you would need to re-initialize your dataframe then run the del code block again. After removing the unnecessary columns, you then use the sort_values method and sort the values by the 'Ticker', 'Acquisition Date', and 'Date' columns (all ascending); you do this to make sure all of the ticker rows are sorted together, and we sort by Acquisition Date (in case we’ve purchased the same stock more than once) and Date ascending in order to filter out the dates prior to your positions’ acquisition dates. In other words, you are only concerned with the closing high since you’ve held the position. In order to filter our dataframe, you create a new column ['Date Delta'] which is calculated by the difference between the Date and Acquisition Date columns. You then convert this column into a numeric column, and you create a new dataframe called adj_close_acq_date_modified where the ['Date Delta'] is \u0026gt;= 0. This ensures that you are only evaluating closing highs since the date that you purchased each position. Now that you have the adj_close_acq_date_modified dataframe, we’ll use a very powerful pandas function called pivot_table. If you’re familiar with pivot tables in Excel, this function is similar in that you can pivot data based on a single or multi-index, specify values to calculate and columns to pivot on, and also use agg functions (which leverage numpy). Using the pivot_table function, we pivot on Ticker and Acquisition Date and specify that we would like to find the maximum (np.max) Adj Close for each position; this allows you to compare the recent Adjusted Close for each position relative to this High Adjusted Close. Now you have an adj_close_pivot dataframe, and you reset the index and join this once again on the adj_close dataframe. This creates the adj_close_pivot_merged dataframe, which tells you when you purchased each position and the date on which it hit its closing high since acquisition. Finally, we will combine our ‘master’ dataframe with this last smaller dataframe, adj_close_pivot_merged. After doing so, you are now able to calculate the final column needed, ['Pct off High']. You take the ['Ticker Adj Close'] and divide it by the ['Closing High Adj Close'] and subtract 1. Note, that this percentage will always be negative, unless the stock happened to have its highest close (in this case it will be zero) on the most recent trading day evaluated (this is generally a very good sign if it’s the case).  This has been a pretty significant lift, and it’s now time for our long-awaited visualizations. If you’ve continued to follow along in your own notebook, you now have a very rich dataframe with a number of calculated portfolio metrics, as shown in the below:\nTotal Return and Cumulative Return Visualizations For all of these visualizations you’ll use Plotly, which allows you to make D3 charts entirely without code. While I also use Matplotlib and Seaborn, I really value the interactivity of Plotly; and once you are used to it, the syntax becomes fairly straightforward and dynamic charts are easily attainable.\nYour first chart below compares each individual position’s total return relative to the S\u0026amp;P 500 (same holding periods for the position and hypothetical investment in the S\u0026amp;P 500). In the below, you’ll see that over their distinct holding periods, 6 of the 8 positions outperformed the S\u0026amp;P. The last two, Twitter (which actually has had a negative return) and Walmart underperformed an equal timed investment in the S\u0026amp;P 500.\nAs each of these visualizations are relatively similar, I’ll explain the code required to generate the above Plotly visualization, and for the remaining ones I’ll only summarize observations from each visualization.\ntrace1 = go.Bar( x = merged_portfolio_sp_latest_YTD_sp_closing_high['Ticker'][0:10], y = merged_portfolio_sp_latest_YTD_sp_closing_high['ticker return'][0:10], name = 'Ticker Total Return') trace2 = go.Scatter( x = merged_portfolio_sp_latest_YTD_sp_closing_high['Ticker'][0:10], y = merged_portfolio_sp_latest_YTD_sp_closing_high['SP Return'][0:10], name = 'SP500 Total Return') data = [trace1, trace2] layout = go.Layout(title = 'Total Return vs S\u0026amp;P 500' , barmode = 'group' , yaxis=dict(title='Returns', tickformat=\u0026quot;.2%\u0026quot;) , xaxis=dict(title='Ticker') , legend=dict(x=.8,y=1) ) fig = go.Figure(data=d   When using Plotly, you create traces which will plot the x and y data you specify. Here, you specify in trace1 that you want to plot a bar chart, with each Ticker on the x-axis and each ticker’s return on the y-axis. In trace2, to break up the data a bit, we’ll use a Scatter line chart for the Ticker on the x-axis and the S\u0026amp;P Return on the y-axis. Where the bar is above the line, the individual ticker (6 of 8 times) has outperformed the S\u0026amp;P 500. You then create a data object with these traces, and then you provide a layout for the chart; in this case you specify a title, barmode, and the position of the legend; you also pass in a title and tick format (percent format to two decimal places) for the y-axis series. You then create a figure object using go.Figure, specifying the data and layout objects, which you previously named data and layout.  The next chart below shows the gain / (loss) dollar amount for each position, relative to the S\u0026amp;P 500, as well as shows the Ticker Total Return %. While it is generally recommended that you allocate an equal position size to your positions (or potentially determine positition sizing based on implied volatility), this may not always be the case. For a less volatile investment, you may invest more than in a riskier position (or you may have other position sizing rules). Given this, this visualization shows both each position’s return and the dollar value contribution to your overall portfolio’s return.\nHere, you can see that although you invested slightly less in Facebook (FB) than other positions, this stock has returned an ~$20k in this mock portfolio, greater than a 4x return relative to an equivalent S\u0026amp;P 500 investment over the same holding period.\nThe next chart below leverages the cumulative columns which you created: 'Cum Invst', 'Cum SP Returns', 'Cum Ticker Returns', and 'Cum Ticker ROI Mult'.\n Across the x-axis you have sorted the portfolio alphabetically. Each position shows the initial investment and total value (investment plus returns or less losses) for that position, combined with the positions preceding it. To explain further, based on the ~$8k investment in AAPL, this grew to ~$22.5k (\u0026gt;$14k in gains), versus $15k in total value for the S\u0026amp;P. This is a 2.75x return over the initial investment in AAPL ($22.5k value from $8k investment is ~2.75x ROI). Continuing to FB, you have invested ~$16k in aggregate ($8k in both positions), and this has grown to over $50k, a greater than 3x total return — this means that FB expanded your overall portfolio ROI. Further down the x-axis, you see that both TWTR and WMT have reduced the overall portfolio ROI — this is obvious, as both have underperformed the S\u0026amp;P, but I believe that the magnitude of the contribution is clearer with this visualization. As a caveat, this cumulative approach, given the different holding periods, is a bit of an apples and oranges combination for some positions based on when they were acquired. However, you can always isolate this analysis by sub-setting into smaller dataframes and separately compare positions which have more consistent holding periods. For example, you could compare your 2H 2016 and 1H 2017 purchases separate of one another.  Adjusted Close % off of High Comparison Your final chart compares how far off each position’s latest close price is from its adjusted closing high since the position was purchased. This is generally an important visualization to consider:\n When a stock closes at higher prices, it’s generally recommended to adjust your trailing stop up as well. To illustrate, here’s an example: A position is acquired at $10 and doubles to $20 — using a 25% trailing stop, you would want to consider selling this position the next day if it closed at $15 ($15 / $20–1 = (25%)). If the position increased to $25, you would want to consider moving your trailing stop up to $18.75 ($18.75 / $25–1 = (25%)). As mentioned early on, nothing in here is intended to be financial advice; different trading systems have different rules for trailing stops, and this is an illustrative example. Trailing stops are meant to help preserve gains and are generally important in mitigating the emotions of investing; while it’s easy to see your position’s current return, what tends to be manual (or somewhat expensive if you use a trailing stop service) is calculating how close your positions are to your trailing stops. This final visualization makes this easy to evaluate for any date you are reviewing; in the chart, we see that AAPL, MTCH, and NFLX all closed on 3/9/2018 at their closing highs (typically a very good sign). However, TWTR is greater than 25% below its highest close (33% below as of 3/9/2018) and WMT is ~20% below its highest close. In this case, you might want to sell TWTR and continue to keep a close eye on the performance of WMT.  Limitations to Approach and Closing Summary Now you have a relatively extensible Jupyter notebook and portfolio dataset, which you are able to use to evaluate your stock portfolio, as well as add in new metrics and visualizations as you see fit.\nPlease note that while this notebook provides a fairly thorough review of a portfolio, the below have not yet been taken into consideration, would have an impact on the overall comparison, and likely present great areas for future development:\n As noted initially, this notebook focuses on active holdings — ideally, we would evaluate all positions, both exited and active, in order to have a truly holistic view on one’s investment strategy relative to alternatives, such as an index comparison. The approach in here does not factor in dividends; while we evaluate adjusted close prices (which reflect dividends), total shareholder return combines share price appreciation and dividends to show a stock’s total return; while this is more difficult to do, it is something I’m evaluating to include in the future. On a related note, investors can also reinvest dividends in a position, rather than take a cash distribution; this is arguably even more complicated than accounting for dividends, as the acquisition costs are low and spread out, and over several years of holding a position you could have four (or more) acquisition dates each year for stocks where you reinvest dividends.  With those future areas in mind, we accomplished a lot here; this includes importing S\u0026amp;P 500 and ticker data using Yahoo! Finance’s API and creating a master dataframe which combines your portfolio with historical ticker and comparative S\u0026amp;P 500 prices. In doing this, you are able to calculate the absolute percent and dollar value returns for each position (and as compared to equally timed S\u0026amp;P 500 investments), as well as the cumulative impact of each position on your overall portfolio’s performance. You can also dynamically monitor your trailing stops, based on your own trading rules. And you have created visualizations which allow you to have much better insight into your master dataframe, focusing on the different metrics and each position’s contribution to each.\nI hope that you found this tutorial useful, and I welcome any feedback in the comments. Feel free to also reach out to me on twitter, @kevinboller, and my personal blog can be found here.\n"});index.add({'id':247,'href':'/library/tutorials/docs/python/snippets/sum_by/','title':"sum_by",'content':"Returns the sum of a list, after mapping each element to a value using the provided function.\nUse map() with fn to map each element to a value using the provided function, use sum() to return the sum of the values.\ndef sum_by(lst, fn): return sum(map(fn, lst))  sum_by([{ 'n': 4 }, { 'n': 2 }, { 'n': 8 }, { 'n': 6 }], lambda v : v['n']) # 20  "});index.add({'id':248,'href':'/library/tutorials/docs/python/snippets/symmetric_difference/','title':"symmetric_difference",'content':"Returns the symmetric difference between two iterables, without filtering out duplicate values.\nCreate a set from each list, then use list comprehension on each one to only keep values not contained in the previously created set of the other.\ndef symmetric_difference(a, b): _a, _b = set(a), set(b) return [item for item in a if item not in _b] + [item for item in b if item not in _a]  symmetric_difference([1, 2, 3], [1, 2, 4]) # [3, 4]  "});index.add({'id':249,'href':'/library/tutorials/docs/python/snippets/symmetric_difference_by/','title':"symmetric_difference_by",'content':"Returns the symmetric difference between two lists, after applying the provided function to each list element of both.\nCreate a set by applying fn to each element in every list, then use list comprehension in combination with fn on each one to only keep values not contained in the previously created set of the other.\ndef symmetric_difference_by(a, b, fn): _a, _b = set(map(fn, a)), set(map(fn, b)) return [item for item in a if fn(item) not in _b] + [item for item in b if fn(item) not in _a]  from math import floor symmetric_difference_by([2.1, 1.2], [2.3, 3.4],floor) # [1.2, 3.4]  "});index.add({'id':250,'href':'/library/tutorials/docs/python/snippets/tail/','title':"tail",'content':"Returns all elements in a list except for the first one.\nReturn lst[1:] if the list\u0026rsquo;s length is more than 1, otherwise, return the whole list.\ndef tail(lst): return lst[1:] if len(lst) \u0026gt; 1 else lst  tail([1, 2, 3]) # [2,3] tail([1]) # [1]  "});index.add({'id':251,'href':'/library/tutorials/docs/python/snippets/transpose/','title':"transpose",'content':"Returns the transpose of a two-dimensional list.\nUse *lst to get the passed list as tuples. Use zip() in combination with list() to create the transpose of the given two-dimensional list.\ndef transpose(lst): return list(zip(*lst))  transpose([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]]) # [(1, 4, 7, 10), (2, 5, 8, 11), (3, 6, 9, 12)]  "});index.add({'id':252,'href':'/library/tutorials/docs/python/beginer/list/tutorial-for-python-lists/','title':"Tutorial for Python Lists",'content':" Tutorial for Python Lists  Home  This tutorial goes through how to work with lists in Python, including many of the built-in methods Python makes available for these data structures. Feel free to click on any of the links below to skip to a section of interest.\n**\nBackground on lists\nReferring to list elements by index\nSlicing lists\nCombining lists\nLists are mutable\nLists support inplace methods**\nAdding elements to a list\nHow to append elements to a list (individually)\nHow to insert elements at specific locations in a list\nHow to append another list of elements to a list\nRemoving elements from a list\nHow to remove specific values from a list\nRemoving an element from a specific index in a list\nRemoving all elements in a list at once\nOther list operations\nHow to filter a list\nHow to reverse a list\nHow to count the occurrence of an element in a list\nCopying a list\nHow to sort a list\nGetting the length of a list\nFinding the first occurrence of a value in a list\nBackground on lists A list in Python is a container of numbers, strings, or other objects (or mixed). Lists can be created using brackets enclosing whatever elements you want in the list, where each element is separated by a comma.\nBelow we define a list containing five numbers – 4, 5, 10, 20, and 34.\nnums = [4, 5, 10, 20, 34] # We can also define a list of strings: strings = [\u0026quot;this\u0026quot;, \u0026quot;is\u0026quot;, \u0026quot;another\u0026quot;, \u0026quot;list\u0026quot;] # Or – here’s a mixed data type list: [\u0026quot;example\u0026quot;, \u0026quot;of\u0026quot;, \u0026quot;a\u0026quot;, 42, 10, \u0026quot;mixed\u0026quot;, \u0026quot;data type list\u0026quot;, 5] # Lists can also contain other lists. These lists are called nested lists. Below we define a list where the last element is just an integer, 100, but the other elements of the list are lists themselves. nested_list = [[\u0026quot;inner list\u0026quot;, 10], [\u0026quot;second inner list\u0026quot;], 100]  Referring to list elements by index One property of lists is that each element in the list can be referred to by an index i.e. there is an order to the elements in the list. In other words, there is the concept of the first element, second element, third element, and so on. Since Python is zero-indexed, the 0th element of the list defined above is 4. The 1st element is 5, the 2nd is 10, and so on.\nWe refer to elements in a list by index using bracket notation like this:\nnums[0] # returns 4 nums[1] # returns 5 nums[2] # returns 10 # We can also refer to elements starting from the end of the list using negative indices. nums[-1] # returns 34 nums[-2] # returns 20 nums[-3] # returns 10  Slicing a list What if want to grab more than one element at a time from a list? For instance, how would we retrieve the first three elements of our nums list?\nnums[0:3] nums[:3]  Each of the above will return the first three elements of the list nums. The 0:3 means that Python will return the elements in the list indexed 0, 1, and 2 – but not 3. So it will include all the elements up until, but not including the third-indexed element.\nHere’s a few more examples:\nnums[1:4] nums[1:3]  The first example above will retrieve the elements indexed 1, 2, and 3 (but not 4) of nums. The second example retrieves the elements indexed 1 and 2 (but not 3).\nHow to combine lists Lists can be combined using the “+” operator.\nlist_1 = [3, 4, 5] list_2 = [6, 7, 8] list_3 = list_1 + list_2 list_3  We can also chain together multiple concatenation operations:\n[1, 2, 3] + [4, 5, 6] + [\u0026quot;python\u0026quot;, \u0026quot;is\u0026quot;, \u0026quot;awesome\u0026quot;] + [[\u0026quot;nested list\u0026quot;]]  Lists are mutable Another property of lists is that they are mutable. We’ll see examples of what this means in the below sections. Effectively, though, mutable means that the state of a list can be changed after it has been defined. What does that mean in practice? Mutability means we can change how a list (or some other object in Python for that matter) is defined without formally redefining the list.\nSuppose, for example, we wanted to change the 0th element of the strings list above. We can do that by referencing just the 0th element of the list, and setting it equal to some other value.\nstrings = [\u0026quot;this\u0026quot;, \u0026quot;is\u0026quot;, \u0026quot;another\u0026quot;, \u0026quot;list\u0026quot;] strings[0] = \u0026quot;that\u0026quot; strings  The above code is an alternative to the below where we redefine the full list strings. The mutability of lists gives us the ability to shorten the amount of code we write to adjust the values they contain.\nstrings = [\u0026quot;that\u0026quot;, \u0026quot;is\u0026quot;, \u0026quot;another\u0026quot;, \u0026quot;list\u0026quot;]  Some of the additional examples below will show how lists can be mutated, or changed, after they have been defined.\nLists support inplace methods Lists in Python have several inplace methods. These are methods, or functions, that perform operations on a list with the result being automatically stored back into the same list, thus generally reducing the amount of code that has to be written. If that isn’t clear, we’ll see examples of how this works in several of the sections below.\nAdding elements to a list How to append elements in a list An example of mutability is via appending elements to a list. To append elements to a list, one at at a time, we can use the (aptly-named) append method. This method is also an example of an inplace operation.\n# append 100 to the end of our list, nums nums.append(100)  Below we append 200 to the end of nums, followed by 300.\nnums.append(200) nums.append(300)  Each of these append examples demonstrates how lists are mutable because they each show how the definition of nums can be changed after its initialization without a new initialization. In other words, we could have taken our original list and then redefined that list multiple times to append elements to the end of the list, like this:\nnums = [4, 5, 10, 20, 34] nums = [4, 5, 10, 20, 34, 100] nums = [4, 5, 10, 20, 34, 100, 200] nums = [4, 5, 10, 20, 34, 100, 200, 300]  …But we don’t have to. We can accomplish what the code above does with the append method because of the fact that lists are mutable, and therefore, we can mutate, or change, lists without reinitialization.\nAlso, because append is inplace, we don’t have to run the last chunk of code above where we’re redefining nums because the method automatically changes nums to have the appended values.\nHow to insert elements at specific locations in a list The append method above appends an element to the end of a list, but what if we want to insert an element at some other specific location in a list? We can perform this task using the insert method.\nTaking the previous value of nums as [4, 5, 10, 20, 34, 100, 200, 300], let’s insert the string “test” into the third indexed position of the list.\nnums.insert(3, \u0026quot;test\u0026quot;)  The insert method takes two parameters. The first is the index in the list we want to insert some element. The second parameter is the element we want to insert. In this case, we insert the string “test” into the third index of the list, nums.\nPutting an element into the nth position in a list will shift the elements in that position and later to the right. In our case, this means the element in the third position initially will now be in the fourth position, the element in the fourth position shifts to the fifth position, the element in the fifth position shifts to the sixth position, etc.\nBelow we insert the string “test” again – though this time we put it into the seventh-indexed position.\nnums.insert(7, \u0026quot;test\u0026quot;)  How to append another list of elements to a list One of my favorite methods for dealing with lists is the extend method because it can append an entire other list of elements at once to your list.\nnums.extend([1000, 2000, 3000])  The extend method can be viewed as a shortcut for writing the below code:\nnums = nums + [1000, 2000, 3000]  The above code will take the initial list, nums, and append the numbers 1000, 2000, and 3000 to the end of the list – just like the extend method. The difference is that in this case we have to redefine nums to be equal to this concatenation, whereas the extend method is inplace.\nRemoving elements from a list How to remove elements from a list by specific values We can remove elements of a list that equal a specific value using the remove method. The remove method will take out the first occurrence of the input value for a given list (and only the first occurrence). For instance, let’s say we want to get rid of the string “test” we inserted into nums in an earlier section.\n# remove first occurrence of \u0026quot;test\u0026quot; nums.remove(\u0026quot;test\u0026quot;) # remove next occurrence of \u0026quot;test\u0026quot; nums.remove(\u0026quot;test\u0026quot;)  Each time we run nums.remove(“test”), Python will remove the first found occurrence of the string “test” in the list. Thus, running the first line above will remove “test” from the third-indexed position in nums. Running the second line will remove the next (and in this case, only other) occurrence of “test” in the list.\nHow to remove an element from a specific index Elements can also be removed from a list based off index. For example, if we want to remove the element in the third-indexed position from a list, we could do this:\n# remove element in the third-indexed position nums.pop(3) # or remove the element in the fifth-indexed position nums.pop(5)  Notice from the snapshot above that the pop method returns the value of the element that is removed. Hence, when used above, it returns 20 and then 200, respectively.\nNow, we can insert those numbers back into our list:\nnums.insert(5, 200) nums.insert(3, 20)  How to remove all elements of a list To clear out all elements of a list we can use the clear method:\nnums.clear()  Other built-in list operations Filtering lists Lists can be filtered using the filter function. The filter function works by taking a function and a list as input. The input function applies a logical condition that returns True or False (i.e. Boolean) for each element in the list. If the function returns True, the output object will retain that list element.\nThe actual object returned by filter is not a list (as of Python \u0026gt;= 3.0) – but instead, is called a filter object. To convert this to a list, we just need to wrap the list function around the filter object.\na = [10, 20, 30, 40] filter(lambda num: num \u0026lt; 30, a)  list(filter(lambda num: num \u0026lt; 30, a))  How to reverse the elements in a list Option 1) There’s a few different ways to reverse the elements in a list. One way is using the inplace method called reverse, like so:\nnums.reverse()  This will reverse the elements of our list, nums, while storing the results of that reversal back in nums. So if we run the below line of code, we can see now that nums contains its original elements in reverse.\nnums  Option 2) Another way of reversing a list is using bracket notation, like this:\nnums[::-1]  Doing the above will reverse the elements of nums, but won’t store the results back into nums unless we tell it to, like this:\nnums = nums[::-1]  How to count the occurrence of an element in a list To count how many times an element occurs in a list, we can use the count method, like this (using a different list this time):\nx = [10, 10, 30, 20, 50, 50, 30, 30, 30] x.count(30)  Here, running x.count(30) will return 4 because 30 occurs four times in x.\nLikewise, if we want to count how many times 50 appears, or 10 appears, we would do this:\nx.count(50) x.count(10)  If we try to use the count method for an element that doesn’t occur in the list, Python will return zero:\nx.count(100)  How to copy a list Lists can be copied using the copy method.\nHow to sort a list Sorting a list can be done using the sort method like this:\n# define a new list new_list = [10, 4, 17, 21, 8, 12, 2] # sort list new_list.sort() # see results stored in new_list new_list  You can also sort a list using the sorted function:\nsorted_list = sorted(new_list)  How to get the length of a list Getting the length of a list can be done in a couple of different ways. The first, more commonly seen way, is using Python’s built-in len function.\na = [4, 5, 6] len(a) # returns 3 b = [10, 20, 30, 40, 50] len(b) # returns 5  You can also get the length of a list using the len method. Note the double underscore on each side of len.\na = [4, 5, 6] a.__len__() # returns 3 b = [10, 20, 30, 40, 50] b.__len__() # returns 5  How to get the index where an element first occurs Figuring out where in a list an element first occurs can be done using the index method.\nstrings = [\u0026quot;this\u0026quot;, \u0026quot;is\u0026quot;, \u0026quot;another\u0026quot;, \u0026quot;list\u0026quot;] strings.index(\u0026quot;another\u0026quot;) # returns 2 strings.index(\u0026quot;list\u0026quot;) # returns 3   Source : .\n "});index.add({'id':253,'href':'/library/tutorials/docs/python/snippets/unfold/','title':"unfold",'content':"Builds a list, using an iterator function and an initial seed value.\nThe iterator function accepts one argument (seed) and must always return a list with two elements ([value, nextSeed]) or False to terminate. Use a generator function, fn_generator, that uses a while loop to call the iterator function and yield the value until it returns False. Use list comprehension to return the list that is produced by the generator, using the iterator function.\ndef unfold(fn, seed): def fn_generator(val): while True: val = fn(val[1]) if val == False: break yield val[0] return [i for i in fn_generator([None, seed])]  f = lambda n: False if n \u0026gt; 50 else [-n, n + 10] unfold(f, 10) # [-10, -20, -30, -40, -50]  "});index.add({'id':254,'href':'/library/tutorials/docs/python/snippets/union/','title':"union",'content':"Returns every element that exists in any of the two lists once.\nCreate a set with all values of a and b and convert to a list.\ndef union(a, b): return list(set(a + b))  union([1, 2, 3], [4, 3, 2]) # [1,2,3,4]  "});index.add({'id':255,'href':'/library/tutorials/docs/python/snippets/union_by/','title':"union_by",'content':"Returns every element that exists in any of the two lists once, after applying the provided function to each element of both.\nCreate a set by applying fn to each element in a, then use list comprehension in combination with fn on b to only keep values not contained in the previously created set, _a. Finally, create a set from the previous result and a and transform it into a list\ndef union_by(a, b, fn): _a = set(map(fn, a)) return list(set(a + [item for item in b if fn(item) not in _a]))  from math import floor union_by([2.1], [1.2, 2.3], floor) # [2.1, 1.2]  "});index.add({'id':256,'href':'/library/tutorials/docs/python/snippets/unique_elements/','title':"unique_elements",'content':"Returns the unique elements in a given list.\nCreate a set from the list to discard duplicated values, then return a list from it.\ndef unique_elements(li): return list(set(li))  unique_elements([1, 2, 2, 3, 4, 3]) # [1, 2, 3, 4]  "});index.add({'id':257,'href':'/library/tutorials/docs/articles/webapp/javascript/javascript-use-map/','title':"Use .map(), .reduce(), and .filter()",'content':" Simplify your JavaScript – Use .map(), .reduce(), and .filter() Jan 29, 2018 · 7 min read\nIf you’re starting in JavaScript, maybe you haven’t heard of .map(), .reduce(), and .filter(). For me, it took a while as I had to support Internet Explorer 8 until a couple years ago. But if you don’t need to be compatible with this very old browser, you have to become familiar with those methods.\nTake note that this article most likely applies to whatever other programming language you might be using, as these are concepts that exist in many other languages.\n.map() Let me explain how it works with a simple example. Say you have received an array containing multiple objects – each one representing a person. The thing you really need in the end, though, is an array containing only the id of each person.\n// What you have var officers = [ { id: 20, name: 'Captain Piett' }, { id: 24, name: 'General Veers' }, { id: 56, name: 'Admiral Ozzel' }, { id: 88, name: 'Commander Jerjerrod' } ];  // What you need [20, 24, 56, 88]  There are multiple ways to achieve this. You might want to do it by creating an empty array, then using .forEach(), .for(...of), or a simple .for() to meet your goal.\nLet’s compare!\nUsing .forEach():\nvar officersIds = [];officers.forEach(function (officer) { officersIds.push(officer.id); });  Notice how you have to create an empty array beforehand? Let’s see what it looks like when using .map():\nvar officersIds = officers.map(function (officer) { return officer.id });  We can even be more concise with arrow functions (requires ES6 support, Babel or TypeScript)\nconst officersIds = officers.map(officer =\u0026gt; officer.id);  So how does .map() work? Basically is takes 2 arguments, a callback and an optional context (will be considered as this in the callback) which I did not use in the previous example. The callback runs for each value in the array and returns each new value in the resulting array.\nKeep in mind that the resulting array will always be the same length as the original array.\n.reduce() Just like .map(), .reduce() also runs a callback for each element of an array. What’s different here is that reduce passes the result of this callback (the accumulator) from one array element to the other.\nThe accumulator can be pretty much anything (integer, string, object, etc.) and must be instantiated or passed when calling .reduce().\nTime for an example! Say you have an array with these pilots and their respective years of experience:\nvar pilots = [ { id: 10, name: \u0026quot;Poe Dameron\u0026quot;, years: 14, }, { id: 2, name: \u0026quot;Temmin 'Snap' Wexley\u0026quot;, years: 30, }, { id: 41, name: \u0026quot;Tallissan Lintra\u0026quot;, years: 16, }, { id: 99, name: \u0026quot;Ello Asty\u0026quot;, years: 22, } ];  We need to know the total years of experience of all of them. With .reduce(), it’s pretty straightforward:\nvar totalYears = pilots.reduce(function (accumulator, pilot) {\nreturn accumulator + pilot.years;\n}, 0);\nNotice that I’ve set the starting value as 0. I could have also used an existing variable if necessary. After running the callback for each element of the array, reduce will return the final value of our accumulator (in our case: 82).\nLet’s see how this can be shortened with ES6’s arrow functions:\nconst totalYears = pilots.reduce((acc, pilot) =\u0026gt; acc + pilot.years, 0);\nNow let’s say I want to find which pilot is the most experienced one. For that, I can use reduce as well:\nvar mostExpPilot = pilots.reduce(function (oldest, pilot) {\nreturn (oldest.years || 0) \u0026gt; pilot.years ? oldest : pilot;\n}, {});\nI named my accumulator oldest. My callback compares the accumulator to each pilot. If a pilot has more years of experience than oldest, then that pilot becomes the new oldest so that’s the one I return.\nAs you can see, using .reduce() is an easy way to generate a single value or object from an array.\n.filter() What if you have an array, but only want some of the elements in it? That’s where .filter() comes in!\nHere’s our data:\nvar pilots = [ { id: 2, name: \u0026quot;Wedge Antilles\u0026quot;, faction: \u0026quot;Rebels\u0026quot;, }, { id: 8, name: \u0026quot;Ciena Ree\u0026quot;, faction: \u0026quot;Empire\u0026quot;, }, { id: 40, name: \u0026quot;Iden Versio\u0026quot;, faction: \u0026quot;Empire\u0026quot;, }, { id: 66, name: \u0026quot;Thane Kyrell\u0026quot;, faction: \u0026quot;Rebels\u0026quot;, } ];  Say we want two arrays now: one for rebel pilots, the other one for imperials. With .filter() it couldn’t be easier!\nvar rebels = pilots.filter(function (pilot) { return pilot.faction === \u0026quot;Rebels\u0026quot;; });var empire = pilots.filter(function (pilot) { return pilot.faction === \u0026quot;Empire\u0026quot;; });  That’s it! And it’s even shorter with arrow functions:\nconst rebels = pilots.filter(pilot =\u0026gt; pilot.faction === \u0026quot;Rebels\u0026quot;); const empire = pilots.filter(pilot =\u0026gt; pilot.faction === \u0026quot;Empire\u0026quot;);  Basically, if the callback function returns true, the current element will be in the resulting array. If it returns false, it won’t be.\nCombining .map(), .reduce(), and .filter() Since all three are called on arrays and since .map() and .filter() both return arrays, we can easily chain our calls.\nLet’s check out another example. Here’s our data:\nvar personnel = [ { id: 5, name: \u0026quot;Luke Skywalker\u0026quot;, pilotingScore: 98, shootingScore: 56, isForceUser: true, }, { id: 82, name: \u0026quot;Sabine Wren\u0026quot;, pilotingScore: 73, shootingScore: 99, isForceUser: false, }, { id: 22, name: \u0026quot;Zeb Orellios\u0026quot;, pilotingScore: 20, shootingScore: 59, isForceUser: false, }, { id: 15, name: \u0026quot;Ezra Bridger\u0026quot;, pilotingScore: 43, shootingScore: 67, isForceUser: true, }, { id: 11, name: \u0026quot;Caleb Dume\u0026quot;, pilotingScore: 71, shootingScore: 85, isForceUser: true, }, ];  Our objective: get the total score of force users only. Let’s do it step by step!\nFirst, we need to filter out the personnel who can’t use the force:\nvar jediPersonnel = personnel.filter(function (person) {\nreturn person.isForceUser;\n});// Result: {\u0026hellip;}, {\u0026hellip;}, {\u0026hellip;}\nWith that we have 3 elements left in our resulting array. We now need to create an array containing the total score of each Jedi.\nvar jediScores = jediPersonnel.map(function (jedi) { return jedi.pilotingScore + jedi.shootingScore; });// Result: [154, 110, 156]  And let’s use reduce to get the total:\nvar totalJediScore = jediScores.reduce(function (acc, score) { return acc + score; }, 0);// Result: 420  And now here’s the fun part… we can chain all of this to get what we want in a single line:\nvar totalJediScore = personnel .filter(function (person) { return person.isForceUser; }) .map(function (jedi) { return jedi.pilotingScore + jedi.shootingScore; }) .reduce(function (acc, score) { return acc + score; }, 0);  And look how pretty it is with arrow functions:\nconst totalJediScore = personnel .filter(person =\u0026gt; person.isForceUser) .map(jedi =\u0026gt; jedi.pilotingScore + jedi.shootingScore) .reduce((acc, score) =\u0026gt; acc + score, 0);  Boom! 💥\nNote: In my previous example, _.map()_ and _.filter()_ weren’t even necessary. We could easily achieve the same result with only _.reduce()_. I left them in there for the sake of this example. Can you guess how we could only keep _.reduce()_ and get the same result with one line of code? See the solution on CodePen\nWhy not use .forEach()? I used to use for loops everywhere instead of .map(), .reduce(), and .filter(). But a couple of years ago I started working a lot more with data that came from an API. That’s where I began to see the advantages of leaving .forEach behind.\nFormatting Say you need to display a list of people, with their name and job title.\nvar data = [ { name: \u0026quot;Jan Dodonna\u0026quot;, title: \u0026quot;General\u0026quot;, }, { name: \u0026quot;Gial Ackbar\u0026quot;, title: \u0026quot;Admiral\u0026quot;, }, ]  The API gives you the above data, but you only need the title and the last name of each person… You need to format the data. However, your app also needs to have a single view for each person, so you must write a data formatting function that both works in a list view and in a single view.\nThat means you can’t have the .forEach loop inside of your formatting function, or else you would have to wrap your single element in an array before you pass it to the function just to make it work, like so:\nvar result = formatElement([element])[0]; // Yeah... that's not right at all  So your loop has to wrap the call of the function, like this:\ndata.forEach(function (element) { var formatted = formatElement(element); // But what then.... });  But .forEach() doesn’t return anything. It can’t. That means you have to push the results inside a predetermined array.\nvar results = [];data.forEach(function (element) { var formatted = formatElement(element); results.push(formatted); });  As a result, you have 2 functions: your formatElement() function and your function that pushes the results in your array.\nWhy have 2 functions when you can have just one?\nvar results = data.map(formatElement);\nTesting is easier If you write unit tests for your code, you’ll find it simpler to test the functions you call with .map(), .reduce(), or .filter().\nAll you have to do is provide inbound data for the function and expect a result to come out. Basically “what comes out if this is passed?”. Less manipulation, less beforeEach()s and afterEach()s. It’s straightforward, simple testing.\nTry it! Try to replace some of your for loops with .map(), .reduce(), .filter() where it seems to fit. I guarantee your code will be way less clunky and much easier to read.\nIf you liked that article and want to learn more array methods, check out my article on how to use [.some()](https://medium.com/poka-techblog/simplify-your-javascript-use-some-and-find-f9fb9826ddfd) and [.find()](https://medium.com/poka-techblog/simplify-your-javascript-use-some-and-find-f9fb9826ddfd) in JavaScript.\nKeep coding!\n[](https://medium.com/poka-techblog?source=post_sidebar--------------------------post_sidebar-)\n Written with StackEdit.\n "});index.add({'id':258,'href':'/library/tutorials/docs/python/flask/flask-blueprint/','title':"Use a Flask Blueprint",'content':" Use a Flask Blueprint to Architect Your Applications Flask is a very popular web application framework that leaves almost all design and architecture decisions up to the developer. In this tutorial, you’ll learn how a Flask Blueprint, or Blueprint for short, can help you structure your Flask application by grouping its functionality into reusable components.\nIn this tutorial, you’ll learn:\n What Flask Blueprints are and how they work How to create and use a Flask Blueprint to organize your code How to improve code reusability using your own or a third-party Flask Blueprint  This tutorial assumes that you have some experience using Flask and that you’ve built some applications before. If you haven’t used Flask before, then check out Python Web Applications with Flask (Tutorial Series).\nFree Bonus: Click here to get access to a free Flask + Python video tutorial that shows you how to build Flask web app, step-by-step.\nWhat a Flask Application Looks Like Let’s start by reviewing the structure of a small Flask application. You can create a small web application by following the steps in this section. To get started, you need to install the Flask Python package. You can run the following command to install Flask using pip:\n$ pip install Flask==1.1.1  The above command installs Flask version 1.1.1. This is the version you’ll use throughout this tutorial, though you can apply what you’ll learn here to other versions, as well.\nNote: For more information on how to install Flask in a virtual environment and other pip options, check out Python Virtual Environments: A Primer and What Is Pip? A Guide for New Pythonistas.\nAfter you install Flask, you’re ready to start implementing its functionality. Since Flask doesn’t impose any restrictions on project structure, you can organize your project’s code as you want. For your first application, you can use a very straightforward layout, as shown below. A single file will contain all the application logic:\napp/ | └── app.py  The file app.py will contain the definition of the application and its views.\nWhen you create a Flask application, you start by creating a Flask object that represents your application, and then you associate views to routes. Flask takes care of dispatching incoming requests to the correct view based on the request URL and the routes you’ve defined.\nIn Flask, views can be any callable (like a function) that receives requests and returns the response for that request. Flask is responsible for sending the response back to the user.\nThe following code block is your application’s full source code:\nfrom flask import Flask app = Flask(__name__) @app.route('/') def index(): return \u0026quot;This is an example app\u0026quot;  This code creates the object app, which belongs to the Flask class. The view function index() is linked to the route / using the app.route decorator. To learn more about decorators, check out Primer on Python Decorators and Python Decorators 101.\nYou can run the application with the following command:\n$ flask run  By default, Flask will run the application you defined in app.py on port 5000. While the application is running, go to http://localhost:5000 using your web browser. You’ll see a page showing the message, This is an example app.\nThe chosen project layout is great for very small applications, but it doesn’t scale well. As your code grows, it can become harder for you to maintain everything in a single file. So, when your application grows in size or complexity, you may want to structure your code in a different way to keep it maintainable and clear to understand. Throughout this tutorial, you’ll learn how to use a Flask Blueprint to achieve this.\nWhat a Flask Blueprint Looks Like Flask Blueprints encapsulate functionality, such as views, templates, and other resources. To get a taste for how a Flask Blueprint would work, you can refactor the previous application by moving the index view into a Flask Blueprint. To do so, you have to create a Flask Blueprint that contains the index view and then use it in the application.\nThis is what the file structure looks like for this new application:\napp/ | ├── app.py └── example_blueprint.py  example_blueprint.py will contain the Flask Blueprint implementation. You’ll then modify app.py to use it.\nThe following code block shows how you can implement this Flask Blueprint in example_blueprint.py. It contains a view at the route / that returns the text This is an example app:\nfrom flask import Blueprint example_blueprint = Blueprint('example_blueprint', __name__) @example_blueprint.route('/') def index(): return \u0026quot;This is an example app\u0026quot;  In the above code, you can see the steps common to most Flask Blueprint definitions:\n Create a Blueprint object called example_blueprint. Add views to example_blueprint using the route decorator.  The following code block shows how your application imports and uses the Flask Blueprint:\nfrom flask import Flask from example_blueprint import example_blueprint app = Flask(__name__) app.register_blueprint(example_blueprint)  To use any Flask Blueprint, you have to import it and then register it in the application using register_blueprint(). When a Flask Blueprint is registered, the application is extended with its contents.\nYou can run the application with the following command:\n$ flask run  While the application is running, go to http://localhost:5000 using your web browser. You’ll see a page showing the message, This is an example app.\nHow Flask Blueprints Work In this section, you’ll learn in detail how a Flask Blueprint is implemented and used. Each Flask Blueprint is an object that works very similarly to a Flask application. They both can have resources, such as static files, templates, and views that are associated with routes.\nHowever, a Flask Blueprint is not actually an application. It needs to be registered in an application before you can run it. When you register a Flask Blueprint in an application, you’re actually extending the application with the contents of the Blueprint.\nThis is the key concept behind any Flask Blueprint. They record operations to be executed later when you register them on an application. For example, when you associate a view to a route in a Flask Blueprint, it records this association to be made later in the application when the Blueprint is registered.\nMaking a Flask Blueprint Let’s revisit the Flask Blueprint definition that you’ve seen previously and review it in detail. The following code shows the Blueprint object creation:\nfrom flask import Blueprint example_blueprint = Blueprint('example_blueprint', __name__)  Note that in the above code, some arguments are specified when creating the Blueprint object. The first argument, \u0026quot;example_blueprint\u0026quot;, is the Blueprint’s name, which is used by Flask’s routing mechanism. The second argument, __name__, is the Blueprint’s import name, which Flask uses to locate the Blueprint’s resources.\nThere are other optional arguments that you can provide to alter the Blueprint’s behavior:\n static_folder: the folder where the Blueprint’s static files can be found\n static_url_path: the URL to serve static files from\n template_folder: the folder containing the Blueprint’s templates\n url_prefix: the path to prepend to all of the Blueprint’s URLs\n subdomain: the subdomain that this Blueprint’s routes will match on by default\n url_defaults: a dictionary of default values that this Blueprint’s views will receive\n root_path: the Blueprint’s root directory path, whose default value is obtained from the Blueprint’s import name\n  Note that all paths, except root_path, are relative to the Blueprint’s directory.\nThe Blueprint object example_blueprint has methods and decorators that allow you to record operations to be executed when registering the Flask Blueprint in an application to extend it. One of the most used decorators is route. It allows you to associate a view function to a URL route. The following code block shows how this decorator is used:\n@example_blueprint.route('/') def index(): return \u0026quot;This is an example app\u0026quot;  You decorate index() using example_blueprint.route and associate the function to the URL /.\nBlueprint objects also provide other methods that you may find useful:\n .errorhandler() to register an error handler function .before_request() to execute an action before every request .after_request() to execute an action after every request .app_template_filter() to register a template filter at the application level  You can learn more about using Blueprints and the Blueprint class in the Flask Blueprints Documentation.\nRegistering the Blueprint in Your Application Recall that a Flask Blueprint is not actually an application. When you register the Flask Blueprint in an application, you extend the application with its contents. The following code shows how you can register the previously-created Flask Blueprint in an application:\nfrom flask import Flask from example_blueprint import example_blueprint app = Flask(__name__) app.register_blueprint(example_blueprint)  When you call .register_blueprint(), you apply all operations recorded in the Flask Blueprint example_blueprint to app. Now, requests to the app for the URL / will be served using .index() from the Flask Blueprint.\nYou can customize how the Flask Blueprint extends the application by providing some parameters to register_blueprint:\n url_prefix is an optional prefix for all the Blueprint’s routes. subdomain is a subdomain that Blueprint routes will match. url_defaults is a dictionary with default values for view arguments.  Being able to do some customization at registration time, instead of at creation time, is particularly useful when you’re sharing the same Flask Blueprint in different projects.\nIn this section, you’ve seen how Flask Blueprints work and how you can create them and use them. In the following sections, you’ll learn how you can leverage a Flask Blueprint to architect your applications, structuring them into independent components. In some cases, it’s also possible for you to reuse these components in different applications to reduce development time!\nHow to Use Flask Blueprints to Architect Your Application’s Code In this section, you’re going to see how you can refactor an example application using a Flask Blueprint. The example application is an e-commerce site with the following features:\n Visitors can sign up, log in, and recover passwords. Visitors can search for products and view their details. Users can add products to their cart and checkout. An API enables external systems to search and retrieve product information.  You don’t need to care much about the details of the implementation. Instead, you’ll focus mainly on how a Flask Blueprint can be used to improve the application’s architecture.\nUnderstanding Why Project Layout Matters Remember, Flask does not enforce any particular project layout. It’s completely feasible to organize this application’s code as follows:\necommerce/ | ├── static/ | ├── logo.png | ├── main.css | ├── generic.js | └── product_view.js | ├── templates/ | ├── login.html | ├── forgot_password.html | ├── signup.html | ├── checkout.html | ├── cart_view.html | ├── index.html | ├── products_list.html | └── product_view.html | ├── app.py ├── config.py └── models.py  This application’s code is organized using these directories and files:\n static/ contains the application’s static files. templates/ contains the application’s templates. models.py contains the definition of the application’s models. app.py contains the application logic. config.py contains the application configuration parameters.  This is an example of how many applications begin. Although this layout is pretty straightforward, it has several drawbacks that arise as the app complexity increases. For example, it will be hard for you to reuse the application logic in other projects because all the functionality is bundled in app.py. If you split this functionality into modules instead, then you could reuse complete modules across different projects.\nAlso, if you have just one file for the application logic, then you would end up with a very large app.py that mixes code that’s nearly unrelated. This can make it hard for you to navigate and maintain the script.\nWhat’s more, large code files are a source of conflicts when you’re working in a team, since everybody will be making changes to the same file. These are just a few reasons why the previous layout is only good for very small applications.\nOrganizing Your Projects Instead of structuring the application using the previous layout, you can leverage a Flask Blueprint to split the code into different modules. In this section, you’ll see how to architect the previous application to make Blueprints that encapsulate related functionality. In this layout, there are five Flask Blueprints:\n API Blueprint to enable external systems to search and retrieve product information Authentication Blueprint to enable users to log in and recover their password Cart Blueprint for cart and checkout functionality General Blueprint for the homepage Products Blueprint for searching and viewing products  If you use a separate directory for each Flask Blueprint and its resources, then the project layout would look as follows:\necommerce/ | ├── api/ | ├── __init__.py | └── api.py | ├── auth/ | ├── templates/ | | └── auth/ | | ├── login.html | | ├── forgot_password.html | | └── signup.html | | | ├── __init__.py | └── auth.py | ├── cart/ | ├── templates/ | | └── cart/ | | ├── checkout.html | | └── view.html | | | ├── __init__.py | └── cart.py | ├── general/ | ├── templates/ | | └── general/ | | └── index.html | | | ├── __init__.py | └── general.py | ├── products/ | ├── static/ | | └── view.js | | | ├── templates/ | | └── products/ | | ├── list.html | | └── view.html | | | ├── __init__.py | └── products.py | ├── static/ | ├── logo.png | ├── main.css | └── generic.js | ├── app.py ├── config.py └── models.py  To organize code in this way, you move all views from app.py into the corresponding Flask Blueprint. You also moved templates and non-global static files. This structure makes it easier for you to find the code and resources related to a given functionality. For example, if you want to find the application logic about products, then you can go to the Products Blueprint in products/products.py instead of scrolling through app.py.\nLet’s see the Products Blueprint implementation in products/products.py:\nfrom flask import Blueprint, render_template from ecommerce.models import Product products_bp = Blueprint('products_bp', __name__, template_folder='templates', static_folder='static', static_url_path='assets') @products_bp.route('/') def list(): products = Product.query.all() return render_template('products/list.html', products=products) @products_bp.route('/view/\u0026lt;int:product_id\u0026gt;') def view(product_id): product = Product.query.get(product_id) return render_template('products/view.html', product=product)  This code defines the products_bp Flask Blueprint and contains only the code that’s related to product functionality. Since this Flask Blueprint has its own templates, you need to specify the template_folder relative to the Blueprint’s root in the Blueprint object creation. Since you specify static_folder='static' and static_url_path='assets', files in ecommerce/products/static/ will be served under the /assets/ URL.\nNow you can move the rest of your code’s functionality to the corresponding Flask Blueprint. In other words, you can create Blueprints for API, authentication, cart, and general functionality. Once you’ve done so, the only code left in app.py will be code that deals with application initialization and Flask Blueprint registration:\nfrom flask import Flask from ecommmerce.api.api import api_bp from ecommmerce.auth.auth import auth_bp from ecommmerce.cart.cart import cart_bp from ecommmerce.general.general import general_bp from ecommmerce.products.products import products_bp app = Flask(__name__) app.register_blueprint(api_bp, url_prefix='/api') app.register_blueprint(auth_bp) app.register_blueprint(cart_bp, url_prefix='/cart') app.register_blueprint(general_bp) app.register_blueprint(products_bp, url_prefix='/products')  Now, app.py simply imports and registers the Blueprints to extend the application. Since you use url_prefix, you can avoid URL collisions between Flask Blueprint routes. For example, the URLs /products/ and /cart/ resolve to different endpoints defined in the products_bp and cart_bp Blueprints for the same route, /.\nIncluding Templates In Flask, when a view renders a template, the template file is searched in all the directories that were registered in the application’s template search path. By default, this path is [\u0026quot;/templates\u0026quot;], so templates are only searched for in the /templates directory inside the application’s root directory.\nIf you set the template_folder argument in a Blueprint’s creation, then its templates folder is added to the application’s template search path when the Flask Blueprint is registered. However, if there are duplicated file paths under different directories that are part of the template search path, then one will take precedence, depending on their registration order.\nFor example, if a view requests the template view.html and there are files with this same name in different directories in the template search path, then one of these will take precedence over the other. Since it may be hard to remember the precedence order, it’s best to avoid having files under the same path in different template directories. That’s why the following structure for the templates in the application makes sense:\necommerce/ | └── products/ └── templates/ └── products/ ├── search.html └── view.html  At first, it may look redundant to have the Flask Blueprint name appear twice:\n As the Blueprint’s root directory Inside the templates directory  However, know that by doing this, you can avoid possible template name collisions between different Blueprints. Using this directory structure, any views requiring the view.html template for products can use products/view.html as the template file name when calling render_template. This avoids conflicts with the view.html that belongs to the Cart Blueprint.\nAs a final note, it’s important to know that templates in the application’s template directory have greater precedence than those inside the Blueprint’s template directory. This can be useful to know if you want to override Flask Blueprint templates without actually modifying the template file.\nFor example, if you wanted to override the template products/view.html in the Products Blueprint, then you can accomplish this by creating a new file products/view.html in the application templates directory:\necommerce/ | ├── products/ | └── templates/ | └── products/ | ├── search.html | └── view.html | └── templates/ └── products/ └── view.html  When you do this, your program will use templates/products/view.html instead of products/templates/products/view.html whenever a view requires the template products/view.html.\nProviding Functionality Other Than Views So far, you’ve only seen Blueprints that extend applications with views, but Flask Blueprints don’t have to provide just views! They can extend applications with templates, static files, and template filters. For example, you could create a Flask Blueprint to provide a set of icons and use it across your applications. This would be the file structure for such a Blueprint:\napp/ | └── icons/ ├── static/ | ├── add.png | ├── remove.png | └── save.png | ├── __init__.py └── icons.py  The static folder contains the icon files and icons.py is the Flask Blueprint definition.\nThis is how icons.py might look:\nfrom flask import Blueprint icons_bp = Blueprint('icons_bp', __name__, static_folder='static', static_url_path='icons')  This code defines the icons_bp Flask Blueprint that exposes the files in the static directory under the /icons/ URL. Note that this Blueprint does not define any route.\nWhen you can create Blueprints that package views and other types of content, you make your code and assets more reusable across your applications. You’ll learn more about Flask Blueprint reusability in the following section.\nHow to Use Flask Blueprints to Improve Code Reuse Besides code organization, there’s another advantage to structuring your Flask application as a collection of independent components. You can reuse these components even across different applications! For example, if you created a Flask Blueprint that provides functionality for a contact form, then you can reuse it in all your applications.\nYou can also leverage Blueprints created by other developers to accelerate your work. While there’s no centralized repository for existing Flask Blueprints, you can find them using the Python Package Index, GitHub Search, and web search engines. You can learn more about searching PyPI packages in What Is Pip? A Guide for New Pythonistas.\nThere are various Flask Blueprints and Flask Extensions (which are implemented using Blueprints) that provide functionality that you may find useful:\n Authentication Admin/CRUD generation CMS functionality And more!  Instead of coding your application from scratch, you may consider searching for an existing Flask Blueprint or Extension that you can reuse. Leveraging third-party Blueprints and Extensions can help you to reduce development time and keep your focus on your application’s core logic!\nConclusion In this tutorial, you’ve seen how Flask Blueprints work, how to use them, and how they can help you to organize your application’s code. Flask Blueprints are a great tool for dealing with application complexity as it increases.\nYou’ve learned:\n What Flask Blueprints are and how they work How you can implement and use a Flask Blueprint How Flask Blueprints can help you to organize your application’s code How you can use Flask Blueprints to ease the reusability of your own and third-party components How using a Flask Blueprint in your project can reduce development time  You can use what you’ve learned in this tutorial to start organizing your applications as a set of blueprints. When you architect your applications this way, you’ll improve code reuse, maintainability, and teamwork!\n Source : .\n "});index.add({'id':259,'href':'/library/tutorials/docs/python/snippets/values_only/','title':"values_only",'content':"Returns a flat list of all the values in a flat dictionary.\nUse dict.values() to return the values in the given dictionary. Return a list() of the previous result.\ndef values_only(flat_dict): return list(flat_dict.values())  ages = { \u0026quot;Peter\u0026quot;: 10, \u0026quot;Isabel\u0026quot;: 11, \u0026quot;Anna\u0026quot;: 9, } values_only(ages) # [10, 11, 9]  "});index.add({'id':260,'href':'/library/tutorials/docs/articles/data-science/web-scraping/web-scraping-101/','title':"Web Scraping 101",'content':" Web Scraping 101 in Python : overview of the tools \u0026amp; the pros and cons of each Summary:  Web Fundamentals Manually opening a socket and sending the HTTP request urllib3 \u0026amp; LXML requests \u0026amp; BeautifulSoup Scrapy Selenium \u0026amp; Chrome —headless Conclusion  Web Fundamentals The internet is really complex–there are many underlying technologies and concepts involved to view a simple web page in your browser. I\u0026rsquo;m not going to explain everything, but I will show you the most important things you have to understand in order to extract data from the web.\nHyperText Transfer Protocol HTTP uses a client/server model, where an HTTP client (a browser, your Python program, curl, Requests, and so on) opens a connection and sends a message (“I want to see the /product page”) to an HTTP server (like Nginx, Apache, and others).\nThen the server answers with a response (the HTML code, for example) and closes the connection. HTTP is called a stateless protocol, because each transaction (request/response) is independent. FTP, for example, is stateful.\nBasically, when you type a website address in your browser, the HTTP request looks like this:\nGET /product/ HTTP/1.1 Host: example.com Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/web\\ p,*/*;q=0.8 Accept-Encoding: gzip, deflate, sdch, br Connection: keep-alive User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit\\ /537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36  In the first line of this request, you can see multiples things:\n The GET verb or method being used, meaning we request data from the specific path, /product/. There are other HTTP verbs, and you can see the full list here. The version of the HTTP protocol. In this tutorial we will focus on HTTP 1. Multiple headers fields.  Here are the most important header fields:\n Host: The domain name of the server. If no port number is given, it is assumed to be 80. User-Agent: Contains information about the client originating the request, including the OS information. In this case, it is my web-browser (Chrome), on OSX. This header is important because it is either used for statistics (how many users visit my website on mobile vs. desktop) or to prevent any violations by bots. Because these headers are sent by the clients, it can be modified with a technique called “Header Spoofing”. This is exactly what we will do with our scrapers to make them look like a normal web browser. Accept: The content types that are acceptable as a response. There are lots of different content types and sub-types: text/plain, text/html, image/jpeg, application/json \u0026hellip; Cookie : name1=value1;name2=value2\u0026hellip; This header field contains a list of name-value pairs. These are called session cookies, and are what websites use to authenticate users and store data in your browser. For example, when you fill in a login form, the server will check if the credentials you entered are correct. If so, it will redirect you and inject a session cookie in your browser. Your browser will then send this cookie with every subsequent request to that server. Referrer: The Referrer header contains the URL from which the actual URL has been requested. This header is important because websites use this header to change their behavior based on where the user came from. For example, lots of news websites have a paying subscription and let you view only 10% of a post. But if the user came from a news aggregator like Reddit, they let you view the full content. Sites use the referrer to check this. Sometimes we will have to spoof this header to get to the content we want to extract.  And the list goes on. You can find the full header list here.\nA server will respond with something like this:\nHTTP/1.1 200 OK Server: nginx/1.4.6 (Ubuntu) Content-Type: text/html; charset=utf-8 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;utf-8\u0026quot; /\u0026gt; ...[HTML CODE]  On the first line, we have a new piece of information, the HTTP code 200 OK. This means the request has succeeded. As for the request headers, there are lots of HTTP codes, split into four common classes: 2XX for successful requests, 3XX for redirects, 4XX for bad requests (the most famous being 404 Not found), and 5XX for server errors.\nIf you are sending an HTTP request with your web browser, it will parse the HTML code, fetch all the eventual assets (JavaScript, CSS, and image files) and render the result into the main window.\nIn the next section we will see the different ways to perform HTTP requests with Python and extract the data we want from the responses.\nManually opening a socket and sending the HTTP request Socket The most basic way to perform an HTTP request in Python is to open a socket and manually send the HTTP request:\nimport socket HOST = 'www.google.com' # Server hostname or IP address PORT = 80 # Port client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM) server_address = (HOST, PORT) client_socket.connect(server_address) request_header = b'GET / HTTP/1.0\\r\\nHost: www.google.com\\r\\n\\r\\n' client_socket.sendall(request_header) response = '' while True: recv = client_socket.recv(1024) if not recv: break response += str(recv) print(response) client_socket.close()  Now that we have the HTTP response, the most basic way to extract data from it is to use regular expressions.\nRegular Expressions A regular expression (RE, or Regex) is a search pattern for strings. With regex, you can search for a particular character or word inside a bigger body of text.\nFor example, you could identify all the phone numbers on a web page. You can also replace items easily. For example, you can replace all the uppercase tags in poorly formatted HTML with lowercase ones. You can also validate some inputs.\nYou may be wondering, why it is important to know about regular expressions when doing web scraping? After all, there are all kinds of different Python modules to parse HTML, XPath, and CSS selectors.\nIn an ideal semantic world, data is easily machine-readable, and information is embedded inside relevant HTML elements with meaningful attributes.\nBut the real world is messy. You will often find huge amounts of text inside a p element. When you want to extract specific data inside this huge block of text like a price, date, or name, you will have to use regular expressions.\nNote: Here is a great website to test your regex, and one awesome blog to learn more about them. This post will only cover a small fraction of what you can do with regular expressions.\nRegular expressions can be useful when you have this kind of data:\n\u0026lt;p\u0026gt;Price : 19.99$\u0026lt;/p\u0026gt;  We could select this text node with an Xpath expression, and then use this kind of regex to extract the price. Remember that regex patterns are applied from left to right, and each source character is only used once.:\n^Price\\s:\\s(\\d+\\.\\d{2})\\$  To extract the text inside an HTML tag, it is annoying to use a regex, but doable:\nimport re html_content = '\u0026lt;p\u0026gt;Price : 19.99$\u0026lt;/p\u0026gt;' m = re.match('\u0026lt;p\u0026gt;(.+)\u0026lt;\\/p\u0026gt;', html_content) if m: print(m.group(1))  As you can see, manually sending the HTTP request with a socket and parsing the response with regular expressions can be done, but it\u0026rsquo;s complicated. There are higher-level APIs that can make this task a lot easier.\nurllib3 \u0026amp; LXML Disclaimer: It is easy to get lost in the urllib universe in Python. You have urllib and urllib2 that are parts of the standard library, but there\u0026rsquo;s also urllib3. urllib2 was split into multiple modules in Python 3, and urllib3 should not be a part of the standard library anytime soon. All of these confusing details will be the subject of its own blog post. In this section, I chose to only talk about urllib3 as it widely used in the Python world.\nurllib3 is a high-level package that allows you to do pretty much whatever you want with an HTTP request. We can do what we did with socket above with way fewer lines of code:\nimport urllib3 http = urllib3.PoolManager() r = http.request('GET', 'http://www.google.com') print(r.data)  Much more concise than the socket version, isn\u0026rsquo;t it? Not only that, but the API is straightforward, and you can do many things easily like adding HTTP headers, using a proxy, POSTing forms, and so on.\nFor example, if we had to set some headers to use a proxy, we would only have to do this:\nimport urllib3 user_agent_header = urllib3.make_headers(user_agent=\u0026quot;\u0026lt;USER AGENT\u0026gt;\u0026quot;) pool = urllib3.ProxyManager(f'\u0026lt;PROXY IP\u0026gt;', headers=user_agent_header) r = pool.request('GET', 'https://www.google.com/')  See? Exactly the same number of lines.\nHowever, there are some things that urllib3 does not handle very easily. If we want to add a cookie, we have to manually create the corresponding headers and add it to the request.\nThere are also things that urllib3 can do that requests can\u0026rsquo;t, like creation and management of pool and proxy pool, and control of retry strategy.\nTo put it simply, urllib3 falls between requests and socket in terms of abstraction, although it\u0026rsquo;s way closer to requests than socket.\nTo parse the response, we are going to use the lxml package and XPath expressions.\nXPath Xpath is a technology that uses path expressions to select nodes or node sets in an XML or HTML document. As with the Document Object Model, Xpath is a W3C standard since 1999. Even if Xpath is not a programming language in itself, it allows you to write expressions that can directly access a specific node or node-set without having to go through the entire XML or HTML tree.\nThink of XPath as a sort of regular expression, but specifically for XML or HMTL.\nTo extract data from an HTML document with XPath we need 3 things:\n an HTML document some XPath expressions an XPath engine that will run those expressions  To begin, we will use the HTML that we got thanks to urllib3. We just want to extract all the links from the Google homepage, so we will use one simple XPath expression, //a, and use LXML to run it. LXML is a fast and easy to use XML and HTML processing library that supports XPATH.\nInstallation:\npip install lxml  Below is the code that comes just after the previous snippet:\nfrom lxml import html # We reuse the reponse from urllib3 data_string = r.data.decode('utf-8', errors='ignore') # We instantiate a tree object from the HTML tree = html.fromstring(data_string) # We run the XPath against this HTML # This returns an array of element links = tree.xpath('//a') for link in links: # For each element we can easily get back the URL print(link.get('href'))  And the output should look like this:\nhttps://books.google.fr/bkshp?hl=fr\u0026amp;tab=wp https://www.google.fr/shopping?hl=fr\u0026amp;source=og\u0026amp;tab=wf https://www.blogger.com/?tab=wj https://photos.google.com/?tab=wq\u0026amp;pageId=none http://video.google.fr/?hl=fr\u0026amp;tab=wv https://docs.google.com/document/?usp=docs_alc ... https://www.google.fr/intl/fr/about/products?tab=wh  Keep in mind that this example is really, really simple, and doesn\u0026rsquo;t really show you how powerful XPath can be. (Note: this XPath expression should have been changed to //a/@href to avoid having to iterate through links to get their href).\nIf you want to learn more about XPath you can read this good introduction. The LXML documentation is also well written and is a good starting point.\nXPath expresions, like regexp, are really powerful and one of the fastest ways to extract information from HTML. Though also like regexp, XPath can quickly become messy, hard to read, and hard to maintain.\nrequests \u0026amp; BeautifulSoup Requests is the king of Python packages–with more than 11,000,000 downloads, it is the most widely used package for Python.\nInstallation:\npip install requests  Making a request with Requests (no comment) is really easy:\nimport requests r = requests.get('https://www.scrapingbee.com') print(r.text)  With Requests it is easy to do things like perform POST requests, handle cookies, and query parameters.\nAuthentication to Hacker News Let\u0026rsquo;s say we want to create a tool to automatically submit our blog post to Hacker News or any other forums like Buffer. We would need to authenticate to those websites before posting our link. That\u0026rsquo;s what we are going to do with Requests and BeautifulSoup!\nHere is the Hacker News login form and the associated DOM:\nThere are three \u0026lt;input\u0026gt; tags on this form. The first one has a type hidden with the name \u0026ldquo;goto\u0026rdquo;, and the two others are the username and password.\nIf you submit the form inside your Chrome browser, you will see that there is a lot going on: a redirect and a cookie is being set. This cookie will be sent by Chrome on each subsequent request in order for the server to know that you are authenticated.\nDoing this with Requests is easy–it will handle redirects automatically for us, and handling cookies can be done with the Session object.\nThe next thing we will need is BeautifulSoup, which is a Python library that will help us parse the HTML returned by the server to find out if we are logged in or not.\nInstallation:\npip install beautifulsoup4  So all we have to do is to POST these three inputs with our credentials to the /login endpoint and check for the presence of an element that is only displayed once logged in:\nimport requests from bs4 import BeautifulSoup BASE_URL = 'https://news.ycombinator.com' USERNAME = \u0026quot;\u0026quot; PASSWORD = \u0026quot;\u0026quot; s = requests.Session() data = {\u0026quot;gogo\u0026quot;: \u0026quot;news\u0026quot;, \u0026quot;acct\u0026quot;: USERNAME, \u0026quot;pw\u0026quot;: PASSWORD} r = s.post(f'{BASE_URL}/login', data=data) soup = BeautifulSoup(r.text, 'html.parser') if soup.find(id='logout') is not None: print('Successfuly logged in') else: print('Authentication Error')  In order to learn more about BeautifulSoup, we could try to extract every link on the homepage.\nBy the way, Hacker News offers a powerful API, so we\u0026rsquo;re doing this as an example. You should really use the API instead of scraping it!\nThe first thing we need to do is to inspect the Hacker News home page to understand the structure and the different CSS classes that we will have to select:\nWe can see that all posts are inside a \u0026lt;tr class=\u0026quot;athing\u0026quot;\u0026gt; , so the first thing we will need to do is to select all these tags. This can be easily done with:\nlinks = soup.findAll('tr', class_='athing')  Then for each link, we will extract its id, title, url and rank:\nimport requests from bs4 import BeautifulSoup r = requests.get('https://news.ycombinator.com') soup = BeautifulSoup(r.text, 'html.parser') links = soup.findAll('tr', class_='athing') formatted_links = [] for link in links: data = { 'id': link['id'], 'title': link.find_all('td')[2].a.text, \u0026quot;url\u0026quot;: link.find_all('td')[2].a['href'], \u0026quot;rank\u0026quot;: int(links[0].td.span.text.replace('.', '')) } formatted_links.append(data) print(formatted_links)  As you saw, Requests and BeautifulSoup are great libraries to extract data and automate different things like filling out forms. If you want to do large-scale web scraping projects, you could still use Requests, but you would need to handle lots of things yourself.\nWhen you need to scrape a lots of webpages, there are many things you have to take care of:\n finding a way of parallelizing your code to make it faster handling errors storing results filtering results throttling your requests so you don\u0026rsquo;t overload the server  Fortunately for us, tools exist that can handle all of those things for us.\nScrapy Scrapy is a powerful Python web scraping framework. It provides many features to download web pages asynchronously, process, and save it. It handles multithreading, crawling (the process of going from link to link to find every URL in a website), sitemap crawling, and much more.\nScrapy has also an interactive mode called the Scrapy Shell. With Scrapy Shell, you can test your things in your scraping code really quickly like XPath expression or CSS selectors.\nThe downside of Scrapy is that the learning curve is steep–there is a lot to learn.\nTo follow up on our example about Hacker News, we are going to write a Scrapy Spider that scrapes the first 15 pages of results and saves everything in a CSV file.\nYou can easily install Scrapy with pip:\npip install Scrapy  Then you can use the scrapy cli to generate the boilerplate code for our project:\nscrapy startproject hacker_news_scraper  Inside hacker_news_scraper/spider we will create a new Python file with our Spider\u0026rsquo;s code:\nfrom bs4 import BeautifulSoup import scrapy class HnSpider(scrapy.Spider): name = \u0026quot;hacker-news\u0026quot; allowed_domains = [\u0026quot;news.ycombinator.com\u0026quot;] start_urls = [f'https://news.ycombinator.com/news?p={i}' for i in range(1,16)] def parse(self, response): soup = BeautifulSoup(response.text, 'html.parser') links = soup.findAll('tr', class_='athing') for link in links: yield { 'id': link['id'], 'title': link.find_all('td')[2].a.text, \u0026quot;url\u0026quot;: link.find_all('td')[2].a['href'], \u0026quot;rank\u0026quot;: int(link.td.span.text.replace('.', '')) }  There is a lot of convention in Scrapy. Here we define an Array of starting URLs. The attribute name will be used to call our Spider with the Scrapy command line.\nThe parse method will be called on each URL in the start_urls array\nWe then need to tune Scrapy a little bit in order for our Spider to behave nicely against the target website.\n# Enable and configure the AutoThrottle extension (disabled by default) # See https://doc.scrapy.org/en/latest/topics/autothrottle.html AUTOTHROTTLE_ENABLED = True # The initial download delay AUTOTHROTTLE_START_DELAY = 5  You should always turn this on. It will make sure the target website will not slow down because of your spiders by analyzing the response time and adapting the number of concurrent threads.\nYou can run this code with the Scrapy CLI and with different output format (CSV, JSON, XML, and so on):\nscrapy crawl hacker-news -o links.json  And that\u0026rsquo;s it! You will now have all your links in a nicely formatted JSON file.\nSelenium \u0026amp; Chrome Scrapy is really nice for large-scale web scraping tasks. But it is not enough if you need to scrape Single Page Applications written with JavaScript frameworks because it won\u0026rsquo;t be able to render the JavaScript code.\nIt can be challenging to scrape these SPAs because there are often lots of AJAX calls and websockets connections involved. If performance is an issue, you should always try to reproduce the JavaScript code, meaning manually inspecting all the network calls with your browser inspector and replicating the AJAX calls containing the interesting data.\nIn some cases, there are just too many asynchronous HTTP calls involved to get the data you want, and it can be easier to just render the page in a headless browser.\nAnother great use case would be to take a screenshot of a page. This is what we are going to do with the Hacker News homepage (again !)\nYou can install the Selenium package with pip:\npip install selenium  You will also need Chromedriver:\nbrew install chromedriver  Then we just have to import the Webdriver from the Selenium package, configure Chrome with headless=True, and set a window size (otherwise it is really small):\nfrom selenium import webdriver from selenium.webdriver.chrome.options import Options options = Options() options.headless = True options.add_argument(\u0026quot;--window-size=1920,1200\u0026quot;) driver = webdriver.Chrome(options=options, executable_path=r'/usr/local/bin/chromedriver') driver.get(\u0026quot;https://news.ycombinator.com/\u0026quot;) driver.save_screenshot('hn_homepage.png') driver.quit()  You should then get a nice screenshot of the homepage:\nYou can do many more things with the Selenium API and Chrome like:\n Executing JavaScript Filling out forms Clicking on elements Extracting elements with CSS selectors or XPath expressions  Selenium and Chrome in headless mode is really the ultimate combination to scrape anything you want. You can automate anything that you could do with your regular Chrome browser.\nThe big drawback is that Chrome needs lots of memory / CPU power. With some fine-tuning you can reduce the memory footprint to 300-400mb per Chrome instance, but you still need 1 CPU core per instance.\nIf you want to run several Chrome instances concurrently, you will need powerful servers (the cost of which goes up quickly) and constant monitoring of resources.\n Source :\n "});index.add({'id':261,'href':'/library/tutorials/docs/articles/data-science/web-scraping/web-scraping-and-beautifulsoup/','title':"Web Scraping and BeautifulSoup",'content':" Web Scraping and BeautifulSoup  Source  To source data for data science projects, you’ll often rely on SQL and NoSQL databases, APIs, or ready-made CSV data sets.\nThe problem is that you can’t always find a data set on your topic, databases are not kept current and APIs are either expensive or have usage limits.\nIf the data you’re looking for is on an web page, however, then the solution to all these problems is web scraping.\nIn this tutorial we’ll learn to scrape multiple web pages with Python using BeautifulSoup and requests. We’ll then perform some simple analysis using pandas, and matplotlib.\nYou should already have some basic understanding of HTML, a good grasp of Python’s basics, and a rough idea about what web scraping is. If you are not comfortable with these, I recommend this beginner web scraping tutorial.\nScraping data for over 2000 movies We want to analyze the distributions of IMDB and Metacritic movie ratings to see if we find anything interesting. To do this, we’ll first scrape data for over 2000 movies.\nIt’s essential to identify the goal of our scraping right from the beginning. Writing a scraping script can take a lot of time, especially if we want to scrape more than one web page. We want to avoid spending hours writing a script which scrapes data we won’t actually need.\nWorking out which pages to scrape Once we’ve established our goal, we then need to identify an efficient set of pages to scrape.\nWe want to find a combination of pages that requires a relatively small number of requests. A request is what happens whenever we access a web page. We ‘request’ the content of a page from the server. The more requests we make, the longer our script will need to run, and the greater the strain on the server.\nOne way to get all the data we need is to compile a list of movie names, and use it to access the web page of each movie on both IMDB and Metacritic websites.\nSince we want to get over 2000 ratings from both IMDB and Metacritic, we’ll have to make at least 4000 requests. If we make one request per second, our script will need a little over an hour to make 4000 requests. Because of this, it’s worth trying to identify more efficient ways of obtaining our data.\nIf we explore the IMDB website, we can discover a way to halve the number of requests. Metacritic scores are shown on the IMDB movie page, so we can scrape both ratings with a single request:\nIf we investigate the IMDB site further, we can discover the page shown below. It contains all the data we need for 50 movies. Given our aim, this means we’ll only have to do about 40 requests, which is 100 times less than our first option. Let’s explore this last option further.\nIdentifying the URL structure Our challenge now is to make sure we understand the logic of the URL as the pages we want to scrape change. If we can’t understand this logic enough so we can implement it into code, then we’ll reach a dead end.\nIf you go on IMDB’s advanced search page, you can browse movies by year:\nLet’s browse by year 2017, sort the movies on the first page by number of votes, then switch to the next page. We’ll arrive at this web page, which has this URL:\nIn the image above, you can see that the URL has several parameters after the question mark:\n release_date — Shows only the movies released in a specific year. sort — Sorts the movies on the page. sort=num_votes,desc translates to sort by number of votes in a descending order. page — Specifies the page number. ref_ — Takes us to the the next or the previous page. The reference is the page we are currently on. adv_nxt and adv_prv are two possible values. They translate to advance to the next page, and advance to the previous page, respectively.  If you navigate through those pages and observe the URL, you will notice that only the values of the parameters change. This means we can write a script to match the logic of the changes and make far fewer requests to scrape our data.\nLet’s start writing the script by requesting the content of this single web page: http://www.imdb.com/search/title?release_date=2017\u0026amp;sort=num_votes,desc\u0026amp;page=1. In the following code cell we will:\n Import the get() function from the requests module. Assign the address of the web page to a variable named url. Request the server the content of the web page by using get(), and store the server’s response in the variable response. Print a small part of response‘s content by accessing its .text attribute (response is now a Response object).\nfrom requests import get url = 'http://www.imdb.com/search/title?release_date=2017\u0026amp;sort=num_votes,desc\u0026amp;page=1' response = get(url) print(response.text[:500])  \u0026lt;!DOCTYPE html\u0026gt;\u0026lt; htmlxmlns:og=\u0026quot;http://ogp.me/ns#\u0026quot;xmlns:fb=\u0026quot;http://www.facebook.com/2008/fbml\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;utf-8\u0026quot;\u0026gt; \u0026lt;meta http-equiv=\u0026quot;X-UA-Compatible\u0026quot; content=\u0026quot;IE=edge\u0026quot;\u0026gt; \u0026lt;meta name=\u0026quot;apple-itunes-app\u0026quot; content=\u0026quot;app-id=342792525, app-argument=imdb:///?src=mdot\u0026quot;\u0026gt; \u0026lt;script type=\u0026quot;text/javascript\u0026quot;\u0026gt; var ue_t0=window.ue_t0||+new Date();\u0026lt;/script\u0026gt; \u0026lt;script type=\u0026quot;text/javascript\u0026quot;\u0026gt; var ue_mid = \u0026quot;A1EVAM02EL8SFB\u0026quot;;   Understanding the HTML structure of a single page As you can see from the first line of response.text, the server sent us an HTML document. This document describes the overall structure of that web page, along with its specific content (which is what makes that particular page unique).\nAll the pages we want to scrape have the same overall structure. This implies that they also have the same overall HTML structure. So, to write our script, it will suffice to understand the HTML structure of only one page. To do that, we’ll use the browser’s Developer Tools.\nIf you use Chrome, right-click on a web page element that interests you, and then click Inspect. This will take you right to the HTML line that corresponds to that element:\nRight-click on the movie’s name, and then left-click Inspect. The HTML line highlighted in gray corresponds to what the user sees on the web page as the movie’s name.\nYou can also do this using both Firefox and Safari DevTools.\nNotice that all of the information for each movie, including the poster, is contained in a div tag.\nThere are a lot of HTML lines nested within each div tag. You can explore them by clicking those little gray arrows on the left of the HTML lines corresponding to each div. Within these nested tags we’ll find the information we need, like a movie’s rating.\nThere are 50 movies shown per page, so there should be a div container for each. Let’s extract all these 50 containers by parsing the HTML document from our earlier request.\nUsing BeautifulSoup to parse the HTML content To parse our HTML document and extract the 50 div containers, we’ll use a Python module called BeautifulSoup, the most common web scraping module for Python.\nIn the following code cell we will:\n Import the BeautifulSoup class creator from the package bs4. Parse response.text by creating a BeautifulSoup object, and assign this object to html_soup. The 'html.parser' argument indicates that we want to do the parsing using Python’s built-in HTML parser.\nfrom bs4 import BeautifulSoup html_soup = BeautifulSoup(response.text, 'html.parser') type(html_soup)  bs4.BeautifulSoup   Before extracting the 50 div containers, we need to figure out what distinguishes them from other div elements on that page. Often, the distinctive mark resides in the class attribute. If you inspect the HTML lines of the containers of interest, you’ll notice that the class attribute has two values: lister-item and mode-advanced. This combination is unique to these div containers. We can see that’s true by doing a quick search (Ctrl + F). We have 50 such containers, so we expect to see only 50 matches:\nNow let’s use the find_all() method to extract all the div containers that have a class attribute of lister-item mode-advanced:\nmovie_containers = html_soup.find_all('div', class_ = 'lister-item mode-advanced') print(type(movie_containers)) print(len(movie_containers))  \u0026lt;class 'bs4.element.ResultSet'\u0026gt; 50  find_all() returned a ResultSet object which is a list containing all the 50 divs we are interested in.\nNow we’ll select only the first container, and extract, by turn, each item of interest:\n The name of the movie. The year of release. The IMDB rating. The Metascore. The number of votes.  Extracting the data for a single movie We can access the first container, which contains information about a single movie, by using list notation on movie_containers.\n\u0026lt;div class=\u0026quot;lister-item mode-advanced\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;lister-top-right\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;ribbonize\u0026quot; data-caller=\u0026quot;filmosearch\u0026quot; data-tconst=\u0026quot;tt3315342\u0026quot;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;lister-item-image float-left\u0026quot;\u0026gt; \u0026lt;a href=\u0026quot;/title/tt3315342/?ref_=adv_li_i\u0026quot;\u0026gt; \u0026lt;img alt=\u0026quot;Logan\u0026quot; class=\u0026quot;loadlate\u0026quot; data-tconst=\u0026quot;tt3315342\u0026quot; height=\u0026quot;98\u0026quot; loadlate=\u0026quot;https://images-na.ssl-images-amazon.com/images/M/MV5BMjQwODQwNTg4OV5BMl5BanBnXkFtZTgwMTk4MTAzMjI@._V1_UX67_CR0,0,67,98_AL_.jpg\u0026quot; src=\u0026quot;http://ia.media-imdb.com/images/G/01/imdb/images/nopicture/large/film-184890147._CB522736516_.png\u0026quot; width=\u0026quot;67\u0026quot;/\u0026gt; \u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;lister-item-content\u0026quot;\u0026gt; \u0026lt;h3 class=\u0026quot;lister-item-header\u0026quot;\u0026gt; \u0026lt;span class=\u0026quot;lister-item-index unbold text-primary\u0026quot;\u0026gt;1.\u0026lt;/span\u0026gt; \u0026lt;a href=\u0026quot;/title/tt3315342/?ref_=adv_li_tt\u0026quot;\u0026gt;Logan\u0026lt;/a\u0026gt; \u0026lt;span class=\u0026quot;lister-item-year text-muted unbold\u0026quot;\u0026gt;(2017)\u0026lt;/span\u0026gt; \u0026lt;/h3\u0026gt; \u0026lt;p class=\u0026quot;text-muted \u0026quot;\u0026gt; \u0026lt;span class=\u0026quot;certificate\u0026quot;\u0026gt;R\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;ghost\u0026quot;\u0026gt;|\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;runtime\u0026quot;\u0026gt;137 min\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;ghost\u0026quot;\u0026gt;|\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;genre\u0026quot;\u0026gt; Action, Drama, Sci-Fi \u0026lt;/span\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;div class=\u0026quot;ratings-bar\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;inline-block ratings-imdb-rating\u0026quot; data-value=\u0026quot;8.3\u0026quot; name=\u0026quot;ir\u0026quot;\u0026gt; \u0026lt;span class=\u0026quot;global-sprite rating-star imdb-rating\u0026quot;\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;strong\u0026gt;8.3\u0026lt;/strong\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;inline-block ratings-user-rating\u0026quot;\u0026gt; \u0026lt;span class=\u0026quot;userRatingValue\u0026quot; data-tconst=\u0026quot;tt3315342\u0026quot; id=\u0026quot;urv_tt3315342\u0026quot;\u0026gt; \u0026lt;span class=\u0026quot;global-sprite rating-star no-rating\u0026quot;\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;rate\u0026quot; data-no-rating=\u0026quot;Rate this\u0026quot; data-value=\u0026quot;0\u0026quot; name=\u0026quot;ur\u0026quot;\u0026gt;Rate this\u0026lt;/span\u0026gt; \u0026lt;/span\u0026gt; \u0026lt;div class=\u0026quot;starBarWidget\u0026quot; id=\u0026quot;sb_tt3315342\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;rating rating-list\u0026quot; data-auth=\u0026quot;\u0026quot; data-ga-identifier=\u0026quot;\u0026quot; data-starbar-class=\u0026quot;rating-list\u0026quot; data-user=\u0026quot;\u0026quot; id=\u0026quot;tt3315342|imdb|8.3|8.3|||search|title\u0026quot; itemprop=\u0026quot;aggregateRating\u0026quot; itemscope=\u0026quot;\u0026quot; itemtype=\u0026quot;http://schema.org/AggregateRating\u0026quot; title=\u0026quot;Users rated this 8.3/10 (320,428 votes) - click stars to rate\u0026quot;\u0026gt; \u0026lt;meta content=\u0026quot;8.3\u0026quot; itemprop=\u0026quot;ratingValue\u0026quot;/\u0026gt; \u0026lt;meta content=\u0026quot;10\u0026quot; itemprop=\u0026quot;bestRating\u0026quot;/\u0026gt; \u0026lt;meta content=\u0026quot;320428\u0026quot; itemprop=\u0026quot;ratingCount\u0026quot;/\u0026gt; \u0026lt;span class=\u0026quot;rating-bg\u0026quot;\u0026gt; \u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;rating-imdb \u0026quot; style=\u0026quot;width: 116.2px\u0026quot;\u0026gt; \u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;rating-stars\u0026quot;\u0026gt; \u0026lt;a href=\u0026quot;/register/login?why=vote\u0026amp;ref_=tt_ov_rt\u0026quot; rel=\u0026quot;nofollow\u0026quot; title=\u0026quot;Register or login to rate this title\u0026quot;\u0026gt;\u0026lt;span\u0026gt;1\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;/register/login?why=vote\u0026amp;ref_=tt_ov_rt\u0026quot; rel=\u0026quot;nofollow\u0026quot; title=\u0026quot;Register or login to rate this title\u0026quot;\u0026gt;\u0026lt;span\u0026gt;2\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;/register/login?why=vote\u0026amp;ref_=tt_ov_rt\u0026quot; rel=\u0026quot;nofollow\u0026quot; title=\u0026quot;Register or login to rate this title\u0026quot;\u0026gt;\u0026lt;span\u0026gt;3\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;/register/login?why=vote\u0026amp;ref_=tt_ov_rt\u0026quot; rel=\u0026quot;nofollow\u0026quot; title=\u0026quot;Register or login to rate this title\u0026quot;\u0026gt;\u0026lt;span\u0026gt;4\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;/register/login?why=vote\u0026amp;ref_=tt_ov_rt\u0026quot; rel=\u0026quot;nofollow\u0026quot; title=\u0026quot;Register or login to rate this title\u0026quot;\u0026gt;\u0026lt;span\u0026gt;5\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;/register/login?why=vote\u0026amp;ref_=tt_ov_rt\u0026quot; rel=\u0026quot;nofollow\u0026quot; title=\u0026quot;Register or login to rate this title\u0026quot;\u0026gt;\u0026lt;span\u0026gt;6\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;/register/login?why=vote\u0026amp;ref_=tt_ov_rt\u0026quot; rel=\u0026quot;nofollow\u0026quot; title=\u0026quot;Register or login to rate this title\u0026quot;\u0026gt;\u0026lt;span\u0026gt;7\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;/register/login?why=vote\u0026amp;ref_=tt_ov_rt\u0026quot; rel=\u0026quot;nofollow\u0026quot; title=\u0026quot;Register or login to rate this title\u0026quot;\u0026gt;\u0026lt;span\u0026gt;8\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;/register/login?why=vote\u0026amp;ref_=tt_ov_rt\u0026quot; rel=\u0026quot;nofollow\u0026quot; title=\u0026quot;Register or login to rate this title\u0026quot;\u0026gt;\u0026lt;span\u0026gt;9\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;/register/login?why=vote\u0026amp;ref_=tt_ov_rt\u0026quot; rel=\u0026quot;nofollow\u0026quot; title=\u0026quot;Register or login to rate this title\u0026quot;\u0026gt;\u0026lt;span\u0026gt;10\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt; \u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;rating-rating \u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;value\u0026quot;\u0026gt;8.3\u0026lt;/span\u0026gt;\u0026lt;span class=\u0026quot;grey\u0026quot;\u0026gt;/\u0026lt;/span\u0026gt;\u0026lt;span class=\u0026quot;grey\u0026quot;\u0026gt;10\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;rating-cancel \u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;/title/tt3315342/vote?v=X;k=\u0026quot; rel=\u0026quot;nofollow\u0026quot; title=\u0026quot;Delete\u0026quot;\u0026gt;\u0026lt;span\u0026gt;X\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026quot;inline-block ratings-metascore\u0026quot;\u0026gt; \u0026lt;span class=\u0026quot;metascore favorable\u0026quot;\u0026gt;77 \u0026lt;/span\u0026gt; Metascore \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;p class=\u0026quot;text-muted\u0026quot;\u0026gt; In the near future, a weary Logan cares for an ailing Professor X somewhere on the Mexican border. However, Logan's attempts to hide from the world and his legacy are upended when a young mutant arrives, pursued by dark forces.\u0026lt;/p\u0026gt; \u0026lt;p class=\u0026quot;\u0026quot;\u0026gt; Director: \u0026lt;a href=\u0026quot;/name/nm0003506/?ref_=adv_li_dr_0\u0026quot;\u0026gt;James Mangold\u0026lt;/a\u0026gt; \u0026lt;span class=\u0026quot;ghost\u0026quot;\u0026gt;|\u0026lt;/span\u0026gt; Stars: \u0026lt;a href=\u0026quot;/name/nm0413168/?ref_=adv_li_st_0\u0026quot;\u0026gt;Hugh Jackman\u0026lt;/a\u0026gt;, \u0026lt;a href=\u0026quot;/name/nm0001772/?ref_=adv_li_st_1\u0026quot;\u0026gt;Patrick Stewart\u0026lt;/a\u0026gt;, \u0026lt;a href=\u0026quot;/name/nm6748436/?ref_=adv_li_st_2\u0026quot;\u0026gt;Dafne Keen\u0026lt;/a\u0026gt;, \u0026lt;a href=\u0026quot;/name/nm2933542/?ref_=adv_li_st_3\u0026quot;\u0026gt;Boyd Holbrook\u0026lt;/a\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;p class=\u0026quot;sort-num_votes-visible\u0026quot;\u0026gt; \u0026lt;span class=\u0026quot;text-muted\u0026quot;\u0026gt;Votes:\u0026lt;/span\u0026gt; \u0026lt;span data-value=\u0026quot;320428\u0026quot; name=\u0026quot;nv\u0026quot;\u0026gt;320,428\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;ghost\u0026quot;\u0026gt;|\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;text-muted\u0026quot;\u0026gt;Gross:\u0026lt;/span\u0026gt; \u0026lt;span data-value=\u0026quot;226,264,245\u0026quot; name=\u0026quot;nv\u0026quot;\u0026gt;$226.26M\u0026lt;/span\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt;  As you can see, the HTML content of one container is very long. To find out the HTML line specific to each data point, we’ll use DevTools once again.\nThe name of the movie We begin with the movie’s name, and locate its correspondent HTML line by using DevTools. You can see that the name is contained within an anchor tag (\u0026lt;a\u0026gt;). This tag is nested within a header tag (\u0026lt;h3\u0026gt;). The \u0026lt;h3\u0026gt; tag is nested within a \u0026lt;div\u0026gt; tag. This \u0026lt;div\u0026gt; is the third of the divs nested in the container of the first movie. We stored the content of this container in the first_movie variable.\nfirst_movie is a Tag object, and the various HTML tags within it are stored as its attributes. We can access them just like we would access any attribute of a Python object. However, using a tag name as an attribute will only select the first tag by that name. If we run first_movie.div, we only get the content of the first div tag:\nfirst_movie.div  \u0026lt;div class=\u0026quot;lister-top-right\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;ribbonize\u0026quot; data-caller=\u0026quot;filmosearch\u0026quot; data-tconst=\u0026quot;tt3315342\u0026quot;\u0026gt;\u0026lt;/div\u0026gt;\u0026lt;/div\u0026gt;  Accessing the first anchor tag (\u0026lt;a\u0026gt;) doesn’t take us to the movie’s name. The first \u0026lt;a\u0026gt; is somewhere within the second div:\nfirst_movie.a  \u0026lt;a href=\u0026quot;/title/tt3315342/?ref_=adv_li_i\u0026quot;\u0026gt; \u0026lt;img alt=\u0026quot;Logan\u0026quot; class=\u0026quot;loadlate\u0026quot; data-tconst=\u0026quot;tt3315342\u0026quot; height=\u0026quot;98\u0026quot; loadlate=\u0026quot;https://images-na.ssl-images-amazon.com/images/M/MV5BMjQwODQwNTg4OV5BMl5BanBnXkFtZTgwMTk4MTAzMjI@._V1_UX67_CR0,0,67,98_AL_.jpg\u0026quot; src=\u0026quot;http://ia.media-imdb.com/images/G/01/imdb/images/nopicture/large/film-184890147._CB522736516_.png\u0026quot; width=\u0026quot;67\u0026quot;/\u0026gt;\u0026lt;/a\u0026gt;  However, accessing the first \u0026lt;h3\u0026gt; tag brings us very close:\nfirst_movie.h3  \u0026lt;h3 class=\u0026quot;lister-item-header\u0026quot;\u0026gt; \u0026lt;span class=\u0026quot;lister-item-index unbold text-primary\u0026quot;\u0026gt;1.\u0026lt;/span\u0026gt; \u0026lt;a href=\u0026quot;/title/tt3315342/?ref_=adv_li_tt\u0026quot;\u0026gt;Logan\u0026lt;/a \u0026gt;\u0026lt;span class=\u0026quot;lister-item-year text-muted unbold\u0026quot;\u0026gt;(2017)\u0026lt;/span\u0026gt; \u0026lt;/h3\u0026gt;  From here, we can use attribute notation to access the first \u0026lt;a\u0026gt; inside the \u0026lt;h3\u0026gt; tag:\nfirst_movie.h3.a  \u0026lt;a href=\u0026quot;/title/tt3315342/?ref_=adv_li_tt\u0026quot;\u0026gt;Logan\u0026lt;/a\u0026gt;  Now it’s all just a matter of accessing the text from within that \u0026lt;a\u0026gt; tag:\nfirst_name = first_movie.h3.a.text first_name  'Logan'  The year of the movie’s release We move on with extracting the year. This data is stored within the \u0026lt;span\u0026gt; tag below the \u0026lt;a\u0026gt; that contains the name.\nDot notation will only access the first span element. We’ll search by the distinctive mark of the second \u0026lt;span\u0026gt;. We’ll use the find() method which is almost the same as find_all(), except that it only returns the first match. In fact, find() is equivalent to find_all(limit = 1). The limit argument limits the output to the first match.\nThe distinguishing mark consists of the values lister-item-year text-muted unbold assigned to the class attribute. So we look for the first \u0026lt;span\u0026gt; with these values within the \u0026lt;h3\u0026gt; tag:\nfirst_year = first_movie.h3.find('span', class_ = 'lister-item-year text-muted unbold') first_year  \u0026lt;span class=\u0026quot;lister-item-year text-muted unbold\u0026quot;\u0026gt;(2017)\u0026lt;/span\u0026gt;  From here, we just access the text using attribute notation:\nfirst_year = first_year.text first_year  '(2017)'  We could easily clean that output and convert it to an integer. But if you explore more pages, you will notice that for some movies the year takes unpredictable values like (2017)(I) or (2015)(V). It’s more efficient to do the cleaning after the scraping, when we’ll know all the year values.\nThe IMDB rating We now focus on extracting the IMDB rating of the first movie.\nThere are a couple of ways to do that, but we’ll first try the easiest one. If you inspect the IMDB rating using DevTools, you’ll notice that the rating is contained within a \u0026lt;strong\u0026gt; tag.\nLet’s use attribute notation, and hope that the first \u0026lt;strong\u0026gt; will also be the one that contains the rating.\nfirst_movie.strong  \u0026lt;strong\u0026gt;8.3\u0026lt;/strong\u0026gt;  Great! We’ll access the text, convert it to the float type, and assign it to the variable first_imdb:\nfirst_imdb = float(first_movie.strong.text) first_imdb  8.3  The Metascore If we inspect the Metascore using DevTools, we’ll notice that we can find it within a span tag.\nAttribute notation clearly isn’t a solution. There are many \u0026lt;span\u0026gt; tags before that. You can see one right above the \u0026lt;strong\u0026gt; tag. We’d better use the distinctive values of the class attribute (metascore favorable).\nNote that if you copy-paste those values from DevTools’ tab, there will be two white space characters between metascore and favorable. Make sure there will be only one whitespace character when you pass the values as arguments to the class_ parameter. Otherwise, find() won’t find anything.\nfirst_mscore = first_movie.find('span', class_ = 'metascore favorable') first_mscore = int(first_mscore.text) print(first_mscore)  77  The favorable value indicates a high Metascore and sets the rating’s background color to green. The other two possible values are unfavorable and mixed. What is specific to all Metascore ratings though is only the metascore value. This is the one we are going to use when we’ll write the script for the entire page.\nThe number of votes The number of votes is contained within a \u0026lt;span\u0026gt; tag. Its distinctive mark is a name attribute with the value nv.\nThe name attribute is different from the class attribute. Using BeautifulSoup we can access elements by any attribute. The find() and find_all() functions have a parameter named attrs. To this we can pass in the attributes and values we are searching for as a dictionary:\nfirst_votes = first_movie.find('span', attrs = {'name':'nv'}) first_votes  \u0026lt;span data-value=\u0026quot;320428\u0026quot; name=\u0026quot;nv\u0026quot;\u0026gt;320,428\u0026lt;/span\u0026gt;  We could use .text notation to access the \u0026lt;span\u0026gt; tag’s content. It would be better though if we accessed the value of the data-value attribute. This way we can convert the extracted datapoint to an int without having to strip a comma.\nYou can treat a Tag object just like a dictionary. The HTML attributes are the dictionary’s keys. The values of the HTML attributes are the values of the dictionary’s keys. This is how we can access the value of the data-value attribute:\nfirst_votes['data-value']  '320428'  Let’s convert that value to an integer, and assign it to first_votes:\nfirst_votes = int(first_votes['data-value'])  That’s it! We’re now in a position to easily write a script for scraping a single page.\nThe script for a single page Before piecing together what we’ve done so far, we have to make sure that we’ll extract the data only from the containers that have a Metascore.\nWe need to add a condition to skip movies without a Metascore.\nUsing DevTools again, we see that the Metascore section is contained within a \u0026lt;div\u0026gt; tag. The class attribute has two values: inline-block and ratings-metascore. The distinctive one is clearly ratings-metascore.\nWe can use find() to search each movie container for a div having that distinct mark. When find() doesn’t find anything, it returns a None object. We can use this result in an if statement to control whether a movie is scraped.\nLet’s look on the web page to search for a movie container that doesn’t have a Metascore, and see what find() returns.\nImportant: when I ran the following code, the eighth container didn’t have a Metascore. However, this is a moving target, because the number of votes constantly changes for each movie. To get the same outputs as I did in the next demonstrative code cell, you should search a container that doesn’t have a Metascore at the time you’re running the code.\neighth_movie_mscore = movie_containers[7].find('div', class_ = 'ratings-metascore') type(eighth_movie_mscore)  NoneType  Now let’s put together the code above, and compress it as much as possible, but only insofar as it’s still easily readable. In the next code block we:\n Declare some list variables to have something to store the extracted data in. Loop through each container in movie_containers (the variable which contains all the 50 movie containers). Extract the data points of interest only if the container has a Metascore.\n# Lists to store the scraped data in names = [] years = [] imdb_ratings = [] metascores = [] votes = [] # Extract data from individual movie container for container in movie_containers: # If the movie has Metascore, then extract: if container.find('div', class_ = 'ratings-metascore') is not None: # The name name = container.h3.a.text names.append(name) # The year year = container.h3.find('span', class_ = 'lister-item-year').text years.append(year) # The IMDB rating imdb = float(container.strong.text) imdb_ratings.append(imdb) # The Metascore m_score = container.find('span', class_ = 'metascore').text metascores.append(int(m_score)) # The number of votes vote = container.find('span', attrs = {'name':'nv'})['data-value'] votes.append(int(vote))   Let’s check the data collected so far. Pandas makes it easy for us to see whether we’ve scraped our data successfully.\nimport pandas as pd test_df = pd.DataFrame({'movie': names, 'year': years, 'imdb': imdb_ratings, 'metascore': metascores, 'votes': votes }) print(test_df.info()) test_df  \u0026lt;class 'pandas.core.frame.DataFrame'\u0026gt; RangeIndex: 32 entries, 0 to 31 Data columns (total 5 columns): imdb 32 non-null float64 metascore 32 non-null int64 movie 32 non-null object votes 32 non-null int64 year 32 non-null object dtypes: float64(1), int64(2), object(2) memory usage: 1.3+ KB None  |id| imdb |metascore | movie | votes |year| |\u0026ndash;|\u0026ndash;|\u0026ndash;|\u0026ndash;|\u0026ndash;|\u0026ndash;| |0|8.3|77| Logan|320428|(2017) | |1|8.1|67|Guardians of the Galaxy Vol. 2|175443|(2017) | |2|8.1|76|Wonder Woman|152067|(2017) |\nEverything went just as expected!\nAs a side note, if you run the code from a country where English is not the main language, it’s very likely that you’ll get some of the movie names translated into the main language of that country.\nMost likely, this happens because the server infers your location from your IP address. Even if you are located in a country where English is the main language, you may still get translated content. This may happen if you’re using a VPN while you’re making the GET requests.\nIf you run into this issue, pass the following values to the headers parameter of the get() function:\nheaders = {\u0026quot;Accept-Language\u0026quot;: \u0026quot;en-US, en;q=0.5\u0026quot;}  This will communicate the server something like “I want the linguistic content in American English (en-US). If en-US is not available, then other types of English (en) would be fine too (but not as much as en-US).”. The q parameter indicates the degree to which we prefer a certain language. If not specified, then the values is set to 1 by default, like in the case of en-US. You can read more about this here.\nNow let’s start building the script for all the pages we want to scrape.\nThe script for multiple pages Scraping multiple pages is a bit more challenging. We’ll build upon our one-page script by doing three more things:\n Making all the requests we want from within the loop. Controlling the loop’s rate to avoid bombarding the server with requests. Monitoring the loop while it runs.  We’ll scrape the first 4 pages of each year in the interval 2000-2017. 4 pages for each of the 18 years makes for a total of 72 pages. Each page has 50 movies, so we’ll scrape data for 3600 movies at most. But not all the movies have a Metascore, so the number will be lower than that. Even so, we are still very likely to get data for over 2000 movies.\nChanging the URL’s parameters As shown earlier, the URLs follow a certain logic as the web pages change.\nAs we are making the requests, we’ll only have to vary the values of only two parameters of the URL: the release_date parameter, and page. Let’s prepare the values we’ll need for the forthcoming loop. In the next code cell we will:\n Create a list called pages, and populate it with the strings corresponding to the first 4 pages. Create a list called years_url and populate it with the strings corresponding to the years 2000-2017.\npages = [str(i) for i in range(1,5)] years_url = [str(i) for i in range(2000,2018)]   Controlling the crawl-rate Controlling the rate of crawling is beneficial for us, and for the website we are scraping. If we avoid hammering the server with tens of requests per second, then we are much less likely to get our IP address banned. We also avoid disrupting the activity of the website we scrape by allowing the server to respond to other users’ requests too.\nWe’ll control the loop’s rate by using the sleep() function from Python’s time module. sleep() will pause the execution of the loop for a specified amount of seconds.\nTo mimic human behavior, we’ll vary the amount of waiting time between requests by using the randint() function from the Python’s random module. randint() randomly generates integers within a specified interval.\nFor now, let’s just import these two functions to prevent overcrowding in the code cell containing our main sleep from loop\nfrom time import sleep from random import randint  Monitoring the loop as it’s still going Given that we’re scraping 72 pages, it would be nice if we could find a way to monitor the scraping process as it’s still going. This feature is definitely optional, but it can be very helpful in the testing and debugging process. Also, the greater the number of pages, the more helpful the monitoring becomes. If you are going to scrape hundreds or thousands of web pages in a single code run, I would say that this feature becomes a must.\nFor our script, we’ll make use of this feature, and monitor the following parameters:\n The frequency (speed) of requests, so we make sure our program is not overloading the server. The number of requests, so we can halt the loop in case the number of expected requests is exceeded. The status code of our requests, so we make sure the server is sending back the proper responses.  To get a frequency value we’ll divide the number of requests by the time elapsed since the first request. This is similar to computing the speed of a car – we divide the distance by the time taken to cover that distance. Let’s experiment with this monitoring technique at a small scale first. In the following code cell we will:\n Set a starting time using the time() function from the time module, and assign the value to start_time. Assign 0 to the variable requests which we’ll use to count the number of requests. Start a loop, and then with each iteration:\n Simulate a request. Increment the number of requests by 1. Pause the loop for a time interval between 8 and 15 seconds. Calculate the elapsed time since the first request, and assign the value to elapsed_time. Print the number of requests and the frequency.\nfrom time import timestart_time = time() requests = 0 for _ in range(5): # A request would go here requests += 1 sleep(randint(1,3)) elapsed_time = time() - start_time print('Request: {}; Frequency: {} requests/s'.format(requests, requests/elapsed_time))  Request: 1; Frequency: 0.49947650463238624 requests/s Request: 2; Frequency: 0.4996998027377252 requests/s Request: 3; Frequency: 0.5995400143227362 requests/s Request: 4; Frequency: 0.4997272043465967 requests/s Request: 5; Frequency: 0.4543451628627026 requests/s    Since we’re going to make 72 requests, our work will look a bit untidy as the output accumulates. To avoid that, we’ll clear the output after each iteration, and replace it with information about the most recent request. To do that we’ll use the clear_output()function from the IPython’s core.display module. We’ll set the wait parameter of clear_output() to True to wait with replacing the current output until some new output appears.\nfrom IPython.core.display import clear_output start_time = time()requests = 0 for _ in range(5): # A request would go here requests += 1 sleep(randint(1,3)) current_time = time() elapsed_time = current_time - start_time print('Request: {}; Frequency: {} requests/s'.format(requests, requests/elapsed_time)) clear_output(wait = True)  Request: 5; Frequency: 0.6240351700607663 requests/s  The output above is the output you will see once the loop has run. Here’s what it looks like while it’s running\nTo monitor the status code we’ll set the program to warn us if there’s something off. A successful request is indicated by a status code of 200. We’ll use the warn() function from the warnings module to throw a warning if the status code is not 200.\nfrom warnings import warnwarn(\u0026quot;Warning Simulation\u0026quot;)  /Users/joshuadevlin/.virtualenvs/everday-ds/lib/python3.4/site-packages/ipykernel/__main__.py:3: UserWarning: Warning Simulation app.launch_new_instance()  We chose a warning over breaking the loop because there’s a good possibility we’ll scrape enough data, even if some of the requests fail. We will only break the loop if the number of requests is greater than expected.\nPiecing everything together Now let’s piece together everything we’ve done so far! In the following code cell, we start by:\n Redeclaring the lists variables so they become empty again. Preparing the monitoring of the loop.  Then, we’ll:\n Loop through the years_url list to vary the release_date parameter of the URL. For each element in years_url, loop through the pages list to vary the page parameter of the URL. Make the GET requests within the pages loop (and give the headers parameter the right value to make sure we get only English content). Pause the loop for a time interval between 8 and 15 seconds. Monitor each request as discussed before. Throw a warning for non-200 status codes. Break the loop if the number of requests is greater than expected. Convert the response‘s HTML content to a BeautifulSoup object. Extract all movie containers from this BeautifulSoup object. Loop through all these containers. Extract the data if a container has a Metascore.\n# Redeclaring the lists to store data in names = [] years = [] imdb_ratings = [] metascores = [] votes = [] # Preparing the monitoring of the loop start_time = time() requests = 0 # For every year in the interval 2000-2017 for year_url in years_url: # For every page in the interval 1-4 for page in pages: # Make a get request response = get('http://www.imdb.com/search/title?release_date=' + year_url + '\u0026amp;sort=num_votes,desc\u0026amp;page=' + page, headers = headers) # Pause the loop sleep(randint(8,15)) # Monitor the requests requests += 1 elapsed_time = time() - start_time print('Request:{}; Frequency: {} requests/s'.format(requests, requests/elapsed_time)) clear_output(wait = True) # Throw a warning for non-200 status codes if response.status_code != 200: warn('Request: {}; Status code: {}'.format(requests, response.status_code)) # Break the loop if the number of requests is greater than expected if requests \u0026gt; 72: warn('Number of requests was greater than expected.') break # Parse the content of the request with BeautifulSoup page_html = BeautifulSoup(response.text, 'html.parser') # Select all the 50 movie containers from a single page mv_containers = page_html.find_all('div', class_ = 'lister-item mode-advanced') # For every movie of these 50 for container in mv_containers: # If the movie has a Metascore, then: if container.find('div', class_ = 'ratings-metascore') is not None: # Scrape the name name = container.h3.a.text names.append(name) # Scrape the year year = container.h3.find('span', class_ = 'lister-item-year').text years.append(year) # Scrape the IMDB rating imdb = float(container.strong.text) imdb_ratings.append(imdb) # Scrape the Metascore m_score = container.find('span', class_ = 'metascore').text metascores.append(int(m_score)) # Scrape the number of votes vote = container.find('span', attrs = {'name':'nv'})['data-value'] votes.append(int(vote))  Request:72; Frequency: 0.07928964663062842 requests/s   Nice! The scraping seems to have worked perfectly. The script ran for about 16 minutes.\nNow let’s merge the data into a pandas DataFrame to examine what we’ve managed to scrape. If everything is as expected, we can move on with cleaning the data to get it ready for analysis.\nExamining the scraped data In the next code block we:\n Merge the data into a pandas DataFrame. Print some informations about the newly created DataFrame. Show the first 10 entries.\nmovie_ratings = pd.DataFrame({'movie': names, 'year': years, 'imdb': imdb_ratings, 'metascore': metascores, 'votes': votes }) print(movie_ratings.info()) movie_ratings.head(10)  \u0026lt;class 'pandas.core.frame.DataFrame'\u0026gt; RangeIndex: 2862 entries, 0 to 2861 Data columns (total 5 columns): imdb 2862 non-null float64 metascore 2862 non-null int64 movie 2862 non-null object votes 2862 non-null int64 year 2862 non-null object dtypes: float64(1), int64(2), object(2) memory usage: 111.9+ KB None   |id| imdb |metascore | movie | votes |year| |\u0026ndash;|\u0026ndash;|\u0026ndash;|\u0026ndash;|\u0026ndash;|\u0026ndash;| |0|8.3|77| Logan|320428|(2017) | |1|8.1|67|Guardians of the Galaxy Vol. 2|175443|(2017) | |2|8.1|76|Wonder Woman|152067|(2017) |\nNow let’s convert all the values in the year column to integers.\nRight now all the values are of the object type. To avoid ValueErrors upon conversion, we want the values to be composed only from numbers from 0 to 9.\nLet’s examine the unique values of the year column. This helps us to get an idea of what we could do to make the conversions we want. To see all the unique values, we’ll use the unique() method:\nmovie_ratings['year'].unique()  array(['(2000)', '(I) (2000)', '(2001)', '(I) (2001)', '(2002)', '(I) (2002)', '(2003)', '(I) (2003)', '(2004)', '(I) (2004)', '(2005)', '(I) (2005)', '(2006)', '(I) (2006)', '(2007)', '(I) (2007)', '(2008)', '(I) (2008)', '(2009)', '(I) (2009)', '(II) (2009)', '(2010)', '(I) (2010)', '(II) (2010)', '(2011)', '(I) (2011)', '(IV) (2011)', '(2012)', '(I) (2012)', '(II) (2012)', '(2013)', '(I) (2013)', '(II) (2013)', '(2014)', '(I) (2014)', '(II) (2014)', '(III) (2014)', '(2015)', '(I) (2015)', '(II) (2015)', '(VI) (2015)', '(III) (2015)', '(2016)', '(II) (2016)', '(I) (2016)', '(IX) (2016)', '(V) (2016)', '(2017)', '(I) (2017)', '(III) (2017)', '(IV) (2017)'], dtype=object)  Counting from the end toward beginning, we can see that the years are always located from the fifth character to the second. We’ll use the .str() method to select only that interval. We’ll also convert the result to an integer using the astype() method:\nmovie_ratings.loc[:, 'year'] = movie_ratings['year'].str[-5:-1].astype(int)  Let’s visualize the first 3 values of the year column for a quick check. We can also see the type of the values on the last line of the output:\nmovie_ratings['year'].head(3)  0 2000 1 2000 2 2000 Name: year, dtype: int64  Now we’ll check the minimum and maximum values of each type of rating. We can do this very quickly by using pandas’ describe() method. When applied on a DataFrame, this method returns various descriptive statistics for each numerical column of the DataFrame. In the next line of code we select only those rows that describe the minimum and maximum values, and only those columns which describe IMDB ratings and Metascores.\nmovie_ratings.describe().loc[['min', 'max'], ['imdb', 'metascore']]  |id| imdb |metascore | movie | votes |year| |\u0026ndash;|\u0026ndash;|\u0026ndash;|\u0026ndash;|\u0026ndash;|\u0026ndash;| |0|8.3|77| Logan|320428|(2017) | |1|8.1|67|Guardians of the Galaxy Vol. 2|175443|(2017) | |2|8.1|76|Wonder Woman|152067|(2017) |\nNice! We are now in a position to save this dataset locally, so we can share it with others more easily. I have already shared it publicly on my GitHub profile. There are other places where you can share a dataset, like Kaggle, or Dataworld.\nSo let’s save it:\nmovie_ratings.to_csv('movie_ratings.csv')  As a side note, I strongly recommend saving the scraped dataset before exiting (or restarting) your notebook kernel. This way you will only have to import the dataset when you resume working, and don’t have to run the scraping script again. This becomes extremely useful if you scrape hundreds or thousands of web pages.\nFinally, let’s plot the distributions!\nPlotting and analyzing the distributions In the following code cell we:\n Import the matplotlib.pyplot submodule. Run the Jupyter magic %matplotlib to activate Jupyter’s matplotlib mode and add inline to have our graphs displayed inside the notebook. Create a figure object with 3 axes. Plot the distribution of each unnormalized rating on an individual ax. Plot the normalized distributions of the two ratings on the same ax. Hide the top and right spines of all the three axes.\nimport matplotlib.pyplot as plt fig, axes = plt.subplots(nrows = 1, ncols = 3, figsize = (16,4)) ax1, ax2, ax3 = fig.axes ax1.hist(movie_ratings['imdb'], bins = 10, range = (0,10)) # bin range = 1 ax1.set_title('IMDB rating') ax2.hist(movie_ratings['metascore'], bins = 10, range = (0,100)) # bin range = 10 ax2.set_title('Metascore') ax3.hist(movie_ratings['n_imdb'], bins = 10, range = (0,100), histtype = 'step') ax3.hist(movie_ratings['metascore'], bins = 10, range = (0,100), histtype = 'step') ax3.legend(loc = 'upper left') ax3.set_title('The Two Normalized Distributions') for ax in fig.axes: ax.spines['top'].set_visible(False) ax.spines['right'].set_visible(False) plt.show()   Starting with the IMDB histogram, we can see that most ratings are between 6 and 8. There are few movies with a rating greater than 8, and even fewer with a rating smaller than 4. This indicates that both very good movies and very bad movies are rarer.\nThe distribution of Metascore ratings resembles a normal distribution – most ratings are average, peaking at the value of approximately 50. From this peak, the frequencies gradually decrease toward extreme rating values. According to this distribution, there are indeed fewer very good and very bad movies, but not that few as the IMDB ratings indicate.\nOn the comparative graph, it’s clearer that the IMDB distribution is highly skewed toward the higher part of the average ratings, while the Metascore ratings seem to have a much more balanced distribution.\nWhat might be the reason for that skew in the IMDB distribution? One hypothesis is that many users tend to have a binary method of assessing movies. If they like the movie, they give it a 10. If they don’t like the movie, they give it a very small rating, or they don’t bother to rate the movie. This an interesting problem that’s worth being explored in more detail.\nNext steps We’ve come a long way from requesting the content of a single web page to analyzing ratings for over 2000 movies. You should now know how to scrape many web pages with the same HTML and URL structure.\nTo build upon what we’ve learned, here are a few next steps to consider:\n Scrape data for different time and page intervals. Scrape additional data about the movies. Find a different website to scrape something that interests you. For example, you could scrape data about laptops to see how prices vary over time.  "});index.add({'id':262,'href':'/library/tutorials/docs/articles/data-science/web-scraping/web-scraping-craigslist/','title':"Web Scraping Craigslist",'content':" Web Scraping Craigslist: A Complete Tutorial I’ve been looking to make a move recently. And what better way to know I’m getting a good price than to sample from the “population” of housing on Craigslist? Sounds like a job for…Python and web scraping!\nIn this article, I’m going to walk you through my code that scrapes East Bay Area Craigslist for apartments. The code here, and/or the URI parameters rather, can be modified to pull from any region, category, property type, etc. Pretty cool, huh?\nI’m going to share GitHub gists of each cell in the original Jupyter Notebook. If you’d like to just see the whole code at once, clone the repo. Otherwise, enjoy the read and follow along!\nGetting the Data First things first I needed to use the get module from the requests package. Then I defined a variable, response, and assigned it to the get method called on the base URL. What I mean by base URL is the URL at the first page you want to pull data from, minus any extra arguments. I went to the apartments section for the East Bay and checked the “Has Picture” filter to narrow down the search just a little though, so it’s not a true base URL.\nI then imported BeautifulSoup from bs4, which is the module that can actually parse the HTML of the web page retrieved from the server. I then checked the type and length of that item to make sure it matches the number of posts on the page (there are 120). You can find my import statements and setup code below:\n#import get to call a get request on the site from requests import get #get the first page of the east bay housing prices response = get('https://sfbay.craigslist.org/search/eby/apa?hasPic=1\u0026amp;availabilityMode=0') #get rid of those lame-o's that post a housing option without a pic using their filter from bs4 import BeautifulSoup html_soup = BeautifulSoup(response.text, 'html.parser') #get the macro-container for the housing posts posts = html_soup.find_all('li', class_= 'result-row') print(type(posts)) #to double check that I got a ResultSet print(len(posts)) #to double check I got 120 (elements/page)  Using the find_all method on the newly created html_soup variable in the code above, I found the posts. I needed to examine the website’s structure to find the parent tag of the posts. Looking at the screenshot below, you can see that it’s . That is the tag for one single post, which is literally the box that contains all the elements I grabbed!\nElement inspection with Chrome (Ctrl+Shift+C shortcut!)\nIn order to scale this, make sure to work in the following way: grab the first post and all the variables you want from it, make sure you know how to access each of them for one post before you loop the whole page, and lastly, make sure you successfully scraped one page before adding the loop that goes through all pages.\nClass bs4.element.ResultSet is indexed, so I looked at the first apartment by indexing posts[0]. Surprise, it’s all the code that belongs to that  tag!\nYou should have this output for the first post in posts (posts[0]), assigned to post_one.\n#grab the price of the first post post_one_price = post_one.a.text post_one_price.strip()  .strip() removes whitespace before and after a string\nI grabbed the date and time by specifying the attribute ‘datetime’ on class ‘result-date’. By specifying the ‘datetime’ attribute, I saved a step in data cleaning by making it unnecessary to convert this attribute from a string to a datetime object. This could also be made into a one-liner by placing ['datetime'] at the end of the .find() call, but I split it into two lines for clarity.\n#grab the time and datetime it was posted post_one_time = post_one.find('time', class_= 'result-date') post_one_datetime = post_one_time['datetime']  The URL and post title are easy because the ‘href’ attribute is the link and is pulled by specifying that argument. The title is just the text of that tag.\n#title is a and that class, link is grabbing the href attribute of that variable post_one_title = post_one.find('a', class_='result-title hdrlnk') post_one_link = post_one_title['href'] #easy to grab the post title by taking the text element of the title variable post_one_title_text = post_one_title.text  The number of bedrooms and square footage are in the same tag, so I split these two values and grabbed each one element-wise. The neighborhood is the  tag of class “result-hood”, so I grabbed the text of that.\n#grabs the whole segment of housing details. We will need missing value handling in the loop as this kind of detail is not common in posts #the text can be split, and we can use indexing to grab the elements we want. number of bedrooms is the first element. #sqft is the third element post_one_num_bedrooms = post_one.find('span', class_ = 'housing').text.split()[0] post_one_sqft = post_one.find('span', class_ = 'housing').text.split()[2][:-3] #cleans the ft2 at the end post_one_hood = posts[0].find('span', class_='result-hood').text #grabs the neighborhood, this is the problem column that requires #a lot of cleaning and figuring out later.  The next block is the loop for all the pages for the East Bay. Since there isn’t always information on square footage and number of bedrooms, I built in a series of if statements embedded within the for loop to handle all cases.\n#build out the loop from time import sleep import re from random import randint #avoid throttling by not sending too many requests one after the other from warnings import warn from time import time from IPython.core.display import clear_output import numpy as np #find the total number of posts to find the limit of the pagination results_num = html_soup.find('div', class_= 'search-legend') results_total = int(results_num.find('span', class_='totalcount').text) #pulled the total count of posts as the upper bound of the pages array #each page has 119 posts so each new page is defined as follows: s=120, s=240, s=360, and so on. So we need to step in size 120 in the np.arange function pages = np.arange(0, results_total+1, 120) iterations = 0 post_timing = [] post_hoods = [] post_title_texts = [] bedroom_counts = [] sqfts = [] post_links = [] post_prices = [] for page in pages: #get request response = get(\u0026quot;https://sfbay.craigslist.org/search/eby/apt?\u0026quot; + \u0026quot;s=\u0026quot; #the parameter for defining the page number + str(page) #the page number in the pages array from earlier + \u0026quot;\u0026amp;hasPic=1\u0026quot; + \u0026quot;\u0026amp;availabilityMode=0\u0026quot;) sleep(randint(1,5)) #throw warning for status codes that are not 200 if response.status_code != 200: warn('Request: {}; Status code: {}'.format(requests, response.status_code)) #define the html text page_html = BeautifulSoup(response.text, 'html.parser') #define the posts posts = html_soup.find_all('li', class_= 'result-row') #extract data item-wise for post in posts: if post.find('span', class_ = 'result-hood') is not None: #posting date #grab the datetime element 0 for date and 1 for time post_datetime = post.find('time', class_= 'result-date')['datetime'] post_timing.append(post_datetime) #neighborhoods post_hood = post.find('span', class_= 'result-hood').text post_hoods.append(post_hood) #title text post_title = post.find('a', class_='result-title hdrlnk') post_title_text = post_title.text post_title_texts.append(post_title_text) #post link post_link = post_title['href'] post_links.append(post_link) #removes the \\n whitespace from each side, removes the currency symbol, and turns it into an int post_price = int(post.a.text.strip().replace(\u0026quot;$\u0026quot;, \u0026quot;\u0026quot;)) post_prices.append(post_price) if post.find('span', class_ = 'housing') is not None: #if the first element is accidentally square footage if 'ft2' in post.find('span', class_ = 'housing').text.split()[0]: #make bedroom nan bedroom_count = np.nan bedroom_counts.append(bedroom_count) #make sqft the first element sqft = int(post.find('span', class_ = 'housing').text.split()[0][:-3]) sqfts.append(sqft) #if the length of the housing details element is more than 2 elif len(post.find('span', class_ = 'housing').text.split()) \u0026gt; 2: #therefore element 0 will be bedroom count bedroom_count = post.find('span', class_ = 'housing').text.replace(\u0026quot;br\u0026quot;, \u0026quot;\u0026quot;).split()[0] bedroom_counts.append(bedroom_count) #and sqft will be number 3, so set these here and append sqft = int(post.find('span', class_ = 'housing').text.split()[2][:-3]) sqfts.append(sqft) #if there is num bedrooms but no sqft elif len(post.find('span', class_ = 'housing').text.split()) == 2: #therefore element 0 will be bedroom count bedroom_count = post.find('span', class_ = 'housing').text.replace(\u0026quot;br\u0026quot;, \u0026quot;\u0026quot;).split()[0] bedroom_counts.append(bedroom_count) #and sqft will be number 3, so set these here and append sqft = np.nan sqfts.append(sqft) else: bedroom_count = np.nan bedroom_counts.append(bedroom_count) sqft = np.nan sqfts.append(sqft) #if none of those conditions catch, make bedroom nan, this won't be needed else: bedroom_count = np.nan bedroom_counts.append(bedroom_count) sqft = np.nan sqfts.append(sqft) # bedroom_counts.append(bedroom_count) # sqft = np.nan # sqfts.append(sqft) iterations += 1 print(\u0026quot;Page \u0026quot; + str(iterations) + \u0026quot; scraped successfully!\u0026quot;) print(\u0026quot;\\n\u0026quot;) print(\u0026quot;Scrape complete!\u0026quot;)  The loop starts on the first page, and for each post in that page, it works through the following logic:\nI included some data cleaning steps in the loop, like pulling the ‘datetime’ attribute and removing the ‘ft2’ from the square footage variable, and making that value an integer. I removed ‘br’ from the number of bedrooms as that was scraped as well. That way, I started data cleaning with some work already done. Elegant code is the best! I wanted to do more, but the code would become too specific to this region and might not work across areas.\nThe code below creates the dataframe from the lists of values!\nimport pandas as pd eb_apts = pd.DataFrame({'posted': post_timing, 'neighborhood': post_hoods, 'post title': post_title_texts, 'number bedrooms': bedroom_counts, 'sqft': sqfts, 'URL': post_links, 'price': post_prices}) print(eb_apts.info()) eb_apts.head(10)  Awesome! There it is. Admittedly, there is still a little bit of data cleaning to be done. I’ll go through that real quick, and then it’s time to explore the data!\n#first things first, drop duplicate URLs because people are spammy on Craigslist. #Let's see how many uniqe posts we really have. eb_apts = eb_apts.drop_duplicates(subset='URL') len(eb_apts.drop_duplicates(subset='URL')) #make the number bedrooms to a float (since np.nan is a float too) eb_apts['number bedrooms'] = eb_apts['number bedrooms'].apply(lambda x: float(x)) #convert datetime string into datetime object to be able to work with it from datetime import datetime eb_apts['posted'] = pd.to_datetime(eb_apts['posted']) #Looking at what neighborhoods there are with eb_apts['neighborhood'].unique() allowed me to see what #I needed to deal with in terms of cleaning those. #remove the parenthesis from the left and right of the neighborhoods eb_apts['neighborhood'] = eb_apts['neighborhood'].map(lambda x: x.lstrip('(').rstrip(')')) #titlecase them eb_apts['neighborhood'] = eb_apts['neighborhood'].str.title() #just take the first name of the neighborhood list, splitting on the '/' delimiter eb_apts['neighborhood'] = eb_apts['neighborhood'].apply(lambda x: x.split('/')[0]) #fix one-offs that eb_apts['neighborhood'].replace('Belmont, Ca', 'Belmont', inplace=True) eb_apts['neighborhood'].replace('Hercules, Pinole, San Pablo, El Sob', 'Hercules', inplace=True) #remove whitespaces eb_apts['neighborhood'] = eb_apts['neighborhood'].apply(lambda x: x.strip()) #save the clean data eb_apts.to_csv(\u0026quot;eb_apts_1642_Jan_2_19_clean.csv\u0026quot;, index=False)  Exploratory Data Analysis Sadly, after removing the duplicate URLs I saw that there are only 120 instances. These numbers will be different if you run the code, since there will be different posts at different times of scraping. There were about 20 posts that didn’t have bedrooms or square footage listed too. For statistical reasons, this isn’t an incredible data set, but I took note of that and pushed forward.\nDescriptive statistics for the quantitative variables\nI wanted to see the distribution of the pricing for the East Bay so I made the above plot. Calling the .describe() method, I got a more detailed look. The cheapest place is $850, and the most expensive is $4,800.\nThe next code block generates a scatter plot, where the points are colored by the number of bedrooms. This shows a clear and understandable stratification: we see layers of points clustered around particular prices and square footages, and as price and square footage increase so do the number of bedrooms.\nimport matplotlib.pylab as pylab params = {'legend.fontsize': 'x-large', 'figure.figsize': (15, 5), 'axes.labelsize': 'x-large', 'axes.titlesize':'x-large', 'xtick.labelsize':'x-large', 'ytick.labelsize':'x-large'} pylab.rcParams.update(params) plt.figure(figsize=(12, 8)) sns.scatterplot(x='price', y='sqft', hue='number bedrooms', palette='summer', x_jitter=True, y_jitter=True, s=125, data=eb_apts.dropna()) plt.legend(fontsize=12) plt.xlabel(\u0026quot;Price\u0026quot;, fontsize=18) plt.ylabel(\u0026quot;Square Footage\u0026quot;, fontsize=18); plt.title(\u0026quot;Price vs. Square Footage Colored by Number of Bedrooms\u0026quot;, fontsize=18);  Let’s not forget the workhorse of Data Science: linear regression. We can call a regplot() on these two variables to get a regression line with a bootstrap confidence interval calculated about the line and shown as a shaded region with the code below. If you haven’t heard of bootstrap confidence intervals, they are a really cool statistical technique that are worth a read.\nplt.figure(figsize=(12, 8)) sns.regplot(x='price', y='sqft', data=eb_apts.dropna()); plt.title('Price vs. Square Footage Regression Plot'); plt.xlabel(\u0026quot;Price (USD)\u0026quot;); plt.ylabel(\u0026quot;Square Feet\u0026quot;);  It looks like we have an okay fit of the line on these two variables. Let’s check the correlations. I called eb_apts.corr() to get these:\nCorrelation matrix for our variables\nAs suspected, correlation is strong between number of bedrooms and square footage. That makes sense since square footage increases as the number of bedrooms increases.\nPricing By Neighborhood Continued I wanted to get a sense of how location affects price, so I grouped by neighborhood, and aggregated by calculating the mean for each variable.\nThe following is produced with this single line of code: eb_apts.groupby('neighborhood').mean() where ‘neighborhood’ is the ‘by=’ argument, and the aggregator function is the mean.\nI noticed that there are two North Oaklands: North Oakland and Oakland North, so I recoded one of them into the other like so:\neb_apts['neighborhood'].replace('North Oakland', ‘Oakland North', inplace=True).  Grabbing the price and sorting it in ascending order can show the cheapest and most expensive places to live. The full line of code is now: eb_apts.groupby('neighborhood').mean()['price'].sort_values() and results in the following output:\nAverage price by neighborhood sorted in ascending order\nLastly, I looked at the spread of each neighborhood in terms of price. By doing this, I saw how prices in neighborhoods can vary, and to what degree.\nHere’s the code that produces the plot that follows.\nsns.boxplot(x='neighborhood', y='price', data=eb_apts) plt.xlabel(\u0026quot;Neighborhood\u0026quot;); plt.xticks(rotation=75) plt.ylabel(\u0026quot;Price USD\u0026quot;); plt.title(\u0026quot;Prices by Neighborhood - Boxplots\u0026quot;);  Berkeley had a huge spread. This is probably because it includes South Berkeley, West Berkeley, and Downtown Berkeley. In a future version of this project it may be important to consider changing the scope of each of the variables so they are more reflective of the variability of price between neighborhoods in each city.\nWell, there you have it! Take a look at this the next time you’re in the market for housing to see what a good price should be. Feel free to check out the repo and try it for yourself, or fork the project and do it for your city! Let me know what you come up with!\nScrape responsibly.\n Source :.\n "});index.add({'id':263,'href':'/library/tutorials/docs/articles/data-science/web-scraping/web-scraping-nba-stats/','title':"Web Scraping NBA Stats",'content':" Web Scraping NBA Stats Source:\nEvery data analysis starts with an idea, hypothesis, problem, etc. The next step usually involves the most important element: data. Today, data is everywhere. For those of us who love diving into data, there are lots of resources to attain this part of the process. Whether it’s through Kaggle or UCI Machine Learning Repository, data is easily available. However, sometimes not all data is available to us. Sometimes, in order to continue a certain data analysis/project, we must do a bit more to get the correct, updated data we need.\nThis brings us to our topic: web scraping to create a data set. A while back, I worked on a basketball analytics project. The project was an analysis on individual stats of NBA players, and using some of those stats to predict win shares for the 2018 NBA season. As I began the project, I realized that the NBA data sets available on Kaggle did not have all the stats I needed to continue my analysis. Therefore, I decided to do a bit more research.\nFirst of all, my go-to site for all NBA stats is Basketball Reference. This site is essentially an encyclopedia for all things NBA stats. Then came my next question: Why not get the data directly from the Basketball Reference? After further research, I discovered a great Python library that solved this portion of my project:BeautifulSoup . This library is a web scraper that allows us to search through the HTML of a webpage and extract the information we need. From there, we will store the data we scraped onto a DataFrameusing pandas.\nFirst, let’s get all the Python libraries we will be using for this project:\nfrom urllib.request import urlopen from bs4 import BeautifulSoup import pandas as pd  Now, we determine the HTML page we will be scraping. For this part, I used the individual per game stats of players for the current 2018–2019 NBA season. The page on Basketball Reference looks like this:\nAs you can see, the data is already organized into a table. This makes web scraping a lot easier! Now we will use urlopen that we imported from the urllib.request library, then create a BeautifulSoup object by passing through html to BeautifulSoup().\n_# NBA season we will be analyzing year = 2019_# URL page we will scraping (see image above) url = \u0026quot;https://www.basketball-reference.com/leagues/NBA_{}_per_game.html\u0026quot;.format(year)_# this is the HTML from the given URL_ html = urlopen(url)soup = BeautifulSoup(html)  Here, the BeautifulSoup function passed through the entire web page in order to convert it into an object. Now we will trim the object to only include the table we need.\nThe next step is to organize the column headers. We want to extract the text content of each column header and store them into a list. We do this by inspecting the HTML (right-clicking the page and selecting “Inspect Element”) we see that the 2nd table row is the one that contains the column headers we want. By looking at the table, we can see the specific HTML tags that we will be using to extract the data:\nNow, we go back to BeautifulSoup. By using findAll(), we can get the first 2 rows (limit = 2) and pass the element we want as the first argument, in this case ‘_tr_’, which is the HTML tag for table row. After using findAll(), we use the getText() to extract the table header, or ‘_th_’, text we need and organize it into a list:\n# use findALL() to get the column headers soup.findAll('tr', limit=2)# use getText()to extract the text we need into a list headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]# exclude the first column as we will not need the ranking order from Basketball Reference for the analysis headers = headers[1:] headers  Next step, we will extract the data from the cells of the table in order to add it to our DataFrame. Although it is similar to extracting data from column header, the data within the cell, in this case player stats, is in a 2-dimensional format. Therefore, we must set up a 2-dimensional list:\n# avoid the first header row rows = soup.findAll('tr')[1:] player_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]  Now comes something a bit more familiar: pandas. With the data and columns headers we have extracted from Basketball Reference, we create a simple DataFrame:\nstats = pd.DataFrame(player_stats, columns = headers) stats.head(10)  Voilà! We have our own data set! In a matter of minutes, we analyzed an HTML document, extracted the data from the table, and organized it onto a DataFrame. For free! And without any hassle of searching for a .csv file that might not be up-to-date. We have data that comes directly from a source that is updated everyday. Of course, not every HTML document is created equally. There are pages that might require a bit more time in analyzing the HTML tags in order to extract the proper data.\nTo conclude this quick walk through, web scraping can be a simple task, but for certain HTML documents, it can be difficult. There are a bunch of helpful resources out there that will help you understand HTML tags, and get the data you need. There might be a problem you want to dive into, so don’t let limited data be an issue!\nHelpful Resources:  HTML Tags: Source 1 | Source 2 BeautifulSoup: Source 1 | Source 2  "});index.add({'id':264,'href':'/library/tutorials/docs/articles/data-science/web-scraping/web-scraping-using-beautifulsoup/','title':"Web Scraping Using BeautifulSoup",'content':" Tutorial: Python Web Scraping Using BeautifulSoup When performing data science tasks, it’s common to want to use data found on the internet. You’ll usually be able to access this data in csv format, or via an Application Programming Interface (API). However, there are times when the data you want can only be accessed as part of a web page. In cases like this, you’ll want to use a technique called web scraping to get the data from the web page into a format you can work with in your analysis.\nIn this tutorial, we’ll show you how to perform web scraping using Python 3 and the BeautifulSoup library. We’ll be scraping weather forecasts from the National Weather Service, and then analyzing them using the Pandas library.\nWe’ll be scraping weather forecasts from the National Weather Service site.\nBefore we get started, if you’re looking for more background on APIs or the csv format, you might want to check out our Dataquest courses on APIs or data analysis.\nThe components of a web page When we visit a web page, our web browser makes a request to a web server. This request is called a GET request, since we’re getting files from the server. The server then sends back files that tell our browser how to render the page for us. The files fall into a few main types:\n HTML — contain the main content of the page. CSS — add styling to make the page look nicer. JS — Javascript files add interactivity to web pages. Images — image formats, such as JPG and PNG allow web pages to show pictures.  After our browser receives all the files, it renders the page and displays it to us. There’s a lot that happens behind the scenes to render a page nicely, but we don’t need to worry about most of it when we’re web scraping. When we perform web scraping, we’re interested in the main content of the web page, so we look at the HTML.\nHTML HyperText Markup Language (HTML) is a language that web pages are created in. HTML isn’t a programming language, like Python — instead, it’s a markup language that tells a browser how to layout content. HTML allows you to do similar things to what you do in a word processor like Microsoft Word — make text bold, create paragraphs, and so on. Because HTML isn’t a programming language, it isn’t nearly as complex as Python.\nLet’s take a quick tour through HTML so we know enough to scrape effectively. HTML consists of elements called tags. The most basic tag is the \u0026lt;html\u0026gt; tag. This tag tells the web browser that everything inside of it is HTML. We can make a simple HTML document just using this tag:\n\u0026lt;html\u0026gt; \u0026lt;/html\u0026gt;  We haven’t added any content to our page yet, so if we viewed our HTML document in a web browser, we wouldn’t see anything:\nRight inside an html tag, we put two other tags, the head tag, and the body tag. The main content of the web page goes into the body tag. The head tag contains data about the title of the page, and other information that generally isn’t useful in web scraping:\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  We still haven’t added any content to our page (that goes inside the body tag), so we again won’t see anything:\nYou may have noticed above that we put the head and body tags inside the html tag. In HTML, tags are nested, and can go inside other tags.\nWe’ll now add our first content to the page, in the form of the p tag. The p tag defines a paragraph, and any text inside the tag is shown as a separate paragraph:\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt; Here's a paragraph of text! \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; Here's a second paragraph of text! \u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  Here’s how this will look:\nHere’s a paragraph of text!\nHere’s a second paragraph of text!\nTags have commonly used names that depend on their position in relation to other tags:\n child — a child is a tag inside another tag. So the two p tags above are both children of the body tag. parent — a parent is the tag another tag is inside. Above, the html tag is the parent of the body tag. sibiling — a sibiling is a tag that is nested inside the same parent as another tag. For example, head and body are siblings, since they’re both inside html. Both p tags are siblings, since they’re both inside body.  We can also add properties to HTML tags that change their behavior:\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt; Here's a paragraph of text! \u0026lt;a href=\u0026quot;https://www.dataquest.io\u0026quot;\u0026gt;Learn Data Science Online\u0026lt;/a\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; Here's a second paragraph of text! \u0026lt;a href=\u0026quot;https://www.python.org\u0026quot;\u0026gt;Python\u0026lt;/a\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt;\u0026lt;/html\u0026gt;  Here’s how this will look:\nHere’s a paragraph of text! Learn Data Science Online\nHere’s a second paragraph of text! Python\nIn the above example, we added two a tags. a tags are links, and tell the browser to render a link to another web page. The href property of the tag determines where the link goes.\na and p are extremely common html tags. Here are a few others:\n div — indicates a division, or area, of the page. b — bolds any text inside. i — italicizes any text inside. table — creates a table. form — creates an input form.  For a full list of tags, look here.\nBefore we move into actual web scraping, let’s learn about the class and id properties. These special properties give HTML elements names, and make them easier to interact with when we’re scraping. One element can have multiple classes, and a class can be shared between elements. Each element can only have one id, and an id can only be used once on a page. Classes and ids are optional, and not all elements will have them.\nWe can add classes and ids to our example:\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p class=\u0026quot;bold-paragraph\u0026quot;\u0026gt; Here's a paragraph of text! \u0026lt;a href=\u0026quot;https://www.dataquest.io\u0026quot; id=\u0026quot;learn-link\u0026quot;\u0026gt;Learn Data Science Online\u0026lt;/a\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;p class=\u0026quot;bold-paragraph extra-large\u0026quot;\u0026gt; Here's a second paragraph of text! \u0026lt;a href=\u0026quot;https://www.python.org\u0026quot; class=\u0026quot;extra-large\u0026quot;\u0026gt;Python\u0026lt;/a\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  Here’s how this will look:\nHere’s a paragraph of text! Learn Data Science Online\nHere’s a second paragraph of text! Python\nAs you can see, adding classes and ids doesn’t change how the tags are rendered at all.\nThe requests library The first thing we’ll need to do to scrape a web page is to download the page. We can download pages using the Python requests library. The requests library will make a GET request to a web server, which will download the HTML contents of a given web page for us. There are several different types of requests we can make using requests, of which GET is just one. If you want to learn more, check out our API tutorial.\nLet’s try downloading a simple sample website, http://dataquestio.github.io/web-scraping-pages/simple.html. We’ll need to first download it using the requests.get method.\nimport requests page = requests.get(\u0026quot;http://dataquestio.github.io/web-scraping-pages/simple.html\u0026quot;) page  \u0026lt;Response [200]\u0026gt;  After running our request, we get a Response object. This object has a status_code property, which indicates if the page was downloaded successfully:\npage.status_code  200  A status_code of 200 means that the page downloaded successfully. We won’t fully dive into status codes here, but a status code starting with a 2 generally indicates success, and a code starting with a 4 or a 5 indicates an error.\nWe can print out the HTML content of the page using the content property:\npage.content  b'\u0026lt;!DOCTYPE html\u0026gt;\\n \u0026lt;html\u0026gt;\\n \u0026lt;head\u0026gt;\\n \u0026lt;title\u0026gt;A simple example page\u0026lt;/title\u0026gt;\\n \u0026lt;/head\u0026gt;\\n \u0026lt;body\u0026gt;\\n \u0026lt;p\u0026gt;Here is some simple content for this page.\u0026lt;/p\u0026gt;\\n \u0026lt;/body\u0026gt;\\n \u0026lt;/html\u0026gt;'  Parsing a page with BeautifulSoup As you can see above, we now have downloaded an HTML document.\nWe can use the BeautifulSoup library to parse this document, and extract the text from the p tag. We first have to import the library, and create an instance of the BeautifulSoup class to parse our document:\nfrom bs4 import BeautifulSoup soup = BeautifulSoup(page.content, 'html.parser')  We can now print out the HTML content of the page, formatted nicely, using the prettify method on the BeautifulSoup object:\nprint(soup.prettify())  \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt; A simple example page \u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt; Here is some simple content for this page. \u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  As all the tags are nested, we can move through the structure one level at a time. We can first select all the elements at the top level of the page using the children property of soup. Note that children returns a list generator, so we need to call the list function on it:\nlist(soup.children)  ['html', '\\n', \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;A simple example page\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Here is some simple content for this page.\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;]  The above tells us that there are two tags at the top level of the page — the initial \u0026lt;!DOCTYPE html\u0026gt; tag, and the \u0026lt;html\u0026gt; tag. There is a newline character (\\n) in the list as well. Let’s see what the type of each element in the list is:\n[type(item) for item in list(soup.children)]  [bs4.element.Doctype, bs4.element.NavigableString, bs4.element.Tag]  As you can see, all of the items are BeautifulSoup objects. The first is a Doctype object, which contains information about the type of the document. The second is a NavigableString, which represents text found in the HTML document. The final item is a Tag object, which contains other nested tags. The most important object type, and the one we’ll deal with most often, is the Tag object.\nThe Tag object allows us to navigate through an HTML document, and extract other tags and text. You can learn more about the various BeautifulSoup objects here.\nWe can now select the html tag and its children by taking the third item in the list:\nhtml = list(soup.children)[2]  Each item in the list returned by the children property is also a BeautifulSoup object, so we can also call the children method on html.\nNow, we can find the children inside the html tag:\nlist(html.children)  ['\\n', \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;A simple example page\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt;, '\\n', \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Here is some simple content for this page.\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt;, '\\n']  As you can see above, there are two tags here, head, and body. We want to extract the text inside the p tag, so we’ll dive into the body:\nbody = list(html.children)[3]  Now, we can get the p tag by finding the children of the body tag:\nlist(body.children)  ['\\n', \u0026lt;p\u0026gt;Here is some simple content for this page.\u0026lt;/p\u0026gt;, '\\n']  We can now isolate the p tag:\np = list(body.children)[1]  Once we’ve isolated the tag, we can use the get_text method to extract all of the text inside the tag:\np.get_text()  'Here is some simple content for this page.'  Finding all instances of a tag at once What we did above was useful for figuring out how to navigate a page, but it took a lot of commands to do something fairly simple. If we want to extract a single tag, we can instead use the find_all method, which will find all the instances of a tag on a page.\nsoup = BeautifulSoup(page.content, 'html.parser') soup.find_all('p')  [\u0026lt;p\u0026gt;Here is some simple content for this page.\u0026lt;/p\u0026gt;]  Note that find_all returns a list, so we’ll have to loop through, or use list indexing, it to extract text:\nsoup.find_all('p')[0].get_text()  'Here is some simple content for this page.'  If you instead only want to find the first instance of a tag, you can use the find method, which will return a single BeautifulSoup object:\nsoup.find('p')  \u0026lt;p\u0026gt;Here is some simple content for this page.\u0026lt;/p\u0026gt;  Searching for tags by class and id We introduced classes and ids earlier, but it probably wasn’t clear why they were useful. Classes and ids are used by CSS to determine which HTML elements to apply certain styles to. We can also use them when scraping to specify specific elements we want to scrape. To illustrate this principle, we’ll work with the following page:\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;A simple example page\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div\u0026gt; \u0026lt;p class=\u0026quot;inner-text first-item\u0026quot; id=\u0026quot;first\u0026quot;\u0026gt; First paragraph. \u0026lt;/p\u0026gt; \u0026lt;p class=\u0026quot;inner-text\u0026quot;\u0026gt; Second paragraph. \u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;p class=\u0026quot;outer-text first-item\u0026quot; id=\u0026quot;second\u0026quot;\u0026gt; \u0026lt;b\u0026gt; First outer paragraph. \u0026lt;/b\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;p class=\u0026quot;outer-text\u0026quot;\u0026gt; \u0026lt;b\u0026gt; Second outer paragraph. \u0026lt;/b\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  We can access the above document at the URL http://dataquestio.github.io/web-scraping-pages/ids_and_classes.html. Let’s first download the page and create a BeautifulSoup object:\npage = requests.get(\u0026quot;http://dataquestio.github.io/web-scraping-pages/ids_and_classes.html\u0026quot;) soup = BeautifulSoup(page.content, 'html.parser') soup  \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;A simple example page \u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div\u0026gt; \u0026lt;p class=\u0026quot;inner-text first-item\u0026quot; id=\u0026quot;first\u0026quot;\u0026gt; First paragraph. \u0026lt;/p\u0026gt;\u0026lt;p class=\u0026quot;inner-text\u0026quot;\u0026gt; Second paragraph. \u0026lt;/p\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;p class=\u0026quot;outer-text first-item\u0026quot; id=\u0026quot;second\u0026quot;\u0026gt;\u0026lt;b\u0026gt; First outer paragraph. \u0026lt;/b\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p class=\u0026quot;outer-text\u0026quot;\u0026gt;\u0026lt;b\u0026gt; Second outer paragraph. \u0026lt;/b\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  Now, we can use the find_all method to search for items by class or by id. In the below example, we’ll search for any p tag that has the class outer-text:\nsoup.find_all('p', class_='outer-text')  [\u0026lt;p class=\u0026quot;outer-text first-item\u0026quot; id=\u0026quot;second\u0026quot;\u0026gt; \u0026lt;b\u0026gt; First outer paragraph. \u0026lt;/b\u0026gt; \u0026lt;/p\u0026gt;, \u0026lt;p class=\u0026quot;outer-text\u0026quot;\u0026gt; \u0026lt;b\u0026gt; Second outer paragraph. \u0026lt;/b\u0026gt; \u0026lt;/p\u0026gt;]  In the below example, we’ll look for any tag that has the class outer-text:\nsoup.find_all(class_=\u0026quot;outer-text\u0026quot;)  \u0026lt;p class=\u0026quot;outer-text first-item\u0026quot; id=\u0026quot;second\u0026quot;\u0026gt; \u0026lt;b\u0026gt; First outer paragraph. \u0026lt;/b\u0026gt; \u0026lt;/p\u0026gt;, \u0026lt;p class=\u0026quot;outer-text\u0026quot;\u0026gt; \u0026lt;b\u0026gt; Second outer paragraph. \u0026lt;/b\u0026gt; \u0026lt;/p\u0026gt;]  We can also search for elements by id:\nsoup.find_all(id=\u0026quot;first\u0026quot;)  [\u0026lt;p class=\u0026quot;inner-text first-item\u0026quot; id=\u0026quot;first\u0026quot;\u0026gt; First paragraph. \u0026lt;/p\u0026gt;]  Using CSS Selectors You can also search for items using CSS selectors. These selectors are how the CSS language allows developers to specify HTML tags to style. Here are some examples:\n p a — finds all a tags inside of a p tag. body p a — finds all a tags inside of a p tag inside of a body tag. html body — finds all body tags inside of an html tag. p.outer-text — finds all p tags with a class of outer-text. p#first — finds all p tags with an id of first. body p.outer-text — finds any p tags with a class of outer-text inside of a body tag.  You can learn more about CSS selectors here.\nBeautifulSoup objects support searching a page via CSS selectors using the select method. We can use CSS selectors to find all the p tags in our page that are inside of a div like this:\nsoup.select(\u0026quot;div p\u0026quot;)  [\u0026lt;p class=\u0026quot;inner-text first-item\u0026quot; id=\u0026quot;first\u0026quot;\u0026gt; First paragraph. \u0026lt;/p\u0026gt;, \u0026lt;p class=\u0026quot;inner-text\u0026quot;\u0026gt; Second paragraph. \u0026lt;/p\u0026gt;]  Note that the select method above returns a list of BeautifulSoup objects, just like find and find_all.\nDownloading weather data We now know enough to proceed with extracting information about the local weather from the National Weather Service website. The first step is to find the page we want to scrape. We’ll extract weather information about downtown San Francisco from this page.\nWe’ll extract data about the extended forecast.\nAs you can see from the image, the page has information about the extended forecast for the next week, including time of day, temperature, and a brief description of the conditions.\nExploring page structure with Chrome DevTools The first thing we’ll need to do is inspect the page using Chrome Devtools. If you’re using another browser, Firefox and Safari have equivalents. It’s recommended to use Chrome though.\nYou can start the developer tools in Chrome by clicking View -\u0026gt; Developer -\u0026gt; Developer Tools. You should end up with a panel at the bottom of the browser like what you see below. Make sure the Elements panel is highlighted:\nChrome Developer Tools.\nThe elements panel will show you all the HTML tags on the page, and let you navigate through them. It’s a really handy feature!\nBy right clicking on the page near where it says “Extended Forecast”, then clicking “Inspect”, we’ll open up the tag that contains the text “Extended Forecast” in the elements panel:\nThe extended forecast text.\nWe can then scroll up in the elements panel to find the “outermost” element that contains all of the text that corresponds to the extended forecasts. In this case, it’s a div tag with the id seven-day-forecast:\nThe div that contains the extended forecast items.\nIf you click around on the console, and explore the div, you’ll discover that each forecast item (like “Tonight”, “Thursday”, and “Thursday Night”) is contained in a div with the class tombstone-container.\nWe now know enough to download the page and start parsing it. In the below code, we:\n Download the web page containing the forecast. Create a BeautifulSoup class to parse the page. Find the div with id seven-day-forecast, and assign to seven_day Inside seven_day, find each individual forecast item. Extract and print the first forecast item.\npage = requests.get(\u0026quot;http://forecast.weather.gov/MapClick.php?lat=37.7772\u0026amp;lon=-122.4168\u0026quot;) soup = BeautifulSoup(page.content, 'html.parser') seven_day = soup.find(id=\u0026quot;seven-day-forecast\u0026quot;) forecast_items = seven_day.find_all(class_=\u0026quot;tombstone-container\u0026quot;) tonight = forecast_items[0] print(tonight.prettify())  \u0026lt;div class=\u0026quot;tombstone-container\u0026quot;\u0026gt; \u0026lt;p class=\u0026quot;period-name\u0026quot;\u0026gt; Tonight \u0026lt;br\u0026gt; \u0026lt;br/\u0026gt; \u0026lt;/br\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; \u0026lt;img alt=\u0026quot;Tonight: Mostly clear, with a low around 49. West northwest wind 12 to 17 mph decreasing to 6 to 11 mph after midnight. Winds could gust as high as 23 mph. \u0026quot; class=\u0026quot;forecast-icon\u0026quot; src=\u0026quot;newimages/medium/nfew.png\u0026quot; title=\u0026quot;Tonight: Mostly clear, with a low around 49. West northwest wind 12 to 17 mph decreasing to 6 to 11 mph after midnight. Winds could gust as high as 23 mph. \u0026quot;/\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;p class=\u0026quot;short-desc\u0026quot;\u0026gt; Mostly Clear \u0026lt;/p\u0026gt; \u0026lt;p class=\u0026quot;temp temp-low\u0026quot;\u0026gt; Low: 49 °F \u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt;   Extracting information from the page As you can see, inside the forecast item tonight is all the information we want. There are 4 pieces of information we can extract:\n The name of the forecast item — in this case, Tonight. The description of the conditions — this is stored in the title property of img. A short description of the conditions — in this case, Mostly Clear. The temperature low — in this case, 49 degrees.  We’ll extract the name of the forecast item, the short description, and the temperature first, since they’re all similar:\nperiod = tonight.find(class_=\u0026quot;period-name\u0026quot;).get_text() short_desc = tonight.find(class_=\u0026quot;short-desc\u0026quot;).get_text() temp = tonight.find(class_=\u0026quot;temp\u0026quot;).get_text() print(period) print(short_desc) print(temp)  Tonight Mostly Clear Low: 49 °F  Now, we can extract the title attribute from the img tag. To do this, we just treat the BeautifulSoup object like a dictionary, and pass in the attribute we want as a key:\nimg = tonight.find(\u0026quot;img\u0026quot;) desc = img['title'] print(desc)  Tonight: Mostly clear, with a low around 49. West northwest wind 12 to 17 mph decreasing to 6 to 11 mph after midnight. Winds could gust as high as 23 mph.  Extracting all the information from the page Now that we know how to extract each individual piece of information, we can combine our knowledge with css selectors and list comprehensions to extract everything at once.\nIn the below code, we:\n Select all items with the class period-name inside an item with the class tombstone-container in seven_day. Use a list comprehension to call the get_text method on each BeautifulSoup object.\nperiod_tags = seven_day.select(\u0026quot;.tombstone-container .period-name\u0026quot;) periods = [pt.get_text() for pt in period_tags] periods  ['Tonight', 'Thursday', 'ThursdayNight', 'Friday', 'FridayNight', 'Saturday', 'SaturdayNight', 'Sunday', 'SundayNight']   As you can see above, our technique gets us each of the period names, in order. We can apply the same technique to get the other 3 fields:\nshort_descs = [sd.get_text() for sd in seven_day.select(\u0026quot;.tombstone-container .short-desc\u0026quot;)] temps = [t.get_text() for t in seven_day.select(\u0026quot;.tombstone-container .temp\u0026quot;)] descs = [d[\u0026quot;title\u0026quot;] for d in seven_day.select(\u0026quot;.tombstone-container img\u0026quot;)]print(short_descs)print(temps)print(descs)  ['Mostly Clear', 'Sunny', 'Mostly Clear', 'Sunny', 'Slight ChanceRain', 'Rain Likely', 'Rain Likely', 'Rain Likely', 'Chance Rain'] ['Low: 49 °F', 'High: 63 °F', 'Low: 50 °F', 'High: 67 °F', 'Low: 57 °F', 'High: 64 °F', 'Low: 57 °F', 'High: 64 °F', 'Low: 55 °F'] ['Tonight: Mostly clear, with a low around 49. West northwest wind 12 to 17 mph decreasing to 6 to 11 mph after midnight. Winds could gust as high as 23 mph. ', 'Thursday: Sunny, with a high near 63. North wind 3 to 5 mph. ', 'Thursday Night: Mostly clear, with a low around 50. Light and variable wind becoming east southeast 5 to 8 mph after midnight. ', 'Friday: Sunny, with a high near 67. Southeast wind around 9 mph. ', 'Friday Night: A 20 percent chance of rain after 11pm. Partly cloudy, with a low around 57. South southeast wind 13 to 15 mph, with gusts as high as 20 mph. New precipitation amounts of less than a tenth of an inch possible. ', 'Saturday: Rain likely. Cloudy, with a high near 64. Chance of precipitation is 70%. New precipitation amounts between a quarter and half of an inch possible. ', 'Saturday Night: Rain likely. Cloudy, with a low around 57. Chance of precipitation is 60%.', 'Sunday: Rain likely. Cloudy, with a high near 64.', 'Sunday Night: A chance of rain. Mostly cloudy, with a low around 55.']  Combining our data into a Pandas Dataframe We can now combine the data into a Pandas DataFrame and analyze it. A DataFrame is an object that can store tabular data, making data analysis easy. If you want to learn more about Pandas, check out our free to start course here.\nIn order to do this, we’ll call the DataFrame class, and pass in each list of items that we have. We pass them in as part of a dictionary. Each dictionary key will become a column in the DataFrame, and each list will become the values in the column:\nimport pandas as pd weather = pd.DataFrame({ \u0026quot;period\u0026quot;: periods, \u0026quot;short_desc\u0026quot;: short_descs, \u0026quot;temp\u0026quot;: temps, \u0026quot;desc\u0026quot;:descs }) weather      desc period short_desc temp     0 Tonight: Mostly clear, with a low around 49. W… Tonight Mostly Clear Low: 49 °F   1 Thursday: Sunny, with a high near 63. North wi… Thursday Sunny High: 63 °F   2 Thursday Night: Mostly clear, with a low aroun… ThursdayNight Mostly Clear Low: 50 °F   3 Friday: Sunny, with a high near 67. Southeast … Friday Sunny High: 67 °F   4 Friday Night: A 20 percent chance of rain afte… FridayNight Slight ChanceRain Low: 57 °F   5 Saturday: Rain likely. Cloudy, with a high ne… Saturday Rain Likely High: 64 °F   6 Saturday Night: Rain likely. Cloudy, with a l… SaturdayNigh t Rain Likely Low: 57 °F   7 Sunday: Rain likely. Cloudy, with a high near… Sunday Rain Likely High: 64 °F   8 Sunday Night: A chance of rain. Mostly cloudy… SundayNight Chance Rain Low: 55 °F    We can now do some analysis on the data. For example, we can use a regular expression and the Series.str.extract method to pull out the numeric temperature values:\ntemp_nums = weather[\u0026quot;temp\u0026quot;].str.extract(\u0026quot;(?P\u0026lt;temp_num\u0026gt;\\d+)\u0026quot;, expand=False) weather[\u0026quot;temp_num\u0026quot;] = temp_nums.astype('int') temp_nums  0 49 1 63 2 50 3 67 4 57 5 64 6 57 7 64 8 55 Name: temp_num, dtype: object  We could then find the mean of all the high and low temperatures:\nweather[\u0026quot;temp_num\u0026quot;].mean()  58.444444444444443  We could also only select the rows that happen at night:\nis_night = weather[\u0026quot;temp\u0026quot;].str.contains(\u0026quot;Low\u0026quot;) weather[\u0026quot;is_night\u0026quot;] = is_night is_night  0 True 1 False 2 True 3 False 4 True 5 False 6 True 7 False 8 True Name: temp, dtype: bool  weather[is_night]      desc period short_desc temp temp_num is_night     0 Tonight: Mostly clear, with a low around 49. W… Tonight Mostly Clear Low: 49 °F 49 True   2 Thursday Night: Mostly clear, with a low aroun… ThursdayNight Mostly Clear Low: 50 °F 50 True   4 Friday Night: A 20 percent chance of rain afte… FridayNight Slight ChanceRain Low: 57 °F 57 True   6 Saturday Night: Rain likely. Cloudy, with a l… SaturdayNight Rain Likely Low: 57 °F 57 True   8 Sunday Night: A chance of rain. Mostly cloudy… SundayNight Chance Rain Low: 55 °F 55 True    Next Steps You should now have a good understanding of how to scrape web pages and extract data. A good next step would be to pick a site and try some web scraping on your own. Some good examples of data to scrape are:\n News articles Sports scores Weather forecasts Stock prices Online retailer prices  You may also want to keep scraping the National Weather Service, and see what other data you can extract from the page, or about your own city.\nIf you want to learn more about any of the topics covered here, check out our interactive courses which you can start for free: Web Scraping in Python\n Source : .\n "});index.add({'id':265,'href':'/library/tutorials/docs/python/snippets/when/','title':"when",'content':"Tests a value, x, against a predicate function, conditionally applying a function.\nCheck if the value of predicate(x) is True and if so return when_true(x), otherwise return x.\ndef when(predicate, when_true): return lambda x: when_true(x) if predicate(x) else x  double_even_numbers = when(lambda x: x % 2 == 0, lambda x : x * 2) double_even_numbers(2) # 4 double_even_numbers(1) # 1  "});index.add({'id':266,'href':'/library/tutorials/docs/articles/data-science/pandas/missing_data/','title':"Working with missing data",'content':" Working with missing data In this section, we will discuss missing (also referred to as NA) values in pandas.\n Note The choice of using NaN internally to denote missing data was largely for simplicity and performance reasons. Starting from pandas 1.0, some optional data types start experimenting with a native NA scalar using a mask-based approach. See here for more.\n See the cookbook for some advanced strategies.\nValues considered “missing” As data comes in many shapes and forms, pandas aims to be flexible with regard to handling missing data. While NaN is the default missing value marker for reasons of computational speed and convenience, we need to be able to easily detect this value with data of different types: floating point, integer, boolean, and general object. In many cases, however, the Python None will arise and we wish to also consider that “missing” or “not available” or “NA”.\n Note\nIf you want to consider inf and -inf to be “NA” in computations, you can set `pandas.options.mode. use_inf_as_na = True.\n In [1]: df = pd.DataFrame(np.random.randn(5, 3), index=['a', 'c', 'e', 'f', 'h'], columns=['one', 'two', 'three']) In [2]: df['four'] = 'bar' In [3]: df['five'] = df['one'] \u0026gt; 0 In [4]: df #Out[4]: one two three four five a 0.469112 -0.282863 -1.509059 bar True c -1.135632 1.212112 -0.173215 bar False e 0.119209 -1.044236 -0.861849 bar True f -2.104569 -0.494929 1.071804 bar False h 0.721555 -0.706771 -1.039575 bar True  In [5]: df2 = df.reindex(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']) In [6]: df2 #Out[6]: one two three four five a 0.469112 -0.282863 -1.509059 bar True b NaN NaN NaN NaN NaN c -1.135632 1.212112 -0.173215 bar False d NaN NaN NaN NaN NaN e 0.119209 -1.044236 -0.861849 bar True f -2.104569 -0.494929 1.071804 bar False g NaN NaN NaN NaN NaN h 0.721555 -0.706771 -1.039575 bar True  To make detecting missing values easier (and across different array dtypes), pandas provides the isna() and notna() functions, which are also methods on Series and DataFrame objects:\nIn [7]: df2['one'] #Out[7]: a 0.469112 b NaN c -1.135632 d NaN e 0.119209 f -2.104569 g NaN h 0.721555 Name: one, dtype: float64  In [8]: pd.isna(df2['one']) #Out[8]: a False b True c False d True e False f False g True h False Name: one, dtype: bool  In [9]: df2['four'].notna() #Out[9]: a True b False c True d False e True f True g False h True Name: four, dtype: bool  In [10]: df2.isna() #Out[11]: one two three four five a False False False False False b True True True True True c False False False False False d True True True True True e False False False False False f False False False False False g True True True True True h False False False False False   Warning One has to be mindful that in Python (and NumPy), the nan's don’t compare equal, but None's do. Note that pandas/NumPy uses the fact that np.nan != np.nan, and treats None like np.nan.\n In [11]: None == None # noqa: E711 #Out[11]: True  In [12]: np.nan == np.nan #Out[12]: False  So as compared to above, a scalar equality comparison versus a None/np.nan doesn’t provide useful information.\nIn [13]: df2['one'] == np.nan a False b False c False d False e False f False g False h False Name: one, dtype: bool  Integer dtypes and missing data Because NaN is a float, a column of integers with even one missing values is cast to floating-point dtype (see Support for integer NA for more). Pandas provides a nullable integer array, which can be used by explicitly requesting the dtype:\nIn [14]: pd.Series([1, 2, np.nan, 4], dtype=pd.Int64Dtype()) #Out[14]: 0 1 1 2 2 \u0026lt;NA\u0026gt; 3 4 dtype: Int64  Alternatively, the string alias dtype='Int64' (note the capital \u0026quot;I\u0026quot;) can be used.\nSee Nullable integer data type for more.\nDatetimes For datetime64[ns] types, NaT represents missing values. This is a pseudo-native sentinel value that can be represented by NumPy in a singular dtype (datetime64[ns]). pandas objects provide compatibility between NaT and NaN.\nIn [15]: df2 = df.copy() In [16]: df2['timestamp'] = pd.Timestamp('20120101') In [17]: df2 #Out[17]: one two three four five timestamp a 0.469112 -0.282863 -1.509059 bar True 2012-01-01 c -1.135632 1.212112 -0.173215 bar False 2012-01-01 e 0.119209 -1.044236 -0.861849 bar True 2012-01-01 f -2.104569 -0.494929 1.071804 bar False 2012-01-01 h 0.721555 -0.706771 -1.039575 bar True 2012-01-01  In [18]: df2.loc[['a', 'c', 'h'], ['one', 'timestamp']] = np.nan In [19]: df2 #Out[19]: one two three four five timestamp a NaN -0.282863 -1.509059 bar True NaT c NaN 1.212112 -0.173215 bar False NaT e 0.119209 -1.044236 -0.861849 bar True 2012-01-01 f -2.104569 -0.494929 1.071804 bar False 2012-01-01 h NaN -0.706771 -1.039575 bar True NaT  In [20]: df2.dtypes.value_counts() #Out[20]: float64 3 datetime64[ns] 1 bool 1 object 1 dtype: int64  Inserting missing data You can insert missing values by simply assigning to containers. The actual missing value used will be chosen based on the dtype.\nFor example, numeric containers will always use NaN regardless of the missing value type chosen:\nIn [21]: s = pd.Series([1, 2, 3]) In [22]: s.loc[0] = None In [23]: s #Out[23]: 0 NaN 1 2.0 2 3.0 dtype: float64  Likewise, datetime containers will always use NaT.\nFor object containers, pandas will use the value given:\nIn [24]: s = pd.Series([\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;]) In [25]: s.loc[0] = None In [26]: s.loc[1] = np.nan In [27]: s #Out[27]: 0 None 1 NaN 2 c dtype: object  Calculations with missing data Missing values propagate naturally through arithmetic operations between pandas objects.\nIn [28]: a #Out[28]: one two a NaN -0.282863 c NaN 1.212112 e 0.119209 -1.044236 f -2.104569 -0.494929 h -2.104569 -0.706771  In [29]: b #Out[29]: one two three a NaN -0.282863 -1.509059 c NaN 1.212112 -0.173215 e 0.119209 -1.044236 -0.861849 f -2.104569 -0.494929 1.071804 h NaN -0.706771 -1.039575  In [30]: a + b #Out[30]: one three two a NaN NaN -0.565727 c NaN NaN 2.424224 e 0.238417 NaN -2.088472 f -4.209138 NaN -0.989859 h NaN NaN -1.413542  The descriptive statistics and computational methods discussed in the data structure overview (and listed here and here) are all written to account for missing data. For example:\n When summing data, NA (missing) values will be treated as zero.\n If the data are all NA, the result will be 0.\n Cumulative methods like cumsum() and cumprod() ignore NA values by default, but preserve them in the resulting arrays. To override this behaviour and include NA values, use skipna=False.\nIn [31]: df #Out[31]: one two three a NaN -0.282863 -1.509059 c NaN 1.212112 -0.173215 e 0.119209 -1.044236 -0.861849 f -2.104569 -0.494929 1.071804 h NaN -0.706771 -1.039575  In [32]: df['one'].sum() #Out[32]: -1.9853605075978744  In [33]: df.mean(1) #Out[33]: a -0.895961 c 0.519449 e -0.595625 f -0.509232 h -0.873173 dtype: float64  In [34]: df.cumsum() #Out[34]: one two three a NaN -0.282863 -1.509059 c NaN 0.929249 -1.682273 e 0.119209 -0.114987 -2.544122 f -1.985361 -0.609917 -1.472318 h NaN -1.316688 -2.511893  In [35]: df.cumsum(skipna=False) #Out[35]: one two three a NaN -0.282863 -1.509059 c NaN 0.929249 -1.682273 e NaN -0.114987 -2.544122 f NaN -0.609917 -1.472318 h NaN -1.316688 -2.511893   Sum/prod of empties/nans  Warning This behavior is now standard as of v0.22.0 and is consistent with the default in numpy; previously sum/prod of all-NA or empty Series/DataFrames would return NaN. See v0.22.0 whatsnew for more.\n The sum of an empty or all-NA Series or column of a DataFrame is 0.\nIn [36]: pd.Series([np.nan]).sum()  #Out[36]: 0.0  In [37]: pd.Series([], dtype=\u0026quot;float64\u0026quot;).sum() #Out[37]: 0.0  The product of an empty or all-NA Series or column of a DataFrame is 1.\nIn [38]: pd.Series([np.nan]).prod() #Out[38]: 1.0  In [39]: pd.Series([], dtype=\u0026quot;float64\u0026quot;).prod() #Out[39]: 1.0  NA values in GroupBy NA groups in GroupBy are automatically excluded. This behavior is consistent with R, for example:\nIn [40]: df #Out[40]: one two three a NaN -0.282863 -1.509059 c NaN 1.212112 -0.173215 e 0.119209 -1.044236 -0.861849 f -2.104569 -0.494929 1.071804 h NaN -0.706771 -1.039575  In [41]: df.groupby('one').mean() #Out[41]: two three one -2.104569 -0.494929 1.071804 0.119209 -1.044236 -0.861849  See the groupby section here for more information.\nCleaning / filling missing data[](https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html#cleaning-filling-missing-data \u0026ldquo;Permalink to this headline\u0026rdquo;) pandas objects are equipped with various data manipulation methods for dealing with missing data.\nFilling missing values: fillna fillna() can “fill in” NA values with non-NA data in a couple of ways, which we illustrate:\nReplace NA with a scalar value\nIn [42]: df2 #Out[42]: one two three four five timestamp a NaN -0.282863 -1.509059 bar True NaT c NaN 1.212112 -0.173215 bar False NaT e 0.119209 -1.044236 -0.861849 bar True 2012-01-01 f -2.104569 -0.494929 1.071804 bar False 2012-01-01 h NaN -0.706771 -1.039575 bar True NaT  In [43]: df2.fillna(0) #Out[43]: one two three four five timestamp a 0.000000 -0.282863 -1.509059 bar True 0 c 0.000000 1.212112 -0.173215 bar False 0 e 0.119209 -1.044236 -0.861849 bar True 2012-01-01 00:00:00 f -2.104569 -0.494929 1.071804 bar False 2012-01-01 00:00:00 h 0.000000 -0.706771 -1.039575 bar True 0  In [44]: df2['one'].fillna('missing') #Out[44]: a missing c missing e 0.119209 f -2.10457 h missing Name: one, dtype: object  Fill gaps forward or backward\nUsing the same filling arguments as reindexing, we can propagate non-NA values forward or backward:\nIn [45]: df #Out[45]: one two three a NaN -0.282863 -1.509059 c NaN 1.212112 -0.173215 e 0.119209 -1.044236 -0.861849 f -2.104569 -0.494929 1.071804 h NaN -0.706771 -1.039575  In [46]: df.fillna(method='pad') #Out[46]: one two three a NaN -0.282863 -1.509059 c NaN 1.212112 -0.173215 e 0.119209 -1.044236 -0.861849 f -2.104569 -0.494929 1.071804 h -2.104569 -0.706771 -1.039575  Limit the amount of filling\nIf we only want consecutive gaps filled up to a certain number of data points, we can use the limit keyword:\nIn [47]: df #Out[47]: one two three a NaN -0.282863 -1.509059 c NaN 1.212112 -0.173215 e NaN NaN NaN f NaN NaN NaN h NaN -0.706771 -1.039575  In [48]: df.fillna(method='pad', limit=1) #Out[48]: one two three a NaN -0.282863 -1.509059 c NaN 1.212112 -0.173215 e NaN 1.212112 -0.173215 f NaN NaN NaN h NaN -0.706771 -1.039575  To remind you, these are the available filling methods:\n   Method Action     pad / ffill Fill values forward   bfill / backfill Fill values backward    With time series data, using pad/ffill is extremely common so that the “last known value” is available at every time point.\nffill() is equivalent to fillna(method='ffill') and bfill() is equivalent to fillna(method='bfill')\nFilling with a PandasObject You can also fillna using a dict or Series that is alignable. The labels of the dict or index of the Series must match the columns of the frame you wish to fill. The use case of this is to fill a DataFrame with the mean of that column.\nIn [49]: dff = pd.DataFrame(np.random.randn(10, 3), columns=list('ABC')) In [50]: dff.iloc[3:5, 0] = np.nan In [51]: dff.iloc[4:6, 1] = np.nan In [52]: dff.iloc[5:8, 2] = np.nan In [53]: dff #Out[53]: A B C 0 0.271860 -0.424972 0.567020 1 0.276232 -1.087401 -0.673690 2 0.113648 -1.478427 0.524988 3 NaN 0.577046 -1.715002 4 NaN NaN -1.157892 5 -1.344312 NaN NaN 6 -0.109050 1.643563 NaN 7 0.357021 -0.674600 NaN 8 -0.968914 -1.294524 0.413738 9 0.276662 -0.472035 -0.013960  In [54]: dff.fillna(dff.mean()) #Out[54]: A B C 0 0.271860 -0.424972 0.567020 1 0.276232 -1.087401 -0.673690 2 0.113648 -1.478427 0.524988 3 -0.140857 0.577046 -1.715002 4 -0.140857 -0.401419 -1.157892 5 -1.344312 -0.401419 -0.293543 6 -0.109050 1.643563 -0.293543 7 0.357021 -0.674600 -0.293543 8 -0.968914 -1.294524 0.413738 9 0.276662 -0.472035 -0.013960  In [55]: dff.fillna(dff.mean()['B':'C']) #Out[55]: A B C 0 0.271860 -0.424972 0.567020 1 0.276232 -1.087401 -0.673690 2 0.113648 -1.478427 0.524988 3 NaN 0.577046 -1.715002 4 NaN -0.401419 -1.157892 5 -1.344312 -0.401419 -0.293543 6 -0.109050 1.643563 -0.293543 7 0.357021 -0.674600 -0.293543 8 -0.968914 -1.294524 0.413738 9 0.276662 -0.472035 -0.013960  Same result as above, but is aligning the ‘fill’ value which is a Series in this case.\nIn [56]: dff.where(pd.notna(dff), dff.mean(), axis='columns') #Out[56]: A B C 0 0.271860 -0.424972 0.567020 1 0.276232 -1.087401 -0.673690 2 0.113648 -1.478427 0.524988 3 -0.140857 0.577046 -1.715002 4 -0.140857 -0.401419 -1.157892 5 -1.344312 -0.401419 -0.293543 6 -0.109050 1.643563 -0.293543 7 0.357021 -0.674600 -0.293543 8 -0.968914 -1.294524 0.413738 9 0.276662 -0.472035 -0.013960  Dropping axis labels with missing data: dropna[](https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html#dropping-axis-labels-with-missing-data-dropna \u0026ldquo;Permalink to this headline\u0026rdquo;) You may wish to simply exclude labels from a data set which refer to missing data. To do this, use dropna():\nIn [57]: df #Out[57]: one two three a NaN -0.282863 -1.509059 c NaN 1.212112 -0.173215 e NaN 0.000000 0.000000 f NaN 0.000000 0.000000 h NaN -0.706771 -1.039575  In [58]: df.dropna(axis=0) #Out[58]: Empty DataFrame Columns: [one, two, three] Index: []  In [59]: df.dropna(axis=1) #Out[59]: two three a -0.282863 -1.509059 c 1.212112 -0.173215 e 0.000000 0.000000 f 0.000000 0.000000 h -0.706771 -1.039575 In [60]: df['one'].dropna() #Out[60]: Series([], Name: one, dtype: float64)  An equivalent dropna() is available for Series. DataFrame.dropna has considerably more options than Series.dropna, which can be examined in the API.\nInterpolation New in version 0.23.0: The limit_area keyword argument was added.\nBoth Series and DataFrame objects have interpolate() that, by default, performs linear interpolation at missing data points.\nIn [61]: ts #Out[61]: 2000-01-31 0.469112 2000-02-29 NaN 2000-03-31 NaN 2000-04-28 NaN 2000-05-31 NaN ... 2007-12-31 -6.950267 2008-01-31 -7.904475 2008-02-29 -6.441779 2008-03-31 -8.184940 2008-04-30 -9.011531 Freq: BM, Length: 100, dtype: float64  In [62]: ts.count() #Out[62]: 66 In [63]: ts.plot()  #Out[63]: In [64]: ts.interpolate() #Out[64]: 2000-01-31 0.469112 2000-02-29 0.434469 2000-03-31 0.399826 2000-04-28 0.365184 2000-05-31 0.330541 ... 2007-12-31 -6.950267 2008-01-31 -7.904475 2008-02-29 -6.441779 2008-03-31 -8.184940 2008-04-30 -9.011531 Freq: BM, Length: 100, dtype: float64  In [65]: ts.interpolate().count() #Out[65]: 100 In [66]: ts.interpolate().plot()  #Out[66]: Index aware interpolation is available via the method keyword:\nIn [67]: ts2 #Out[67]: 2000-01-31 0.469112 2000-02-29 NaN 2002-07-31 -5.785037 2005-01-31 NaN 2008-04-30 -9.011531 dtype: float64  In [68]: ts2.interpolate() #Out[68]: 2000-01-31 0.469112 2000-02-29 -2.657962 2002-07-31 -5.785037 2005-01-31 -7.398284 2008-04-30 -9.011531 dtype: float64  In [69]: ts2.interpolate(method='time') #Out[69]: 2000-01-31 0.469112 2000-02-29 0.270241 2002-07-31 -5.785037 2005-01-31 -7.190866 2008-04-30 -9.011531 dtype: float64  For a floating-point index, use method='values':\nIn [70]: ser #Out[70]: 0.0 0.0 1.0 NaN 10.0 10.0 dtype: float64  In [71]: ser.interpolate() #Out[71]: 0.0 0.0 1.0 5.0 10.0 10.0 dtype: float64  In [72]: ser.interpolate(method='values') #Out[72]: 0.0 0.0 1.0 1.0 10.0 10.0 dtype: float64  You can also interpolate with a DataFrame:\nIn [73]: df = pd.DataFrame({'A': [1, 2.1, np.nan, 4.7, 5.6, 6.8], ....: 'B': [.25, np.nan, np.nan, 4, 12.2, 14.4]}) ....: In [74]: df #Out[74]: A B 0 1.0 0.25 1 2.1 NaN 2 NaN NaN 3 4.7 4.00 4 5.6 12.20 5 6.8 14.40  In [75]: df.interpolate() #Out[75]: A B 0 1.0 0.25 1 2.1 1.50 2 3.4 2.75 3 4.7 4.00 4 5.6 12.20 5 6.8 14.40  The method argument gives access to fancier interpolation methods. If you have scipy installed, you can pass the name of a 1-d interpolation r#Outine to method. You’ll want to consult the full scipy interpolation documentation and reference guide for details. The appropriate interpolation method will depend on the type of data you are working with.\n If you are dealing with a time series that is growing at an increasing rate, method='quadratic' may be appropriate.\n If you have values approximating a cumulative distribution function, then method='pchip' should work well.\n To fill missing values with goal of smooth plotting, consider method='akima'.\n  Warning\nThese methods require scipy.\nIn [76]: df.interpolate(method='barycentric') #Out[76]: A B 0 1.00 0.250 1 2.10 -7.660 2 3.53 -4.515 3 4.70 4.000 4 5.60 12.200 5 6.80 14.400  In [77]: df.interpolate(method='pchip') #Out[77]: A B 0 1.00000 0.250000 1 2.10000 0.672808 2 3.43454 1.928950 3 4.70000 4.000000 4 5.60000 12.200000 5 6.80000 14.400000  In [78]: df.interpolate(method='akima') #Out[78]: A B 0 1.000000 0.250000 1 2.100000 -0.873316 2 3.406667 0.320034 3 4.700000 4.000000 4 5.600000 12.200000 5 6.800000 14.400000  When interpolating via a polynomial or spline approximation, you must also specify the degree or order of the approximation:\nIn [79]: df.interpolate(method='spline', order=2) #Out[79]: A B 0 1.000000 0.250000 1 2.100000 -0.428598 2 3.404545 1.206900 3 4.700000 4.000000 4 5.600000 12.200000 5 6.800000 14.400000  In [80]: df.interpolate(method='polynomial', order=2) #Out[80]: A B 0 1.000000 0.250000 1 2.100000 -2.703846 2 3.451351 -1.453846 3 4.700000 4.000000 4 5.600000 12.200000 5 6.800000 14.400000  Compare several methods:\nIn [81]: np.random.seed(2) In [82]: ser = pd.Series(np.arange(1, 10.1, .25) ** 2 + np.random.randn(37)) In [83]: missing = np.array([4, 13, 14, 15, 16, 17, 18, 20, 29]) In [84]: ser[missing] = np.nan In [85]: methods = ['linear', 'quadratic', 'cubic'] In [86]: df = pd.DataFrame({m: ser.interpolate(method=m) for m in methods}) In [87]: df.plot()  #Out[87]: Another use case is interpolation at new values. Suppose you have 100 observations from some distribution. And let’s suppose that you’re particularly interested in what’s happening around the middle. You can mix pandas’ reindex and interpolate methods to interpolate at the new values.\nIn [88]: ser = pd.Series(np.sort(np.random.uniform(size=100))) # interpolate at new_index In [89]: new_index = ser.index | pd.Index([49.25, 49.5, 49.75, 50.25, 50.5, 50.75]) In [90]: interp_s = ser.reindex(new_index).interpolate(method='pchip') In [91]: interp_s[49:51] #Out[91]: 49.00 0.471410 49.25 0.476841 49.50 0.481780 49.75 0.485998 50.00 0.489266 50.25 0.491814 50.50 0.493995 50.75 0.495763 51.00 0.497074 dtype: float64  Interpolation limits[](https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html#interpolation-limits \u0026ldquo;Permalink to this headline\u0026rdquo;) Like other pandas fill methods, interpolate() accepts a limit keyword argument. Use this argument to limit the number of consecutive NaN values filled since the last valid observation:\nIn [92]: ser = pd.Series([np.nan, np.nan, 5, np.nan, np.nan, ....: np.nan, 13, np.nan, np.nan]) ....: In [93]: ser #Out[93]: 0 NaN 1 NaN 2 5.0 3 NaN 4 NaN 5 NaN 6 13.0 7 NaN 8 NaN dtype: float64  # fill all consecutive values in a forward direction In [94]: ser.interpolate() #Out[94]: 0 NaN 1 NaN 2 5.0 3 7.0 4 9.0 5 11.0 6 13.0 7 13.0 8 13.0 dtype: float64  # fill one consecutive value in a forward direction In [95]: ser.interpolate(limit=1) #Out[95]: 0 NaN 1 NaN 2 5.0 3 7.0 4 NaN 5 NaN 6 13.0 7 13.0 8 NaN dtype: float64  By default, NaN values are filled in a forward direction. Use limit_direction parameter to fill backward or from both directions.\n# fill one consecutive value backwards In [96]: ser.interpolate(limit=1, limit_direction='backward') #Out[96]: 0 NaN 1 5.0 2 5.0 3 NaN 4 NaN 5 11.0 6 13.0 7 NaN 8 NaN dtype: float64  # fill one consecutive value in both directions In [97]: ser.interpolate(limit=1, limit_direction='both') #Out[97]: 0 NaN 1 5.0 2 5.0 3 7.0 4 NaN 5 11.0 6 13.0 7 13.0 8 NaN dtype: float64  # fill all consecutive values in both directions In [98]: ser.interpolate(limit_direction='both') #Out[98]: 0 5.0 1 5.0 2 5.0 3 7.0 4 9.0 5 11.0 6 13.0 7 13.0 8 13.0 dtype: float64  By default, NaN values are filled whether they are inside (surrounded by) existing valid values, or #Outside existing valid values. Introduced in v0.23 the limit_area parameter restricts filling to either inside or #Outside values.\n# fill one consecutive inside value in both directions In [99]: ser.interpolate(limit_direction='both', limit_area='inside', limit=1) #Out[99]: 0 NaN 1 NaN 2 5.0 3 7.0 4 NaN 5 11.0 6 13.0 7 NaN 8 NaN dtype: float64  # fill all consecutive #Outside values backward In [100]: ser.interpolate(limit_direction='backward', limit_area='#Outside') #Out[100]: 0 5.0 1 5.0 2 5.0 3 NaN 4 NaN 5 NaN 6 13.0 7 NaN 8 NaN dtype: float64  # fill all consecutive #Outside values in both directions In [101]: ser.interpolate(limit_direction='both', limit_area='#Outside') #Out[101]: 0 5.0 1 5.0 2 5.0 3 NaN 4 NaN 5 NaN 6 13.0 7 13.0 8 13.0 dtype: float64  Replacing generic values Often times we want to replace arbitrary values with other values.\nreplace() in Series and replace() in DataFrame provides an efficient yet flexible way to perform such replacements.\nFor a Series, you can replace a single value or a list of values by another value:\nIn [102]: ser = pd.Series([0., 1., 2., 3., 4.]) In [103]: ser.replace(0, 5) #Out[103]: 0 5.0 1 1.0 2 2.0 3 3.0 4 4.0 dtype: float64  You can replace a list of values by a list of other values:\nIn [104]: ser.replace([0, 1, 2, 3, 4], [4, 3, 2, 1, 0]) #Out[104]: 0 4.0 1 3.0 2 2.0 3 1.0 4 0.0 dtype: float64  You can also specify a mapping dict:\nIn [105]: ser.replace({0: 10, 1: 100}) #Out[105]: 0 10.0 1 100.0 2 2.0 3 3.0 4 4.0 dtype: float64  For a DataFrame, you can specify individual values by column:\nIn [106]: df = pd.DataFrame({'a': [0, 1, 2, 3, 4], 'b': [5, 6, 7, 8, 9]}) In [107]: df.replace({'a': 0, 'b': 5}, 100) #Out[107]: a b 0 100 100 1 1 6 2 2 7 3 3 8 4 4 9  Instead of replacing with specified values, you can treat all given values as missing and interpolate over them:\nIn [108]: ser.replace([1, 2, 3], method='pad') #Out[108]: 0 0.0 1 0.0 2 0.0 3 0.0 4 4.0 dtype: float64  String/regular expression replacement Note\nPython strings prefixed with the r character such as r'hello world' are so-called “raw” strings. They have different semantics regarding backslashes than strings with#Out this prefix. Backslashes in raw strings will be interpreted as an escaped backslash, e.g., r'\\' == '\\\\'. You should read ab#Out them if this is unclear.\nReplace the ‘.’ with NaN (str -\u0026gt; str):\nIn [109]: d = {'a': list(range(4)), 'b': list('ab..'), 'c': ['a', 'b', np.nan, 'd']} In [110]: df = pd.DataFrame(d) In [111]: df.replace('.', np.nan) #Out[111]: a b c 0 0 a a 1 1 b b 2 2 NaN NaN 3 3 NaN d  Now do it with a regular expression that removes surrounding whitespace (regex -\u0026gt; regex):\nIn [112]: df.replace(r'\\s*\\.\\s*', np.nan, regex=True) #Out[112]: a b c 0 0 a a 1 1 b b 2 2 NaN NaN 3 3 NaN d  Replace a few different values (list -\u0026gt; list):\nIn [113]: df.replace(['a', '.'], ['b', np.nan]) #Out[113]: a b c 0 0 b b 1 1 b b 2 2 NaN NaN 3 3 NaN d  list of regex -\u0026gt; list of regex:\nIn [114]: df.replace([r'\\.', r'(a)'], ['dot', r'\\1stuff'], regex=True) #Out[114]: a b c 0 0 astuff astuff 1 1 b b 2 2 dot NaN 3 3 dot d  Only search in column 'b' (dict -\u0026gt; dict):\nIn [115]: df.replace({'b': '.'}, {'b': np.nan}) #Out[115]: a b c 0 0 a a 1 1 b b 2 2 NaN NaN 3 3 NaN d  Same as the previous example, but use a regular expression for searching instead (dict of regex -\u0026gt; dict):\nIn [116]: df.replace({'b': r'\\s*\\.\\s*'}, {'b': np.nan}, regex=True) #Out[116]: a b c 0 0 a a 1 1 b b 2 2 NaN NaN 3 3 NaN d  You can pass nested dictionaries of regular expressions that use regex=True:\nIn [117]: df.replace({'b': {'b': r''}}, regex=True) #Out[117]: a b c 0 0 a a 1 1 b 2 2 . NaN 3 3 . d  Alternatively, you can pass the nested dictionary like so:\nIn [118]: df.replace(regex={'b': {r'\\s*\\.\\s*': np.nan}}) #Out[118]: a b c 0 0 a a 1 1 b b 2 2 NaN NaN 3 3 NaN d  You can also use the group of a regular expression match when replacing (dict of regex -\u0026gt; dict of regex), this works for lists as well.\nIn [119]: df.replace({'b': r'\\s*(\\.)\\s*'}, {'b': r'\\1ty'}, regex=True) #Out[119]: a b c 0 0 a a 1 1 b b 2 2 .ty NaN 3 3 .ty d  You can pass a list of regular expressions, of which those that match will be replaced with a scalar (list of regex -\u0026gt; regex).\nIn [120]: df.replace([r'\\s*\\.\\s*', r'a|b'], np.nan, regex=True) #Out[120]: a b c 0 0 NaN NaN 1 1 NaN NaN 2 2 NaN NaN 3 3 NaN d  All of the regular expression examples can also be passed with the to_replace argument as the regex argument. In this case the value argument must be passed explicitly by name or regex must be a nested dictionary. The previous example, in this case, would then be:\nIn [121]: df.replace(regex=[r'\\s*\\.\\s*', r'a|b'], value=np.nan) #Out[121]: a b c 0 0 NaN NaN 1 1 NaN NaN 2 2 NaN NaN 3 3 NaN d  This can be convenient if you do not want to pass regex=True every time you want to use a regular expression.\nNote\nAnywhere in the above replace examples that you see a regular expression a compiled regular expression is valid as well.\nNumeric replacement replace() is similar to fillna().\nIn [122]: df = pd.DataFrame(np.random.randn(10, 2)) In [123]: df[np.random.rand(df.shape[0]) \u0026gt; 0.5] = 1.5 In [124]: df.replace(1.5, np.nan) #Out[124]: 0 1 0 -0.844214 -1.021415 1 0.432396 -0.323580 2 0.423825 0.799180 3 1.262614 0.751965 4 NaN NaN 5 NaN NaN 6 -0.498174 -1.060799 7 0.591667 -0.183257 8 1.019855 -1.482465 9 NaN NaN  Replacing more than one value is possible by passing a list.\nIn [125]: df00 = df.iloc[0, 0] In [126]: df.replace([1.5, df00], [np.nan, 'a']) #Out[126]: 0 1 0 a -1.02141 1 0.432396 -0.32358 2 0.423825 0.79918 3 1.26261 0.751965 4 NaN NaN 5 NaN NaN 6 -0.498174 -1.0608 7 0.591667 -0.183257 8 1.01985 -1.48247 9 NaN NaN In [127]: df[1].dtype #Out[127]: dtype('float64')  You can also operate on the DataFrame in place:\nIn [128]: df.replace(1.5, np.nan, inplace=True)  Warning\nWhen replacing multiple bool or datetime64 objects, the first argument to replace (to_replace) must match the type of the value being replaced. For example,\ns = pd.Series([True, False, True]) s.replace({'a string': 'new value', True: False}) # raises # TypeError: Cannot compare types 'ndarray(dtype=bool)' and 'str'  will raise a TypeError because one of the dict keys is not of the correct type for replacement.\nHowever, when replacing a single object such as,\nIn [129]: s = pd.Series([True, False, True]) In [130]: s.replace('a string', 'another string') #Out[130]: 0 True 1 False 2 True dtype: bool  the original NDFrame object will be returned untouched. We’re working on unifying this API, but for backwards compatibility reasons we cannot break the latter behavior. See GH6354 for more details.\nMissing data casting rules and indexing While pandas supports storing arrays of integer and boolean type, these types are not capable of storing missing data. Until we can switch to using a native NA type in NumPy, we’ve established some “casting rules”. When a reindexing operation introduces missing data, the Series will be cast according to the rules introduced in the table below. | data type | Cast to | |\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;|\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;| | integer | float | |boolean|object| |float|no cast| |object|no cast|\nFor example:\nIn [131]: s = pd.Series(np.random.randn(5), index=[0, 2, 4, 6, 7]) In [132]: s \u0026gt; 0 #Out[132]: 0 True 2 True 4 True 6 True 7 True dtype: bool  In [133]: (s \u0026gt; 0).dtype #Out[133]: dtype('bool') In [134]: crit = (s \u0026gt; 0).reindex(list(range(8))) In [135]: crit #Out[135]: 0 True 1 NaN 2 True 3 NaN 4 True 5 NaN 6 True 7 True dtype: object  In [136]: crit.dtype #Out[136]: dtype('O')  Ordinarily NumPy will complain if you try to use an object array (even if it contains boolean values) instead of a boolean array to get or set values from an ndarray (e.g. selecting values based on some criteria). If a boolean vector contains NAs, an exception will be generated:\nIn [137]: reindexed = s.reindex(list(range(8))).fillna(0) In [138]: reindexed[crit] --------------------------------------------------------------------------- ValueError Traceback (most recent call last) \u0026lt;ipython-input-138-0dac417a4890\u0026gt; in \u0026lt;module\u0026gt; ----\u0026gt; 1 reindexed[crit] /pandas/pandas/core/series.py in __getitem__(self, key) 905 key = list(key) 906 --\u0026gt; 907 if com.is_bool_indexer(key): 908 key = check_bool_indexer(self.index, key) 909 /pandas/pandas/core/common.py in is_bool_indexer(key) 134 if not lib.is_bool_array(key): 135 if isna(key).any(): --\u0026gt; 136 raise ValueError(na_msg) 137 return False 138 return True ValueError: cannot mask with array containing NA / NaN values  However, these can be filled in using fillna() and it will work fine:\nIn [139]: reindexed[crit.fillna(False)] #Out[139]: 0 0.126504 2 0.696198 4 0.697416 6 0.601516 7 0.003659 dtype: float64  In [140]: reindexed[crit.fillna(True)] #Out[140]: 0 0.126504 1 0.000000 2 0.696198 3 0.000000 4 0.697416 5 0.000000 6 0.601516 7 0.003659 dtype: float64  Pandas provides a nullable integer dtype, but you must explicitly request it when creating the series or column. Notice that we use a capital “I” in the dtype=\u0026quot;Int64\u0026quot;.\nIn [141]: s = pd.Series([0, 1, np.nan, 3, 4], dtype=\u0026quot;Int64\u0026quot;) In [142]: s #Out[142]: 0 0 1 1 2 \u0026lt;NA\u0026gt; 3 3 4 4 dtype: Int64  See Nullable integer data type for more.\nExperimental NA scalar to denote missing values Warning\nExperimental: the behaviour of pd.NA can still change with#Out warning.\nNew in version 1.0.0.\nStarting from pandas 1.0, an experimental pd.NA value (singleton) is available to represent scalar missing values. At this moment, it is used in the nullable integer, boolean and dedicated string data types as the missing value indicator.\nThe goal of pd.NA is provide a “missing” indicator that can be used consistently across data types (instead of np.nan, None or pd.NaT depending on the data type).\nFor example, when having missing values in a Series with the nullable integer dtype, it will use pd.NA:\nIn [143]: s = pd.Series([1, 2, None], dtype=\u0026quot;Int64\u0026quot;) In [144]: s #Out[144]: 0 1 1 2 2 \u0026lt;NA\u0026gt; dtype: Int64 In [145]: s[2] #Out[145]: \u0026lt;NA\u0026gt; In [146]: s[2] is pd.NA #Out[146]: True  Currently, pandas does not yet use those data types by default (when creating a DataFrame or Series, or when reading in data), so you need to specify the dtype explicitly. An easy way to convert to those dtypes is explained here.\nPropagation in arithmetic and comparison operations In general, missing values propagate in operations involving pd.NA. When one of the operands is unknown, the #Outcome of the operation is also unknown.\nFor example, pd.NA propagates in arithmetic operations, similarly to np.nan:\nIn [147]: pd.NA + 1 #Out[147]: \u0026lt;NA\u0026gt; In [148]: \u0026quot;a\u0026quot; * pd.NA #Out[148]: \u0026lt;NA\u0026gt;  There are a few special cases when the result is known, even when one of the operands is NA.\nIn [149]: pd.NA ** 0 #Out[149]: 1 In [150]: 1 ** pd.NA #Out[150]: 1  In equality and comparison operations, pd.NA also propagates. This deviates from the behaviour of np.nan, where comparisons with np.nan always return False.\nIn [151]: pd.NA == 1 #Out[151]: \u0026lt;NA\u0026gt; In [152]: pd.NA == pd.NA #Out[152]: \u0026lt;NA\u0026gt; In [153]: pd.NA \u0026lt; 2.5 #Out[153]: \u0026lt;NA\u0026gt;  To check if a value is equal to pd.NA, the isna() function can be used:\nIn [154]: pd.isna(pd.NA) #Out[154]: True  An exception on this basic propagation rule are reductions (such as the mean or the minimum), where pandas defaults to skipping missing values. See above for more.\nLogical operations For logical operations, pd.NA follows the rules of the three-valued logic (or Kleene logic, similarly to R, SQL and Julia). This logic means to only propagate missing values when it is logically required.\nFor example, for the logical “or” operation (|), if one of the operands is True, we already know the result will be True, regardless of the other value (so regardless the missing value would be True or False). In this case, pd.NA does not propagate:\nIn [155]: True | False #Out[155]: True In [156]: True | pd.NA #Out[156]: True In [157]: pd.NA | True #Out[157]: True  On the other hand, if one of the operands is False, the result depends on the value of the other operand. Therefore, in this case pd.NA propagates:\nIn [158]: False | True #Out[158]: True In [159]: False | False #Out[159]: False In [160]: False | pd.NA #Out[160]: \u0026lt;NA\u0026gt;  The behaviour of the logical “and” operation (\u0026amp;) can be derived using similar logic (where now pd.NA will not propagate if one of the operands is already False):\nIn [161]: False \u0026amp; True #Out[161]: False In [162]: False \u0026amp; False #Out[162]: False In [163]: False \u0026amp; pd.NA #Out[163]: False In [164]: True \u0026amp; True #Out[164]: True In [165]: True \u0026amp; False #Out[165]: False In [166]: True \u0026amp; pd.NA #Out[166]: \u0026lt;NA\u0026gt;  NA in a boolean context Since the actual value of an NA is unknown, it is ambiguous to convert NA to a boolean value. The following raises an error:\nIn [167]: bool(pd.NA) --------------------------------------------------------------------------- TypeError Traceback (most recent call last) \u0026lt;ipython-input-167-5477a57d5abb\u0026gt; in \u0026lt;module\u0026gt; ----\u0026gt; 1 bool(pd.NA) /pandas/pandas/_libs/missing.pyx in pandas._libs.missing.NAType.__bool__() TypeError: boolean value of NA is ambiguous  This also means that pd.NA cannot be used in a context where it is evaluated to a boolean, such as if condition: ... where condition can potentially be pd.NA. In such cases, isna() can be used to check for pd.NA or condition being pd.NA can be avoided, for example by filling missing values beforehand.\nA similar situation occurs when using Series or DataFrame objects in if statements, see Using if/truth statements with pandas.\nNumPy ufuncs pandas.NA implements NumPy’s __array_ufunc__ protocol. Most ufuncs work with NA, and generally return NA:\nIn [168]: np.log(pd.NA) #Out[168]: \u0026lt;NA\u0026gt;  In [169]: np.add(pd.NA, 1) #Out[169]: \u0026lt;NA\u0026gt;   Warning Currently, ufuncs involving an ndarray and NA will return an object-dtype filled with NA values.\nIn [170]: a = np.array([1, 2, 3]) In [171]: np.greater(a, pd.NA) #Out[171]: array([\u0026lt;NA\u0026gt;, \u0026lt;NA\u0026gt;, \u0026lt;NA\u0026gt;], dtype=object)  The return type here may change to return a different array type in the future.\n See DataFrame interoperability with NumPy functions for more on ufuncs.\nConversion If you have a DataFrame or Series using traditional types that have missing data represented using np.nan, there are convenience methods convert_dtypes() in Series and convert_dtypes() in DataFrame that can convert data to use the newer dtypes for integers, strings and booleans listed here. This is especially helpful after reading in data sets when letting the readers such as read_csv() and read_excel() infer default dtypes.\nIn this example, while the dtypes of all columns are changed, we show the results for the first 10 columns.\nIn [172]: bb = pd.read_csv('data/baseball.csv', index_col='id') In [173]: bb[bb.columns[:10]].dtypes #Out[173]: player object year int64 stint int64 team object lg object g int64 ab int64 r int64 h int64 X2b int64 dtype: object  In [174]: bbn = bb.convert_dtypes() In [175]: bbn[bbn.columns[:10]].dtypes #Out[175]: player string year Int64 stint Int64 team string lg string g Int64 ab Int64 r Int64 h Int64 X2b Int64 dtype: object   Source : .\n "});index.add({'id':267,'href':'/library/tutorials/docs/articles/git/what-git/','title':"Working with missing data",'content':" Git คืออะไร \u0026gt; Source : .\n1. Git คืออะไร Git คือ Version Control แบบ Distributed ตัวหนึ่ง เป็นระบบที่ใช้จัดเก็บและควบคุมการเปลี่ยนแปลงที่เกิดขึ้นกับไฟล์ชนิดใดก็ได้ ไม่ว่าจะเป็น Text File หรือ Binary File (จากนี้จะขอเรียก Text File หรือ Binary File รวมกันว่า Source Code)\nทำไมถึงต้องใช้ Git Track version ของ Source Code ย้อนกลับได้  เมื่อจัดเก็บไฟล์เข้าไปในระบบของ Git จะเรียกว่า Git Repository ซึ่งเก็บสำรองข้อมูลและการเปลี่ยนแปลงของ Source Code ทำให้สามารถย้อนกลับไปที่เวอร์ชั่นใดๆ ก่อนหน้า และดูรายละเอียดการเปลี่ยนแปลงของแต่ละเวอร์ชั่นได้ นอกจากนั้นยังสามารถดูได้ว่าใครเป็นคนแก้ไข!!  ช่วยในการพัฒนาซอฟต์แวร์เป็นทีม  Git สามารถเก็บบันทึกการเปลี่ยนแปลงของ Source Code เวอร์ชั่นล่าสุดไว้ที่ Local Repository ซึ่งสามารถทำงานได้โดยที่ไม่ต้องต่อกับอินเตอร์เน็ต และเมื่อต้อง Update การเปลี่ยนแปลงของ Source Code เวอร์ชั่นล่าสุดให้กับเพื่อนร่วมทีมก็สามารถที่จะ Push ขึ้นไปเก็บที่ Remote Repository(Git Hosting) และเพื่อนร่วมทีมก็สามารถ Pull เวอร์ชั้นล่าสุดนั้นมารวม(Auto Merge) ที่เครื่องของเขาเอง ทำให้ Source Code ที่พัฒนาร่วมกันกับคนภายในทีมเป็นเวอร์ชั่นล่าสุดเสมอ  Git Status สถานะของ Source Code ที่เก็บอยู่ในระบบของ Git นั้นมีดั่งนี้\n Untracked เป็นสถานะที่ Source Code ถูกเพิ่มเข้ามาใหม่และยังไม่ได้ถูกเก็บไว้ในระบบของ Git Working Directory เป็นสถานะที่กำลังมีการเปลี่ยนแปลงหรือแก้ไข Source Code หรืออาจจะเรียกสถานะนี้ว่า Modified Staged เป็นสถานะที่ Source Code กำลังเตรียมที่จะ Commit เพื่อยืนยันการเปลี่ยนแปลงก่อนที่จะเก็บลงในสถานะ Local Repository Local Repository เป็นสถานะที่มีการเก็บบันทึกข้อมูลการเปลี่ยนแปลงของ Source Code ลงไปที่ Git Repository ที่เป็น Local (ที่เครื่องตัวเอง) Remote Repository เป็นสถานะที่มีการเก็บบันทึกข้อมูลการเปลี่ยนแปลงของ Source Code ลงไปที่ Git Repository ที่เป็น Hosting (ที่เครื่องเซิร์ฟเวอร์)  Forward\nฺBackward\n2. ติดตั้ง Git Git สามารถที่จะติดตั้งได้ทั้ง Windows, Mac OS X, Linux ซึ่ง Download ได้จาก https://git-scm.com สำหรับการติดตั้งก็คงไม่ต้องอธิบายแล้วนะครับ แต่มีคำแนะนำว่าควรใช้เวอร์ชั่นล่าสุด(2017/01/12 v2.11.1) เหตุผลเพราะมีการแก้บั๊กและเพิ่มคำอธิบายให้เข้าใจยิ่งขึ้นในเวอร์ชั่นใหม่ครับ [2], [3]\nเมื่อติดตั้งเสร็จแล้วสามารถตรวจสอบ Git Version ได้จากคำสั่งนี้ (Max OS X, Linux ใช้ Terminal ส่วนใน Windows ใช้ ฺGit Bash ติดตั้งมาพร้อมกับ Git)\n$git \u0026ndash;version\n3. Git Command Line ถามว่าทำไมถึงใช้ Git แบบ Command Line ส่วนตัวคิดว่ามันจะทำให้เข้าใจพื้นฐานของ Git ได้ดีกว่าการใช้ Git-GUI Client และมีส่วนที่มีแค่ Command Line เท่านั้นที่ทำได้ (-__-)/ เมื่อเข้าใจพื้นฐานแล้วสามารถที่จะใช้ Git-GUI Client ตัวไหนก็ได้ หรือใช้แค่ Command Line อย่างเดียวก็พอครับ ;P\nแนะนำให้ลองเล่นตามทีละคำสั่งเลยนะครับ จะได้เข้าใจมากขึ้น Go Go Go..\nเริ่มที่คำสั่งที่ใช้งานบ่อยๆ Git Config เป็นคำสั่งที่ใช้แสดงและกำหนดข้อมูลของผู้ใช้เพื่อระบุตัวตน และคุณสมบัติอื่นๆ ของ Git\n$git config --global --list #แสดงคุณสมบัติของ Git ทั้งหมด $git config --list #แสดงคุณสมบัติของ Git เฉพาะ Repository นั้น  การกำหนดชื่อและอีเมล์ของผู้ใช้\n$git config --global user.name \u0026quot;Your Name\u0026quot; #กำหนดชื่อผู้ใช้ $git config --global user.email \u0026quot;example@email.com\u0026quot; #กำหนดอีเมล์ของผู้ใช้ $git config --global --list #ตรวจสองอีกครั้งหลังจากกำหนดค่าเสร็จแล้ว  Git Init เป็นคำสั่งที่ใช้สร้างระบบของ Git ขึ้นมาภายใต้โฟลเดอร์หรือ Path นั้น โดยจะสร้างโฟลเดอร์ .git ขึ้นมาเพื่อใช้เก็บ สำรองข้อมูล การเปลี่ยนแปลงและคุณสมบัติอื่นๆ ของ Git\n$git init  Git Status เป็นคำสั่งที่ใช้ตรวจสองสถานะของ Source Code ในระบบของ Git ซึ่งจะแสดงสถานะดั่งที่ได้อธิบายข้างต้นไปแล้ว\n$git status  Git Add เป็นคำสั่งที่ใช้เพิ่มการเปลี่ยนแปลงของ Source Code เข้าไปที่สถานะ Staged\n$git add \u0026lt;file_name\u0026gt; $git add README.md #เพิ่มไฟล์ชื่อ README.md เข้าไปที่สถานะ Staged $git add . #ใช้ในกรณีที่มีหลายๆ ไฟล์และต้องการเพิ่มเข้าไปทั้งหมด  Git Commit เป็นคำสั่งที่ใช้ยืนยัน Source Code ที่อยู่ในสถานะ Staged เข้าไปเก็บไว้ที่ Local Repository\n$git commit -m \u0026quot;message\u0026quot; #ยืนยันการเปลี่ยนแปลงพร้อมข้อความ $git commit -am \u0026quot;message\u0026quot; #เพิ่มการเปลี่ยนแปลงและยืนยันพร้อมข้อความ $git commit #เพิ่มข้อความในโปรแกรม vi #ยืนยันการเปลี่ยนแปลงพร้อมข้อความและ merge ลงใน commit ล่าสุด $git commit --amend -m \u0026quot;message\u0026quot;  ถ้าต้องการเขียน Commit Message ยาวๆ สามารถใช้คำสั่ง Git commit ระบบจะเปิดโปรแกรม vi ให้เขียน Message [วิธีใช้ vi, vim]\nGit Log เป็นคำสั่งที่ใช้แสดงประวัติของ Commit ที่เก็บไว้ใน Repository\n$git log $git log --oneline $git log --oneline --decorate $git log --oneline --decorate --graph$git log --stat #Diff from log $git log --grep=\u0026quot;Message\u0026quot; #Log by message $git log --after=\u0026quot;2017-2-14\u0026quot; #Log in date $git log --before=\u0026quot;2017-2-14\u0026quot; #Log in date $git log --author=pakin #Log by user  Git Branch เป็นคำสั่งที่ใช้ในแสดงและแตงกิ่งสาขาในการพัฒนา ซึ่งทำให้การพัฒนาซอฟต์แวร์มีความยืดยุ่นมากขึ้น\n$git branch $git branch --all $git branch develop #สร้าง branch ชื่อ develop $git branch --delete develop #ลบ branch ชื่อ develop#ส่งการเปลี่ยนแปลง branch develop ไปยัง Remote ที่ชื่อ origin $git push origin develop#ส่งการเปลี่ยนแปลงลบ branch develop ไปยัง Remote ที่ชื่อ origin $git push --delete origin develop  เรื่องของ Branch และ Tag นั้นมีความเกี่ยวข้องกับเรื่องของ Release Process ของการพัฒนาซอฟต์แวร์ ขึ้นอยู่กับการตกลงกันภายในทีมและรูปแบบที่เหมาะสมกับซอฟต์แวร์ที่กำลังพัฒนา ซึ่งเรียกเทคนิคนี้ว่า Branch Strategy(Git Workflow, Branching Models, Branching Workflow, Git Flow)\nGit Checkout เป็นคำสั่งที่ใช้ในการสลับ Working Directory ไปยัง Branch หรือ Commit ที่เราระบุ คำสั่งนี้ยังสามารถให้งานได้ในอีกหลายๆ แบบ\n#ย้ายการทำงานไปที่ Branch หรือ commit_id ที่ระบุ $git checkout \u0026lt;branch name, commit id\u0026gt;#สร้าง branch ชื่อ test และทำการสลับการทำงานมาที่ Branch นี้ $git checkout -b test#ยกเลิกการเปลี่ยนแปลงของไฟล์ใน Working Directory $git checkout -- \u0026lt;file name\u0026gt; #เลือกแค่บางไฟล์จาก Branch อื่น เข้ามา Merge กับ Working Directory ที่กำลังทำงาน $git checkout \u0026lt;branch name\u0026gt; \u0026lt;file name\u0026gt; #คำสั่งนี้จะเหมือนคำสั่งด้านบน แต่จะมีโหมดตอบโต้ กับผู้ใช้ในการเลือกสถานะของไฟล์ที่ระบุ $git checkout --patch \u0026lt;branch name\u0026gt; \u0026lt;file name\u0026gt;  Git Reset เป็นคำสั่งที่ใช้ย้อนกลับไปที่เวอร์ชั่นไดๆ ก่อนหน้า โดยระบุ ฺBranch หรือ Commit Id (SH-1 แบบย่อของ Commit 7 ตัว เช่น 4bcb295) ซึ่งมี Option ที่สำคัญ 3 ตัวดั่งนี้\n soft ย้อนการเปลี่ยนแปลง และคงสถานะการเปลี่ยนแปลงของ Source Code ไว้ที่สถานะ Staged mixed ย้อนการเปลี่ยนแปลง และคงสถานะการเปลี่ยนแปลงของ Source Code ไว้ที่สถานะ Working Directory หรือ Modified hard ย้อนการเปลี่ยนแปลงแบบลบทับการเปลี่ยนแปลงก่อนหน้าทั้งหมด คำสั่งนี้อันตรายเพราะมันจะทำให้ประวัติของ Commit ที่เก็บไว้ใน Repository หายไป จึงยังไม่เหมาะกับมือใหม่\n$git reset --soft 4bcb295 #ย้อนกลับไปที่ Commit id 4bcb295 $git reset --mixed develop #ย้อนกลับไปที่ Branch develop   Git Merge เป็นคำสั่งที่ใช้ในการรวม Branch หรือ Commit ทั้งสองเข้าด้วยกัน\nตัวอย่างเราจะอยู่ที่ Branch Master และต้องการ Merge Branch Feature เข้ามาทำงานร่วมด้วย การ Merge แบบ No Fast Forward จะเรียกอีกอย่างหนึ่งว่า 3-Way Merge\n#รวม branch master กับ branch feature แบบ no fast forward $git merge --no-ff feature#รวม branch master กับ branch feature แบบ fast forward $git merge feature  Git Remote [เริ่มต้นทำงานกับ Git Hosting (Remote Repository)] เพิ่ม URL ของ Remote Repository เข้าไปยังคุณสมบัติของ Git โดยชื่อว่า origin ส่วนใหญ่จะเป็นชื่อ Default ที่หลาย ๆ คนเข้าใจตรงกัน แต่เราก็สามารถตั้งชื่ออื่นๆ ได้\n$git remote add origin \u0026lt;URL\u0026gt; #เพิ่ม Remote Repository ชื่อ origin $git remote add origin https://github.com/NewGame0/Android_HelloWorld.git #เพิ่ม Remote Repository ใหม่ชื่อ origin $git remote set-url origin \u0026lt;New URL\u0026gt;$git remote -v #แสดง Remote Repository $git config --list #แสดงคุณสมบัติต่างๆของ Git ซึ่งจะมี Remote Repository แสดงออกมาด้วย  Git Push เป็นคำสั่งที่ใช้ส่งการเปลี่ยนแปลงของ Source Code ที่เก็บอยู่บน Local Repository ขึ้นไปยัง Remote Repository\n#ส่งการเปลี่ยนแปลง Branch master ไปยัง Remote ที่ชื่อ origin $git push origin master  Git Fetch เป็นคำสั่งที่ใช้รับการเปลี่ยนแปลงของ Source Code ล่าสุดที่อยู่บน Remote Repository ลงมายัง Local Repository แต่ยังไม่ได้ทำการรวม Source Code (Merge)\n#รับการเปลี่ยนแปลงทุก Branch จาก Remote Repository $git fetch --all #รับการเปลี่ยนแปลง Branch master จาก Remote Repository ที่ชื่อ origin $git fetch origin master  Git Pull [fetch + merge] เป็นคำสั่งที่ใช้รับการเปลี่ยนแปลงของ Source Code ล่าสุดที่อยู่บน Remote Repository ลงมายัง Local Repository และทำการ Auto Merge\n$git pull \u0026lt;remote\u0026gt; \u0026lt;branch\u0026gt; $git pull origin master  Git Clone เป็นคำสั่งที่ใช้ดึงประวัติทั้งหมดบน Remote Repository ของเพื่อนร่วมทีม ของคนอื่นหรือของเราเองที่มีอยู่แล้วบน Git Hosting มาที่เครื่องของเรา คำสั่งนี้จะคล้ายๆ Git Init ที่ใช้สร้างระบบ Git ขึ้นมาตอนเริ่มต้น แต่เราจะได้ประวัติเดิมของ Repository มาด้วย ทำให้เราเริ่มพัฒนาต่อจากตรงจุดนี้ได้เลย\n$git clone https://github.com/NewGame0/Android_HelloWorld.git  คำสั่ง Git Clone นั้นจะ Checkout Branch หลักมาเป็น Master และดึง Tag ลงมาทั้งหมด\nคำสั่งอื่นๆ Git Ignore [.gitignore] Git Ignore ไม่ได้เป็นคำสั่งแต่เป็นคุณสมบัติของ Git โดยการเพิ่มไฟล์ที่ชื่อ .gitignore เข้าไปในระบบของ Git เพื่อทำการบอกให้ Git ไม่ต้องสนใจไฟล์หรือโฟลเดอร์นั้นๆ เช่นไฟล์หรือโฟลเดอร์ที่เป็น Output ของการ Build ใน Java (.class) ไฟล์ที่เป็นคุณสมบัติเฉพาะของ IDE หรือ Working Space ก็ไม่ควรแชร์ไปให้คนอื่นๆ ในทีม\n$touch .gitignore #สร้างไฟล์ .gitignore#เพิ่ม String เข้าไปในไฟล์ .gitignore เพื่อ ignore ไฟล์ .class ทั้งหมด และโฟลเดอร์ Debug, Build $echo \u0026gt;\u0026gt; .gitignore \u0026quot;*.class\u0026quot; $echo \u0026gt;\u0026gt; .gitignore \u0026quot;/Debug\u0026quot; $echo \u0026gt;\u0026gt; .gitignore \u0026quot;/Build\u0026quot;$git add .gitignore #เพิ่มไฟล์ชื่อ .gitignore เข้าไปที่สถานะ Staged $git commit -m \u0026quot;Add .gitignore file\u0026quot;  ในกรณีที่มีการเพิ่มไฟล์ที่ไม่ต้องการเข้าไปยังสถานะ Staged แล้ว และเพิ่มไฟล์ .gitignore เข้าไปทีหลัง สามารถใช้คำสั่งนี้เพื่อลบไฟล์หรือโฟล์เดอร์ที่ไม่ต้องการออกจากสถานะ Staged และ Commit Apply .gitignore เข้าไปอีกครั้ง\n$git rm --cached \u0026lt;file name\u0026gt; $git rm --cached \u0026lt;path to file\u0026gt; $git rm --cached .class $git rm --cached Debug/* $git rm --cached Build/* $git rm -r --cashed *$git commit -am \u0026quot;apply .gitignore file\u0026quot; #แสดงไฟล์ที่ Track ไว้ในระบบของ Git ไฟล์ที่ ignore จะหายไปแม้จะยังอยู่ในโฟล์เดอร์ $git ls-files  Git Ignore ที่มีการรวบรวมไว้บน GitHub https://github.com/github/gitignore\nGit Tag เป็นคำสั่งที่ใช้แสดงและสร้าง Tag ขึ้นที่จุด commit นั้น\n$git tag #แสดงแท็กทั้งหมด $git tag -n99 #แสดงแท็กทั้งหมดพร้อมข้อความ $git tag v1.0.0 #สร้างแท็กชื่อ v1.0.0 $git tag v1.0.1 -m \u0026quot;Tag Message\u0026quot; #สร้างแท็กชื่อ v1.0.0 พร้อมระบุข้อความ $git tag --delete v1.0.0 #ลบแท็กชื่อ v1.0.0 $git push origin \u0026lt;tag name\u0026gt; #ส่งแท็กขึ้นไปที่ Remote Repository $git push origin --tags #ส่งแท็กทั้งหมดขึ้นไปที่ Remote Repository $git push --delete origin \u0026lt;tag name\u0026gt; #ลบแท็กที่ Remote Repository  เรื่องของ Branch และ Tag นั้นมีความเกี่ยวข้องกับเรื่องของ Release Process ของการพัฒนาซอฟต์แวร์ ดั่งที่ได้กล่าวไปแล้ว ส่วนใหญ่แล้วการตั้งชื่อ Tag จะตรงกับเลขเวอร์ชั้นของซอฟต์แวร์ที่ Release, Deploy, หรือที่ส่งให้กับลูกค้า เช่น v1.12.4 (v.x.y.z) [4]\n v คือบอกว่าเป็นเวอร์ชั่นอะไร x คือ Major เวอร์ชั่น y คือ Minor เวอร์ชั่น z คือ Patch เวอร์ชั้น  ส่วนข้อความภายใน Tag จะนิยมระบุ Date, Release to, New Feature?, Fix Bug?\nGit Clean เป็นคำสั่งที่ใช้แสดงและลบ Source Code ที่อยู่ในสถานะ Untracked ออกจาก Working Directory\n$git clean -n #แสดง Source Code ที่อยู่ในสถานะ Untracked $git clean -df #ลบ Source Code ที่อยู่ในสถานะ Untracked  Git Diff เป็นคำสั่งที่ใช้แสดงความเปลี่ยนแปลงระหว่าง Working Directory ที่กำลังทำงานอยู่กับ Branch หรือ Commit Id ที่ระบุ\n$git diff 82de188 $git diff develop  Git Stash เป็นคำสั่งที่ใช้ซ่อนการเปลี่ยนแปลงใน Working Directory ทำให้ Working Directory Clean นิยมใช้ก่อนคำสั่ง Git Pull\n$git stash #ซ่อนการเปลี่ยนแปลงลงใน stash $git stash list #แสดงรายการการเปลี่ยนแปลงที่ซ่อนไว้ $git stash show #แสดงการเปลี่ยนแปลงล่าสุดที่ซ่อนไว้ $git stash pop #ดึงการเปลี่ยนแปลงล่าสุดมาออกมา merge กับ working directory  Git Reflog เป็นคำสั่งที่ใช้แสดงและจัดการกับ Reference Log ของ Git Repository\nขอยกตัวอย่างการใช้งาน ผม(พลาด)ใช้คำสั่ง Git Reset -hard ย้อนกลับไป 3 commit ก่อนหน้า ทำให้ประวัติของ Commit ทั้ง 3 ก่อนหน้าที่จะย้อนมา หายไป ใช้คำสั่งตามด้านล่านนี้\n#แสดง Reference Log ของ Git Repository $git reflog show #ย้อนกลับไปยัง head log ก่อนหน้า เท่านี้ก็จะได้ 3 commit กลับมาแล้ว $git reset HEAD@{1}  Git Help เป็นคำสั่งที่ใช้ในการแสดงและอธิบายคำสั่งของ Git\n$git help \u0026lt;command name\u0026gt; $git help merge  คำสั่งอื่นๆ ที่เคยได้ยิน (ยังไม่เคยใช้จริง แค่ลองเล่น -__-)  git revert git rebase git cherry-pick git hooks  Git Command + Option + Parameter เยอะแบบนี้จะจำกันได้ยังไง ? จำไม่ได้ครับ… ถ้าแค่อ่าน Command มาจากด้านบนจนถึงตรงนี้แล้ว งง ก็คงไม่แปลก คำแนะนำคือต้องฝึกใช้แต่ละ Command และใช้งานบ่อยๆ บางคำสั่งมี Option ช่วยทำให้ใช้งานง่ายขึ้น และ Command ส่วนใหญ่จะใช้ต่อกันเป็นชุดๆ ครับ เช่น Git Status, Git Add , Git Commit, Git Push ถ้าใช้บ่อยๆ แล้วจะจำกันได้เองครับ :P\nทดลองเล่นคำสั่ง Git บนเว็บไซต์ Try Git: Git Tutorial\n4. Git-GUI Client สำหรับคนที่ยัง งง และไม่ชอบใช้ Command Line ลองเปลี่ยนมาใช้งานแบบ GUI อาจจะช่วยให้ใช้งานง่ายขึ้น :)\nSource Tree เป็นซอฟต์แวร์ของบริษัท Atlassian สามารถติดตั้งได้ทั้งบน Windoew และ Mac\nOS X ซึ่งใช้งานได้แบบฟรีเพียงแค่สมัคร Account ของ Atlassian\nแนะนำสำหรับมือใหม่หน้าตาใช้งานง่าย Graphic สวยเข้าใจได้ง่าย ส่วนวิธีใช้ก็คงไม่ยากเกินไป สามารถ Download ได้จาก https://www.sourcetreeapp.com/\nGitk แนะนำเป็นการส่วนตัว เพราะเมื่อใช้ Command Line บ่อยๆ มีปัญหากับคำสั่ง Git Diff, Git, Log ที่แสดงผลแล้วดูยากไปหน่อยใน Command Line เลยต้องใช้ GUI ช่วย ถ้าต้องไปเปิด SourceTree ก็คงดูยุ่งยากไปหน่อย(รู้สึกหนวงๆ ช้าๆ ยังไงไม่รู้)\nก็มาเจอกับ Gitk ที่เบาและสามารถตอบโจทย์ได้ ติดตั้งมาพร้อมกับ Git บน Windows ส่วนใน Linux ต้องติดตั้งเพิ่ม สามารถเรียกใช้งานได้ที่ Terminal เลย\n$gitk #แสดง Working Directory ที่กำลังทำงานอยู่ $gitk --all #แสดง Working Directory ที่กำลังทำงานอยู่และ Branch ทั้งหมด  หน้าตาอาจจะดูใช้งานยากไปหน่อยแต่แค่ดู Diff, Log แล้วถือว่าเพียงพอ\ngitk  Git-GUI Client ตัวอื่นๆ https://git-scm.com/downloads/guis\n5. Git Hosting (Remote Repository) บริการฝาก Repository ที่ไว้ Git Hosting ซึ่งมีเจ้าหลักๆ ดั่งนี้\nBitbucket https://bitbucket.org\nส่วนตัวแล้วใช้ของ Bitbucket เป็นหลัก สามารถสร้าง Repository ทั้งแบบ Private และ Public ได้ฟรีไม่จำกัด Repository (แต่จำกัดขนาดแต่ละ Repo ไม่เกิน 1 GB) แบบ Private จำกัดจำนวนผู้ใช้ที่เข้าถึงได้แค่ 5 คน(แบบฟรี) ถ้าเยอะกว่านี้ต้องจ่ายตังเพิ่ม ทดลองใช้เลยที่ https://bitbucket.org\nGitHub https://github.com\nเชื่อว่าหลายคนคงรู้ต้องรู้จักเพราะเป็นบริการฝาก Repository ที่มีคนใช้งานเยอะมาก สามารถสร้าง Repository แบบ Public ได้ฟรีไม่จำกัด Repository แต่ถ้าต้องการให้เป็นแบบ Private ต้องจ่ายตังเพิ่ม ทดลองใช้เลยที่ https://github.com\nGitLab https://gitlab.com\nGitLab สามารถสร้าง Repository ฝากไว้ที่ Hosting แบบ Private ได้ฟรีไม่จำกัด Repo สำหรับคนที่กลัวและไม่อยากที่จะนำ Source Code ไปฝากไว้ที่ Git Hosting สามารถที่จะตั้ง Server Git เองได้ที่บริษัท โดยติดตั้ง GitLab ได้ฟรี (สามารถติดตั้งบน Linux Server ได้โดยง่าย รายละเอียดเพิ่มเติมที่ https://gitlab.com และควรมีคนที่คอย Management Server Git)\nhttps://about.gitlab.com/downloads\nGitLab เพิ่งมีข่าวว่าเผลอลบข้อมูลผู้ใช้บน Server ของตัวเองและมีปัญการในการกู้ข้อมูลกลับคืนก ลองพิจารณาดูครับก่อนตัดสินใจใช้งาน รายละเอียดตามนี้ครับ https://www.blognone.com/node/89724\nFork \u0026amp; Pull Request Fork และ Pull Request ไม่ใช่เรื่องของ Git โดยตรงแต่เป็นคุณสมบัติที่เพิ่มมากับ Git Hosting เพื่อให้สามารถใช้งานได้สะดวกขึ้น\nโดยปกติแล้วเมื่อเราสนใจ Project บน Remote Repository ของคนอื่นและต้องการนำมาพัฒนาต่อยอด เราก็เริ่มด้วยคำสั่ง Git Clone หลังจากนั้นก็สร้าง Remote Repository บน Git Hosting ของเราเองและทำการ Push ขึ้นไปเก็บไว้ การทำงานแบบนี้เกิดขึ้นได้บ่อยในการพัฒนาซอฟต์แวร์ร่วมกัน ซึ่ง Git Hosting(Bitbucket, GitHub, GitLab) ก็ช่วยอำนวยความสะดวกด้วยคำสั่งเดียวคือ Fork\nการ Fork Project ของคนอื่นๆ มาพัฒนายังมีความเกี่ยวข้องกับ Repository ของเจ้าของเดิม เมื่อเรามีการเพิ่มการเปลี่ยนแปลงของ Source Code ใน Repository ที่ Fork มา และเราเห็นว่ามันมีประโยชน์กับ Project หลักของคนที่เรา Fork Project มา เราก็สามารถส่งการเปลี่ยนแปลงนี้เข้าไปที่ Repository หลักของผู้ที่เป็นเจ้าของ Project ได้ ซึ่งเรียกว่า Pull Request เจ้าของ Project จะเป็นคนตัดสินใจเองว่าจะรวมการเปลี่ยนแปลงของเราเข้าไปยัง Repository หลักของเขาหรือเปล่า\nWorking with Git Hosting การติดต่อกับ Git Hosting จะมี Protocol ที่ใช้ติดต่อ 2 แบบคือ HTTPs และ SSH Key (Secure Shell key) เพื่อยืนยันตัวตนของผู้ใช้\nHTTPs จะเหมือนกับการ Log in เข้าใช้งานที่ Git Hosting โดยเมื่อเราใช้คำสั่ง Git Clone, Git Push, Git Pull ในครั้งแรกจะมีหน้าต่างขึ้นมาหรือ Command Line ให้เราใส่ Account ของ Git Hosting ที่เราใช้งาน\nGit Credential Manager for Windows\nในเวอร์ชั่นของ Git (\u0026lt; 1.7.10) มีการเก็บ Account(User, Password) ไว้ในไฟล์ โดยใครๆ ก็สามารถเข้าไปดูได้ ซึ่งไม่ปลอดภัย หลังจาก Git เวอร์ชั่นที่ 1.7.10 เป็นต้นมา จะมีคุณสมบัตินี้เรียกว่า Credential Helpers ซึ่งเข้ามาช่วยในการจดจำ User และ Password ทุกครั้งที่มีการติดต่อกับ Git Hosting โดยจะนำไปเก็บไว้ที่ Secure Disk บนแต่ละระบบปฏิบัติการ ทำให้เราไม่ต้องใส่ User และ Password ทุกๆ ครั้ง และ User และ Password ของเราจะถูกเก็บไว้ในที่พื้นที่ปลอดภัย (คนทั่วไปไม่สามรถอ่านไม่ได้)\nCredential Helper ที่ใช้งานในแต่ละระบบปฎิบัติการไม่เหมือนกัน ใน Windows นั้น ตั้งแต่ Git เวอร์ชั่นที่ 2.7.3 จะมีการติดตั้ง Git Credential Manager เข้ามาด้วยตั้งแต่ขั้นตอนในการติดตั้ง Git\nส่วนใน Mac OS X นั้นใช้ osxkeychain และใน Linux ใช้ gnome-keyring\n#Mac OS X #git config --global credential.helper osxkeychain#Linux sudo apt-get install libgnome-keyring-devcd /usr/share/doc/git/contrib/credential/gnome-keyringsudo makegit config --global credential.helper /usr/share/doc/git/contrib/credential/gnome-keyring/git-credential-gnome-keyring  Reference [5], [6]\nSSH Key จะเป็นสร้าง Key ที่ใช้ในการเข้ารหัสข้อมูลขึ้นคือไฟล์ Public Key(id_rsa.pub) กับ Private Key(id_rsa) ที่เป็นคู่กันเพื่อยืนยันตัวตนของผู้ใช้\nโดยใช้คำสั่งดั่งนี้\n#คำสั่งสร้าง SSH key โดยที่ถูกเก็บไว้ที่ Path ~/.ssh/ หรือ C:\\Users\\Pakin.ssh\n$ssh-keygen -t rsa -C \u0026ldquo;example@email.com\u0026rdquo;#ถ้าเครื่องมีการสร้าง SSH Key ไว้แล้วระบบจะถามว่าต้องการเขียนทับข้อมูล SSH Key เดิมเลยไหม และจะมีการถาม Password ในการป้องกันคนอื่นๆ มาอ่านไฟล์ SSH Key ของเรา ขั้นตอนนี้ถ้าไม่ต้องการใส่รหัสก็สามารถ Enter ข้ามไปได้เลย cat ~/.ssh/id_rsa.pub\nPublic Key\nPublic Key (id_rsa.pub) กับ Private Key (id_rsa) สามารถที่จะใช้เข้าหรัสข้อมูลได้ทั้งคู่ และถ้าต้องการเปิดอ่านข้อมูลที่เข้ารหัสต้องใช้ Key อีกอันที่เป็นคู่กัน เช่นถ้าใช้ Private Key (id_rsa) ในการเข้ารหัสข้อมูลก็ต้องถอดรหัสด้วย Public key (id_rsa.pub) ที่คู่กัน(สร้างมาพร้อมกัน) วิธีนี้จะสามารถยืนยันตัวตนของผู้ใช้กับ Git Hosting ได้และวิธีนี้น่าจะมีความปลอดภัยมากกว่า HTTPs ถ้าเราไม่ปล่อยให้ Key หลุดออกไป\nเมื่อทำการสร้าง SSH Key แล้ว เราจะนำ Public Key(id_rsa.pub) ไปเพิ่มเข้าใน Git Hosting ซึ่งขั้นตอนในการเพิ่มของทั้ง Bitbucket, GitHub, GitLab ก็คล้ายๆ กัน\nAdd SSH Key on GitHub\nAdd SSH Key on Bitbucket  สรุป Git กลายมาเป็นสิ่งที่จำเป็นและต้องใช้สำหรับผมไปแล้ว ในการทำงานกับ Source Code เหตุผลก็ได้อธิบายไปข้างต้นแล้ว และแทบไม่มีข้อเสียอะไรเลย ช่วยเก็บ Source Code ให้ไม่หาย สามารถย้อนไปเวร์อชั่นเก่าๆ ได้เมื่องานมีปัญหา ชีวิตการในการเขียนโปรแกรมดีขึ้นเยอะ\nคนที่กำลังสนใจ(สับสน)อยู่ว่า Git คืออะไร ควรใช้ดีไหม และทำไมถึงต้องใช้ แนะนำให้ลองใช้เลยครับ และเราจะขอบคุณตัวเราเองเมื่อเวลาผ่านไปที่เราได้รู้จักกับ Git\n “Git is your friend”\n ผมเขียนเรื่องของ Git เป็นบล็อกแรก หากผิดพลาดประการใดต้องขออภัยและคำแนะนำด้วยครับ\nเรื่องที่ยังไม่ได้กล่าวถึง ขอติดไว้ก่อน จะเขียนเป็น Blog แยกครับ -__-)”  Commit Message Merge Conflict (Merge tools) Git Flow Git Submodule, Git Subtree  References [1] รู้จักกับ Git ประวัติศาสตร์และแนวคิดของระบบจัดการซอร์ส\n[2] พบช่องโหว่ Remote Code Execution บน Git รุ่นเก่ากว่า 2.7.1 ผู้ใช้ควรอัพเดทโดยเร็ว\n[3] Git 2.10 ออกแล้ว แสดงสถานะความคืบหน้าของ git push อย่างละเอียด\n[4] Semantic Versioning\n[5] Credential Helper\n[6] How to use git with gnome-keyring integration\n"});index.add({'id':268,'href':'/library/tutorials/docs/articles/data-science/finance/yahoo-finance-api_1/','title':"Yahoo \u0026 Google Finance API",'content':" Python for Finance, Part I: Yahoo \u0026amp; Google Finance API, pandas, and matplotlib Getting the Data Pandas and matplotlib are included in the more popular distributions of Python for Windows, such as Anaconda.\nIn case it\u0026rsquo;s not included in your Python distribution, just simply use pip or conda install. Once installed, to use pandas, all one needs to do is import it. We will also need the pandas_datareader package (pip install pandas-datareader), as well as matplotlib for visualizing our results.\nfrom pandas_datareader import data import matplotlib.pyplot as plt import pandas as pd\nHaving imported the appropriate tools, getting market data from a free online source, such as Yahoo Finance, is super easy. Since pandas has a simple remote data access for the Yahoo Finance API data, this is as simple as:\nUPDATE (4/14/18): YAHOO FINANCE API ISSUE Yahoo finance has changed the structure of its website and as a result the most popular Python packages for retrieving data have stopped functioning properly. Until this is resolved, we will be using Google Finance for the rest this article so that data is taken from Google Finance instead. We are using the ETF \u0026ldquo;SPY\u0026rdquo; as proxy for S\u0026amp;P 500 on Google Finance\nPlease note that there has been some issues with missing data in Google\u0026rsquo;s API, as well as frequent, random errors that occur when pulling a lot of data.\n# Define the instruments to download. We would like to see Apple, Microsoft and the S\u0026amp;P500 index. tickers = ['AAPL', 'MSFT', '^GSPC'] # We would like all available data from 01/01/2000 until 12/31/2016. start_date = '2010-01-01' end_date = '2016-12-31' # User pandas_reader.data.DataReader to load the desired data. As simple as that. panel_data = data.DataReader('INPX', 'google', start_date, end_date)  What does panel_data look like? data.DataReader returns a Panel object, which can be thought of as a 3D matrix. The first dimension consists of the various fields Yahoo Finance returns for a given instrument, namely, the Open, High, Low, Close and Adj Close prices for each date. The second dimension contain the dates. The third one contains the instrument identifiers.\nLet\u0026rsquo;s see what panel_data actually is by temporarily making it a dataframe and calling the top nine rows:\npanel_data.to_frame().head(9)  Preparing the Data Let us assume we are interested in working with the Close prices which have been already been adjusted by Google finance to account for stock splits. We want to make sure that all weekdays are included in our dataset, which is very often desirable for quantitative trading strategies.\nOf course, some of the weekdays might be public holidays in which case no price will be available. For this reason, we will fill the missing prices with the latest available prices:\n# All we need to do is reindex close using all_weekdays as the new index close = close.reindex(all_weekdays) # Reindexing will insert missing values (NaN) for the dates that were not present # in the original set. To cope with this, we can fill the missing by replacing them # with the latest available price for each instrument. close = close.fillna(method='ffill')  Initially, close contains all the closing prices for all instruments and all the dates that Google returned. Some of the week days might be missing from the data Google provides. For this reason we create a Series of all the weekdays between the first and last date of interest and store them in the all_weekdays variable. Getting all the weekdays is achieved by passing the freq=’B’ named parameter to the pd.date_range() function. This function return a DatetimeIndex which is shown below:\nprint(all_weekdays) # DatetimeIndex(['2010-01-01', '2010-01-04', '2010-01-05', '2010-01-06', # '2010-01-07', '2010-01-08', '2010-01-11', '2010-01-12', # '2010-01-13', '2010-01-14', # ... # '2016-12-19', '2016-12-20', '2016-12-21', '2016-12-22', # '2016-12-23', '2016-12-26', '2016-12-27', '2016-12-28', # '2016-12-29', '2016-12-30'], # dtype='datetime64[ns]', length=1826, freq='B')  Aligning the original DataFrame with the new DatetimeIndex is accomplished by substitution of the initial DatetimeIndex of the close DataFrame. If any of the new dates were not included in the original DatetimeIndex, the prices for that date will be filled with NaNs. For this reason, we will fill any resulting NaNs with the last available price. The final, clean DataFrame is shown below:\nclose.head(10)     Date AAPL MSFT SPY     01/01/2010 nan nan nan   04/01/2010 30.57 30.95 113.33   05/01/2010 30.63 30.96 113.63   06/01/2010 30.14 30.77 113.71   07/01/2010 30.08 30.45 114.19   08/01/2010 30.28 30.66 114.57   11/01/2010 30.02 30.27 114.73   12/01/2010 29.67 30.07 113.66   13/01/2010 30.09 30.35 114.62   14/01/2010 29.92 30.96 114.93    Looking at the Data Our dataset is now complete and free of missing values. We can see a summary of the values in each of the instrument by calling the describe() method of a Pandas DataFrame:\nclose.describe()     Dest AAPL MSFT SPY     count 1825.0 1825.0 1825.0   mean 79.413167 37.118404999999996 164.67498600000002   std 28.30244 10.814263 37.049846   min 27.44 23.01 102.2   25% 55.46 27.84 131.28   50% 78.44 33.03 165.22   75% 103.12 46.11 201.99   max 133.0 63.62 227.76    Suppose we would like to plot the MSFT time-series. We would also like to see how the stock behaves compared to a short and longer term moving average of its price.\nA simple moving average of the original time-series is calculated by taking for each date the average of the last W prices (including the price on the date of interest). pandas has rolling(), a built in function for Series which returns a rolling object for a user-defined window, e.g. 20 days.\nOnce a rolling object has been obtained, a number of functions can be applied on it, such as sum(), std() (to calculate the standard deviation of the values in the window) or mean(). See below:\n# Get the MSFT timeseries. This now returns a Pandas Series object indexed by date. msft = close.loc[:, 'MSFT'] # Calculate the 20 and 100 days moving averages of the closing prices short_rolling_msft = msft.rolling(window=20).mean() long_rolling_msft = msft.rolling(window=100).mean() # Plot everything by leveraging the very powerful matplotlib package fig, ax = plt.subplots(figsize=(16,9)) ax.plot(msft.index, msft, label='MSFT') ax.plot(short_rolling_msft.index, short_rolling_msft, label='20 days rolling') ax.plot(long_rolling_msft.index, long_rolling_msft, label='100 days rolling') ax.set_xlabel('Date') ax.set_ylabel('Adjusted closing price ($)') ax.legend()  RESULT:\nNow, we finally the stock price history together with the two moving averages plotted!\nWhat\u0026rsquo;s Next All of this has been but a small preview of the way a quantitative analyst can leverage the power of Python and pandas to analyze scores of financial data. In part 2 of this series on Python and financial quantitative analysis, we are going to show how to use the two technical indicators already created to create a simple yet realistic trading strategy.\n Written with StackEdit.\n "});index.add({'id':269,'href':'/library/tutorials/docs/python/snippets/zip/','title':"zip",'content':"Creates a list of elements, grouped based on the position in the original lists.\nUse max combined with list comprehension to get the length of the longest list in the arguments. Loop for max_length times grouping elements. If lengths of lists vary, use fill_value (defaults to None).\nzip() and itertools.zip_longest() provide similar functionality to this snippet.\ndef zip(*args, fill_value=None): max_length = max([len(lst) for lst in args]) result = [] for i in range(max_length): result.append([ args[k][i] if i \u0026lt; len(args[k]) else fillvalue for k in range(len(args)) ]) return result  zip(['a', 'b'], [1, 2], [True, False]) # [['a', 1, True], ['b', 2, False]] zip(['a'], [1, 2], [True, False]) # [['a', 1, True], [None, 2, False]] zip(['a'], [1, 2], [True, False], fill_value = '_') # [['a', 1, True], ['_', 2, False]]  "});index.add({'id':270,'href':'/library/tutorials/docs/python/beginer/date-and-time/python-datetime/','title':"การจัดการวันเวลาด้วย datetime",'content':" การจัดการวันเวลาใน python ด้วย datetime  เขียนเมื่อ 2016/06/21 19:35\n มอดูล datetime เป็นหนึ่งในมอดูลภายในตัวของไพธอน มีหน้าที่จัดการเกี่ยวกับเรื่องวันเดือนปีและเวลาต่างๆ หน้าที่มีความคล้ายคลึงกับมอดูล time (อ่านรายละเอียดใน https://phyblas.hinaboshi.com/20160610) แต่ก็มีความต่างกันอยู่ บางครั้งก็อาจใช้ร่วมกัน datetime มักถูกใช้เมื่อต้องการจัดการกับข้อมูลที่อยู่ในรูปของวันเดือนปีหรือเวลาชั่วโมงนาทีวินาที เวลาและวันเดือนปีนั้นเป็นปริมาณที่ใช้หน่วยหลากหลายในการอธิบาย และการแปลงหน่วยก็มีความยุ่งยากเพราะมีความไม่สม่ำเสมอ เช่นจำนวนวันในหนึ่งปีหรือหนึ่งเดือนเป็นต้น\nการใช้ออบเจ็กต์พิเศษของ datetime จะทำให้การคำนวณทำได้โดยง่ายขึ้น อีกทั้งยังสามารถปรับเปลี่ยนรูปแบบการแสดงผลให้เป็นไปตามที่ต้องการได้ง่ายด้วย การใช้มอดูลนี้ก่อนอื่นต้องเริ่มจากทำการ import เรียกใช้ก่อน\nimport datetime  ออบเจ็กต์พิเศษใน datetime มอดูล datetime นั้นมีการนิยามคลาสของออบเจ็กต์สำหรับเก็บค่าวันเดือนปีและเวลาโดยเฉพาะ มีอยู่ 4 ชนิดคือ\n datetime.date ออบเจ็กต์เก็บค่าวันเดือนปี datetime.time ออบเจ็กต์เก็บค่าเวลา datetime.datetime เป็นออบเจ็กต์ที่เอา datetime.date กับ datetime.time มารวมกัน เก็บค่าทั้งวันเดือนปีและเวลา datetime.timedelta ออบเจ็กต์เก็บค่าระยะห่างระหว่างเวลาซึ่งมีหน่วยเป็นวันและวินาที   datetime.date จะเก็บค่าตัวเลขปี เดือน วัน ทั้งหมดเป็นจำนวนเต็มเอาไว้ ในการสร้าง datetime.date จะต้องใส่ค่าปี, เดือน, วัน ตามลำดับ เช่น\ndatetime.date(1905, 6, 1)  เมื่อใช้คำสั่ง print จะแสดงผลเป็น ปี-เดือน-วัน\nprint(datetime.date(1905, 6, 1)) # ได้ 1905-06-01  ค่าเดือนจะใส่ได้แค่ 1 ถึง 12 และค่าวันจะใส่ได้แค่ไหนขึ้นอยู่กับจำนวนวันในเดือนนั้น และทั้งหมดต้องเป็นจำนวนเต็มเท่านั้น จะมีทศนิยมไม่ได้ ถ้าใส่ค่าที่ไม่อยู่ในขอบเขตที่กำหนดจะเกิดข้อผิดพลาดทันที เช่น\ndatetime.date(1911,2,29) # ได้ ValueError: day is out of range for month datetime.date(1911,0,28) # ได้ ValueError: month must be in 1..12 datetime.date(1911,2,27.1) # ได้ TypeError: integer argument expected, got float  ส่วน datetime.timeจะเก็บค่าเวลาในหน่วยชั่วโมง, นาที, วินาที และไมโครวินาที การสร้าง datetime.time จะต้องใส่ค่า ชั่วโมง, นาที, วินาที และไมโครวินาที เรียงตามลำดับ โดยจะใส่แต่ค่าชั่วโมงอย่างเดียวก็ได้ ค่าที่เหลือจะเป็น 0 เช่น\ndatetime.time(1) # คือ 1 ชั่วโมง 0 นาที 0 วินาที 0 ไมโครวินาที datetime.time(23, 59, 59, 999999) # คือ 23 ชั่วโมง 59 นาที 59 วินาที 999999 ไมโครวินาที  เมื่อสั่ง print จะแสดงผลเป็น ชั่วโมง:นาที:วินาที.ไมโครวินาที\nprint(datetime.time(23, 59, 59, 999999)) # ได้ 23:59:59.999999  ค่าชั่วโมงจะต้องอยู่ในช่วง 0 ถึง 23 นาทีและวินาทีเป็น 0 ถึง 60 ส่วนไมโครวินาทีตั้งแต่ 0 ถึง 999999 ค่าทั้งหมดต้องเป็นจำนวนเต็มเท่านั้น ส่วนออบเจ็กต์ชนิด datetime.datetime นั้นเป็นตัวที่รวม datetime.date กับ datetime.time เข้าด้วยกัน คือจะเก็บค่า ปี, เดือน, วัน, ชั่วโมง, นาที, วินาที, ไมโครวินาที\nเวลาที่สร้าง datetime.datetime ขึ้นมาก็ใส่ค่าเรียงไล่ตั้งแต่ปีไปจนถึงไมโครวินาที โดยอาจใส่แค่ปีเดือนวัน 3 ตัวเท่านั้นส่วนที่เหลือละไว้ก็ได้ เช่น\ndatetime.datetime(2016,6,21) # 21 มิ.ย. 2016 เวลา 0:00:00:000000 น.  เมื่อสั่ง print จะแสดงผลเป็น ปี-เดือน-วัน ชั่วโมง:นาที:วินาที.ไมโครวินาที\nprint(datetime.datetime(2016,6,21,17,35,30,115421)) # ได้ 2016-06-21 17:35:30.115421  ส่วน datetime.timedelta นั้นจะเก็บค่าช่วงระยะเวลา โดยเก็บในรูปของวัน, วินาที และ ไมโครวินาทีเท่านั้น โดย 1 วันมีค่าเท่ากับ 60*60*24 = 86400 วินาที การสร้าง datetime.timedelta นั้นต้องใส่ค่าเป็น วัน, วินาที และไมโครวินาที ตามลำดับ โดยสามารถละตัวหลังแล้วใส่แต่ตัวแรกๆก็ได้ เช่น\ndatetime.timedelta(1, 60) # คือ 1 วัน 60 วินาที (1 นาที)  ค่าวันและวินาทีจะเป็นทศนิยมก็ได้ ถ้าใส่เป็นทศนิยมค่าจะถูกแปลงไปเป็นตัวหลังแทน เช่น\ndatetime.timedelta(1.1) # กลายเป็น datetime.timedelta(1, 8640) datetime.timedelta(1.1111111111) # กลายเป็น datetime.timedelta(1, 9599, 999999)  ในทางกลับกันหากใส่ค่าวินาทีเกิน 86400 ก็จะถูกแปลงเป็นวัน และหากใส่ไมโครวินาทีเกิน 1 ล้านก็จะถูกแปลงเป็นวินาที\nค่าที่ใส่จะติดลบก็ได้ ถ้าหากวินาทีหรือไมโครวินาทีติดลบจะถูกนำไปหักจากวันและวินาทีตามลำดับ เช่น\ndatetime.timedelta(1,-1,-1) # กลายเป็น datetime.timedelta(0, 86398, 999999)  เรายังอาจสร้าง datetime.timedelta โดยกำหนดระยะเวลาเป็นมิลลิวินาที, นาที, ชั่วโมง, หรือสัปดาห์ได้ด้วย โดยใส่ในรูปคีย์เวิร์ด เวลาจะถูกแปลงเป็นหน่วยวัน, วินาที และไมโครวินาทีโดยอัตโนมัติ\ndatetime.timedelta(weeks=1,hours=17,minutes=2,milliseconds=999) # ได้ datetime.timedelta(7, 61320, 999000)  เมื่อสั่ง print จะอยู่ในรูปของ วัน days, ชั่วโมง:นาที:วินาที.ไมโครวินาที\nprint(datetime.timedelta(111.9999999)) # ได้ 111 days, 23:59:59.991360  การคำนวณของ datetime.datetime และ datetime.timedelta เมื่อนำ datetime.datetime มาลบกันจะได้ผลออกมาเป็น datetime.timedeltaซึ่งเก็บค่าระยะเวลาระหว่างสองเวลาที่เอามาลบกันนั้น เช่น\ndatetime.datetime(2016,6,21)-datetime.datetime(2016,6,20) # ได้ datetime.timedelta(1)  เนื่องจากหน่วยที่เก็บใน datetime.timedelta นั้นใหญ่สุดเป็นวัน และรองลงมาเป็นวินาที ดังนั้นหน่วยอื่นก็จะถูกแปลงเป็นวันและวินาทีหมด\ndatetime.datetime(2016,6,21,7)-datetime.datetime(2016,6,21,3) # ได้ datetime.timedelta(0, 14400) datetime.datetime(2016,6,21)-datetime.datetime(1905,6,21) # ได้ datetime.timedelta(40543)  นอกจากการลบกันแล้ว datetime.datetime และ datetime.datetime ด้วยกันไม่สามารถนำมาคำนวณอย่างอื่นได้เลย ทั้งบวก, คูณ, และยกกำลังแต่ datetime.datetime สามารถนำมาบวกหรือลบกับ datetime.timedelta ได้ ซึ่งก็จะได้ผลเป็น datetime.datetime ตัวใหม่ เช่น\ndatetime.datetime(2016,6,21)+datetime.timedelta(0.71) # ได้ datetime.datetime(2016, 6, 21, 17, 2, 24) datetime.datetime(2016,6,21)-datetime.timedelta(1,1,1) # ได้ datetime.datetime(2016, 6, 19, 23, 59, 58, 999999)  ส่วน datetime.timedelta นั้นสามารถเอามาคูณหรือหารกับตัวเลขได้ แต่ไม่สามารถบวกหรือลบหรือยกกำลังได้\ndatetime.timedelta(1,1,1)*2 # ได้ datetime.timedelta(2, 2, 2) datetime.timedelta(1,1,1)/2 # ได้ datetime.timedelta(0, 43200, 500000)  datetime.timedelta กับ datetime.timedelta สามารถนำมาบวกหรือลบกันได้ แต่ไม่สามารถคูณหรือยกกำลังกันได้\ndatetime.timedelta(1,1)+datetime.timedelta(0,0,111) # ได้ datetime.timedelta(1, 1, 111) datetime.timedelta(1,1,1)-datetime.timedelta(1,1,1) # ได้ datetime.timedelta(0)  และสามารถหารกันได้ ผลที่ได้คือค่าจำนวนเท่าของระยะเวลา\ndatetime.timedelta(1,1,1)/datetime.timedelta(1) # ได้ 1.0000115740856481  และสามารถหารเอาเศษได้\ndatetime.timedelta(7,1,1)%datetime.timedelta(1) # ได้ datetime.timedelta(0, 1, 1) datetime.timedelta(7,2,1)%datetime.timedelta(0,0,999999) # ได้ datetime.timedelta(0, 0, 604803)  สำหรับการเปรียบเทียบระหว่างเวลานั้น datetime.datetime นึงจะมากกว่าอีก datetime.datetime หนึ่งเมื่อเป็นเวลาช้ากว่า ส่วน datetime.timedelta ก็เทียบตามความยาวของเวลา\ndatetime.datetime(2016,6,21)\u0026gt;datetime.datetime(2016,6,20) # ได้ True  แอตทริบิวต์และเมธอดของ datetime.timedelta ค่าของวัน, วินาที และไมโครวินาที ถูกเก็บอยู่ในแอตทริบิวต์ days, seconds และ microseconds ตามลำดับ\nสามารถแสดงค่าทั้งหมดเป็นวินาทีได้ด้วยเมธอด total_seconds()\nตัวอย่าง\ntdt = datetime.timedelta(3,70000,400000) print(tdt.days) # ได้ 3 print(tdt.seconds) # ได้ 70000 print(tdt.microseconds) # ได้ 400000 print(tdt.total_seconds()) # ได้ 329200.4  แอตทริบิวต์และเมธอดของ datetime.datetime ภายในออบเจ็กต์ datetime.datetime นั้นเก็บข้อมูลของปี, เดือน, วัน, ชั่วโมง, นาที, วินาที, ไมโครวินาที เอาไว้โดยสามารถดูค่าแต่ละค่าได้ที่แอตทริบิวต์ year, month, day, hour, minute, second, microsecond\ndtdt = datetime.datetime(2016,6,21,17,35,30,115421) print(dtdt.year) # ได้ 2016 print(dtdt.month) # ได้ 6 print(dtdt.day) # ได้ 21 print(dtdt.hour) # ได้ 17 print(dtdt.minute) # ได้ 35 print(dtdt.second) # ได้ 30 print(dtdt.microsecond) # ได้ 115421  datetime.datetime ยังประกอบด้วยเมธอดต่างๆที่ใช้แสดงผลข้อมูลส่วนต่างๆในรูปแบบต่างๆ ได้แก่\ndate()\t# แสดงส่วนวันเดือนปีในรูป datetime.date time()\t# แสดงส่วนเวลาในรูป datetime.time weekday()\t# แสดงเลขวันในสัปดาห์ โดยวันจันทร์เป็น 0 วันอาทิตย์เป็น 6 isoweekday()\t# แสดงเลขวันในสัปดาห์ โดยวันจันทร์เป็น 1 วันอาทิตย์เป็น 7 isocalendar()\t# แสดงผลวันเดือนปีในรูปแบบทูเพิล ctime()\t# แสดงวันเวลาในรูป _วันในสัปดาห์ เดือน วัน ชั่วโมง:นาที:วินาที ปี_ timetuple()\t# แสดงวันเวลาในรูปออบเจ็กต์ time.struct_time timestamp()\t# แสดงเวลาในรูปของจำนวนวินาทีนับจากเที่ยงคืนเวลา UTC ของวันที่ 1 ม.ค. 1970 isoformat()\t# แสดงวันเวลาในรูป _ปี-เดือน-วันTชั่วโมง:นาที:วินาที.ไมโครวินาที_  สำหรับ isoformat ถ้าใส่อาร์กิวเมนต์ลงไปจะเป็นตัวคั่นระหว่างวันกับชั่วโมงแทนตัว T\nตัวอย่างเมธอดต่างๆ\ndtdt = datetime.datetime(2016,6,21,17,35,30,115421) print(dtdt.date()) # ได้ 2016-06-21 print(dtdt.time()) # ได้ 17:35:30.115421 print(dtdt.weekday()) # ได้ 1 print(dtdt.isoweekday()) # ได้ 2 print(dtdt.isocalendar()) # ได้ (2016, 25, 2) print(dtdt.ctime()) # ได้ Tue Jun 21 17:35:30 2016 print(dtdt.timetuple()) # ได้ time.struct_time(tm_year=2016, tm_mon=6, tm_mday=21, tm_hour=17, tm_min=35, tm_sec=30, tm_wday=1, tm_yday=173, tm_isdst=-1) print(dtdt.isoformat()) # ได้ 2016-06-21T17:35:30.115421 print(dtdt.isoformat(' ')) # ได้ 2016-06-21 17:35:30.115421  สำหรับ timestamp() ค่าจะเป็น 0 ที่เวลา 7 โมงเช้าของวันที่ 1 ม.ค. 1970 เนื่องจากไทยอยู่เขตเวลา +7\nprint(dtdt.timestamp()) # ได้ 1466505330.115421 print(datetime.datetime(1970,1,1,0,0,0).timestamp()) # ได้ -25200.0 print(datetime.datetime(1970,1,1,7,0,0).timestamp()) # ได้ 0.0  การแก้ค่าวันเวลาใน datetime.datetime ใน datetime.datetime มีเมธอด replace ซึ่งใช้แก้ไขค่าต่างๆภายใน datetime.datetime โดยอาร์กิวเมนต์ที่ต้องใส่นั้นเหมือนกับตอนสร้าง datetime.datetime เพียงแต่ว่าจะใส่แค่บางค่าในรูปคีย์เวิร์ด เฉพาะค่าที่ต้องการแก้เท่านั้น เพียงแต่ว่าเมธอดนี้ไม่ได้ทำการเปลี่ยนแปลงตัว datetime.datetime แค่คืนค่าของ datetime.datetime ที่ถูกแก้แล้วกลับมาเท่านั้น\nตัวอย่าง\ndtdt = datetime.datetime(2016,6,21,17,35,30,115421) dtdt.replace(2015) # ได้ datetime.datetime(2015, 6, 21, 17, 35, 30, 115421) dtdt.replace(month=7) # ได้ datetime.datetime(2016, 7, 21, 17, 35, 30, 115421) dtdt.replace(second=0,microsecond=0) # ได้ datetime.datetime(2016, 6, 21, 17, 35)  การแสดงผลวันเวลาตามที่ต้องการ นอกจาก การแสดงผล datetime.datetime ด้วยเมธอดตามที่กล่าวมาข้างต้น เราสามารถให้แสดงผล วันเวลาในรูปแบบตามที่ต้องการซึ่งกำหนดเองได้โดยใช้เมธอด strftime อาร์กิวเมนต์ที่ต้องใส่คือสายอักขระที่ประกอบไปด้วย % ตามด้วยอักษร ซึ่งแทนค่าในส่วนต่างๆในรูปแบบต่างๆของวันเวลา ซึ่งสรุปได้ตามนี้\n%a\t# วันในสัปดาห์ในรูปย่อ %A\t# วันในสัปดาห์เป็นชื่อเต็ม %w\t# วันในสัปดาห์เป็นตัวเลข อาทิตย์เป็น 0 เสาร์เป็น 6\t%d\t# วันที่ในรูปเลขสองหลัก (เติม 0 เมื่อมีหลักเดียว) %b\t# ชื่อเดือนในรูปย่อ %B\t# ชื่อเดือนเป็นชื่อเต็ม %m\t# เลขเดือนเป็นเลขสองหลัก (เติม 0 เมื่อมีหลักเดียว) %y\t# เลขปีในรูปเลขสองหลักสุดท้าย %Y\t# เลขปีในรูปเลขสี่หลัก (เติม 0 เมื่อมีไม่ถึงสี่หลัก) %H\t# เวลาชั่วโมงเป็นเลขสองหลักถึง 24 (เติม 0 เมื่อมีหลักเดียว) %I\t# เวลาชั่วโมงเป็นเลขสองหลักไม่เกิน 12 (เติม 0 เมื่อมีหลักเดียว) %p\t# เวลา AM หรือ PM %M\t# เวลานาทีเป็นเลขสองหลัก (เติม 0 เมื่อมีหลักเดียว) %S\t# เวลาวินาทีเป็นเลขสองหลัก (เติม 0 เมื่อมีหลักเดียว) %f\t# เวลาไมโครวินาทีเป็นเลขหกหลัก (เติม 0 เมื่อมีไม่ถึงหกหลัก) %j\t# เลขลำดับวันในปี (1 ถึง 366) %U\t# หรือ %W ลำดับของสัปดาห์ภายในปี %c\t# แสดงวันเวลาในรูปแบบเดียวกับ ctime() %x\t# เดือน/ปี/วัน %X\t# ชั่วโมง:นาที:วินาที  ตัวอย่าง\ndtdt = datetime.datetime(2016,6,21,17,35,30,115421) print(dtdt.strftime('%a')) # ได้ Tue print(dtdt.strftime('%A')) # ได้ Tuesday print(dtdt.strftime('%w')) # ได้ 2 print(dtdt.strftime('%d')) # ได้ 21 print(dtdt.strftime('%b')) # ได้ Jun print(dtdt.strftime('%B')) # ได้ June print(dtdt.strftime('%m')) # ได้ 06 print(dtdt.strftime('%y')) # ได้ 16 print(dtdt.strftime('%Y')) # ได้ 2016 print(dtdt.strftime('%H')) # ได้ 17 print(dtdt.strftime('%I')) # ได้ 05 print(dtdt.strftime('%p')) # ได้ PM print(dtdt.strftime('%M')) # ได้ 35 print(dtdt.strftime('%S')) # ได้ 30 print(dtdt.strftime('%f')) # ได้ 115421 print(dtdt.strftime('%j')) # ได้ 173 print(dtdt.strftime('%U')) # ได้ 25 print(dtdt.strftime('%W')) # ได้ 25 print(dtdt.strftime('%c')) # ได้ Tue Jun 21 17:35:30 2016 print(dtdt.strftime('%x')) # ได้ 06/21/16 print(dtdt.strftime('%X')) # ได้ 17:35:30  การสร้าง datetime.datetime จากเมธอดของคลาส\nเราสามารถสร้าง datetime.datetime ขึ้นมาจากเมธอดของคลาส datetime.datetime เองได้ด้วย เมธอดเหล่านั้นได้แก่\nnow()\t# สร้าง datetime.datetime ขึ้นจากเวลาขณะนี้ utcnow()\t# สร้าง datetime.datetime ขึ้นจากเวลาขณะนี้ในเขตเวลาสากล fromtimestamp()\t# สร้าง datetime.datetime ขึ้นจาก timestamp โดยอิงเวลาท้องถิ่น utcfromtimestamp()\t# สร้าง datetime.datetime ขึ้นจาก timestamp โดยอิงเวลาสากล combine()\t# สร้าง datetime.datetime โดยใช้ datetime.date และ datetime.time มารวมกัน strptime()\t# สร้าง datetime.datetime ขึ้นจากกระบวนการตรงข้ามกับ strftime  ตัวอย่าง\nprint(datetime.datetime.now()) # ได้เวลาปัจจุบัน print(datetime.datetime.utcnow()) # ได้เวลาปัจจุบันลบ 7 ชั่วโมง print(datetime.datetime.fromtimestamp(0)) # ได้ 1970-01-01 07:00:00 print(datetime.datetime.utcfromtimestamp(0)) # ได้ 1970-01-01 00:00:00 dtd = datetime.date(2016,6,21) dtt = datetime.time(17,35,30,115421) print(datetime.datetime.combine(dtd,dtt)) # ได้ 2016-06-21 17:35:30.115421  เมธอด strptime นั้นเป็นกระบวนการที่ตรงกันข้ามกันกับ strftime ใช้แปลงสายอักขระที่มีรูปแบบตามที่กำหนดให้กลายเป็น datetime.datetime ในการใช้ให้ใส่สายอักขระที่จะแปลง ตามด้วยสายอักขระที่เขียนรูปแบบที่กำหนดการแปลง\nตัวอย่าง\nprint(datetime.datetime.strptime('11:11:11.1111','%X.%f')) # ได้ 1900-01-01 11:11:11.111100 print(datetime.datetime.strptime('02','%H')) # ได้ 1900-01-01 02:00:00 print(datetime.datetime.strptime('7/6/1991','%d/%m/%Y')) # ได้ 1991-06-07 00:00:00 r = u'1842-11-5 เวลา 8 โมง 41 นาที 32 วินาที' fmt = u'%Y-%m-%d เวลา %I โมง %M นาที %S วินาที' print(datetime.datetime.strptime(r,fmt)) # ได้ 1842-11-05 08:41:32  อ้างอิง\nhttp://docs.python.jp/3/library/datetime.html\nhttp://nkmk.github.io/blog/python-datetime\n Source : \n "});index.add({'id':271,'href':'/library/tutorials/docs/articles/data-science/web-scraping/equinox-blog-web-scraping/','title':"ทำ Web Scraping ด้วย BeautifulSoup",'content':" ทำ Web Scraping ด้วย BeautifulSoup กัน สำหรับ Blog นี้เราจะมาดูวิธีการทำ Web scraping ด้วย Python3 และ BeautifulSoup ในระดับ Basic มากกกกกกกกกกกกก กันดูนะ :)\nก่อนที่เราจะเริ่มทำ web scraping เรามาเรียนรู้พื้นฐานเรื่อง website กันก่อนดีกว่า\nComponenet of web page เมื่อเราเข้าไปที่ web page ซัก url นึงแล้ว web browser ของเราก็จะทำการ request ไปที่ web server เราจะเรียกการ request ประเภทนี้ว่า GET request เนื่องจากเรา request ไปที่ server แล้วเราก็จะได้ file จาก server กลับมาเพื่อที่จะบอกกับ web browser นี้ว่าเราจะแสดงหน้า web page ของเราอย่างไร ซึ่งเนื้อหาใน file ที่กลับมาก็จะมีส่วนประกอบคร่าวๆ ดังนี้\n HTML : เป็นเนื้อหาหลักของหน้านั้นๆ CSS : เป็นตัวจัดการตกแต่ง HTML ของเราให้สวยงาม ดูดีขึ้น JS : เป็นตัวจัดการ interactive ของ HTML ของเราให้ดีขึ้น Image : รูปภาพใน format เช่น JPG , PNG สำหรับแสดงบน web  หลังจาก web browser ได้รับดังกล่าวมาแล้ว ก็จะทำการ render ออกมาสวยงามตามที่เราเห็นกันเป็นปกติ\nHTML HyperText Markup Language (HTML) คือ ภาษาสำหรับสร้าง web page ไม่ใช่ภาษา programming เหมือน python โดยตัว HTML จะเป็นตัวบอก web browser ว่าจะต้องทำการวาดโครงสร้างหน้าตาออกมาเป็นอย่างไร\nเอาล่ะ เรามาทำความเข้าใจตัว HTML กันอย่างรวดเร็วกันดีกว่า HTML ประกอบไปด้วย tag \u0026lt;\u0026gt; โดยจะเริ่มด้วย \u0026lt;html\u0026gt; ซึ่งจะเป็นตัวบอก browser ว่าภายใต้สิ่งนี้คือสิ่งที่เราต้องการจะวาด ถ้าเราลองสร้าง file html เราก็จะได้ประมาณนี้\n\u0026lt;html\u0026gt; \u0026lt;/html\u0026gt;  ต่อมาภายใน \u0026lt;html\u0026gt; เราสามารถใส่ tag head และ tag body เพื่อแยกส่วน content ต่างๆในหน้า web page ของเราได้\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  ตอนนี้เราจะเพิ่มเนื้อหาใน web page ของเราด้วย tag p โดย p คือ paragraph\nและทำการใส่ css class และใส่ id ดังนี้\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p class=\u0026quot;bold-paragraph\u0026quot;\u0026gt; Here's a paragraph of text! \u0026lt;a href=\u0026quot;https://www.google.com\u0026quot; id=\u0026quot;link1\u0026quot;\u0026gt;Google\u0026lt;/a\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;p class=\u0026quot;bold-paragraph extra-large\u0026quot;\u0026gt; Here's a second paragraph of text! \u0026lt;a href=\u0026quot;https://www.python.org\u0026quot; class=\u0026quot;link2\u0026quot;\u0026gt;Python\u0026lt;/a\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  เราก็จะได้หน้า web page ของเราประมาณนี้\nRequest Library ขั้นแรกของการทำ web scraping คือเราต้องทำการ request ไปที่ url ที่เราต้องการจะทำการ scrap ซึ่งเราสามารถใช้ Python library ที่ชื่อว่า request โดยเจ้า lib ตัวนี้จะทำการ GET request ไปที่ web server ของ url ที่เราระบุ และจำทำการ download content ของ web page นั้นมาให้เรา ป่ะๆ ลองทำกันดีกว่า\nทำการ install lib ใน cmd ด้วย pip install request จากนั้นก็เขียน code ตามนี้\nเราจะได้ output เป็น \u0026lt;Response [200]\u0026gt; ซึ่งก็คือ request success\nซึ่งตัวเลข status_code ที่ขึ้นต้นด้วย 2 คือ success แต่หากขึ้นต้นด้วย 4 5 คือ error สามารถดูรายละเอียดเพิ่มเติมเรื่อง request status code ได้ที่นี่ click\nถ้าเราลอง print(page.content) เราจะเห็นได้ว่าตัว content ที่เราได้มานั้นดูเข้าใจได้ยาก ดังรูป\nb\u0026rsquo;\u0026lt;!DOCTYPE html\u0026gt;\\n\\n \\n A simple example page\\n\\n\\nHere is some simple content for this page.\n\\n \\n\u0026lsquo;\nBeautifulSoup และแล้วก็ถึงเวลาของพระเอกของเรา เจ้า BeautifulSoup เนี่ยจะมาทำการ parse content ที่เรา download ได้มา ให้มันสวยงามเข้าใจได้ง่ายมากขึ้น ลองกันเลยดีกว่า\nทำการ install pip install beautifulsoup4 จากนั้นก็เขียน code ตามนี้\nเราจะได้ output สวยงาม ตามนี้\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;A simple example page\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Here is some simple content for this page.\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  ค้นหา Tags ทั้งหมดบน Content หากเราได้ content จาก web page ที่เราต้องการมาแล้ว แล้วเราต้องการหา tag p ทั้งหมดที่อยู่บนนั้น เราสามารถทำได้โดยใช้คำสั่ง find_all() เช่น\nprint(soup.find_all('p')) ต่อจาก ตัวอย่างก่อนหน้า จะได้ list ออกมาตามนี้\n[\u0026lt;p\u0026gt;Here is some simple content for this page.\u0026lt;/p\u0026gt;]  จะเห็นได้ว่าเจ้า find_all() เนี่ยมัน return ออกมาเป็น list ให้เรา เราจึงสามารถ get position ของ list ได้ด้วย soup.find_all('p')[0].getText() ก็จะได้ผลลัพธ์ตามนี้\nHere is some simple content for this page.\nค้นหา Tags ทั้งหมดบน Content ด้วย Class หรือ Id ลองสร้าง web page ด้วย html ใหม่โดยมีการใส่ class และ id ใหม่ ตามนี้\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;A simple example page\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div\u0026gt; \u0026lt;p class=\u0026quot;inner-text first-item\u0026quot; id=\u0026quot;first\u0026quot;\u0026gt; First paragraph. \u0026lt;/p\u0026gt; \u0026lt;p class=\u0026quot;inner-text\u0026quot;\u0026gt; Second paragraph. \u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;p class=\u0026quot;outer-text first-item\u0026quot; id=\u0026quot;second\u0026quot;\u0026gt; \u0026lt;b\u0026gt; First outer paragraph. \u0026lt;/b\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;p class=\u0026quot;outer-text\u0026quot;\u0026gt; \u0026lt;b\u0026gt; Second outer paragraph. \u0026lt;/b\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  แต่ ณ ที่นี้จากเราสามารถยิง url ไปลองได้ที่ https://dataquestio.github.io/web-scraping-pages/ids_and_classes.html โอเคไปเขียน code ลองดึง tag ที่มี id = first ออกมาแสดง ลองเขียน code ตามนี้ดู\nsoup.find_all(id=\u0026quot;first\u0026quot;)  เราก็จะได้ผลลัพธ์ของ tag ที่มี id = first ออกมาตามนี้\n[\u0026lt;p class=\u0026quot;inner-text first-item\u0026quot; id=\u0026quot;first\u0026quot;\u0026gt; First paragraph. \u0026lt;/p\u0026gt;]  ต่อมาเราจะลองทำการหา tag p ที่มี class outer-tex โดยทำการเขียน code ดังนี้\nsoup.find_all(‘p’, class_=’outer-text’)  เราก็จะได้ผลลัพธ์ของ tag ที่มี class outer-text ออกมาตามนี้\n[\u0026lt;p class=\u0026quot;outer-text first-item\u0026quot; id=\u0026quot;second\u0026quot;\u0026gt; \u0026lt;b\u0026gt;First outer paragraph.\u0026lt;/b\u0026gt; \u0026lt;/p\u0026gt;, \u0026lt;p class=\u0026quot;outer-text\u0026quot;\u0026gt; \u0026lt;b\u0026gt;Second outer paragraph.\u0026lt;/b\u0026gt; \u0026lt;/p\u0026gt;]  มาถึงตรงจุดนี้เราก็จะทำการดึง content จาก web page หรือที่เรียกว่า web scraping กันได้แล้ว อีกทั้งยังสามารถแยกตาม tag , id , class ของ content นั้นได้ด้วย\nจบไปแล้วสำหรับ basic การทำ web scraping แบบ baby walk ถ้าติดขัดตรงไหน หรือมีอะไรจะแนะนำ comment หรือ inbox มาได้โดยตรงเลยนะครับ :P\nReference  Python Web Scraping Tutorial using BeautifulSoup When performing data science tasks, it\u0026rsquo;s common to want to use data found on the internet. You\u0026rsquo;ll usually be able to…   Source : .\n "});index.add({'id':272,'href':'/library/tutorials/docs/articles/webapp/javascript/api-for-javascript/','title':"รวม API สำหรับ Javascript ที่น่าสนใจในปี 2020",'content':" รวม API สำหรับ Javascript ที่น่าสนใจในปี 2020 หากคุณอยากเขียนไซต์หรือโปรแกรมของคุณ ในหัวของคุณคงมีภาพไซต์ที่มีฟีเจอร์มากมาย แต่จะทำอย่างไรล่ะให้ไซต์ของคุณเป็นไปตามที่วาดเอาไว้ เราจึงได้รวบรวม API สำหรับ JavaScript ที่จะทำให้ไซต์ของคุณทำงานได้อย่างหลากหลายทันต่อยุคสมัยปี 2020\nYoutube API Youtube เป็นหนึ่งในสิ่งที่ทุกคนใช้กันอย่างล้นหลาม และเป็นส่วนหนึ่งในชีวิตประจำวันของทุกคน จะเป็นอย่างไรถ้าเรานำยูทูปมาเป็นส่วนหนึ่งในไซต์ของเรา โดย Youtube API จะช่วยให้เราสามารถนำวิดิโอที่เราต้องการมาแปะในไซต์ของเราได้โดยไม่จำเป็นต้องเปลี่ยนหน้าไปที่ลิงค์วิดิโอของวิดิโอนั้นๆ\nhttps://developers.google.com/youtube\nGoogle Map API เราสามารถย่อส่วนกูเกิ้ลแมพมาใส่ไซต์ของเราได้!! ด้วย API ของ Google Map จะทำให้เราสามารถนำ service ต่างๆของ Google Map มาใส่ในไซต์ของเราได้ ไม่ว่าจะเป็นนำแผนที่มาใส่ในไซต์ หรือปักหมุดบนแผนที่ ซึ่งเป็นประโยชน์มากหากเราต้องการระบุตำแหน่งสถานที่ต่างๆบนแผนที่ ถึงแม้จะไม่สามารถทำทุกอย่างได้เหมือนกูเกิ้ลแมพหลักแต่ก็มีประโยชน์มากไม่น้อย\nhttps://developers.google.com/maps/documentation/javascript/tutorial\nNasa API นาซ่าเองก็มี API ของตัวเอง โดย API ของนาซ่าจะทำให้เราสามารถนำข้อมูลต่างๆที่น่าสนใจของนาซ่ามาแปะไว้ในไซต์ของเราได้ ไม่ว่าจะเป็นข้อมูลทางดาราศาสตร์ต่างๆ บทคความสนุกๆของนาซ่า หรือรูปภาพสวยๆของนาซ่า ซึ่งแต่ละวันนาซ่าจะมี Picture of The Day ที่เป็นภาพที่นาซ่าคัดมาไม่ซ้ำกัน ช่วยเพิ่มความสนุกให้ในการเยี่ยมชมไซต์ของเราได้ไม่น้อย\nhttps://api.nasa.gov/\nWeb Animation API อยากให้ไซต์ของเรามีอนิชั่นสวยๆ แต่CSSมันก็ใช้ยากเหลือเกิน แถมการเคลื่อนไหวก็ดูไม่ค่อยสมูท ปัญหานี้จะหมดไปเมื่อเราใช้ Web Animation API ซึ่งช่วยให้เราจัดการอนิเมชั่นของCSS animationได้ง่ายขึ้น ช่วยให้ไซต์ของเราให้มีชีวิตชีวามากขึ้น\nhttps://developers.google.com/web/updates/2018/10/animation-worklet\nWeb Speech API API นี้จะช่วยให้ไซต์ของเราสามารถรับ input ด้วยเสียงได้ เป็นการปลดขีดความสามารถให้ไซต์ของเราน่าใช้งานมากขึ้น เนื่องจากการรับinput ด้วยเสียงสามารถนำไปต่อยอดได้อย่างหลากหลาย และที่สำคัญ APIนี้สามารถรองรับการนำเข้าเสียงภาษาไทยได้อีกด้วย\nhttps://wicg.github.io/speech-api/\nFacebook API หากพูดถึง social media ในยุคปัจจุบัน คงจะเป็นไปม่ได้เลยที่จะไม่นึกถึง Facebook ที่มีผู้คนจากทั่วโลกใช้กันอย่างล้นหลามแทบทุกคนก็ย่อมมีบัญชีใช้งานของเฟซบุ๊คกันทั้งนั้น ซึ่งทางเฟซบุ๊คเองก็มี API ที่ทำให้ไซต์ของเราสามารถล็อคอินเพื่อยืนยันตัวตนผ่านบัญชีของเฟซบุ๊ค และสามารถแชร์ไซต์ของเราผ่านบัญชีผู้ใช้ได้อีกด้วย\nhttps://developers.facebook.com/\n Twitter API social media อีกค่ายหนึ่งที่มีผู้คนใช้มากมายไม่แพ้กันอีกค่ายหนึ่งคงหนีไม่พ้นเจ้านกน้อยสีฟ้าอย่าง Twitter ซึ่งทาง Twitter เองก็มี API สำหรับให้ผู้ใช้จัดการบัญชีบนไซต์ของเราได้เช่นเดียวกัน\nhttps://developer.twitter.com/\nGoogle Cloud Vision API หากเราต้องการให้ไซต์เข้าใจรูปๆหนึ่งว่าเป็นรูปอะไร ตามปกติเราจะต้องสร้าง neural network ขึ้นมาเองซึ่งทำเองได้ยาก Google ได้สร้าง API ตัวนี้ข้นมาเพื่อให้เราสามารถใช้ neural network ของ Google ได้เลย เพื่อให้ไซต์ของเราสามารถวิเคราะห์ภาพเองได้\nhttps://cloud.google.com/vision/\nGeneric Sensor API สมัยนี้เซนเซอร์ต่างๆ มีผลต่อชีวิตของเรามากขึ้น เช่น แสง อุณหภูมิ ความชื้นในอากาศ API ตัวนี้จะทำให้เราสามารถรับค่าจากเซนเซอร์ต่างๆ เพื่อให้เราตอบสนองต่อปัจจัยเหล่านั้นได้\nhttps://www.w3.org/TR/generic-sensor/\nRapidAPI ไซต์ที่เป็นแหล่งรวม API ที่มีข้อมูลจิปาถะย่อยๆที่สามารถนำมาแปะไว้ในไซต์ของเราได้ ไม่ว่าจะเป็นผลฟุลบอล ข้อมูลหนังต่างๆ หรือแม้แต่ข้อมูลสูตรทำอาหาร ที่มีให้เลือกสรรอย่างมากมาย โดยจะมีทั้งแบบฟรีและไม่ฟรีตามการใช้งาน\nhttps://rapidapi.com/\nจะเห็นว่าในยุคปัจจุบันนี้เรามี API มากมายที่ช่วยให้การเพิ่มความสะดวกสบายในการเขียนเว็ปหรือโปรแกรมของเรา ดังนั้นเวลาที่ต้องการให้โปรแกรมมีการทำงานอะไรเพิ่มขึ้นมา อย่าลืมที่จะเสิร์ชหา API เพื่อนรักที่จะทำให้เราเขียนเว็ปได้อย่างแฮปปี้มากขึ้นนะครับ\n Written with StackEdit.\n "});})();